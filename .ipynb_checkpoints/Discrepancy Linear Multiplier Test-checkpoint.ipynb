{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdce957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import GPE_ensemble as GPE\n",
    "\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from GPErks.gp.data.dataset import Dataset\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.means import LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from torchmetrics import MeanSquaredError, R2Score\n",
    "#from GPErks.gp.experiment import GPExperiment\n",
    "#from GPErks.train.emulator import GPEmulator\n",
    "#from GPErks.perks.inference import Inference\n",
    "#from GPErks.train.early_stop import NoEarlyStoppingCriterion\n",
    "#from GPErks.train.early_stop import (\n",
    "#    GLEarlyStoppingCriterion,\n",
    "#    PQEarlyStoppingCriterion,\n",
    "#    UPEarlyStoppingCriterion,\n",
    "#)\n",
    "#from GPErks.train.early_stop import PkEarlyStoppingCriterion\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set logger and enforce reproducibility\n",
    "#from GPErks.log.logger import get_logger\n",
    "#from GPErks.utils.random import set_seed\n",
    "#log = get_logger()\n",
    "seed = 7\n",
    "#set_seed(seed)\n",
    "from time import process_time \n",
    "import scipy\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c4623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/input/xlabels_EP.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "y_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/output/ylabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "y_labels\n",
    "\n",
    "inputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/01/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/01/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "inputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/02/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/02/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "inputData_2 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/03/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_2 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/03/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "inputData_3 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/03/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_3 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/03/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "\n",
    "X0 = torch.tensor(inputData_0)\n",
    "Y0 = torch.tensor(outputData_0)\n",
    "\n",
    "X1 = torch.tensor(inputData_1)\n",
    "Y1 = torch.tensor(outputData_1)\n",
    "\n",
    "X2 = torch.tensor(inputData_1)\n",
    "Y2 = torch.tensor(outputData_1)\n",
    "\n",
    "X3 = torch.tensor(inputData_1)\n",
    "Y3 = torch.tensor(outputData_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0d845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X1.float(),\n",
    "                Y1.float(),\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284c6ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy(a,y_train,m0,output,emulator):\n",
    "    m_t = emulator_0.normalise_output(m0)\n",
    "    y_t = emulator_0.normalise_output(y_train)\n",
    "    a=torch.tensor(a)\n",
    "    res = ((a*m_t-y_t)**2).mean(axis=0).detach().numpy()\n",
    "    return res[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a880c6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623180f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4159235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[1.18456827]\n",
      "[1.01666799]\n",
      "tensor([1.1846, 1.0167], dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_86005/2216012697.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[b] - a_d*m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_86005/2216012697.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_a = ((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy()\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_86005/2216012697.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_a = (1-((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()\n"
     ]
    }
   ],
   "source": [
    "m=20\n",
    "n=180\n",
    "a=np.random.choice(range(X0.shape[0]),n,replace=False)\n",
    "a2 = np.random.choice(range(X0.shape[0]),n,replace=False)\n",
    "b=np.random.choice(range(X_train.shape[0]),m,replace=False)\n",
    "\n",
    "\n",
    "emulator_0 = GPE.ensemble(X0,Y0,mean_func=\"linear\",training_iter=500)\n",
    "emulator_2 = GPE.ensemble(X2,Y2,mean_func=\"linear\",training_iter=500)\n",
    "emulator_3 = GPE.ensemble(X3,Y3,mean_func=\"linear\",training_iter=500)\n",
    "emulator_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "m0 = emulator_0.predict(X_train[b,:])\n",
    "\n",
    "a_d=np.zeros(y_train.shape[1])\n",
    "for l in range(y_train.shape[1]):\n",
    "    result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulator_0), method='Nelder-Mead', tol=1e-8)\n",
    "    print(result.x)\n",
    "    a_d[l]=result.x\n",
    "\n",
    "a_d=torch.tensor(a_d)\n",
    "#a_d=torch.ones(a_d.shape)\n",
    "print(a_d)\n",
    "\n",
    "\n",
    "m0 = emulator_0.predict(X_train[b,:])\n",
    "y_adjust = torch.tensor(y_train[b] - a_d*m0)\n",
    "delta_1 = GPE.ensemble(X_train[b,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "MSE_a = ((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy()\n",
    "R2_a = (1-((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c072a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df1070bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulators=[emulator_0,emulator_2,emulator_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec68f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.18456827]\n",
      "[1.01666799]\n"
     ]
    }
   ],
   "source": [
    "m0 = emulator_0.predict(X_train[b,:])\n",
    "a_d=np.zeros(y_train.shape[1])\n",
    "for l in range(y_train.shape[1]):\n",
    "    result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulator_0), method='Nelder-Mead', tol=1e-8)\n",
    "    print(result.x)\n",
    "    a_d[l]=result.x\n",
    "\n",
    "a_d=torch.tensor(a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c91ba8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00239573]\n",
      "[0.99734344]\n"
     ]
    }
   ],
   "source": [
    "m0 = emulator_0.predict(X_train[b,:])\n",
    "\n",
    "m_t = emulator_0.normalise_output(m0)\n",
    "y_t = emulator_0.normalise_output(y_train[b,:])\n",
    "\n",
    "a_d=np.zeros(y_train.shape[1])\n",
    "for l in range(y_train.shape[1]):\n",
    "    result = scipy.optimize.minimize(proxy, 1, args=(y_t,m_t,l,emulator_0), method='Nelder-Mead', tol=1e-8)\n",
    "    print(result.x)\n",
    "    a_d[l]=result.x\n",
    "\n",
    "a_d=torch.tensor(a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf3f26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proxy_cohort(a,y_test,emulators,x_test,output):\n",
    "#     a=torch.tensor(a)\n",
    "#     res=torch.zeros((y_test.shape[1]))\n",
    "#     m0=torch.zeros(y_test.shape)\n",
    "#     for i in range(len(emulators)):\n",
    "#         m0+=a[i]*emulators[i].predict(x_test)\n",
    "#     res += ((m0-y_test)**2).mean(axis=0).detach().numpy()\n",
    "#     return res[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b09a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_cohort(a,y_test,emulators,x_test,output):\n",
    "    a=torch.tensor(a)\n",
    "    res=torch.zeros((y_test.shape[1]))\n",
    "    m0=torch.zeros(y_test.shape)\n",
    "    for i in range(len(emulators)):\n",
    "        m=emulators[i].predict(x_test)\n",
    "        m_t=emulators[i].normalise_output(m)\n",
    "        y_t=emulators[i].normalise_output(y_test)\n",
    "        m0+=a[i]*m_t\n",
    "    res += ((m0-y_t)**2).mean(axis=0).detach().numpy()\n",
    "    return res[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "374083e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_d=np.zeros((y_train.shape[1],len(emulators)))\n",
    "for l in range(y_train.shape[1]):\n",
    "    result = scipy.optimize.minimize(proxy_cohort, [0,0,0], args=(y_train[b,:],emulators,X_train[b,:],l), method='Nelder-Mead', tol=1e-8)\n",
    "    a_d[l]=result.x\n",
    "a_d=torch.tensor(a_d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c16c8866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0042, -0.1124,  1.1183],\n",
       "        [-0.0591,  0.2815,  0.7718]], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ca20e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.52452516,   3.54852194])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fe30cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96754684, 0.99394991])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80d89b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_d = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators[0]],a=torch.tensor([[1],[1]]))#,a=a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63c09810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_dc = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators,a=a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "010fd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_dc_a = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "061f7932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([333.2314,  34.3150], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator_1.MSE(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "128dd534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8985, 0.9415], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator_1.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5574323f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([871.0911,   3.5791], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.MSE(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40d67002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7346, 0.9939], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_d.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c03a4ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([357.7969,   0.4614], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.MSE(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cf9b533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8910, 0.9992], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "507233e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([55.3059,  0.8552], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc_a.MSE(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8d103de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9832, 0.9985], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc_a.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51003f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.0.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.0.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.0.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.0.ref_model.mean_module.weights\n",
      "covar_module.kernels.0.ref_model.mean_module.bias\n",
      "covar_module.kernels.1.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.1.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.1.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.1.ref_model.mean_module.weights\n",
      "covar_module.kernels.1.ref_model.mean_module.bias\n",
      "covar_module.kernels.2.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.2.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.2.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.2.ref_model.mean_module.weights\n",
      "covar_module.kernels.2.ref_model.mean_module.bias\n",
      "covar_module.kernels.3.raw_outputscale\n",
      "covar_module.kernels.3.base_kernel.raw_lengthscale\n",
      "mean_module.weights\n",
      "mean_module.bias\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model_dc.models[0].named_parameters():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d834070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-4.7634], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-11.7198])\n",
      "Parameter containing:\n",
      "tensor(-1.1921)\n",
      "Parameter containing:\n",
      "tensor([[17.1456, 17.2042, 18.9032,  0.6846,  3.8971,  1.1902]])\n",
      "Parameter containing:\n",
      "tensor([[ 2.5209e-03],\n",
      "        [ 1.0727e-02],\n",
      "        [-7.8590e-04],\n",
      "        [-1.3228e+00],\n",
      "        [-2.8835e-01],\n",
      "        [-5.0135e-01]])\n",
      "Parameter containing:\n",
      "tensor([1.2116])\n",
      "Parameter containing:\n",
      "tensor([-11.6881])\n",
      "Parameter containing:\n",
      "tensor(-1.2380)\n",
      "Parameter containing:\n",
      "tensor([[18.0596, 15.1450, 18.3840,  0.6713,  3.8863,  1.1757]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0060],\n",
      "        [ 0.0026],\n",
      "        [ 0.0025],\n",
      "        [-1.3223],\n",
      "        [-0.2871],\n",
      "        [-0.4969]])\n",
      "Parameter containing:\n",
      "tensor([1.1906])\n",
      "Parameter containing:\n",
      "tensor([-12.2325])\n",
      "Parameter containing:\n",
      "tensor(-0.1350)\n",
      "Parameter containing:\n",
      "tensor([[19.6428, 18.2322, 26.2978,  1.1134,  6.6651,  1.3153]])\n",
      "Parameter containing:\n",
      "tensor([[ 3.2882e-03],\n",
      "        [-6.4619e-03],\n",
      "        [ 1.2593e-03],\n",
      "        [-1.6990e+00],\n",
      "        [-2.3300e-01],\n",
      "        [-5.5172e-01]])\n",
      "Parameter containing:\n",
      "tensor([1.9934])\n",
      "Parameter containing:\n",
      "tensor(-10.5022, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[6.7506, 5.6771, 6.5292, 5.9640, 6.5711, 6.7139]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0387],\n",
      "        [ 0.0622],\n",
      "        [-0.0053],\n",
      "        [ 0.2352],\n",
      "        [ 0.0034],\n",
      "        [-0.0246]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0212], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model_dc.models[0].named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "224ce527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-4.3361], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-12.2325])\n",
      "Parameter containing:\n",
      "tensor(-0.1350)\n",
      "Parameter containing:\n",
      "tensor([[19.6428, 18.2322, 26.2978,  1.1134,  6.6651,  1.3153]])\n",
      "Parameter containing:\n",
      "tensor([[ 3.2882e-03],\n",
      "        [-6.4619e-03],\n",
      "        [ 1.2593e-03],\n",
      "        [-1.6990e+00],\n",
      "        [-2.3300e-01],\n",
      "        [-5.5172e-01]])\n",
      "Parameter containing:\n",
      "tensor([1.9934])\n",
      "Parameter containing:\n",
      "tensor(-9.9931, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[6.4661, 6.8179, 6.2867, 5.8837, 6.0974, 5.9681]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0370],\n",
      "        [ 0.0426],\n",
      "        [-0.0168],\n",
      "        [ 0.3296],\n",
      "        [-0.0316],\n",
      "        [-0.0258]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0324], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model_d.models[0].named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97628910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-8.5777])\n",
      "Parameter containing:\n",
      "tensor(-1.1652)\n",
      "Parameter containing:\n",
      "tensor([[ 1.6988,  3.8381, -0.2462, 18.0124, 19.1737, 19.6991]])\n",
      "Parameter containing:\n",
      "tensor([[-1.1171],\n",
      "        [-0.3240],\n",
      "        [-0.5605],\n",
      "        [-0.0155],\n",
      "        [-0.0054],\n",
      "        [ 0.0013]])\n",
      "Parameter containing:\n",
      "tensor([1.1344])\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in emulator_2.models[1].named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e969b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m0_mat(y_test,emulators,x_test,output):\n",
    "    res=torch.zeros((y_test.shape[1]))\n",
    "    m0=torch.zeros((y_test.shape[0],len(emulators)))\n",
    "    for i in range(len(emulators)):\n",
    "        m0[:,i]=emulators[i].normalise_output(emulators[i].predict(x_test))[:,output]\n",
    "\n",
    "    return m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9e5fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0=m0_mat(y_train[b],emulators,X_train[b],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0350c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e66db6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    #('scaler', StandardScaler()),\n",
    "    ('preprocessor', PolynomialFeatures(degree=1, include_bias=False,interaction_only=False)),\n",
    "    ('lasso', LassoCV(n_alphas=10,max_iter=1000))\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57411ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_d=torch.zeros((y_train.shape[1],len(emulators)))\n",
    "for i in range(y_train.shape[1]):\n",
    "    m0=m0_mat(y_train[b],emulators,X_train[b],i)\n",
    "    # fit to an order-3 polynomial data\n",
    "    model = model.fit(m0.detach().numpy(), y_train[b,i].detach().numpy())\n",
    "    a_d[i]=torch.tensor(model.named_steps['lasso'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f1908cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.4106e-02, 9.5080e-01, 5.0484e-05],\n",
       "        [0.0000e+00, 9.8681e-01, 8.7843e-03]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de8b1fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.9868128 , 0.00878434], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['lasso'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1340d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_dc = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4dbbaf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9740, 0.9993], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b2674432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "meshes=['01','02','03','04','05','06','07','08','09','10','11','12','13','14','16','17','18','19']\n",
    "\n",
    "Ys=[]\n",
    "Xs=[]\n",
    "emulators=[]\n",
    "for i in range(len(meshes)):\n",
    "    val=meshes[i]\n",
    "    \n",
    "    inputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/\"+val+\"/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    outputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/\"+val+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    Xs.append(torch.tensor(inputData))\n",
    "    Ys.append(torch.tensor(outputData))\n",
    "    emulator = GPE.ensemble(Xs[i],Ys[i],mean_func=\"linear\",training_iter=500)\n",
    "    emulators.append(emulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b94a3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    #('scaler', StandardScaler()),\n",
    "    ('preprocessor', PolynomialFeatures(degree=1, include_bias=False,interaction_only=False)),\n",
    "    ('lasso', LassoCV(n_alphas=1000,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf571181",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                Xs[-1].float(),\n",
    "                Ys[-1].float(),\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "302df4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=40\n",
    "b=np.random.choice(range(X_train.shape[0]),n,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "905735aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.158863067626953, tolerance: 1.6553491353988647\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.195115089416504, tolerance: 1.6553491353988647\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "emulators2=emulators[0:16]\n",
    "\n",
    "\n",
    "a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "for i in range(y_train.shape[1]):\n",
    "    m0=m0_mat(y_train[b],emulators2,X_train[b],i)\n",
    "    # fit to an order-3 polynomial data\n",
    "    model = model.fit(m0.detach().numpy(), y_train[b,i].detach().numpy())\n",
    "    a_d[i]=torch.tensor(model.named_steps['lasso'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fe260ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.0000, 0.1440, 0.2761, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.2635, 0.0000, 0.1842, 0.0000, -0.0000],\n",
       "        [0.0817, 0.0000, 0.0000, 0.0000, 0.0077, 0.1073, 0.0112, 0.1967, 0.0868,\n",
       "         0.0000, 0.1184, 0.0000, 0.1723, 0.0000, 0.0896, 0.0140]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0df099d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_dc = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "de82f6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9888, 0.9953], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aebf754e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.0000, 0.1440, 0.2761, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.2635, 0.0000, 0.1842, 0.0000, -0.0000],\n",
       "        [0.0817, 0.0000, 0.0000, 0.0000, 0.0077, 0.1073, 0.0112, 0.1967, 0.0868,\n",
       "         0.0000, 0.1184, 0.0000, 0.1723, 0.0000, 0.0896, 0.0140]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d83af592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, 0.0000, 0.1440, 0.2761, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.2635, 0.0000, 0.1842, 0.0000, -0.0000],\n",
       "        [0.0817, 0.0000, 0.0000, 0.0000, 0.0077, 0.1073, 0.0112, 0.1967, 0.0868,\n",
       "         0.0000, 0.1184, 0.0000, 0.1723, 0.0000, 0.0896, 0.0140]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "485b3489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "model_dc = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9dbf5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9952, 0.9965], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5cfade3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2581,  0.0560,  0.5175,  0.2546,  0.0426,  0.3098,  0.1669,  0.0770,\n",
       "        -0.0784, -0.0613], requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dc.models[1].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f10f0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulators[17].R2(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef18b89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.0.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.0.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.0.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.0.ref_model.mean_module.weights\n",
      "covar_module.kernels.0.ref_model.mean_module.bias\n",
      "covar_module.kernels.1.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.1.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.1.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.1.ref_model.mean_module.weights\n",
      "covar_module.kernels.1.ref_model.mean_module.bias\n",
      "covar_module.kernels.2.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.2.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.2.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.2.ref_model.mean_module.weights\n",
      "covar_module.kernels.2.ref_model.mean_module.bias\n",
      "covar_module.kernels.3.ref_model.likelihood.noise_covar.raw_noise\n",
      "covar_module.kernels.3.ref_model.covar_module.raw_outputscale\n",
      "covar_module.kernels.3.ref_model.covar_module.base_kernel.raw_lengthscale\n",
      "covar_module.kernels.3.ref_model.mean_module.weights\n",
      "covar_module.kernels.3.ref_model.mean_module.bias\n",
      "covar_module.kernels.4.raw_outputscale\n",
      "covar_module.kernels.4.base_kernel.raw_lengthscale\n",
      "mean_module.weights\n",
      "mean_module.bias\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model_dc.models[0].named_parameters():\n",
    "    print(param_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd09f497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0487, 0.9723, 0.2348, 0.0380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-9.7645], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-11.2646])\n",
      "Parameter containing:\n",
      "tensor(-1.3091)\n",
      "Parameter containing:\n",
      "tensor([[16.0438, 16.4095, 17.4025,  0.4889,  5.3199,  1.5291]])\n",
      "Parameter containing:\n",
      "tensor([[-8.0050e-03],\n",
      "        [-5.2030e-03],\n",
      "        [ 4.3013e-04],\n",
      "        [-1.3439e+00],\n",
      "        [-1.8575e-01],\n",
      "        [-5.8882e-01]])\n",
      "Parameter containing:\n",
      "tensor([1.2518])\n",
      "Parameter containing:\n",
      "tensor([-11.8510])\n",
      "Parameter containing:\n",
      "tensor(-0.5533)\n",
      "Parameter containing:\n",
      "tensor([[16.5816, 14.8892, 14.6753,  1.0448,  8.0899,  0.7342]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0086],\n",
      "        [-0.0144],\n",
      "        [ 0.0113],\n",
      "        [-1.3355],\n",
      "        [-0.1456],\n",
      "        [-0.6514]])\n",
      "Parameter containing:\n",
      "tensor([1.4432])\n",
      "Parameter containing:\n",
      "tensor([-12.2667])\n",
      "Parameter containing:\n",
      "tensor(-0.4471)\n",
      "Parameter containing:\n",
      "tensor([[24.0803, 23.3262, 23.6537,  1.0728,  6.7553,  0.9907]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0031],\n",
      "        [ 0.0016],\n",
      "        [-0.0080],\n",
      "        [-1.4369],\n",
      "        [-0.2441],\n",
      "        [-0.7861]])\n",
      "Parameter containing:\n",
      "tensor([1.6898])\n",
      "Parameter containing:\n",
      "tensor([-11.0163])\n",
      "Parameter containing:\n",
      "tensor(-1.0308)\n",
      "Parameter containing:\n",
      "tensor([[21.2529, 18.7155, 19.6561,  0.5883,  6.8966,  1.1005]])\n",
      "Parameter containing:\n",
      "tensor([[-1.8077e-04],\n",
      "        [ 7.9779e-03],\n",
      "        [-1.6772e-02],\n",
      "        [-1.3986e+00],\n",
      "        [-1.7418e-01],\n",
      "        [-5.5999e-01]])\n",
      "Parameter containing:\n",
      "tensor([1.3489])\n",
      "Parameter containing:\n",
      "tensor(-4.5734, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 4.6332, 10.1630, 10.4964,  1.8775,  7.7184,  8.8510]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0058],\n",
      "        [-0.0084],\n",
      "        [-0.0164],\n",
      "        [ 0.1686],\n",
      "        [-0.0046],\n",
      "        [ 0.0070]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0135], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model_dc.models[0].named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5056c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1],[1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "143b5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d671b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.60406818]\n",
      "[0.88961976]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.54254699]\n",
      "[0.8376123]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.52906359]\n",
      "[0.83233601]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.75018005]\n",
      "[0.988401]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.70091712]\n",
      "[0.88334249]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "R2=torch.zeros(7,2)\n",
    "Ti=torch.zeros(7)\n",
    "reps=5\n",
    "n=40\n",
    "for i in range(reps):\n",
    "    \n",
    "    b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "    R2[0]+=model_f.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[0]+=(end-start)/reps\n",
    "    \n",
    "#     start = time.time()\n",
    "#     for j in range(len(emulators2)):\n",
    "#         model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[i]],a=torch.tensor([[1],[1]]))\n",
    "#         R2[1]+=model_dc_1.R2(X_test,y_test)/(reps*len(emulators2))\n",
    "#         print(model_dc_1.R2(X_test,y_test))\n",
    "#         print(R2[1])\n",
    "#     end = time.time()\n",
    "#     Ti[1]+=(end-start)/reps\n",
    "    \n",
    "    em=np.random.randint(len(emulators2))\n",
    "    start = time.time()\n",
    "    model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=torch.tensor([[1],[1]]))\n",
    "    end = time.time()\n",
    "    R2[1]+=model_dc_1.R2(X_test,y_test)/reps\n",
    "    Ti[1]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    m0 = emulators2[0].predict(X_train[b,:])\n",
    "    a_d=np.zeros((y_train.shape[1],1))\n",
    "    for l in range(y_train.shape[1]):\n",
    "        result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulators2[0]), method='Nelder-Mead', tol=1e-8)\n",
    "        print(result.x)\n",
    "        a_d[l]=result.x\n",
    "    a_d=torch.tensor(a_d)\n",
    "    model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]],a=a_d)\n",
    "    R2[2]+=model_dc_reg.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[2]+=(end-start)/reps\n",
    "    \n",
    "\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]])\n",
    "    R2[3]+=model_dc_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[3]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "    R2[4]+=model_dc_all.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[4]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "    for i in range(y_train.shape[1]):\n",
    "        m0=m0_mat(y_train[b],emulators2,X_train[b],i)\n",
    "        # fit to an order-3 polynomial data\n",
    "        model = model.fit(m0.detach().numpy(), y_train[b,i].detach().numpy())\n",
    "        a_d[i]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "    \n",
    "    \n",
    "    model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "    R2[5]+=model_dc_lasso.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[5]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "    R2[6]+=model_dc_lasso_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[6]+=(end-start)/reps\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c624c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(torch.cat((R2.T,Ti[None])).T.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ffe862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.index=['$f_1$','$\\delta_1$, a=1','$\\delta_1$, regression a','$\\delta_1$, learned a','$\\delta_c$, all','$\\delta_c$, lasso','$\\delta_c$, lasso indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ca9c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=['A_TAT','V_TAT','Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb5026",
   "metadata": {},
   "source": [
    "Models!\n",
    "\n",
    "$y=f_1+\\epsilon$\n",
    "\n",
    "$y=af_0+\\delta_1 +epsilon$\n",
    "\n",
    "Options: Assign $a(=1)$, learn $a$ via regression, learn $a$ during GP training.\n",
    "\n",
    "$y=\\sum a_if_i + \\delta_c + \\epsilon$\n",
    "\n",
    "Options: Learn all $a_i$, learn $a_i$ via lasso regression, perform lasso regression to learn $a_i$ then us $a_i\\neq 0$ as an indicator function and learn these $a_i$ during GP training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b8190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35a3f537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f919c_row0_col0, #T_f919c_row0_col1, #T_f919c_row0_col2 {\n",
       "  background-color: pink;\n",
       "}\n",
       "#T_f919c_row2_col1, #T_f919c_row4_col2, #T_f919c_row6_col0 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f919c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f919c_level0_col0\" class=\"col_heading level0 col0\" >A_TAT</th>\n",
       "      <th id=\"T_f919c_level0_col1\" class=\"col_heading level0 col1\" >V_TAT</th>\n",
       "      <th id=\"T_f919c_level0_col2\" class=\"col_heading level0 col2\" >Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row0\" class=\"row_heading level0 row0\" >$f_1$</th>\n",
       "      <td id=\"T_f919c_row0_col0\" class=\"data row0 col0\" >0.991678</td>\n",
       "      <td id=\"T_f919c_row0_col1\" class=\"data row0 col1\" >0.983263</td>\n",
       "      <td id=\"T_f919c_row0_col2\" class=\"data row0 col2\" >1.196573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row1\" class=\"row_heading level0 row1\" >$\\delta_1$, a=1</th>\n",
       "      <td id=\"T_f919c_row1_col0\" class=\"data row1 col0\" >0.997151</td>\n",
       "      <td id=\"T_f919c_row1_col1\" class=\"data row1 col1\" >0.995211</td>\n",
       "      <td id=\"T_f919c_row1_col2\" class=\"data row1 col2\" >3.052090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row2\" class=\"row_heading level0 row2\" >$\\delta_1$, regression a</th>\n",
       "      <td id=\"T_f919c_row2_col0\" class=\"data row2 col0\" >0.997398</td>\n",
       "      <td id=\"T_f919c_row2_col1\" class=\"data row2 col1\" >0.997976</td>\n",
       "      <td id=\"T_f919c_row2_col2\" class=\"data row2 col2\" >3.036733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row3\" class=\"row_heading level0 row3\" >$\\delta_1$, learned a</th>\n",
       "      <td id=\"T_f919c_row3_col0\" class=\"data row3 col0\" >0.996586</td>\n",
       "      <td id=\"T_f919c_row3_col1\" class=\"data row3 col1\" >0.996217</td>\n",
       "      <td id=\"T_f919c_row3_col2\" class=\"data row3 col2\" >3.069094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row4\" class=\"row_heading level0 row4\" >$\\delta_c$, all</th>\n",
       "      <td id=\"T_f919c_row4_col0\" class=\"data row4 col0\" >0.996587</td>\n",
       "      <td id=\"T_f919c_row4_col1\" class=\"data row4 col1\" >0.997513</td>\n",
       "      <td id=\"T_f919c_row4_col2\" class=\"data row4 col2\" >29.997746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row5\" class=\"row_heading level0 row5\" >$\\delta_c$, lasso</th>\n",
       "      <td id=\"T_f919c_row5_col0\" class=\"data row5 col0\" >0.998769</td>\n",
       "      <td id=\"T_f919c_row5_col1\" class=\"data row5 col1\" >0.996854</td>\n",
       "      <td id=\"T_f919c_row5_col2\" class=\"data row5 col2\" >12.440411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f919c_level0_row6\" class=\"row_heading level0 row6\" >$\\delta_c$, lasso indicator</th>\n",
       "      <td id=\"T_f919c_row6_col0\" class=\"data row6 col0\" >0.998875</td>\n",
       "      <td id=\"T_f919c_row6_col1\" class=\"data row6 col1\" >0.997352</td>\n",
       "      <td id=\"T_f919c_row6_col2\" class=\"data row6 col2\" >12.314893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b42cde10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c615e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.53329174]\n",
      "[0.94770213]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[1.16797594]\n",
      "[0.8950299]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.79773726]\n",
      "[0.79327296]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[1.442243]\n",
      "[0.78942754]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.45294099]\n",
      "[0.76589944]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.66634952]\n",
      "[0.93093892]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.36228324]\n",
      "[0.81659538]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.52461247]\n",
      "[0.84081085]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.3802284]\n",
      "[0.80221829]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.69007554]\n",
      "[0.74043159]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "R2=torch.zeros(7,2)\n",
    "Ti=torch.zeros(7)\n",
    "reps=10\n",
    "n=20\n",
    "for i in range(reps):\n",
    "    \n",
    "    b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "    R2[0]+=model_f.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[0]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]],a=torch.tensor([[1],[1]]))\n",
    "    R2[1]+=model_dc_1.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[1]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    m0 = emulators2[0].predict(X_train[b,:])\n",
    "    a_d=np.zeros((y_train.shape[1],1))\n",
    "    for l in range(y_train.shape[1]):\n",
    "        result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulators2[0]), method='Nelder-Mead', tol=1e-8)\n",
    "        print(result.x)\n",
    "        a_d[l]=result.x\n",
    "    a_d=torch.tensor(a_d)\n",
    "    model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]],a=a_d)\n",
    "    R2[2]+=model_dc_reg.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[2]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]])\n",
    "    R2[3]+=model_dc_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[3]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "    R2[4]+=model_dc_all.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[4]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "    for j in range(y_train.shape[1]):\n",
    "        m0=m0_mat(y_train[b],emulators2,X_train[b],j)\n",
    "        # fit to an order-3 polynomial data\n",
    "        model = model.fit(m0.detach().numpy(), y_train[b,j].detach().numpy())\n",
    "        a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "    \n",
    "    \n",
    "    model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "    R2[5]+=model_dc_lasso.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[5]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "    R2[6]+=model_dc_lasso_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[6]+=(end-start)/reps\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "638c1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(torch.cat((R2.T,Ti[None])).T.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "122faa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.index=['$f_1$','$\\delta_1$, a=1','$\\delta_1$, regression a','$\\delta_1$, learned a','$\\delta_c$, all','$\\delta_c$, lasso','$\\delta_c$, lasso indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2cef6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=['A_TAT','V_TAT','Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0371e4b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2a4a1_row0_col0, #T_2a4a1_row0_col1, #T_2a4a1_row0_col2 {\n",
       "  background-color: pink;\n",
       "}\n",
       "#T_2a4a1_row4_col2, #T_2a4a1_row6_col0, #T_2a4a1_row6_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2a4a1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2a4a1_level0_col0\" class=\"col_heading level0 col0\" >A_TAT</th>\n",
       "      <th id=\"T_2a4a1_level0_col1\" class=\"col_heading level0 col1\" >V_TAT</th>\n",
       "      <th id=\"T_2a4a1_level0_col2\" class=\"col_heading level0 col2\" >Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row0\" class=\"row_heading level0 row0\" >$f_1$</th>\n",
       "      <td id=\"T_2a4a1_row0_col0\" class=\"data row0 col0\" >0.791831</td>\n",
       "      <td id=\"T_2a4a1_row0_col1\" class=\"data row0 col1\" >0.914575</td>\n",
       "      <td id=\"T_2a4a1_row0_col2\" class=\"data row0 col2\" >1.258665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row1\" class=\"row_heading level0 row1\" >$\\delta_1$, a=1</th>\n",
       "      <td id=\"T_2a4a1_row1_col0\" class=\"data row1 col0\" >0.963311</td>\n",
       "      <td id=\"T_2a4a1_row1_col1\" class=\"data row1 col1\" >0.978768</td>\n",
       "      <td id=\"T_2a4a1_row1_col2\" class=\"data row1 col2\" >3.303380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row2\" class=\"row_heading level0 row2\" >$\\delta_1$, regression a</th>\n",
       "      <td id=\"T_2a4a1_row2_col0\" class=\"data row2 col0\" >0.925350</td>\n",
       "      <td id=\"T_2a4a1_row2_col1\" class=\"data row2 col1\" >0.978564</td>\n",
       "      <td id=\"T_2a4a1_row2_col2\" class=\"data row2 col2\" >3.296277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row3\" class=\"row_heading level0 row3\" >$\\delta_1$, learned a</th>\n",
       "      <td id=\"T_2a4a1_row3_col0\" class=\"data row3 col0\" >0.981935</td>\n",
       "      <td id=\"T_2a4a1_row3_col1\" class=\"data row3 col1\" >0.987207</td>\n",
       "      <td id=\"T_2a4a1_row3_col2\" class=\"data row3 col2\" >3.292830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row4\" class=\"row_heading level0 row4\" >$\\delta_c$, all</th>\n",
       "      <td id=\"T_2a4a1_row4_col0\" class=\"data row4 col0\" >0.981811</td>\n",
       "      <td id=\"T_2a4a1_row4_col1\" class=\"data row4 col1\" >0.985455</td>\n",
       "      <td id=\"T_2a4a1_row4_col2\" class=\"data row4 col2\" >32.473412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row5\" class=\"row_heading level0 row5\" >$\\delta_c$, lasso</th>\n",
       "      <td id=\"T_2a4a1_row5_col0\" class=\"data row5 col0\" >0.961160</td>\n",
       "      <td id=\"T_2a4a1_row5_col1\" class=\"data row5 col1\" >0.986675</td>\n",
       "      <td id=\"T_2a4a1_row5_col2\" class=\"data row5 col2\" >11.217630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2a4a1_level0_row6\" class=\"row_heading level0 row6\" >$\\delta_c$, lasso indicator</th>\n",
       "      <td id=\"T_2a4a1_row6_col0\" class=\"data row6 col0\" >0.991898</td>\n",
       "      <td id=\"T_2a4a1_row6_col1\" class=\"data row6 col1\" >0.992278</td>\n",
       "      <td id=\"T_2a4a1_row6_col2\" class=\"data row6 col2\" >10.923800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b404c590>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.66963545]\n",
      "[0.90404307]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.65959816]\n",
      "[0.89341905]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.60440493]\n",
      "[0.93145205]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.56954043]\n",
      "[0.9041577]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.57196523]\n",
      "[0.89696861]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.63134806]\n",
      "[0.96953011]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "[0.57047307]\n",
      "[0.88280755]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "R2=torch.zeros(7,2)\n",
    "Ti=torch.zeros(7)\n",
    "reps=10\n",
    "n=100\n",
    "for i in range(reps):\n",
    "    \n",
    "    b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "    R2[0]+=model_f.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[0]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]],a=torch.tensor([[1],[1]]))\n",
    "    R2[1]+=model_dc_1.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[1]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    m0 = emulators2[0].predict(X_train[b,:])\n",
    "    a_d=np.zeros((y_train.shape[1],1))\n",
    "    for l in range(y_train.shape[1]):\n",
    "        result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulators2[0]), method='Nelder-Mead', tol=1e-8)\n",
    "        print(result.x)\n",
    "        a_d[l]=result.x\n",
    "    a_d=torch.tensor(a_d)\n",
    "    model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]],a=a_d)\n",
    "    R2[2]+=model_dc_reg.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[2]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[0]])\n",
    "    R2[3]+=model_dc_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[3]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "    R2[4]+=model_dc_all.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[4]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "    for j in range(y_train.shape[1]):\n",
    "        m0=m0_mat(y_train[b],emulators2,X_train[b],j)\n",
    "        # fit to an order-3 polynomial data\n",
    "        model = model.fit(m0.detach().numpy(), y_train[b,j].detach().numpy())\n",
    "        a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "    \n",
    "    \n",
    "    model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "    R2[5]+=model_dc_lasso.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[5]+=(end-start)/reps\n",
    "    \n",
    "    start = time.time()\n",
    "    model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "    R2[6]+=model_dc_lasso_learned.R2(X_test,y_test)/reps\n",
    "    end = time.time()\n",
    "    Ti[6]+=(end-start)/reps\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c61e8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(torch.cat((R2.T,Ti[None])).T.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.index=['$f_1$','$\\delta_1$, a=1','$\\delta_1$, regression a','$\\delta_1$, learned a','$\\delta_c$, all','$\\delta_c$, lasso','$\\delta_c$, lasso indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=['A_TAT','V_TAT','Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab35af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #b=np.random.choice(range(X_train.shape[0]),18,replace=False)\n",
    "# p = int(X0.shape[0]*0.05)\n",
    "# n = int(X0.shape[0]/p)\n",
    "# m = 18\n",
    "# MSE_mn = np.zeros((n,m,2))\n",
    "# R2_mn = np.zeros((n,m,2))\n",
    "# reps = 5\n",
    "# for i in range(n):\n",
    "#     for k in range(m):\n",
    "#         for j in range(reps):\n",
    "#             b=np.random.choice(range(X_train.shape[0]),(k+1)*p,replace=False)\n",
    "#             a=np.random.choice(range(X0.shape[0]),(i+1)*p,replace=False)\n",
    "#             emulator_0 = GPE.ensemble(X0[a,:],Y0[a,:],mean_func=\"linear\",training_iter=500)\n",
    "#             delta_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy\",training_iter=500,ref_emulator=emulator_0)\n",
    "#             MSE_mn[i,k] += delta_1.MSE(X_test,y_test).detach().numpy()/reps\n",
    "#             R2_mn[i,k] += delta_1.R2(X_test,y_test).detach().numpy()/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc7710d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637cf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(9,162,18)\n",
    "\n",
    "# y = np.linspace(9,180,20)\n",
    "\n",
    "# xx,yy=np.meshgrid(x,y)\n",
    "\n",
    "# xx[1:,1:].shape\n",
    "\n",
    "# level = 1\n",
    "\n",
    "# plt.contourf(xx[level:,level:],yy[level:,level:],R2_mn[level:,level:,0],origin='lower',levels=50,cmap='magma')\n",
    "# plt.ylabel('n')\n",
    "# plt.xlabel('m')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8426035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(9,162,18)\n",
    "\n",
    "# y = np.linspace(9,180,20)\n",
    "\n",
    "# xx,yy=np.meshgrid(x,y)\n",
    "\n",
    "# xx[1:,1:].shape\n",
    "\n",
    "# level = 1\n",
    "\n",
    "# plt.contourf(xx[level:,level:],yy[level:,level:],MSE_mn[level:,level:,0],origin='lower',levels=50)\n",
    "# plt.ylabel('n')\n",
    "# plt.xlabel('m')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97641355",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reps=10\n",
    "n=10\n",
    "R2=torch.zeros(7,2,reps)\n",
    "ISE=torch.zeros(7,2,reps)\n",
    "Ti=torch.zeros(7,reps)\n",
    "\n",
    "for k in range(len(emulators)):\n",
    "    emulators2=emulators.copy()\n",
    "    emulators2.pop(k)\n",
    "    print(len(emulators2))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                Xs[k].float(),\n",
    "                Ys[k].float(),\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )\n",
    "    for i in range(reps):\n",
    "\n",
    "        b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "\n",
    "        start = time.time()\n",
    "        model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "        end = time.time()\n",
    "        R2[0,:,i]+=model_f.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[0,:,i]+=model_f.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[0,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        \n",
    "        em=np.random.randint(len(emulators2))\n",
    "        start = time.time()\n",
    "        model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=torch.tensor([[1],[1]]))\n",
    "        end = time.time()\n",
    "        R2[1,:,i]+=model_dc_1.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[1,:,i]+=model_dc.ISE(X_test,y_test)/(len(emulators))\n",
    "        print(model_dc_1.R2(X_test,y_test))\n",
    "        print(R2[1])\n",
    "        \n",
    "        Ti[1,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        start = time.time()\n",
    "        m0 = emulators2[em].predict(X_train[b,:])\n",
    "        a_d=np.zeros((y_train.shape[1],1))\n",
    "        for l in range(y_train.shape[1]):\n",
    "            result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l,emulators[em]), method='Nelder-Mead', tol=1e-8)\n",
    "            print(result.x)\n",
    "            a_d[l]=result.x\n",
    "        a_d=torch.tensor(a_d)\n",
    "        model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=a_d)\n",
    "        end = time.time()\n",
    "        R2[2,:,i]+=model_dc_reg.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[2,:,i]+=model_dc_reg.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[2,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        start = time.time()\n",
    "        model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]])\n",
    "        end = time.time()\n",
    "        R2[3,:,i]+=model_dc_learned.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[3,:,i]+=model_dc_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[3,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        start = time.time()\n",
    "        model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "        end = time.time()\n",
    "        R2[4,:,i]+=model_dc_all.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[4,:,i]+=model_dc_all.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[4,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        start = time.time()\n",
    "        a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "        for j in range(y_train.shape[1]):\n",
    "            m0=m0_mat(y_train[b],emulators2,X_train[b],j)\n",
    "            # fit to an order-3 polynomial data\n",
    "            model = model.fit(m0.detach().numpy(), y_train[b,j].detach().numpy())\n",
    "            a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "\n",
    "\n",
    "        model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "        end = time.time()\n",
    "        R2[5,:,i]+=model_dc_lasso.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[5,:,i]+=model_dc_lasso.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[5,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "        start = time.time()\n",
    "        model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "        end = time.time()\n",
    "        R2[6,:,i]+=model_dc_lasso_learned.R2(X_test,y_test)/(len(emulators))\n",
    "        ISE[6,:,i]+=model_dc_lasso_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "        \n",
    "        Ti[6,i]+=(end-start)/(len(emulators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = emulators2[0].predict(X_train[b,:])\n",
    "g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb202548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ti.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(torch.cat((R2.mean(axis=2).T,Ti.mean(axis=1)[None])).T.detach().numpy())\n",
    "\n",
    "results.index=['$f_1$','$f_\\delta$, a=1','$f_\\delta$, regression a','$f_\\delta$, learned a','$f_{\\delta c}$, all','$f_{\\delta c}$, lasso','$f_{\\delta c}$, lasso indicator']\n",
    "\n",
    "results.columns=['A_TAT','V_TAT','Time']\n",
    "\n",
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(torch.cat((ISE.mean(axis=2).T,Ti.mean(axis=1)[None])).T.detach().numpy())\n",
    "\n",
    "results.index=['$f_1$','$f_\\delta$, a=1','$f_\\delta$, regression a','$f_\\delta$, learned a','$f_{\\delta c}$, all','$f_{\\delta c}$, lasso','$f_{\\delta c}$, lasso indicator']\n",
    "\n",
    "results.columns=['A_TAT','V_TAT','Time']\n",
    "\n",
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d06518",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2.mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(emulators2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3957a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(emulators2)[[1,5,6]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82347f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emn = [1,3,5,7,9,11,13,15,17]\n",
    "reps=1\n",
    "n=20\n",
    "R2_all=torch.zeros(len(emn),2,reps)\n",
    "R2_lasso=torch.zeros(len(emn),2,reps)\n",
    "R2_lasso_i=torch.zeros(len(emn),2,reps)\n",
    "\n",
    "\n",
    "for k in range(len(emulators)):\n",
    "    emulators2=emulators.copy()\n",
    "    emulators2.pop(k)\n",
    "    print(len(emulators2))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                Xs[k].float(),\n",
    "                Ys[k].float(),\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )\n",
    "    for m in range(len(emn)):\n",
    "        a =np.random.choice(len(emulators2),emn[m],replace=False)\n",
    "        emulators3 = np.array(emulators2)[a].tolist()\n",
    "        print(emulators3)\n",
    "        for i in range(reps):\n",
    "            \n",
    "            b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "\n",
    "            model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators3)\n",
    "\n",
    "            R2_all[m,:,i]+=model_dc_all.R2(X_test,y_test)/(len(emulators))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            a_d=torch.zeros((y_train.shape[1],len(emulators3)))\n",
    "            for j in range(y_train.shape[1]):\n",
    "                m0=m0_mat(y_train[b],emulators3,X_train[b],j)\n",
    "                # fit to an order-3 polynomial data\n",
    "                model = model.fit(m0.detach().numpy(), y_train[b,j].detach().numpy())\n",
    "                a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "\n",
    "\n",
    "            model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators3,a=a_d)\n",
    "            end = time.time()\n",
    "            R2_lasso[m,:,i]+=model_dc_lasso.R2(X_test,y_test)/(len(emulators))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators3,a=a_d,a_indicator=True)\n",
    "            end = time.time()\n",
    "            R2_lasso_i[m,:,i]+=model_dc_lasso_learned.R2(X_test,y_test)/(len(emulators))\n",
    "            \n",
    "            print(R2_lasso_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_lasso_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee081f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79631f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R2_all.detach().numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4529c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_lasso.detach().numpy().T.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3d9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
