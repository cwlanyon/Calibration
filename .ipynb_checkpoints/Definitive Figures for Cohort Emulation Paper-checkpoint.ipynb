{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b1e403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import GPE_ensemble as GPE\n",
    "\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from GPErks.gp.data.dataset import Dataset\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.means import LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from torchmetrics import MeanSquaredError, R2Score\n",
    "#from GPErks.gp.experiment import GPExperiment\n",
    "#from GPErks.train.emulator import GPEmulator\n",
    "#from GPErks.perks.inference import Inference\n",
    "#from GPErks.train.early_stop import NoEarlyStoppingCriterion\n",
    "#from GPErks.train.early_stop import (\n",
    "#    GLEarlyStoppingCriterion,\n",
    "#    PQEarlyStoppingCriterion,\n",
    "#    UPEarlyStoppingCriterion,\n",
    "#)\n",
    "#from GPErks.train.early_stop import PkEarlyStoppingCriterion\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set logger and enforce reproducibility\n",
    "#from GPErks.log.logger import get_logger\n",
    "#from GPErks.utils.random import set_seed\n",
    "#log = get_logger()\n",
    "seed = 7\n",
    "#set_seed(seed)\n",
    "from time import process_time \n",
    "import scipy\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf45825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "406.703\n",
      "02\n",
      "317.407\n",
      "03\n",
      "332.914\n",
      "04\n",
      "309.14\n",
      "05\n",
      "277.849\n",
      "06\n",
      "296.377\n",
      "07\n",
      "355.546\n",
      "08\n",
      "283.103\n",
      "09\n",
      "391.145\n",
      "10\n",
      "439.316\n",
      "11\n",
      "348.01\n",
      "12\n",
      "292.465\n",
      "13\n",
      "301.222\n",
      "14\n",
      "325.678\n",
      "16\n",
      "297.968\n",
      "17\n",
      "317.709\n",
      "18\n",
      "297.346\n",
      "19\n",
      "312.492\n"
     ]
    }
   ],
   "source": [
    "mode_weights = pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/modes_weights.csv',index_col=0,delim_whitespace=False,header=0)\n",
    "\n",
    "mode_weights\n",
    "\n",
    "mode_weights=mode_weights.drop(15,axis=0)\n",
    "#mode_weights=mode_weights.drop(14,axis=0)\n",
    "\n",
    "meshes=['01','02','03','04','05','06','07','08','09','10','11','12','13','14','16','17','18','19']\n",
    "\n",
    "x_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/input/xlabels_EP.txt',delim_whitespace=True,header=None)\n",
    "x_labels=x_labels.values.flatten().tolist()+mode_weights.columns.tolist()\n",
    "\n",
    "y_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/output/ylabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "\n",
    "all_input = []\n",
    "all_output=[]\n",
    "all_x=[]\n",
    "for i in range(len(meshes)):\n",
    "    val=meshes[i]\n",
    "    \n",
    "    inputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/\"+val+\"/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    outputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/\"+val+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    modeweights = np.tile(mode_weights.iloc[i,:].values, (inputData.shape[0],1))\n",
    "    input_modes = np.concatenate((inputData,modeweights),axis=1)\n",
    "    all_x.append(torch.tensor(inputData))\n",
    "    all_input.append(torch.tensor(input_modes))\n",
    "    all_output.append(torch.tensor(outputData))\n",
    "    print(val)\n",
    "    print(np.max(outputData))\n",
    "#all_input=pd.concat(all_input)\n",
    "#all_output=pd.concat(all_output\n",
    "#all_input.columns=x_labels\n",
    "#all_output.columns=y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1493530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input=[]\n",
    "test_input = []\n",
    "train_output=[]\n",
    "test_output = []\n",
    "\n",
    "train_input_modes=[]\n",
    "test_input_modes = []\n",
    "train_output_modes=[]\n",
    "test_output_modes = []\n",
    "\n",
    "for i in range(len(meshes)):\n",
    "\n",
    "    X=all_x[i]\n",
    "    y=all_output[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=seed+i\n",
    "    )\n",
    "    train_input.append(X_train)\n",
    "    test_input.append(X_test)\n",
    "    train_output.append(y_train)\n",
    "    test_output.append(y_test)\n",
    "    \n",
    "for i in range(len(meshes)):\n",
    "\n",
    "    X=all_input[i]\n",
    "    y=all_output[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=seed+i\n",
    "    )\n",
    "    train_input_modes.append(X_train)\n",
    "    test_input_modes.append(X_test)\n",
    "    train_output_modes.append(y_train)\n",
    "    test_output_modes.append(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a8dda",
   "metadata": {},
   "source": [
    "# Emulator per mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ff58820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "emulators=[]\n",
    "for i in range(len(meshes)):\n",
    "    emulators.append(GPE.ensemble(train_input[i],train_output[i],mean_func=\"linear\",training_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3056f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3dda116d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R2 = torch.zeros(len(meshes),2)\n",
    "R2_std = torch.zeros(len(meshes),2)\n",
    "for i in range(len(meshes)):\n",
    "    meanR, stdR = emulators[i].R2_sample(test_input[i],test_output[i],n=1000)\n",
    "    R2[i,:]=meanR\n",
    "    R2_std[i,:] = stdR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2beb20e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9983, 0.9981, 0.9982, 0.9985, 0.9992, 0.9982, 0.9989, 0.9974, 0.9983,\n",
       "        0.9947, 0.9978, 0.9971, 0.9986, 0.9985, 0.9975, 0.9988, 0.9985, 0.9988])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3aec3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0003, 0.0006],\n",
       "        [0.0002, 0.0009],\n",
       "        [0.0003, 0.0006],\n",
       "        [0.0002, 0.0005],\n",
       "        [0.0003, 0.0002],\n",
       "        [0.0002, 0.0005],\n",
       "        [0.0002, 0.0004],\n",
       "        [0.0004, 0.0008],\n",
       "        [0.0005, 0.0004],\n",
       "        [0.0002, 0.0017],\n",
       "        [0.0003, 0.0011],\n",
       "        [0.0007, 0.0008],\n",
       "        [0.0003, 0.0004],\n",
       "        [0.0001, 0.0007],\n",
       "        [0.0006, 0.0010],\n",
       "        [0.0001, 0.0005],\n",
       "        [0.0004, 0.0005],\n",
       "        [0.0004, 0.0004]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75a30b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "fontS=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04b4da4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.scatter(meshes,R2[:,0].detach().numpy())\n",
    "plt.errorbar(meshes,R2[:,0].detach().numpy(),fmt='o',yerr=R2_std[:,0].detach().numpy())\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\",\n",
    "         rotation_mode=\"anchor\");\n",
    "\n",
    "ax.scatter(meshes,R2[:,1].detach().numpy())\n",
    "plt.errorbar(meshes,R2[:,1].detach().numpy(),fmt='o',yerr=R2_std[:,1].detach().numpy())\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\",\n",
    "         rotation_mode=\"anchor\");\n",
    "\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Mesh')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xticks(fontsize=fontS)\n",
    "plt.yticks(fontsize=fontS)\n",
    "plt.savefig('WeavingDTIndivEm.pdf' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5d48880",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=[20,40,60,80,100,120,140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1cf2ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "R2 = torch.zeros(len(meshes),len(nn),2)\n",
    "R2_std = torch.zeros(len(meshes),len(nn),2)\n",
    "reps=5\n",
    "for i in range(len(meshes)):\n",
    "    for j in range(len(nn)):\n",
    "        for k in range(reps):\n",
    "            a=np.random.choice(range(train_input[i].shape[0]),nn[j],replace=False)\n",
    "            emulator=GPE.ensemble(train_input[i][a],train_output[i][a],mean_func=\"linear\",training_iter=1000)\n",
    "            meanR, stdR = emulator.R2_sample(test_input[i],test_output[i],n=1000)\n",
    "            R2[i,j,:]+=meanR/reps\n",
    "            R2_std[i,j,:] += stdR/reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "697aa666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 1.01)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(nn,R2.mean(axis=0)[:,0].detach().numpy(),fmt='o',yerr=R2_std.mean(axis=0)[:,0].detach().numpy())\n",
    "plt.errorbar(nn,R2.mean(axis=0)[:,1].detach().numpy(),fmt='o',yerr=R2_std.mean(axis=0)[:,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.ylim(0.7,1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5a39573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 40, 60, 80, 100, 120, 140]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed729f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9009, 0.9211],\n",
       "        [0.9911, 0.9810],\n",
       "        [0.9960, 0.9900],\n",
       "        [0.9973, 0.9933],\n",
       "        [0.9980, 0.9951],\n",
       "        [0.9985, 0.9964],\n",
       "        [0.9988, 0.9972]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2.mean(axis=0)[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c9821",
   "metadata": {},
   "source": [
    "# Emulator trained with 17/18 meshes and evaluated on the left out mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56b6bdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 200., 300., 400., 500., 600., 700., 800.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(100,800,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40f6432b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning: A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "  warnings.warn(\n",
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/linear_operator/operators/_linear_operator.py:2155: NumericalWarning: Runtime Error when computing Cholesky decomposition: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.. Using symeig method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.9817, 0.9839],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.9817, 0.9839],\n",
      "         [0.9785, 0.9812],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.9817, 0.9839],\n",
      "         [0.9785, 0.9812],\n",
      "         [0.9822, 0.9846],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.9817, 0.9839],\n",
      "         [0.9785, 0.9812],\n",
      "         [0.9822, 0.9846],\n",
      "         [0.9746, 0.9803],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9642, 0.9559],\n",
      "         [0.9731, 0.9667],\n",
      "         [0.9727, 0.9439],\n",
      "         [0.9747, 0.9448],\n",
      "         [0.9600, 0.9407]],\n",
      "\n",
      "        [[0.9831, 0.9813],\n",
      "         [0.9914, 0.9819],\n",
      "         [0.9889, 0.9821],\n",
      "         [0.9917, 0.9806],\n",
      "         [0.9912, 0.9750]],\n",
      "\n",
      "        [[0.9940, 0.9866],\n",
      "         [0.9940, 0.9891],\n",
      "         [0.9948, 0.9886],\n",
      "         [0.9955, 0.9891],\n",
      "         [0.9949, 0.9857]],\n",
      "\n",
      "        [[0.9952, 0.9911],\n",
      "         [0.9959, 0.9920],\n",
      "         [0.9959, 0.9914],\n",
      "         [0.9966, 0.9914],\n",
      "         [0.9963, 0.9911]],\n",
      "\n",
      "        [[0.9966, 0.9934],\n",
      "         [0.9969, 0.9939],\n",
      "         [0.9964, 0.9937],\n",
      "         [0.9977, 0.9937],\n",
      "         [0.9974, 0.9927]],\n",
      "\n",
      "        [[0.9972, 0.9945],\n",
      "         [0.9974, 0.9950],\n",
      "         [0.9975, 0.9946],\n",
      "         [0.9974, 0.9948],\n",
      "         [0.9975, 0.9945]],\n",
      "\n",
      "        [[0.9972, 0.9951],\n",
      "         [0.9978, 0.9954],\n",
      "         [0.9978, 0.9953],\n",
      "         [0.9982, 0.9954],\n",
      "         [0.9978, 0.9949]],\n",
      "\n",
      "        [[0.9975, 0.9951],\n",
      "         [0.9980, 0.9959],\n",
      "         [0.9980, 0.9958],\n",
      "         [0.9985, 0.9958],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9824, 0.9855],\n",
      "         [0.9800, 0.9865],\n",
      "         [0.9816, 0.9882],\n",
      "         [0.9808, 0.9786],\n",
      "         [0.9768, 0.9896]],\n",
      "\n",
      "        [[0.9817, 0.9839],\n",
      "         [0.9785, 0.9812],\n",
      "         [0.9822, 0.9846],\n",
      "         [0.9746, 0.9803],\n",
      "         [0.9791, 0.9895]]])\n"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "train_p = np.linspace(100,800,8)\n",
    "R2_test = torch.zeros(len(train_p),reps,2)\n",
    "R2_leftout= torch.zeros(len(train_p),reps,2)\n",
    "for i in range(len(train_p)):\n",
    "    for j in range(reps):\n",
    "        X=torch.cat(train_input_modes[0:17])[:,0:16]\n",
    "        y=torch.cat(train_output_modes[0:17])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=int(train_p[i]),\n",
    "            random_state=j\n",
    "        )\n",
    "        emulator=GPE.ensemble(X_train,y_train,mean_func=\"linear\",training_iter=1000)\n",
    "        meanR, stdR = emulator.R2_sample(torch.cat(test_input_modes[0:17])[:,0:16],torch.cat(test_output_modes[0:17]),1000)\n",
    "        \n",
    "        R2_test[i,j,:]+=meanR\n",
    "        \n",
    "        meanR, stdR=emulator.R2_sample(test_input_modes[17][:,0:16],test_output_modes[17],1000) \n",
    "        R2_leftout[i,j,:] = meanR\n",
    "        print(R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ecdc0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "tensor([0.9715, 0.9658])\n",
      "tensor([0.3809, 0.5596])\n",
      "0\n",
      "1\n",
      "tensor([0.9731, 0.9721])\n",
      "tensor([0.3864, 0.6657])\n",
      "0\n",
      "1\n",
      "tensor([0.9763, 0.9699])\n",
      "tensor([0.5070, 0.7578])\n",
      "0\n",
      "1\n",
      "tensor([0.9609, 0.9618])\n",
      "tensor([0.7184, 0.7835])\n",
      "0\n",
      "1\n",
      "tensor([0.9647, 0.9301])\n",
      "tensor([0.3395, 0.8579])\n",
      "0\n",
      "1\n",
      "tensor([0.9734, 0.9639])\n",
      "tensor([-0.2319,  0.3717])\n",
      "0\n",
      "1\n",
      "tensor([0.9685, 0.9697])\n",
      "tensor([0.4504, 0.1233])\n",
      "0\n",
      "1\n",
      "tensor([0.9715, 0.9659])\n",
      "tensor([0.3417, 0.5725])\n",
      "0\n",
      "1\n",
      "tensor([0.9721, 0.9557])\n",
      "tensor([-0.1906,  0.5627])\n",
      "0\n",
      "1\n",
      "tensor([0.9729, 0.9249])\n",
      "tensor([0.2347, 0.9227])\n",
      "0\n",
      "1\n",
      "tensor([0.9663, 0.9587])\n",
      "tensor([0.5957, 0.8136])\n",
      "0\n",
      "1\n",
      "tensor([0.9589, 0.9757])\n",
      "tensor([0.8423, 0.7580])\n",
      "0\n",
      "1\n",
      "tensor([0.9676, 0.9675])\n",
      "tensor([0.7538, 0.8543])\n",
      "0\n",
      "1\n",
      "tensor([0.9693, 0.9642])\n",
      "tensor([0.9404, 0.7642])\n",
      "0\n",
      "1\n",
      "tensor([0.9664, 0.9514])\n",
      "tensor([0.8431, 0.7344])\n",
      "0\n",
      "1\n",
      "tensor([0.9803, 0.9522])\n",
      "tensor([-0.2959,  0.8698])\n",
      "0\n",
      "1\n",
      "tensor([0.9629, 0.9616])\n",
      "tensor([0.1105, 0.5279])\n",
      "0\n",
      "1\n",
      "tensor([0.9745, 0.9590])\n",
      "tensor([0.1226, 0.2661])\n",
      "0\n",
      "1\n",
      "tensor([0.9745, 0.9529])\n",
      "tensor([-0.2458, -0.1256])\n",
      "0\n",
      "1\n",
      "tensor([0.9691, 0.9390])\n",
      "tensor([-0.3382,  0.7442])\n",
      "0\n",
      "1\n",
      "tensor([0.9737, 0.9431])\n",
      "tensor([0.8855, 0.9144])\n",
      "0\n",
      "1\n",
      "tensor([0.9529, 0.9710])\n",
      "tensor([0.9478, 0.8605])\n",
      "0\n",
      "1\n",
      "tensor([0.9695, 0.9638])\n",
      "tensor([0.8773, 0.6085])\n",
      "0\n",
      "1\n",
      "tensor([0.9513, 0.9648])\n",
      "tensor([0.7428, 0.9233])\n",
      "0\n",
      "1\n",
      "tensor([0.9665, 0.9292])\n",
      "tensor([0.7498, 0.8417])\n",
      "0\n",
      "1\n",
      "tensor([0.9718, 0.9465])\n",
      "tensor([0.9641, 0.9749])\n",
      "0\n",
      "1\n",
      "tensor([0.9578, 0.9616])\n",
      "tensor([0.9679, 0.9716])\n",
      "0\n",
      "1\n",
      "tensor([0.9682, 0.9501])\n",
      "tensor([0.9783, 0.8646])\n",
      "0\n",
      "1\n",
      "tensor([0.9728, 0.9630])\n",
      "tensor([0.9107, 0.9605])\n",
      "0\n",
      "1\n",
      "tensor([0.9670, 0.9343])\n",
      "tensor([0.7347, 0.9363])\n",
      "0\n",
      "1\n",
      "tensor([0.9741, 0.9331])\n",
      "tensor([0.9133, 0.9442])\n",
      "0\n",
      "1\n",
      "tensor([0.9561, 0.9633])\n",
      "tensor([0.9729, 0.9462])\n",
      "0\n",
      "1\n",
      "tensor([0.9683, 0.9501])\n",
      "tensor([0.9740, 0.9563])\n",
      "0\n",
      "1\n",
      "tensor([0.9645, 0.9597])\n",
      "tensor([0.9098, 0.9665])\n",
      "0\n",
      "1\n",
      "tensor([0.9732, 0.9297])\n",
      "tensor([0.9094, 0.8601])\n",
      "0\n",
      "1\n",
      "tensor([0.9581, 0.9565])\n",
      "tensor([0.7366, 0.7552])\n",
      "0\n",
      "1\n",
      "tensor([0.9645, 0.9580])\n",
      "tensor([0.9019, 0.6851])\n",
      "0\n",
      "1\n",
      "tensor([0.9630, 0.9691])\n",
      "tensor([0.8171, 0.8716])\n",
      "0\n",
      "1\n",
      "tensor([0.9716, 0.9559])\n",
      "tensor([0.7449, 0.8814])\n",
      "0\n",
      "1\n",
      "tensor([0.9752, 0.9130])\n",
      "tensor([0.7324, 0.8661])\n",
      "0\n",
      "1\n",
      "tensor([0.9627, 0.9578])\n",
      "tensor([0.6619, 0.9326])\n",
      "0\n",
      "1\n",
      "tensor([0.9646, 0.9595])\n",
      "tensor([0.9552, 0.7410])\n",
      "0\n",
      "1\n",
      "tensor([0.9695, 0.9615])\n",
      "tensor([0.9554, 0.7994])\n",
      "0\n",
      "1\n",
      "tensor([0.9730, 0.9534])\n",
      "tensor([0.8462, 0.6113])\n",
      "0\n",
      "1\n",
      "tensor([0.9653, 0.9523])\n",
      "tensor([0.8484, 0.5720])\n",
      "0\n",
      "1\n",
      "tensor([0.9417, 0.9571])\n",
      "tensor([-0.3098,  0.2097])\n",
      "0\n",
      "1\n",
      "tensor([0.9586, 0.9650])\n",
      "tensor([ 0.8976, -0.1574])\n",
      "0\n",
      "1\n",
      "tensor([0.9660, 0.9657])\n",
      "tensor([ 0.4726, -1.1399])\n",
      "0\n",
      "1\n",
      "tensor([0.9736, 0.9640])\n",
      "tensor([0.9317, 0.0036])\n",
      "0\n",
      "1\n",
      "tensor([0.9658, 0.9406])\n",
      "tensor([ 0.5996, -1.0631])\n",
      "0\n",
      "1\n",
      "tensor([0.9543, 0.9583])\n",
      "tensor([0.6521, 0.7185])\n",
      "0\n",
      "1\n",
      "tensor([0.9576, 0.9532])\n",
      "tensor([0.9446, 0.7833])\n",
      "0\n",
      "1\n",
      "tensor([0.9665, 0.9662])\n",
      "tensor([0.9501, 0.9035])\n",
      "0\n",
      "1\n",
      "tensor([0.9687, 0.9606])\n",
      "tensor([0.8201, 0.9360])\n",
      "0\n",
      "1\n",
      "tensor([0.9548, 0.9518])\n",
      "tensor([0.8507, 0.7197])\n",
      "0\n",
      "1\n",
      "tensor([0.9444, 0.9445])\n",
      "tensor([0.6112, 0.8297])\n",
      "0\n",
      "1\n",
      "tensor([0.9593, 0.9595])\n",
      "tensor([0.9799, 0.9312])\n",
      "0\n",
      "1\n",
      "tensor([0.9663, 0.9614])\n",
      "tensor([0.9765, 0.9618])\n",
      "0\n",
      "1\n",
      "tensor([0.9719, 0.9619])\n",
      "tensor([0.9566, 0.9569])\n",
      "0\n",
      "1\n",
      "tensor([0.9588, 0.9445])\n",
      "tensor([0.9591, 0.9543])\n",
      "0\n",
      "1\n",
      "tensor([0.9709, 0.9626])\n",
      "tensor([0.8587, 0.8354])\n",
      "0\n",
      "1\n",
      "tensor([0.9665, 0.9625])\n",
      "tensor([0.8187, 0.8269])\n",
      "0\n",
      "1\n",
      "tensor([0.9658, 0.9595])\n",
      "tensor([0.7945, 0.6813])\n",
      "0\n",
      "1\n",
      "tensor([0.9638, 0.9727])\n",
      "tensor([0.7664, 0.7794])\n",
      "0\n",
      "1\n",
      "tensor([0.9741, 0.9479])\n",
      "tensor([0.8165, 0.7749])\n",
      "0\n",
      "1\n",
      "tensor([0.9654, 0.9622])\n",
      "tensor([0.6928, 0.8355])\n",
      "0\n",
      "1\n",
      "tensor([0.9724, 0.9629])\n",
      "tensor([0.8777, 0.7182])\n",
      "0\n",
      "1\n",
      "tensor([0.9722, 0.9454])\n",
      "tensor([0.7496, 0.8079])\n",
      "0\n",
      "1\n",
      "tensor([0.9770, 0.9424])\n",
      "tensor([0.2279, 0.8028])\n",
      "0\n",
      "1\n",
      "tensor([0.9638, 0.9464])\n",
      "tensor([0.4509, 0.8923])\n",
      "0\n",
      "1\n",
      "tensor([0.9656, 0.9708])\n",
      "tensor([0.8774, 0.8166])\n",
      "0\n",
      "1\n",
      "tensor([0.9717, 0.9580])\n",
      "tensor([0.9764, 0.5752])\n",
      "0\n",
      "1\n",
      "tensor([0.9722, 0.9645])\n",
      "tensor([0.9784, 0.3272])\n",
      "0\n",
      "1\n",
      "tensor([0.9688, 0.9605])\n",
      "tensor([0.9612, 0.8654])\n",
      "0\n",
      "1\n",
      "tensor([0.9557, 0.9418])\n",
      "tensor([0.9281, 0.6322])\n",
      "0\n",
      "1\n",
      "tensor([0.9627, 0.9539])\n",
      "tensor([0.8067, 0.8368])\n",
      "0\n",
      "1\n",
      "tensor([0.9728, 0.9651])\n",
      "tensor([0.8632, 0.6992])\n",
      "0\n",
      "1\n",
      "tensor([0.9700, 0.9533])\n",
      "tensor([0.9762, 0.9384])\n",
      "0\n",
      "1\n",
      "tensor([0.9722, 0.9599])\n",
      "tensor([0.9540, 0.8711])\n",
      "0\n",
      "1\n",
      "tensor([0.9535, 0.9406])\n",
      "tensor([0.5617, 0.8938])\n",
      "0\n",
      "1\n",
      "tensor([0.9664, 0.9533])\n",
      "tensor([0.7066, 0.8680])\n",
      "0\n",
      "1\n",
      "tensor([0.9726, 0.9677])\n",
      "tensor([0.9329, 0.8653])\n",
      "0\n",
      "1\n",
      "tensor([0.9745, 0.9458])\n",
      "tensor([0.7626, 0.8609])\n",
      "0\n",
      "1\n",
      "tensor([0.9773, 0.9463])\n",
      "tensor([-0.0375,  0.8505])\n",
      "0\n",
      "1\n",
      "tensor([0.9622, 0.9413])\n",
      "tensor([0.7002, 0.9035])\n",
      "0\n",
      "1\n",
      "tensor([0.9639, 0.9560])\n",
      "tensor([0.6376, 0.4113])\n",
      "0\n",
      "1\n",
      "tensor([0.9705, 0.9661])\n",
      "tensor([0.9035, 0.9386])\n",
      "0\n",
      "1\n",
      "tensor([0.9719, 0.9442])\n",
      "tensor([0.9200, 0.8482])\n",
      "0\n",
      "1\n",
      "tensor([0.9748, 0.9441])\n",
      "tensor([0.5963, 0.9608])\n",
      "0\n",
      "1\n",
      "tensor([0.9591, 0.9406])\n",
      "tensor([0.9625, 0.9107])\n",
      "0\n",
      "1\n",
      "tensor([0.9903, 0.9786])\n",
      "tensor([0.2463, 0.8747])\n",
      "0\n",
      "1\n",
      "tensor([0.9907, 0.9801])\n",
      "tensor([0.5439, 0.7450])\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9819])\n",
      "tensor([0.6154, 0.8035])\n",
      "0\n",
      "1\n",
      "tensor([0.9905, 0.9843])\n",
      "tensor([0.0659, 0.7802])\n",
      "0\n",
      "1\n",
      "tensor([0.9901, 0.9715])\n",
      "tensor([0.3272, 0.8680])\n",
      "0\n",
      "1\n",
      "tensor([0.9905, 0.9730])\n",
      "tensor([-0.1288,  0.7829])\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9810])\n",
      "tensor([0.0460, 0.5427])\n",
      "0\n",
      "1\n",
      "tensor([0.9920, 0.9809])\n",
      "tensor([-0.0502,  0.6926])\n",
      "0\n",
      "1\n",
      "tensor([0.9894, 0.9809])\n",
      "tensor([0.1749, 0.6960])\n",
      "0\n",
      "1\n",
      "tensor([0.9910, 0.9719])\n",
      "tensor([0.1273, 0.6874])\n",
      "0\n",
      "1\n",
      "tensor([0.9897, 0.9818])\n",
      "tensor([0.9232, 0.9035])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9813])\n",
      "tensor([0.7429, 0.7778])\n",
      "0\n",
      "1\n",
      "tensor([0.9886, 0.9826])\n",
      "tensor([0.8107, 0.8265])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9814])\n",
      "tensor([0.8789, 0.7302])\n",
      "0\n",
      "1\n",
      "tensor([0.9907, 0.9809])\n",
      "tensor([0.7821, 0.7531])\n",
      "0\n",
      "1\n",
      "tensor([0.9923, 0.9753])\n",
      "tensor([-0.6963,  0.8641])\n",
      "0\n",
      "1\n",
      "tensor([0.9901, 0.9826])\n",
      "tensor([0.0810, 0.9614])\n",
      "0\n",
      "1\n",
      "tensor([0.9899, 0.9789])\n",
      "tensor([-1.8059,  0.4945])\n",
      "0\n",
      "1\n",
      "tensor([0.9905, 0.9796])\n",
      "tensor([-3.7716,  0.9654])\n",
      "0\n",
      "1\n",
      "tensor([0.9918, 0.9772])\n",
      "tensor([-0.3257,  0.9380])\n",
      "0\n",
      "1\n",
      "tensor([0.9908, 0.9747])\n",
      "tensor([0.7661, 0.8657])\n",
      "0\n",
      "1\n",
      "tensor([0.9898, 0.9813])\n",
      "tensor([0.9502, 0.9523])\n",
      "0\n",
      "1\n",
      "tensor([0.9902, 0.9812])\n",
      "tensor([0.8714, 0.9527])\n",
      "0\n",
      "1\n",
      "tensor([0.9886, 0.9817])\n",
      "tensor([0.8428, 0.9518])\n",
      "0\n",
      "1\n",
      "tensor([0.9897, 0.9790])\n",
      "tensor([0.8632, 0.9455])\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9747])\n",
      "tensor([0.9880, 0.9814])\n",
      "0\n",
      "1\n",
      "tensor([0.9896, 0.9829])\n",
      "tensor([0.9872, 0.9780])\n",
      "0\n",
      "1\n",
      "tensor([0.9913, 0.9798])\n",
      "tensor([0.8923, 0.9811])\n",
      "0\n",
      "1\n",
      "tensor([0.9914, 0.9808])\n",
      "tensor([0.8482, 0.9742])\n",
      "0\n",
      "1\n",
      "tensor([0.9903, 0.9758])\n",
      "tensor([0.8654, 0.9377])\n",
      "0\n",
      "1\n",
      "tensor([0.9912, 0.9761])\n",
      "tensor([0.9582, 0.9838])\n",
      "0\n",
      "1\n",
      "tensor([0.9904, 0.9840])\n",
      "tensor([0.9558, 0.9579])\n",
      "0\n",
      "1\n",
      "tensor([0.9907, 0.9794])\n",
      "tensor([0.9262, 0.9830])\n",
      "0\n",
      "1\n",
      "tensor([0.9911, 0.9806])\n",
      "tensor([0.9311, 0.9821])\n",
      "0\n",
      "1\n",
      "tensor([0.9920, 0.9746])\n",
      "tensor([0.9276, 0.9760])\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9811])\n",
      "tensor([0.7749, 0.8537])\n",
      "0\n",
      "1\n",
      "tensor([0.9896, 0.9818])\n",
      "tensor([0.7710, 0.8443])\n",
      "0\n",
      "1\n",
      "tensor([0.9890, 0.9800])\n",
      "tensor([0.7829, 0.8636])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9809])\n",
      "tensor([0.6906, 0.8782])\n",
      "0\n",
      "1\n",
      "tensor([0.9913, 0.9759])\n",
      "tensor([0.7660, 0.8928])\n",
      "0\n",
      "1\n",
      "tensor([0.9919, 0.9837])\n",
      "tensor([0.7650, 0.6806])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9819])\n",
      "tensor([0.7537, 0.8731])\n",
      "0\n",
      "1\n",
      "tensor([0.9888, 0.9797])\n",
      "tensor([0.8019, 0.9486])\n",
      "0\n",
      "1\n",
      "tensor([0.9916, 0.9831])\n",
      "tensor([0.7891, 0.7508])\n",
      "0\n",
      "1\n",
      "tensor([0.9909, 0.9736])\n",
      "tensor([0.7176, 0.7590])\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9829])\n",
      "tensor([ 0.7387, -0.2223])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9852])\n",
      "tensor([ 0.5929, -0.6627])\n",
      "0\n",
      "1\n",
      "tensor([0.9857, 0.9794])\n",
      "tensor([0.7433, 0.2156])\n",
      "0\n",
      "1\n",
      "tensor([0.9932, 0.9817])\n",
      "tensor([0.3449, 0.1146])\n",
      "0\n",
      "1\n",
      "tensor([0.9901, 0.9751])\n",
      "tensor([0.5641, 0.0839])\n",
      "0\n",
      "1\n",
      "tensor([0.9902, 0.9836])\n",
      "tensor([0.8874, 0.7542])\n",
      "0\n",
      "1\n",
      "tensor([0.9885, 0.9860])\n",
      "tensor([0.8952, 0.3289])\n",
      "0\n",
      "1\n",
      "tensor([0.9860, 0.9802])\n",
      "tensor([0.9102, 0.6993])\n",
      "0\n",
      "1\n",
      "tensor([0.9914, 0.9807])\n",
      "tensor([0.9384, 0.6247])\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9795])\n",
      "tensor([0.6965, 0.6571])\n",
      "0\n",
      "1\n",
      "tensor([0.9908, 0.9817])\n",
      "tensor([0.7482, 0.9689])\n",
      "0\n",
      "1\n",
      "tensor([0.9891, 0.9854])\n",
      "tensor([0.9860, 0.9792])\n",
      "0\n",
      "1\n",
      "tensor([0.9869, 0.9795])\n",
      "tensor([0.9219, 0.9811])\n",
      "0\n",
      "1\n",
      "tensor([0.9910, 0.9811])\n",
      "tensor([0.9473, 0.9813])\n",
      "0\n",
      "1\n",
      "tensor([0.9900, 0.9821])\n",
      "tensor([0.9669, 0.9689])\n",
      "0\n",
      "1\n",
      "tensor([0.9914, 0.9792])\n",
      "tensor([0.8583, 0.8323])\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9897, 0.9853])\n",
      "tensor([0.7695, 0.7760])\n",
      "0\n",
      "1\n",
      "tensor([0.9858, 0.9805])\n",
      "tensor([0.9136, 0.7987])\n",
      "0\n",
      "1\n",
      "tensor([0.9918, 0.9836])\n",
      "tensor([0.7816, 0.6928])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9809])\n",
      "tensor([0.8042, 0.7824])\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9758])\n",
      "tensor([0.8743, 0.8602])\n",
      "0\n",
      "1\n",
      "tensor([0.9873, 0.9866])\n",
      "tensor([0.7614, 0.8880])\n",
      "0\n",
      "1\n",
      "tensor([0.9864, 0.9792])\n",
      "tensor([0.9407, 0.8641])\n",
      "0\n",
      "1\n",
      "tensor([0.9896, 0.9828])\n",
      "tensor([0.5315, 0.9313])\n",
      "0\n",
      "1\n",
      "tensor([0.9893, 0.9751])\n",
      "tensor([0.4852, 0.7467])\n",
      "0\n",
      "1\n",
      "tensor([0.9903, 0.9817])\n",
      "tensor([0.9166, 0.9047])\n",
      "0\n",
      "1\n",
      "tensor([0.9893, 0.9845])\n",
      "tensor([0.9766, 0.9334])\n",
      "0\n",
      "1\n",
      "tensor([0.9883, 0.9815])\n",
      "tensor([0.9720, 0.6544])\n",
      "0\n",
      "1\n",
      "tensor([0.9909, 0.9837])\n",
      "tensor([0.9766, 0.5880])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9797])\n",
      "tensor([0.9259, 0.8362])\n",
      "0\n",
      "1\n",
      "tensor([0.9850, 0.9815])\n",
      "tensor([0.9760, 0.8581])\n",
      "0\n",
      "1\n",
      "tensor([0.9897, 0.9791])\n",
      "tensor([0.7559, 0.9062])\n",
      "0\n",
      "1\n",
      "tensor([0.9856, 0.9798])\n",
      "tensor([0.9527, 0.9036])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9821])\n",
      "tensor([0.6403, 0.9161])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9762])\n",
      "tensor([0.8078, 0.9062])\n",
      "0\n",
      "1\n",
      "tensor([0.9896, 0.9797])\n",
      "tensor([0.5314, 0.9019])\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9804])\n",
      "tensor([0.7972, 0.8949])\n",
      "0\n",
      "1\n",
      "tensor([0.9871, 0.9801])\n",
      "tensor([0.5502, 0.8583])\n",
      "0\n",
      "1\n",
      "tensor([0.9925, 0.9826])\n",
      "tensor([0.6077, 0.8806])\n",
      "0\n",
      "1\n",
      "tensor([0.9894, 0.9753])\n",
      "tensor([0.5984, 0.9159])\n",
      "0\n",
      "1\n",
      "tensor([0.9911, 0.9813])\n",
      "tensor([0.8799, 0.9629])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9815])\n",
      "tensor([0.7963, 0.7653])\n",
      "0\n",
      "1\n",
      "tensor([0.9902, 0.9815])\n",
      "tensor([0.7703, 0.9067])\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9798])\n",
      "tensor([0.8527, 0.9122])\n",
      "0\n",
      "1\n",
      "tensor([0.9916, 0.9750])\n",
      "tensor([0.7369, 0.8984])\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9889])\n",
      "tensor([0.4250, 0.8064])\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9877])\n",
      "tensor([0.2613, 0.5098])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9883])\n",
      "tensor([0.2224, 0.7591])\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9898])\n",
      "tensor([0.2741, 0.7713])\n",
      "0\n",
      "1\n",
      "tensor([0.9933, 0.9880])\n",
      "tensor([0.8462, 0.8381])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9864])\n",
      "tensor([-0.0536,  0.8651])\n",
      "0\n",
      "1\n",
      "tensor([0.9934, 0.9881])\n",
      "tensor([0.1699, 0.5199])\n",
      "0\n",
      "1\n",
      "tensor([0.9951, 0.9884])\n",
      "tensor([0.0111, 0.9353])\n",
      "0\n",
      "1\n",
      "tensor([0.9945, 0.9894])\n",
      "tensor([0.0556, 0.8863])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9869])\n",
      "tensor([0.2157, 0.9060])\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9877])\n",
      "tensor([0.7583, 0.8383])\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9871])\n",
      "tensor([0.7282, 0.7802])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9888])\n",
      "tensor([0.8362, 0.8345])\n",
      "0\n",
      "1\n",
      "tensor([0.9943, 0.9878])\n",
      "tensor([0.7843, 0.8499])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9887])\n",
      "tensor([0.8144, 0.8082])\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9868])\n",
      "tensor([-0.8373,  0.8455])\n",
      "0\n",
      "1\n",
      "tensor([0.9933, 0.9867])\n",
      "tensor([-0.4009,  0.5254])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9868])\n",
      "tensor([-2.3987,  0.9661])\n",
      "0\n",
      "1\n",
      "tensor([0.9929, 0.9891])\n",
      "tensor([-5.0860,  0.8518])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9876])\n",
      "tensor([-2.3326,  0.9311])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9873])\n",
      "tensor([0.8531, 0.9179])\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9885])\n",
      "tensor([0.9314, 0.9561])\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9879])\n",
      "tensor([0.8834, 0.9379])\n",
      "0\n",
      "1\n",
      "tensor([0.9927, 0.9904])\n",
      "tensor([0.9356, 0.9412])\n",
      "0\n",
      "1\n",
      "tensor([0.9946, 0.9901])\n",
      "tensor([0.8336, 0.9378])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9863])\n",
      "tensor([0.8595, 0.9886])\n",
      "0\n",
      "1\n",
      "tensor([0.9924, 0.9889])\n",
      "tensor([0.9826, 0.9886])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9867])\n",
      "tensor([0.9920, 0.9747])\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9893])\n",
      "tensor([0.8574, 0.9870])\n",
      "0\n",
      "1\n",
      "tensor([0.9943, 0.9882])\n",
      "tensor([0.8156, 0.9816])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9854])\n",
      "tensor([0.9494, 0.9712])\n",
      "0\n",
      "1\n",
      "tensor([0.9934, 0.9883])\n",
      "tensor([0.9391, 0.9751])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9863])\n",
      "tensor([0.9614, 0.9677])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9877])\n",
      "tensor([0.9360, 0.9824])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9871])\n",
      "tensor([0.9347, 0.9821])\n",
      "0\n",
      "1\n",
      "tensor([0.9939, 0.9867])\n",
      "tensor([0.7604, 0.8842])\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9878])\n",
      "tensor([0.7707, 0.8440])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9855])\n",
      "tensor([0.7621, 0.9125])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9883])\n",
      "tensor([0.7145, 0.8457])\n",
      "0\n",
      "1\n",
      "tensor([0.9936, 0.9890])\n",
      "tensor([0.7487, 0.8981])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9883])\n",
      "tensor([0.7502, 0.8085])\n",
      "0\n",
      "1\n",
      "tensor([0.9935, 0.9888])\n",
      "tensor([0.7041, 0.7386])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9856])\n",
      "tensor([0.7469, 0.7903])\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9900])\n",
      "tensor([0.7500, 0.6945])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9895])\n",
      "tensor([0.7328, 0.7093])\n",
      "0\n",
      "1\n",
      "tensor([0.9946, 0.9865])\n",
      "tensor([0.5660, 0.9055])\n",
      "0\n",
      "1\n",
      "tensor([0.9933, 0.9874])\n",
      "tensor([ 0.4560, -0.2853])\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.9879])\n",
      "tensor([0.1721, 0.0081])\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9885])\n",
      "tensor([ 0.4729, -0.0622])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9880])\n",
      "tensor([3.0191e-01, 2.9166e-04])\n",
      "0\n",
      "1\n",
      "tensor([0.9943, 0.9883])\n",
      "tensor([0.9123, 0.8124])\n",
      "0\n",
      "1\n",
      "tensor([0.9932, 0.9891])\n",
      "tensor([0.8934, 0.7818])\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9880])\n",
      "tensor([0.8475, 0.8586])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9908])\n",
      "tensor([0.9121, 0.5240])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9899])\n",
      "tensor([0.8855, 0.7905])\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.9875])\n",
      "tensor([0.8176, 0.9811])\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9884])\n",
      "tensor([0.9902, 0.9549])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9869])\n",
      "tensor([0.8286, 0.9795])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9908])\n",
      "tensor([0.9520, 0.9793])\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9890])\n",
      "tensor([0.9903, 0.9754])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9853])\n",
      "tensor([0.8696, 0.8460])\n",
      "0\n",
      "1\n",
      "tensor([0.9945, 0.9881])\n",
      "tensor([0.7582, 0.7370])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9882])\n",
      "tensor([0.8800, 0.8195])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9912])\n",
      "tensor([0.8092, 0.7634])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9902])\n",
      "tensor([0.7724, 0.8225])\n",
      "0\n",
      "1\n",
      "tensor([0.9932, 0.9843])\n",
      "tensor([0.9162, 0.9236])\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9877])\n",
      "tensor([0.7680, 0.8817])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9872])\n",
      "tensor([0.5864, 0.9044])\n",
      "0\n",
      "1\n",
      "tensor([0.9951, 0.9892])\n",
      "tensor([0.5260, 0.8832])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9870])\n",
      "tensor([0.4835, 0.8683])\n",
      "0\n",
      "1\n",
      "tensor([0.9935, 0.9872])\n",
      "tensor([0.9348, 0.9582])\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.9876])\n",
      "tensor([0.9599, 0.7338])\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9880])\n",
      "tensor([0.9342, 0.5354])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9902])\n",
      "tensor([0.9544, 0.9584])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9882])\n",
      "tensor([0.9177, 0.8963])\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9868])\n",
      "tensor([0.9641, 0.8923])\n",
      "0\n",
      "1\n",
      "tensor([0.9939, 0.9882])\n",
      "tensor([0.6671, 0.8541])\n",
      "0\n",
      "1\n",
      "tensor([0.9939, 0.9875])\n",
      "tensor([0.4200, 0.9396])\n",
      "0\n",
      "1\n",
      "tensor([0.9951, 0.9891])\n",
      "tensor([0.9689, 0.8813])\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9874])\n",
      "tensor([0.4408, 0.9319])\n",
      "0\n",
      "1\n",
      "tensor([0.9939, 0.9860])\n",
      "tensor([0.4628, 0.9160])\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9885])\n",
      "tensor([0.6531, 0.9056])\n",
      "0\n",
      "1\n",
      "tensor([0.9943, 0.9870])\n",
      "tensor([0.3394, 0.9424])\n",
      "0\n",
      "1\n",
      "tensor([0.9954, 0.9882])\n",
      "tensor([0.5841, 0.9448])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9884])\n",
      "tensor([0.4271, 0.9378])\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.9865])\n",
      "tensor([0.8623, 0.7322])\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9889])\n",
      "tensor([0.8093, 0.9492])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9885])\n",
      "tensor([0.7903, 0.9416])\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9871])\n",
      "tensor([0.7885, 0.9702])\n",
      "0\n",
      "1\n",
      "tensor([0.9947, 0.9883])\n",
      "tensor([0.7851, 0.9580])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9918])\n",
      "tensor([0.3557, 0.8382])\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9912])\n",
      "tensor([0.7703, 0.7899])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9913])\n",
      "tensor([0.2808, 0.7180])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9927])\n",
      "tensor([0.2278, 0.8254])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9920])\n",
      "tensor([0.8588, 0.8045])\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9912])\n",
      "tensor([-0.0091,  0.8705])\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9898])\n",
      "tensor([0.1308, 0.8756])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9900])\n",
      "tensor([-0.0297,  0.9652])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9924])\n",
      "tensor([-0.0482,  0.9131])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9908])\n",
      "tensor([0.1336, 0.9123])\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9915])\n",
      "tensor([0.7214, 0.8292])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9895])\n",
      "tensor([0.8069, 0.9008])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9904])\n",
      "tensor([0.8645, 0.8991])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9915])\n",
      "tensor([0.8066, 0.8873])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9916])\n",
      "tensor([0.7413, 0.8356])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9921])\n",
      "tensor([-1.1001,  0.8646])\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9896])\n",
      "tensor([-0.9813,  0.8802])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9904])\n",
      "tensor([-5.0765,  0.9194])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9923])\n",
      "tensor([-4.3044,  0.9049])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9916])\n",
      "tensor([-4.3231,  0.9232])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9918])\n",
      "tensor([0.9129, 0.9531])\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9917])\n",
      "tensor([0.9405, 0.9696])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9904])\n",
      "tensor([0.9399, 0.9297])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9927])\n",
      "tensor([0.9008, 0.9519])\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9926])\n",
      "tensor([0.8410, 0.9460])\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9914])\n",
      "tensor([0.9899, 0.9913])\n",
      "0\n",
      "1\n",
      "tensor([0.9945, 0.9903])\n",
      "tensor([0.8788, 0.9892])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9902])\n",
      "tensor([0.9876, 0.9829])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9916])\n",
      "tensor([0.9790, 0.9848])\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9917])\n",
      "tensor([0.8404, 0.9892])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9922])\n",
      "tensor([0.9487, 0.9823])\n",
      "0\n",
      "1\n",
      "tensor([0.9954, 0.9894])\n",
      "tensor([0.9179, 0.9793])\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9965, 0.9894])\n",
      "tensor([0.9595, 0.9794])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9930])\n",
      "tensor([0.9450, 0.9828])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9912])\n",
      "tensor([0.9352, 0.9844])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9920])\n",
      "tensor([0.7505, 0.8829])\n",
      "0\n",
      "1\n",
      "tensor([0.9951, 0.9891])\n",
      "tensor([0.7650, 0.8803])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9906])\n",
      "tensor([0.7303, 0.9084])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9927])\n",
      "tensor([0.7568, 0.8624])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9922])\n",
      "tensor([0.8230, 0.9081])\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9910])\n",
      "tensor([0.6598, 0.8035])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9902])\n",
      "tensor([0.6660, 0.8384])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9915])\n",
      "tensor([0.7210, 0.7477])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9926])\n",
      "tensor([0.7269, 0.6873])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9919])\n",
      "tensor([0.7294, 0.6998])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9917])\n",
      "tensor([0.4320, 0.3822])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9903])\n",
      "tensor([0.3278, 0.1379])\n",
      "0\n",
      "1\n",
      "tensor([0.9954, 0.9912])\n",
      "tensor([ 0.2709, -0.0571])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9930])\n",
      "tensor([0.4521, 0.7433])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9920])\n",
      "tensor([0.4589, 0.3089])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9917])\n",
      "tensor([0.9346, 0.7247])\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9916])\n",
      "tensor([0.8792, 0.8087])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9917])\n",
      "tensor([0.8558, 0.7932])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9938])\n",
      "tensor([0.8970, 0.5730])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9931])\n",
      "tensor([0.9521, 0.7752])\n",
      "0\n",
      "1\n",
      "tensor([0.9950, 0.9914])\n",
      "tensor([0.9840, 0.9789])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9917])\n",
      "tensor([0.9614, 0.9794])\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9904])\n",
      "tensor([0.9671, 0.9801])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9938])\n",
      "tensor([0.9557, 0.9704])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9921])\n",
      "tensor([0.9887, 0.9800])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9911])\n",
      "tensor([0.8821, 0.7795])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9911])\n",
      "tensor([0.7764, 0.7530])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9911])\n",
      "tensor([0.8631, 0.8252])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9942])\n",
      "tensor([0.7637, 0.7959])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9923])\n",
      "tensor([0.9186, 0.8135])\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9922])\n",
      "tensor([0.8534, 0.9424])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9900])\n",
      "tensor([0.3885, 0.7256])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9902])\n",
      "tensor([0.5349, 0.9208])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9931])\n",
      "tensor([0.5165, 0.9095])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9918])\n",
      "tensor([0.5716, 0.9243])\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9922])\n",
      "tensor([0.9523, 0.9395])\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9911])\n",
      "tensor([0.9750, 0.9358])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9906])\n",
      "tensor([0.9330, 0.6646])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9922])\n",
      "tensor([0.9695, 0.7847])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9927])\n",
      "tensor([0.9162, 0.9736])\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9919])\n",
      "tensor([0.9809, 0.9560])\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9911])\n",
      "tensor([0.6608, 0.9484])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9910])\n",
      "tensor([0.9396, 0.9298])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9921])\n",
      "tensor([0.5527, 0.9281])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9916])\n",
      "tensor([0.9832, 0.9353])\n",
      "0\n",
      "1\n",
      "tensor([0.9953, 0.9921])\n",
      "tensor([0.8811, 0.9349])\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9913])\n",
      "tensor([0.4007, 0.9164])\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9912])\n",
      "tensor([0.8836, 0.9513])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9909])\n",
      "tensor([0.3987, 0.8900])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9916])\n",
      "tensor([0.3440, 0.9079])\n",
      "0\n",
      "1\n",
      "tensor([0.9946, 0.9911])\n",
      "tensor([0.9786, 0.8073])\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9912])\n",
      "tensor([0.7901, 0.9513])\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9912])\n",
      "tensor([0.9638, 0.9320])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9917])\n",
      "tensor([0.8085, 0.8964])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9909])\n",
      "tensor([0.7379, 0.9653])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9931])\n",
      "tensor([0.3637, 0.8228])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9935])\n",
      "tensor([0.8360, 0.7727])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9943])\n",
      "tensor([0.3860, 0.8433])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9943])\n",
      "tensor([0.1040, 0.8270])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9931])\n",
      "tensor([0.3097, 0.8081])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9928])\n",
      "tensor([-0.0550,  0.8755])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9928])\n",
      "tensor([0.1943, 0.7694])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9931])\n",
      "tensor([-0.0544,  0.9331])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9936])\n",
      "tensor([0.0773, 0.8771])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9929])\n",
      "tensor([0.1035, 0.9152])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9927])\n",
      "tensor([0.7183, 0.8844])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9927])\n",
      "tensor([0.8288, 0.8067])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9932])\n",
      "tensor([0.8184, 0.8977])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9934])\n",
      "tensor([0.7369, 0.8890])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9929])\n",
      "tensor([0.7051, 0.8441])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9936])\n",
      "tensor([-1.4731,  0.7995])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9924])\n",
      "tensor([-1.3508,  0.8085])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9928])\n",
      "tensor([-4.5654,  0.9393])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9935])\n",
      "tensor([-11.7093,   0.3763])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9932])\n",
      "tensor([-3.7314,  0.9689])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9943])\n",
      "tensor([0.9299, 0.9508])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9941])\n",
      "tensor([0.9355, 0.9568])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9933])\n",
      "tensor([0.9095, 0.9256])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9944])\n",
      "tensor([0.8644, 0.9529])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9942])\n",
      "tensor([0.8321, 0.9546])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9927])\n",
      "tensor([0.9896, 0.9872])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9930])\n",
      "tensor([0.9879, 0.9909])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9931])\n",
      "tensor([0.9891, 0.9793])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9930])\n",
      "tensor([0.8757, 0.9858])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9932])\n",
      "tensor([0.7857, 0.9917])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9926])\n",
      "tensor([0.9608, 0.9806])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9929])\n",
      "tensor([0.9913, 0.9818])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9920])\n",
      "tensor([0.9390, 0.9820])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9938])\n",
      "tensor([0.9369, 0.9672])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9934])\n",
      "tensor([0.9287, 0.9868])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9929])\n",
      "tensor([0.7725, 0.8739])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9924])\n",
      "tensor([0.7695, 0.8984])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9929])\n",
      "tensor([0.7202, 0.9001])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9939])\n",
      "tensor([0.6435, 0.8964])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9942])\n",
      "tensor([0.7661, 0.9050])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9938])\n",
      "tensor([0.7461, 0.7809])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9938])\n",
      "tensor([0.9598, 0.7601])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9932])\n",
      "tensor([0.6998, 0.8042])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9923])\n",
      "tensor([0.9729, 0.4316])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9939])\n",
      "tensor([0.7227, 0.7009])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9926])\n",
      "tensor([0.3495, 0.4136])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9924])\n",
      "tensor([0.6081, 0.5250])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9927])\n",
      "tensor([ 0.2980, -0.1555])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9937])\n",
      "tensor([0.4890, 0.8009])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9938])\n",
      "tensor([0.9738, 0.1975])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9934])\n",
      "tensor([0.9269, 0.7595])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9940])\n",
      "tensor([0.9599, 0.7970])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9937])\n",
      "tensor([0.8799, 0.8026])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9937])\n",
      "tensor([0.9106, 0.5107])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9939])\n",
      "tensor([0.9053, 0.7132])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9926])\n",
      "tensor([0.9823, 0.9819])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9929])\n",
      "tensor([0.9895, 0.9799])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9933])\n",
      "tensor([0.8144, 0.9831])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9940])\n",
      "tensor([0.9736, 0.9738])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9942])\n",
      "tensor([0.9865, 0.9782])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9933])\n",
      "tensor([0.8859, 0.8118])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9930])\n",
      "tensor([0.8197, 0.7772])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9935])\n",
      "tensor([0.8151, 0.8255])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9945])\n",
      "tensor([0.7961, 0.7866])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9941])\n",
      "tensor([0.7855, 0.8126])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9932])\n",
      "tensor([0.9301, 0.9435])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9938])\n",
      "tensor([0.8711, 0.8840])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9927])\n",
      "tensor([0.8243, 0.9349])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9929])\n",
      "tensor([0.8982, 0.8933])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9941])\n",
      "tensor([0.7201, 0.9311])\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9931])\n",
      "tensor([0.9602, 0.9082])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9938])\n",
      "tensor([0.9720, 0.9289])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9944])\n",
      "tensor([0.9618, 0.6292])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9938])\n",
      "tensor([0.9585, 0.6353])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9944])\n",
      "tensor([0.9097, 0.7489])\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9933])\n",
      "tensor([0.9726, 0.9557])\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9932])\n",
      "tensor([0.9810, 0.8787])\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9933])\n",
      "tensor([0.6565, 0.9415])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9935])\n",
      "tensor([0.9789, 0.9430])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9933])\n",
      "tensor([0.9809, 0.9391])\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9928])\n",
      "tensor([0.9088, 0.9557])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9941])\n",
      "tensor([0.9263, 0.8372])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9937])\n",
      "tensor([0.8779, 0.9460])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9933])\n",
      "tensor([0.3585, 0.9085])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9938])\n",
      "tensor([0.4487, 0.9381])\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9929])\n",
      "tensor([0.8432, 0.9631])\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9941])\n",
      "tensor([0.8264, 0.8661])\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9938])\n",
      "tensor([0.9629, 0.9466])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9935])\n",
      "tensor([0.7990, 0.8756])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9932])\n",
      "tensor([0.8556, 0.9541])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9945])\n",
      "tensor([0.0321, 0.8123])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9944])\n",
      "tensor([0.6268, 0.7557])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9949])\n",
      "tensor([0.1875, 0.8118])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9955])\n",
      "tensor([0.1747, 0.8438])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([0.9976, 0.9940])\n",
      "tensor([0.9422, 0.8174])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9945])\n",
      "tensor([-0.1071,  0.9465])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9940])\n",
      "tensor([0.0836, 0.6930])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9945])\n",
      "tensor([0.0063, 0.9210])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9947])\n",
      "tensor([0.0452, 0.9113])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9945])\n",
      "tensor([0.0283, 0.8983])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9940])\n",
      "tensor([0.7812, 0.8844])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9938])\n",
      "tensor([0.7296, 0.7916])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9940])\n",
      "tensor([0.7690, 0.9229])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9940])\n",
      "tensor([0.7240, 0.8251])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9933])\n",
      "tensor([0.7313, 0.8151])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9942])\n",
      "tensor([-2.1478,  0.8216])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9938])\n",
      "tensor([-1.5080,  0.7505])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9944])\n",
      "tensor([-4.7202,  0.8424])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9943])\n",
      "tensor([-9.7628,  0.6818])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9946])\n",
      "tensor([-4.9574,  0.8690])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9954])\n",
      "tensor([0.9214, 0.9519])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9948])\n",
      "tensor([0.9480, 0.9506])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9943])\n",
      "tensor([0.9170, 0.9482])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9957])\n",
      "tensor([0.8648, 0.9444])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9955])\n",
      "tensor([0.9455, 0.9505])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9943])\n",
      "tensor([0.9885, 0.9933])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9923])\n",
      "tensor([0.8844, 0.9496])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9936])\n",
      "tensor([0.8336, 0.9922])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9944])\n",
      "tensor([0.9913, 0.9891])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9947])\n",
      "tensor([0.9922, 0.9908])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9935])\n",
      "tensor([0.9534, 0.9838])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9935])\n",
      "tensor([0.9498, 0.9817])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9934])\n",
      "tensor([0.9905, 0.9839])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9953])\n",
      "tensor([0.9491, 0.9809])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9946])\n",
      "tensor([0.9224, 0.9828])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9942])\n",
      "tensor([0.6839, 0.9114])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9935])\n",
      "tensor([0.8030, 0.8897])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9938])\n",
      "tensor([0.7336, 0.9457])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9943])\n",
      "tensor([0.7082, 0.8719])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9949])\n",
      "tensor([0.7562, 0.9017])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9952])\n",
      "tensor([0.7223, 0.8016])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9928])\n",
      "tensor([0.9665, 0.7953])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9947])\n",
      "tensor([0.6289, 0.7961])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9934])\n",
      "tensor([0.7182, 0.4761])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9948])\n",
      "tensor([0.7129, 0.7224])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9946])\n",
      "tensor([0.4310, 0.1077])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9933])\n",
      "tensor([0.9541, 0.6704])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9934])\n",
      "tensor([ 0.2828, -0.2295])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9946])\n",
      "tensor([0.5233, 0.8368])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9948])\n",
      "tensor([0.5977, 0.1047])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9947])\n",
      "tensor([0.9722, 0.7766])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9946])\n",
      "tensor([0.9648, 0.7229])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9946])\n",
      "tensor([0.8767, 0.7908])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9957])\n",
      "tensor([0.9051, 0.5615])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9953])\n",
      "tensor([0.9103, 0.6941])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9945])\n",
      "tensor([0.9871, 0.9840])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9945])\n",
      "tensor([0.9895, 0.9501])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9946])\n",
      "tensor([0.7909, 0.9810])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9956])\n",
      "tensor([0.9733, 0.9740])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9952])\n",
      "tensor([0.9089, 0.9791])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9947])\n",
      "tensor([0.8818, 0.8503])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9939])\n",
      "tensor([0.9073, 0.7915])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9938])\n",
      "tensor([0.8739, 0.8386])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9955])\n",
      "tensor([0.8900, 0.8076])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9948])\n",
      "tensor([0.8041, 0.8178])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9944])\n",
      "tensor([0.4708, 0.9346])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9946])\n",
      "tensor([0.8766, 0.9112])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9943])\n",
      "tensor([0.8853, 0.9379])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9953])\n",
      "tensor([0.9540, 0.9331])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9951])\n",
      "tensor([0.7104, 0.9413])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9949])\n",
      "tensor([0.9645, 0.9794])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9945])\n",
      "tensor([0.9759, 0.9367])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9947])\n",
      "tensor([0.9572, 0.6191])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9954])\n",
      "tensor([0.9697, 0.7635])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952])\n",
      "tensor([0.9145, 0.7638])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9947])\n",
      "tensor([0.9034, 0.9405])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9947])\n",
      "tensor([0.9839, 0.8989])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9942])\n",
      "tensor([0.9610, 0.9296])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9955])\n",
      "tensor([0.9404, 0.9484])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9948])\n",
      "tensor([0.9783, 0.9439])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9946])\n",
      "tensor([0.8834, 0.9449])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9948])\n",
      "tensor([0.7598, 0.9379])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9948])\n",
      "tensor([0.8861, 0.9277])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9953])\n",
      "tensor([0.4712, 0.8798])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9943])\n",
      "tensor([0.4392, 0.9325])\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9942])\n",
      "tensor([0.9754, 0.9466])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9952])\n",
      "tensor([0.9789, 0.7701])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9947])\n",
      "tensor([0.7999, 0.9486])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9952])\n",
      "tensor([0.9801, 0.9134])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9947])\n",
      "tensor([0.9651, 0.9519])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9957])\n",
      "tensor([0.7784, 0.8178])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9956])\n",
      "tensor([0.8892, 0.7516])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9957])\n",
      "tensor([-0.1038,  0.8089])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9953])\n",
      "tensor([0.8495, 0.8528])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9949])\n",
      "tensor([0.9080, 0.8146])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9953])\n",
      "tensor([-0.0102,  0.9068])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9954])\n",
      "tensor([-0.2261,  0.7592])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9954])\n",
      "tensor([-0.0239,  0.9287])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9953])\n",
      "tensor([-0.0332,  0.9223])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9946])\n",
      "tensor([0.0797, 0.8960])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9952])\n",
      "tensor([0.8173, 0.9114])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9950])\n",
      "tensor([0.8178, 0.7920])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9946])\n",
      "tensor([0.6817, 0.8387])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9950])\n",
      "tensor([0.7268, 0.9214])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9941])\n",
      "tensor([0.7670, 0.8544])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9953])\n",
      "tensor([-4.2347,  0.7930])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9956])\n",
      "tensor([-0.9237,  0.6835])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9949])\n",
      "tensor([-3.5600,  0.7985])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9952])\n",
      "tensor([-11.6298,   0.7634])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9954])\n",
      "tensor([-3.3399,  0.7253])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9961])\n",
      "tensor([0.9345, 0.9486])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9963])\n",
      "tensor([0.9308, 0.9367])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9959])\n",
      "tensor([0.9290, 0.9265])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9959])\n",
      "tensor([0.8522, 0.9438])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9961])\n",
      "tensor([0.9461, 0.9523])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9954])\n",
      "tensor([0.9910, 0.9933])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9952])\n",
      "tensor([0.9901, 0.9906])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9950])\n",
      "tensor([0.8527, 0.9926])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9953])\n",
      "tensor([0.9919, 0.9920])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9948])\n",
      "tensor([0.7965, 0.9896])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9952])\n",
      "tensor([0.9917, 0.9823])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9946])\n",
      "tensor([0.9813, 0.9821])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9948])\n",
      "tensor([0.9296, 0.9797])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9955])\n",
      "tensor([0.9917, 0.9815])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952])\n",
      "tensor([0.9493, 0.9780])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9952])\n",
      "tensor([0.7158, 0.9076])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9942])\n",
      "tensor([0.7350, 0.8885])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9944])\n",
      "tensor([0.7508, 0.9222])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9952])\n",
      "tensor([0.7857, 0.9410])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9948])\n",
      "tensor([0.7382, 0.9077])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9956])\n",
      "tensor([0.9755, 0.7794])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9948])\n",
      "tensor([0.9622, 0.7078])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9951])\n",
      "tensor([0.9498, 0.7544])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9955])\n",
      "tensor([0.6990, 0.7238])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9952])\n",
      "tensor([0.9765, 0.7238])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9957])\n",
      "tensor([0.9264, 0.0997])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9940])\n",
      "tensor([0.5550, 0.6465])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9946])\n",
      "tensor([ 0.3540, -0.3089])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9953])\n",
      "tensor([0.5576, 0.6002])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9948])\n",
      "tensor([0.6321, 0.4194])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9959])\n",
      "tensor([0.9681, 0.7544])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9942])\n",
      "tensor([0.9689, 0.8254])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9953])\n",
      "tensor([0.8903, 0.7641])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9955])\n",
      "tensor([0.9180, 0.6490])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9954])\n",
      "tensor([0.8767, 0.6794])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9959])\n",
      "tensor([0.9867, 0.9849])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9948])\n",
      "tensor([0.9934, 0.9560])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9958])\n",
      "tensor([0.9846, 0.9822])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952])\n",
      "tensor([0.9679, 0.9801])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9955])\n",
      "tensor([0.9906, 0.9777])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9956])\n",
      "tensor([0.8662, 0.8301])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9951])\n",
      "tensor([0.9033, 0.7605])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9951])\n",
      "tensor([0.8904, 0.8289])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9954])\n",
      "tensor([0.8825, 0.8032])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9948])\n",
      "tensor([0.8885, 0.8323])\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9977, 0.9949])\n",
      "tensor([0.6082, 0.9385])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9953])\n",
      "tensor([0.8993, 0.9326])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9952])\n",
      "tensor([0.8831, 0.9354])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9953])\n",
      "tensor([0.9500, 0.9183])\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9952])\n",
      "tensor([0.6486, 0.9397])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9957])\n",
      "tensor([0.9595, 0.9249])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952])\n",
      "tensor([0.9696, 0.7440])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9957])\n",
      "tensor([0.9122, 0.8083])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9954])\n",
      "tensor([0.9707, 0.7318])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9961])\n",
      "tensor([0.9334, 0.7433])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9954])\n",
      "tensor([0.9689, 0.9407])\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9953])\n",
      "tensor([0.9844, 0.9549])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9952])\n",
      "tensor([0.9697, 0.9332])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9947])\n",
      "tensor([0.9792, 0.9329])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9950])\n",
      "tensor([0.9766, 0.9394])\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9955])\n",
      "tensor([0.8826, 0.9503])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9955])\n",
      "tensor([0.9409, 0.9527])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9952])\n",
      "tensor([0.9168, 0.9119])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9953])\n",
      "tensor([0.4292, 0.9207])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9952])\n",
      "tensor([0.8505, 0.9204])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9952])\n",
      "tensor([0.9810, 0.9419])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9954])\n",
      "tensor([0.9749, 0.8420])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9953])\n",
      "tensor([0.9731, 0.9495])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9951])\n",
      "tensor([0.8705, 0.9321])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9952])\n",
      "tensor([0.8648, 0.9274])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9962])\n",
      "tensor([0.8847, 0.7939])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9961])\n",
      "tensor([0.8909, 0.7580])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9963])\n",
      "tensor([-0.1455,  0.8394])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9960])\n",
      "tensor([0.8416, 0.8352])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9958])\n",
      "tensor([0.8679, 0.8073])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9959])\n",
      "tensor([0.0110, 0.9291])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9965])\n",
      "tensor([-0.1372,  0.7872])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9961])\n",
      "tensor([-0.0558,  0.8878])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9955])\n",
      "tensor([0.0143, 0.9208])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9957])\n",
      "tensor([0.1349, 0.8913])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9957])\n",
      "tensor([0.7975, 0.9050])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9947])\n",
      "tensor([0.7993, 0.8529])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9960])\n",
      "tensor([0.6323, 0.9101])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9945])\n",
      "tensor([0.7477, 0.8022])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9950])\n",
      "tensor([0.7729, 0.8596])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9954])\n",
      "tensor([-8.4122,  0.7326])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9960])\n",
      "tensor([-4.8760,  0.6926])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9960])\n",
      "tensor([-3.8419,  0.6882])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9957])\n",
      "tensor([-1.7112,  0.7069])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9960])\n",
      "tensor([-3.1606,  0.5764])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9959])\n",
      "tensor([0.9491, 0.9420])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9964])\n",
      "tensor([0.9342, 0.9500])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9960])\n",
      "tensor([0.9322, 0.9500])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9965])\n",
      "tensor([0.9266, 0.9393])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9966])\n",
      "tensor([0.9472, 0.9488])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9950])\n",
      "tensor([0.9907, 0.9933])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9956])\n",
      "tensor([0.9917, 0.9923])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9954])\n",
      "tensor([0.9916, 0.9941])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9959])\n",
      "tensor([0.9826, 0.9927])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9953])\n",
      "tensor([0.9930, 0.9889])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9951])\n",
      "tensor([0.9932, 0.9812])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9952])\n",
      "tensor([0.9868, 0.9841])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9955])\n",
      "tensor([0.9897, 0.9796])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9959])\n",
      "tensor([0.9470, 0.9796])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9957])\n",
      "tensor([0.9848, 0.9776])\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9956])\n",
      "tensor([0.7669, 0.8995])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9947])\n",
      "tensor([0.6838, 0.8938])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9957])\n",
      "tensor([0.7178, 0.9354])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9959])\n",
      "tensor([0.7370, 0.9460])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9956])\n",
      "tensor([0.6811, 0.9200])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9958])\n",
      "tensor([0.9812, 0.7308])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9956])\n",
      "tensor([0.6175, 0.7357])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9959])\n",
      "tensor([0.5962, 0.7011])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9962])\n",
      "tensor([0.7130, 0.7032])\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9958])\n",
      "tensor([0.6507, 0.7317])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9958])\n",
      "tensor([0.9132, 0.1501])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9947])\n",
      "tensor([0.9668, 0.6446])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9951])\n",
      "tensor([0.3990, 0.2846])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9958])\n",
      "tensor([0.4376, 0.8984])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9957])\n",
      "tensor([0.6805, 0.3767])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9961])\n",
      "tensor([0.9650, 0.7122])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9952])\n",
      "tensor([0.9743, 0.7625])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9960])\n",
      "tensor([0.9349, 0.5818])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9961])\n",
      "tensor([0.9189, 0.5915])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9960])\n",
      "tensor([0.8950, 0.7252])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9959])\n",
      "tensor([0.9874, 0.9833])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9954])\n",
      "tensor([0.9931, 0.9505])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9961])\n",
      "tensor([0.9801, 0.9775])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9959])\n",
      "tensor([0.9911, 0.9814])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9957])\n",
      "tensor([0.9920, 0.9786])\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9958])\n",
      "tensor([0.8930, 0.8118])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9952])\n",
      "tensor([0.8659, 0.7513])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9957])\n",
      "tensor([0.8995, 0.7853])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9960])\n",
      "tensor([0.8976, 0.7991])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9958])\n",
      "tensor([0.8839, 0.8132])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9954])\n",
      "tensor([0.9508, 0.9431])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9959])\n",
      "tensor([0.9299, 0.9362])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9955])\n",
      "tensor([0.9506, 0.9304])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9959])\n",
      "tensor([0.9576, 0.9299])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9958])\n",
      "tensor([0.9649, 0.9147])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9957])\n",
      "tensor([0.9673, 0.9062])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9955])\n",
      "tensor([0.9442, 0.6252])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9958])\n",
      "tensor([0.9205, 0.7490])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9958])\n",
      "tensor([0.9468, 0.7006])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9959])\n",
      "tensor([0.9454, 0.7378])\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9955])\n",
      "tensor([0.9688, 0.9514])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9958])\n",
      "tensor([0.9784, 0.9547])\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9954])\n",
      "tensor([0.9707, 0.9351])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9958])\n",
      "tensor([0.9459, 0.9459])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9957])\n",
      "tensor([0.9735, 0.9306])\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9953])\n",
      "tensor([0.9003, 0.9611])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9959])\n",
      "tensor([0.9003, 0.9608])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9956])\n",
      "tensor([0.8905, 0.8847])\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9952])\n",
      "tensor([0.8997, 0.9169])\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9955])\n",
      "tensor([0.5170, 0.9498])\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952])\n",
      "tensor([0.9789, 0.9385])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9959])\n",
      "tensor([0.7906, 0.9350])\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9956])\n",
      "tensor([0.9752, 0.9492])\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9959])\n",
      "tensor([0.8388, 0.9221])\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9958])\n",
      "tensor([0.9086, 0.9171])\n"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "train_p = np.linspace(100,800,8)\n",
    "R2_test = torch.zeros(len(train_p),reps,len(meshes),2)\n",
    "R2_leftout= torch.zeros(len(train_p),reps,len(meshes),2)\n",
    "for k in range(len(train_p)):\n",
    "    for i in range(len(meshes)):\n",
    "        for j in range(reps):\n",
    "            X=torch.cat(train_input_modes[0:i]+train_input_modes[i+1:])[:,0:16]\n",
    "            y=torch.cat(train_output_modes[:i]+train_output_modes[i+1:])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X,\n",
    "                y,\n",
    "                train_size=int(train_p[k]),\n",
    "                random_state=j\n",
    "            )\n",
    "            X_test= torch.cat(test_input_modes[0:i]+test_input_modes[i+1:])[:,0:16]\n",
    "            y_test=torch.cat(test_output_modes[:i]+test_output_modes[i+1:])\n",
    "            emulator=GPE.ensemble(X_train,y_train,mean_func=\"linear\",training_iter=1000)\n",
    "\n",
    "            meanR, stdR = meanR, stdR = emulator.R2_sample(X_test,y_test,1000)\n",
    "            R2_test[k,j,i,:]=meanR\n",
    "\n",
    "            meanR, stdR=emulator.R2_sample(test_input_modes[i][:,0:16],test_output_modes[i],1000) \n",
    "            R2_leftout[k,j,i,:] = meanR\n",
    "            print(R2_test[k,j,i,:])\n",
    "            print(R2_leftout[k,j,i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "684e7db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bd8839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.9342,  0.9279])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1283f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "796ab181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_test.mean(axis=[1,2])[:8,0].detach().numpy(),fmt='o',yerr=R2_test.std(axis=[1,2])[:8,0].detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_test.mean(axis=[1,2])[:8,1].detach().numpy(),fmt='o',yerr=R2_test.std(axis=[1,2])[:8,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Training Points')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "401de880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_leftout.mean(axis=[1,2])[:8,0].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=[1,2])[:8,0].detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_leftout.mean(axis=[1,2])[:8,1].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=[1,2])[:8,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Training Points')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b4934a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "me=3\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_leftout[:,:,me].mean(axis=1)[:8,0].detach().numpy(),fmt='o',yerr=R2_leftout[:,:,me].std(axis=1)[:8,0].detach().numpy())\n",
    "plt.errorbar(train_p[:8],R2_leftout[:,:,me].mean(axis=1)[:8,1].detach().numpy(),fmt='o',yerr=R2_leftout[:,:,me].std(axis=1)[:8,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Training Points')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58e4d7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100.,  200.,  300.,  400.,  500.,  600.,  700.,  800.,  900.,\n",
       "       1000.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9e632a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 18, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_leftout.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e88b3667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6679, -0.0066,  0.7499, -4.4004,  0.9379,  0.9899,  0.9803,  0.7173,\n",
       "         0.7117,  0.6794,  0.9376,  0.9887,  0.8880,  0.9508,  0.9448,  0.9674,\n",
       "         0.8215,  0.8984])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_leftout.mean(axis=1)[7,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6df877d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(meshes,R2_leftout.mean(axis=1)[7,:,0].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=1)[7,:,0].detach().numpy())\n",
    "plt.errorbar(meshes,R2_leftout.mean(axis=1)[7,:,1].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=1)[7,:,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Mesh')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d021bf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.9977, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.9977, 0.9954],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.9977, 0.9954],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.9977, 0.9954],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9983, 0.9958],\n",
      "         [0.0000, 0.0000]]])\n",
      "0\n",
      "1\n",
      "tensor([[[0.9981, 0.9964],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9982, 0.9959],\n",
      "         [0.9985, 0.9963],\n",
      "         [0.9984, 0.9958],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9983, 0.9947],\n",
      "         [0.9981, 0.9957]],\n",
      "\n",
      "        [[0.9984, 0.9956],\n",
      "         [0.9984, 0.9960],\n",
      "         [0.9983, 0.9959],\n",
      "         [0.9984, 0.9955],\n",
      "         [0.9982, 0.9960]],\n",
      "\n",
      "        [[0.9981, 0.9960],\n",
      "         [0.9984, 0.9964],\n",
      "         [0.9982, 0.9965],\n",
      "         [0.9982, 0.9964],\n",
      "         [0.9983, 0.9962]],\n",
      "\n",
      "        [[0.9981, 0.9951],\n",
      "         [0.9984, 0.9956],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9984, 0.9957]],\n",
      "\n",
      "        [[0.9982, 0.9954],\n",
      "         [0.9983, 0.9949],\n",
      "         [0.9981, 0.9955],\n",
      "         [0.9984, 0.9961],\n",
      "         [0.9983, 0.9956]],\n",
      "\n",
      "        [[0.9978, 0.9952],\n",
      "         [0.9985, 0.9947],\n",
      "         [0.9983, 0.9957],\n",
      "         [0.9984, 0.9957],\n",
      "         [0.9981, 0.9953]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9983, 0.9952],\n",
      "         [0.9982, 0.9959],\n",
      "         [0.9981, 0.9960],\n",
      "         [0.9984, 0.9954]],\n",
      "\n",
      "        [[0.9978, 0.9957],\n",
      "         [0.9982, 0.9946],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9984, 0.9956]],\n",
      "\n",
      "        [[0.9981, 0.9962],\n",
      "         [0.9982, 0.9947],\n",
      "         [0.9981, 0.9961],\n",
      "         [0.9984, 0.9962],\n",
      "         [0.9980, 0.9960]],\n",
      "\n",
      "        [[0.9977, 0.9962],\n",
      "         [0.9982, 0.9956],\n",
      "         [0.9982, 0.9962],\n",
      "         [0.9985, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9978, 0.9958],\n",
      "         [0.9983, 0.9951],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9961],\n",
      "         [0.9983, 0.9958]],\n",
      "\n",
      "        [[0.9978, 0.9951],\n",
      "         [0.9982, 0.9958],\n",
      "         [0.9982, 0.9957],\n",
      "         [0.9982, 0.9960],\n",
      "         [0.9982, 0.9959]],\n",
      "\n",
      "        [[0.9980, 0.9959],\n",
      "         [0.9982, 0.9955],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9983, 0.9964]],\n",
      "\n",
      "        [[0.9977, 0.9955],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9979, 0.9953],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9957]],\n",
      "\n",
      "        [[0.9975, 0.9954],\n",
      "         [0.9981, 0.9959],\n",
      "         [0.9980, 0.9957],\n",
      "         [0.9983, 0.9956],\n",
      "         [0.9982, 0.9958]],\n",
      "\n",
      "        [[0.9977, 0.9954],\n",
      "         [0.9983, 0.9961],\n",
      "         [0.9981, 0.9954],\n",
      "         [0.9983, 0.9958],\n",
      "         [0.9983, 0.9957]]])\n"
     ]
    }
   ],
   "source": [
    "reps = 5\n",
    "\n",
    "R2_test = torch.zeros(len(meshes),reps,2)\n",
    "R2_leftout= torch.zeros(len(meshes),reps,2)\n",
    "for i in range(len(meshes)):\n",
    "    for j in range(reps):\n",
    "        X=torch.cat(train_input_modes[0:i]+train_input_modes[i+1:])[:,0:16]\n",
    "        y=torch.cat(train_output_modes[:i]+train_output_modes[i+1:])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=800,\n",
    "            random_state=j\n",
    "        )\n",
    "        X_test= torch.cat(test_input_modes[0:i]+test_input_modes[i+1:])[:,0:16]\n",
    "        y_test=torch.cat(test_output_modes[:i]+test_output_modes[i+1:])\n",
    "        emulator=GPE.ensemble(X_train,y_train,mean_func=\"linear\",training_iter=1000)\n",
    "        \n",
    "        meanR, stdR = emulator.R2_sample(X_test,y_test,1000)\n",
    "        \n",
    "        R2_test[i,j,:]=meanR\n",
    "        \n",
    "        meanR, stdR=emulator.R2_sample(test_input_modes[i][:,0:16],test_output_modes[i],1000) \n",
    "        R2_leftout[i,j,:] = meanR\n",
    "        print(R2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ece5301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(meshes,R2_test.mean(axis=1)[:,0].detach().numpy(),fmt='o',yerr=R2_test.std(axis=1)[:,0].detach().numpy())\n",
    "plt.errorbar(meshes,R2_test.mean(axis=1)[:,1].detach().numpy(),fmt='o',yerr=R2_test.std(axis=1)[:,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Mesh')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a278048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dee6d54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 5, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36d99a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17858fcd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "#plt.plot(t_size,R2.mean(axis=1).detach().numpy())\n",
    "plt.errorbar(meshes,R2_leftout.mean(axis=1)[:,0].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=1)[:,0].detach().numpy())\n",
    "plt.errorbar(meshes,R2_leftout.mean(axis=1)[:,1].detach().numpy(),fmt='o',yerr=R2_leftout.std(axis=1)[:,1].detach().numpy())\n",
    "plt.legend(('A_TAT','V_TAT'))\n",
    "plt.xlabel('Mesh')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.legend(['A_TAT','V_TAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0c7726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9938008, 0.9939864], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(R2_leftout),axis=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fb7a5",
   "metadata": {},
   "source": [
    "# Discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fafeff3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " value = ('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-13.3014], requires_grad=True))\n",
      " value = ('covar_module.raw_outputscale', Parameter containing:\n",
      "tensor(0.7227, requires_grad=True))\n",
      " value = ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
      "tensor([[35.7926, 31.0921, 36.7859,  1.3546,  6.6028,  1.7258]],\n",
      "       requires_grad=True))\n",
      " value = ('mean_module.weights', Parameter containing:\n",
      "tensor([[ 0.0057],\n",
      "        [-0.0066],\n",
      "        [ 0.0020],\n",
      "        [-1.9271],\n",
      "        [-0.2774],\n",
      "        [-0.7203]], requires_grad=True))\n",
      " value = ('mean_module.bias', Parameter containing:\n",
      "tensor([2.6332], requires_grad=True))\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[5.0725e+03, 1.8434e+03],\n",
       "         [6.1528e+03, 2.5492e+02],\n",
       "         [4.5062e+03, 6.3526e+02],\n",
       "         [5.9133e+03, 4.4856e+01],\n",
       "         [4.4736e+03, 3.6228e+03]],\n",
       "\n",
       "        [[6.5894e+02, 2.0790e+01],\n",
       "         [5.7574e+01, 1.8839e+01],\n",
       "         [1.0801e+02, 1.2706e+01],\n",
       "         [6.4082e+02, 5.6617e+01],\n",
       "         [1.1996e+02, 3.1628e+01]],\n",
       "\n",
       "        [[3.6089e+01, 1.4953e+01],\n",
       "         [6.1920e+01, 4.8956e+00],\n",
       "         [1.6878e+01, 4.1464e+00],\n",
       "         [6.1193e+01, 4.7720e+00],\n",
       "         [3.9449e+01, 8.2081e+00]],\n",
       "\n",
       "        [[2.7546e+01, 2.1954e+00],\n",
       "         [3.9185e+01, 1.4219e+01],\n",
       "         [2.2553e+01, 1.4319e+01],\n",
       "         [1.1794e+01, 3.3993e+00],\n",
       "         [2.0645e+01, 1.0223e+01]],\n",
       "\n",
       "        [[8.3327e+01, 4.4930e+00],\n",
       "         [1.2805e+01, 8.0375e+00],\n",
       "         [3.4425e+01, 1.2978e+00],\n",
       "         [7.8243e+01, 2.0428e+00],\n",
       "         [5.5748e+00, 1.5769e+00]],\n",
       "\n",
       "        [[6.0207e+01, 2.8806e+00],\n",
       "         [1.9772e+01, 5.5428e+00],\n",
       "         [5.8959e+00, 1.2996e+00],\n",
       "         [2.0252e+01, 1.6549e+00],\n",
       "         [6.4252e+00, 3.0435e+00]],\n",
       "\n",
       "        [[4.0662e+01, 1.4028e+00],\n",
       "         [1.0967e+01, 1.4525e+00],\n",
       "         [2.1050e+01, 2.2928e+00],\n",
       "         [8.9891e+00, 1.9755e+00],\n",
       "         [4.5896e+00, 1.5196e+00]],\n",
       "\n",
       "        [[4.5053e+00, 2.4041e+00],\n",
       "         [4.7680e+00, 2.5436e+00],\n",
       "         [1.2523e+01, 3.2851e+00],\n",
       "         [4.9651e+00, 1.2510e+00],\n",
       "         [3.7066e+00, 1.7758e+00]],\n",
       "\n",
       "        [[3.6862e+00, 1.4337e+00],\n",
       "         [5.4355e+00, 1.1790e+00],\n",
       "         [6.0894e+00, 1.5080e+00],\n",
       "         [1.7904e+01, 2.1378e+00],\n",
       "         [2.3015e+01, 1.3173e+00]],\n",
       "\n",
       "        [[6.5362e+00, 1.4928e+00],\n",
       "         [3.6299e+00, 1.2970e+00],\n",
       "         [3.3388e+00, 3.8363e+00],\n",
       "         [1.7405e+01, 1.1149e+00],\n",
       "         [8.4596e+00, 1.5875e+00]],\n",
       "\n",
       "        [[3.6113e+00, 2.6417e+00],\n",
       "         [5.1998e+00, 9.2142e-01],\n",
       "         [4.2592e+00, 3.7868e+00],\n",
       "         [8.3963e+00, 1.0469e+00],\n",
       "         [5.0503e+00, 2.4980e+00]],\n",
       "\n",
       "        [[3.7325e+00, 8.5427e-01],\n",
       "         [6.4716e+00, 1.0518e+00],\n",
       "         [3.6329e+00, 1.5623e+00],\n",
       "         [2.9487e+00, 1.3345e+00],\n",
       "         [3.3767e+00, 2.4115e+00]],\n",
       "\n",
       "        [[3.1004e+00, 1.1642e+00],\n",
       "         [4.8493e+00, 1.2632e+00],\n",
       "         [3.6399e+00, 8.3803e-01],\n",
       "         [9.0938e+00, 1.0128e+00],\n",
       "         [4.9936e+00, 1.4099e+00]],\n",
       "\n",
       "        [[6.3955e+00, 3.6341e+00],\n",
       "         [2.2352e+00, 3.3367e+00],\n",
       "         [5.0627e+00, 1.9650e+00],\n",
       "         [4.8827e+00, 1.0089e+00],\n",
       "         [3.2560e+00, 2.3398e+00]],\n",
       "\n",
       "        [[5.6860e+00, 9.1723e-01],\n",
       "         [3.8452e+00, 1.3427e+00],\n",
       "         [3.9831e+00, 9.7216e-01],\n",
       "         [4.9556e+00, 9.9155e-01],\n",
       "         [4.4791e+00, 1.0080e+00]],\n",
       "\n",
       "        [[3.2796e+00, 1.5614e+00],\n",
       "         [3.0889e+00, 1.0217e+00],\n",
       "         [3.5263e+00, 1.4452e+00],\n",
       "         [3.8653e+00, 1.3947e+00],\n",
       "         [2.7969e+00, 1.0241e+00]],\n",
       "\n",
       "        [[3.3200e+00, 9.4526e-01],\n",
       "         [5.5836e+00, 1.0210e+00],\n",
       "         [6.5319e+00, 1.0105e+00],\n",
       "         [5.7469e+00, 1.7324e+00],\n",
       "         [4.7765e+00, 8.4502e-01]],\n",
       "\n",
       "        [[2.1502e+00, 8.3605e-01],\n",
       "         [3.6266e+00, 1.8729e+00],\n",
       "         [4.7920e+00, 8.9507e-01],\n",
       "         [3.7660e+00, 1.1739e+00],\n",
       "         [4.8378e+00, 1.3519e+00]],\n",
       "\n",
       "        [[3.4487e+00, 8.5717e-01],\n",
       "         [4.3862e+00, 9.1816e-01],\n",
       "         [6.1433e+00, 9.3985e-01],\n",
       "         [2.8942e+00, 1.0826e+00],\n",
       "         [2.1732e+00, 8.9547e-01]],\n",
       "\n",
       "        [[2.7066e+00, 8.2020e-01],\n",
       "         [2.4610e+00, 1.2872e+00],\n",
       "         [3.1087e+00, 8.6970e-01],\n",
       "         [5.7612e+00, 9.5005e-01],\n",
       "         [2.6301e+00, 7.9931e-01]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/input/xlabels_EP.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "# y_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/output/ylabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "# y_labels\n",
    "\n",
    "# inputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/01/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "# outputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/01/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "# inputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/02/X_EP.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "# outputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/EP_healthy/02/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "X0 = train_input[0]\n",
    "Y0 = train_output[0]\n",
    "X1 = train_input[1]\n",
    "Y1 = train_output[1]\n",
    "\n",
    "\n",
    "for param in emulators[0].models[0].named_parameters():\n",
    "    print(f' value = {param}')\n",
    "\n",
    "# split original dataset in training, validation and testing sets\n",
    "X_train=X0\n",
    "y_train=Y0\n",
    "X_test=test_input[0]\n",
    "y_test=test_output[0]\n",
    "\n",
    "p = int(X1.shape[0]*0.05)\n",
    "n = int(X_train.shape[0]/p)\n",
    "reps = 5\n",
    "MSE = torch.zeros((n,reps,2))\n",
    "R2 = torch.zeros((n,reps,2))\n",
    "MSE_p = torch.zeros((n,reps,2))\n",
    "R2_p = torch.zeros((n,reps,2))\n",
    "MSEa = torch.zeros((n,reps,2))\n",
    "R2a = torch.zeros((n,reps,2))\n",
    "for i in range(n):\n",
    "    for j in range(reps):\n",
    "        a=np.random.choice(range(X_train.shape[0]),(i+1)*p,replace=False)\n",
    "        m0 = emulators[0].predict(X_train[a,:])\n",
    "#         y_adjust = torch.tensor(y_train[a] - m0)\n",
    "#         delta_1 = GPE.ensemble(X_train[a,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "#         MSE[i,j] += ((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy()\n",
    "#         R2[i,j] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-y_test)**2).mean(axis=0)/y_test.var(axis=0)).detach().numpy()\n",
    "        \n",
    "        \n",
    "        delta_1=GPE.ensemble(X_train[a,:],y_train[a],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators[1:],a=None)\n",
    "        MSEaM,MSEaSTD = delta_1.MSE_sample(X_test,y_test,1000)\n",
    "        R2aM,R2aSTD = delta_1.R2_sample(X_test,y_test,1000)\n",
    "        \n",
    "        MSE[i,j] += MSEaM\n",
    "        R2[i,j] += R2aM\n",
    "        \n",
    "        \n",
    "        delta_1=GPE.ensemble(X_train[a,:],y_train[a],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators[1]],a=None)\n",
    "        MSEaM,MSEaSTD = delta_1.MSE_sample(X_test,y_test,1000)\n",
    "        R2aM,R2aSTD = delta_1.R2_sample(X_test,y_test,1000)\n",
    "        \n",
    "        MSEa[i,j] += MSEaM\n",
    "        R2a[i,j] += R2aM\n",
    "        \n",
    "        delta_1p = GPE.ensemble(X_train[a,:],y_train[a],mean_func=\"linear\",training_iter=500)\n",
    "        MSEaM,MSEaSTD = delta_1p.MSE_sample(X_test,y_test,1000)\n",
    "        R2aM,R2aSTD = delta_1p.R2_sample(X_test,y_test,1000)\n",
    "        \n",
    "        MSE_p[i,j] += MSEaM\n",
    "        R2_p[i,j] += R2aM\n",
    "\n",
    "x = np.linspace(9,162,18)\n",
    "\n",
    "x\n",
    "\n",
    "MSE.mean(axis=1)[0]\n",
    "\n",
    "MSE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "586b4eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e86b9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbff548f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ed33931",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(7,144,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2afc7fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,MSE.mean(axis=1))\n",
    "plt.fill_between(x, MSE.mean(axis=1)[:,0]+MSE.std(axis=1)[:,0], y2=MSE.mean(axis=1)[:,0]-MSE.std(axis=1)[:,0],alpha=0.4)\n",
    "plt.fill_between(x, MSE.mean(axis=1)[:,1]+MSE.std(axis=1)[:,1], y2=MSE.mean(axis=1)[:,1]-MSE.std(axis=1)[:,1],alpha=0.4)\n",
    "plt.legend(y_labels.values)\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ea26be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0672e+04, 4.9921e+03],\n",
       "         [1.3724e+04, 2.4195e+02],\n",
       "         [1.0002e+04, 3.6872e+02],\n",
       "         [1.6555e+04, 1.5175e+02],\n",
       "         [2.4985e+03, 6.2443e+02]],\n",
       "\n",
       "        [[8.7861e+02, 2.2815e+02],\n",
       "         [2.6593e+02, 1.0157e+02],\n",
       "         [4.5729e+02, 9.9715e+01],\n",
       "         [1.7334e+02, 2.3831e+02],\n",
       "         [3.1022e+02, 1.0330e+02]],\n",
       "\n",
       "        [[1.0312e+02, 2.7501e+01],\n",
       "         [8.0002e+02, 6.7234e+01],\n",
       "         [1.1714e+02, 1.3610e+02],\n",
       "         [6.5656e+02, 5.0196e+01],\n",
       "         [2.5417e+02, 1.2410e+02]],\n",
       "\n",
       "        [[6.3947e+01, 3.3470e+01],\n",
       "         [6.3925e+01, 1.2823e+02],\n",
       "         [5.8746e+01, 1.8288e+01],\n",
       "         [8.8181e+01, 2.3680e+01],\n",
       "         [4.4960e+01, 2.7236e+01]],\n",
       "\n",
       "        [[5.4529e+01, 1.9058e+01],\n",
       "         [5.4628e+01, 2.7886e+01],\n",
       "         [4.0131e+01, 1.5516e+01],\n",
       "         [2.7684e+01, 2.2534e+01],\n",
       "         [2.9996e+01, 1.5637e+01]],\n",
       "\n",
       "        [[4.3661e+01, 1.2426e+01],\n",
       "         [3.6535e+01, 7.8772e+00],\n",
       "         [4.2623e+01, 8.6398e+00],\n",
       "         [3.7254e+01, 1.3632e+01],\n",
       "         [2.1918e+01, 1.6222e+01]],\n",
       "\n",
       "        [[2.9064e+01, 7.6176e+00],\n",
       "         [2.3208e+01, 2.0309e+01],\n",
       "         [2.3379e+01, 6.0915e+00],\n",
       "         [6.9917e+01, 1.6236e+01],\n",
       "         [1.9802e+01, 1.0295e+01]],\n",
       "\n",
       "        [[1.5461e+01, 5.2669e+00],\n",
       "         [1.2215e+01, 1.2644e+01],\n",
       "         [1.6883e+01, 6.5634e+00],\n",
       "         [1.0905e+01, 6.7230e+00],\n",
       "         [1.6817e+01, 5.0006e+00]],\n",
       "\n",
       "        [[7.4070e+00, 5.4648e+00],\n",
       "         [2.4368e+01, 3.4472e+00],\n",
       "         [1.8906e+01, 5.3056e+00],\n",
       "         [2.2968e+01, 8.0626e+00],\n",
       "         [2.1206e+01, 5.6157e+00]],\n",
       "\n",
       "        [[1.6160e+01, 4.6227e+00],\n",
       "         [8.1695e+00, 3.5326e+00],\n",
       "         [9.0958e+00, 4.8422e+00],\n",
       "         [1.6007e+01, 6.1708e+00],\n",
       "         [1.8073e+01, 3.9466e+00]],\n",
       "\n",
       "        [[8.5441e+00, 5.8140e+00],\n",
       "         [1.1116e+01, 3.3362e+00],\n",
       "         [1.3378e+01, 9.5248e+00],\n",
       "         [8.1889e+00, 3.3801e+00],\n",
       "         [1.2963e+01, 2.9572e+00]],\n",
       "\n",
       "        [[8.8990e+00, 2.5929e+00],\n",
       "         [8.5235e+00, 2.1811e+00],\n",
       "         [1.5826e+01, 2.8536e+00],\n",
       "         [1.4269e+01, 6.3662e+00],\n",
       "         [1.0540e+01, 3.7591e+00]],\n",
       "\n",
       "        [[5.6638e+00, 2.9167e+00],\n",
       "         [7.5222e+00, 1.9237e+00],\n",
       "         [8.7420e+00, 2.4471e+00],\n",
       "         [1.1118e+01, 3.1438e+00],\n",
       "         [1.1563e+01, 3.2174e+00]],\n",
       "\n",
       "        [[1.3508e+01, 3.5558e+00],\n",
       "         [6.7779e+00, 4.9712e+00],\n",
       "         [1.4114e+01, 3.9213e+00],\n",
       "         [8.9607e+00, 2.4728e+00],\n",
       "         [9.1598e+00, 3.7761e+00]],\n",
       "\n",
       "        [[7.4005e+00, 1.9895e+00],\n",
       "         [8.2837e+00, 2.6488e+00],\n",
       "         [8.2263e+00, 2.6847e+00],\n",
       "         [1.1497e+01, 2.6768e+00],\n",
       "         [1.3140e+01, 2.3763e+00]],\n",
       "\n",
       "        [[1.1721e+01, 2.9037e+00],\n",
       "         [6.2106e+00, 1.7887e+00],\n",
       "         [8.7450e+00, 2.4938e+00],\n",
       "         [5.2537e+00, 2.5977e+00],\n",
       "         [7.0520e+00, 2.0230e+00]],\n",
       "\n",
       "        [[7.0178e+00, 1.8864e+00],\n",
       "         [7.3107e+00, 2.2965e+00],\n",
       "         [8.7586e+00, 2.1929e+00],\n",
       "         [9.2949e+00, 2.5079e+00],\n",
       "         [8.2287e+00, 2.1502e+00]],\n",
       "\n",
       "        [[5.8938e+00, 1.6506e+00],\n",
       "         [5.2628e+00, 2.4603e+00],\n",
       "         [5.9196e+00, 2.3918e+00],\n",
       "         [5.8018e+00, 2.1803e+00],\n",
       "         [5.8016e+00, 2.6568e+00]],\n",
       "\n",
       "        [[8.5909e+00, 1.6419e+00],\n",
       "         [5.5615e+00, 2.0330e+00],\n",
       "         [4.5525e+00, 1.7591e+00],\n",
       "         [4.4047e+00, 2.2535e+00],\n",
       "         [4.9686e+00, 1.9856e+00]],\n",
       "\n",
       "        [[4.5665e+00, 1.6299e+00],\n",
       "         [4.6916e+00, 2.0304e+00],\n",
       "         [4.8833e+00, 1.6283e+00],\n",
       "         [5.2080e+00, 1.9807e+00],\n",
       "         [4.4993e+00, 2.0396e+00]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE.mean(axis=1)[:,0]+MSE.std(axis=1)[:,0]\n",
    "\n",
    "MSE.mean(axis=1)[:,0]-MSE.std(axis=1)[:,0]\n",
    "\n",
    "delta_1p.MSE(X_test,y_test)/reps\n",
    "\n",
    "plt.plot(x,MSE.mean(axis=1),'o') \n",
    "plt.legend(y_labels.values)\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')\n",
    "\n",
    "np.hstack((MSE_p,MSE))\n",
    "\n",
    "MSE_p.mean(axis=1)[:,0]+MSE_p.std(axis=1)[:,0]\n",
    "\n",
    "MSE_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e880643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2721e+03, 2.0851e+03],\n",
       "        [2.7762e+02, 7.2236e+01],\n",
       "        [3.2183e+02, 4.7152e+01],\n",
       "        [1.5611e+01, 4.6197e+01],\n",
       "        [1.2915e+01, 5.2097e+00],\n",
       "        [8.6879e+00, 3.4881e+00],\n",
       "        [2.0862e+01, 5.9990e+00],\n",
       "        [2.7435e+00, 3.1159e+00],\n",
       "        [6.7792e+00, 1.6433e+00],\n",
       "        [4.5300e+00, 1.0112e+00],\n",
       "        [2.4147e+00, 2.7704e+00],\n",
       "        [3.2736e+00, 1.6770e+00],\n",
       "        [2.4700e+00, 5.4172e-01],\n",
       "        [3.1673e+00, 8.9301e-01],\n",
       "        [2.4765e+00, 3.0016e-01],\n",
       "        [2.5415e+00, 4.4996e-01],\n",
       "        [9.5786e-01, 2.2624e-01],\n",
       "        [2.6981e-01, 3.8483e-01],\n",
       "        [1.7227e+00, 2.4003e-01],\n",
       "        [2.8525e-01, 2.1356e-01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_p.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c80519db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([139.4554,  64.3709,  48.3408,  28.4792,  27.7102,  12.2115,  11.7126,\n",
       "         12.1917,   8.9710,   8.4233,   8.3378,   6.4518,   7.3367,   7.2331,\n",
       "          5.2549,   7.1643,   5.4661,   3.8930,   4.4845])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_p.mean(axis=1)[1:,0]-MSE_p.std(axis=1)[1:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a8961da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1),MSEa.mean(axis=1)))[1:,[0,2,4]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,0]+MSE.std(axis=1)[1:,0], y2=MSE.mean(axis=1)[1:,0]-MSE.std(axis=1)[1:,0],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,0]+MSE_p.std(axis=1)[1:,0], y2=MSE_p.mean(axis=1)[1:,0]-MSE_p.std(axis=1)[1:,0],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSEa.mean(axis=1)[1:,0]+MSEa.std(axis=1)[1:,0], y2=MSEa.mean(axis=1)[1:,0]-MSEa.std(axis=1)[1:,0],alpha=0.4)\n",
    "plt.legend(['$\\delta_a$','$f_1$','$\\delta_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d559838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4486, -6.7947],\n",
       "         [-2.1489,  0.6222],\n",
       "         [-1.2949,  0.4254],\n",
       "         [-2.7790,  0.7632],\n",
       "         [ 0.4265,  0.0251]],\n",
       "\n",
       "        [[ 0.7986,  0.6462],\n",
       "         [ 0.9389,  0.8404],\n",
       "         [ 0.8949,  0.8452],\n",
       "         [ 0.9599,  0.6278],\n",
       "         [ 0.9294,  0.8394]],\n",
       "\n",
       "        [[ 0.9758,  0.9573],\n",
       "         [ 0.8167,  0.8941],\n",
       "         [ 0.9724,  0.7847],\n",
       "         [ 0.8496,  0.9223],\n",
       "         [ 0.9422,  0.8059]],\n",
       "\n",
       "        [[ 0.9852,  0.9477],\n",
       "         [ 0.9852,  0.8022],\n",
       "         [ 0.9864,  0.9714],\n",
       "         [ 0.9798,  0.9638],\n",
       "         [ 0.9896,  0.9582]],\n",
       "\n",
       "        [[ 0.9875,  0.9705],\n",
       "         [ 0.9875,  0.9561],\n",
       "         [ 0.9909,  0.9762],\n",
       "         [ 0.9935,  0.9649],\n",
       "         [ 0.9930,  0.9756]],\n",
       "\n",
       "        [[ 0.9901,  0.9804],\n",
       "         [ 0.9913,  0.9879],\n",
       "         [ 0.9901,  0.9866],\n",
       "         [ 0.9914,  0.9789],\n",
       "         [ 0.9949,  0.9747]],\n",
       "\n",
       "        [[ 0.9934,  0.9880],\n",
       "         [ 0.9947,  0.9680],\n",
       "         [ 0.9946,  0.9905],\n",
       "         [ 0.9838,  0.9749],\n",
       "         [ 0.9955,  0.9839]],\n",
       "\n",
       "        [[ 0.9965,  0.9916],\n",
       "         [ 0.9972,  0.9804],\n",
       "         [ 0.9961,  0.9898],\n",
       "         [ 0.9975,  0.9895],\n",
       "         [ 0.9961,  0.9922]],\n",
       "\n",
       "        [[ 0.9983,  0.9914],\n",
       "         [ 0.9944,  0.9946],\n",
       "         [ 0.9956,  0.9917],\n",
       "         [ 0.9948,  0.9874],\n",
       "         [ 0.9951,  0.9913]],\n",
       "\n",
       "        [[ 0.9963,  0.9929],\n",
       "         [ 0.9981,  0.9944],\n",
       "         [ 0.9979,  0.9924],\n",
       "         [ 0.9963,  0.9903],\n",
       "         [ 0.9958,  0.9938]],\n",
       "\n",
       "        [[ 0.9980,  0.9909],\n",
       "         [ 0.9975,  0.9949],\n",
       "         [ 0.9969,  0.9852],\n",
       "         [ 0.9981,  0.9946],\n",
       "         [ 0.9970,  0.9955]],\n",
       "\n",
       "        [[ 0.9980,  0.9960],\n",
       "         [ 0.9980,  0.9967],\n",
       "         [ 0.9963,  0.9956],\n",
       "         [ 0.9968,  0.9899],\n",
       "         [ 0.9976,  0.9941]],\n",
       "\n",
       "        [[ 0.9987,  0.9954],\n",
       "         [ 0.9983,  0.9969],\n",
       "         [ 0.9980,  0.9962],\n",
       "         [ 0.9975,  0.9951],\n",
       "         [ 0.9974,  0.9950]],\n",
       "\n",
       "        [[ 0.9969,  0.9946],\n",
       "         [ 0.9984,  0.9921],\n",
       "         [ 0.9968,  0.9938],\n",
       "         [ 0.9979,  0.9962],\n",
       "         [ 0.9979,  0.9940]],\n",
       "\n",
       "        [[ 0.9983,  0.9968],\n",
       "         [ 0.9981,  0.9958],\n",
       "         [ 0.9982,  0.9958],\n",
       "         [ 0.9973,  0.9959],\n",
       "         [ 0.9969,  0.9963]],\n",
       "\n",
       "        [[ 0.9972,  0.9954],\n",
       "         [ 0.9986,  0.9972],\n",
       "         [ 0.9980,  0.9961],\n",
       "         [ 0.9988,  0.9959],\n",
       "         [ 0.9984,  0.9968]],\n",
       "\n",
       "        [[ 0.9983,  0.9970],\n",
       "         [ 0.9984,  0.9964],\n",
       "         [ 0.9980,  0.9966],\n",
       "         [ 0.9978,  0.9961],\n",
       "         [ 0.9981,  0.9967]],\n",
       "\n",
       "        [[ 0.9986,  0.9974],\n",
       "         [ 0.9988,  0.9961],\n",
       "         [ 0.9986,  0.9963],\n",
       "         [ 0.9987,  0.9966],\n",
       "         [ 0.9987,  0.9959]],\n",
       "\n",
       "        [[ 0.9981,  0.9974],\n",
       "         [ 0.9987,  0.9968],\n",
       "         [ 0.9990,  0.9972],\n",
       "         [ 0.9990,  0.9965],\n",
       "         [ 0.9989,  0.9969]],\n",
       "\n",
       "        [[ 0.9989,  0.9974],\n",
       "         [ 0.9989,  0.9968],\n",
       "         [ 0.9989,  0.9975],\n",
       "         [ 0.9988,  0.9969],\n",
       "         [ 0.9990,  0.9968]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cddf2fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8891, -4.7997],\n",
       "         [-1.6917,  0.9426],\n",
       "         [ 0.9393,  0.4236],\n",
       "         [-0.4336,  0.9212],\n",
       "         [ 0.9785,  0.3436]],\n",
       "\n",
       "        [[ 0.9725,  0.9568],\n",
       "         [ 0.9781,  0.9879],\n",
       "         [ 0.9775,  0.9527],\n",
       "         [ 0.8825,  0.9753],\n",
       "         [ 0.9920,  0.8952]],\n",
       "\n",
       "        [[ 0.9929,  0.9824],\n",
       "         [ 0.9918,  0.9681],\n",
       "         [ 0.9926,  0.9828],\n",
       "         [ 0.9796,  0.9189],\n",
       "         [ 0.9903,  0.8940]],\n",
       "\n",
       "        [[ 0.9960,  0.9772],\n",
       "         [ 0.9914,  0.8094],\n",
       "         [ 0.9919,  0.9837],\n",
       "         [ 0.9955,  0.9923],\n",
       "         [ 0.9741,  0.9787]],\n",
       "\n",
       "        [[ 0.9853,  0.9906],\n",
       "         [ 0.9957,  0.9967],\n",
       "         [ 0.9972,  0.9942],\n",
       "         [ 0.9971,  0.9929],\n",
       "         [ 0.9946,  0.9957]],\n",
       "\n",
       "        [[ 0.9943,  0.9943],\n",
       "         [ 0.9926,  0.9939],\n",
       "         [ 0.9979,  0.9955],\n",
       "         [ 0.9954,  0.9930],\n",
       "         [ 0.9969,  0.9963]],\n",
       "\n",
       "        [[ 0.9970,  0.9943],\n",
       "         [ 0.9940,  0.9947],\n",
       "         [ 0.9958,  0.9949],\n",
       "         [ 0.9940,  0.9967],\n",
       "         [ 0.9978,  0.9950]],\n",
       "\n",
       "        [[ 0.9981,  0.9935],\n",
       "         [ 0.9969,  0.9940],\n",
       "         [ 0.9962,  0.9959],\n",
       "         [ 0.9976,  0.9949],\n",
       "         [ 0.9977,  0.9955]],\n",
       "\n",
       "        [[ 0.9980,  0.9960],\n",
       "         [ 0.9967,  0.9968],\n",
       "         [ 0.9970,  0.9972],\n",
       "         [ 0.9971,  0.9944],\n",
       "         [ 0.9974,  0.9957]],\n",
       "\n",
       "        [[ 0.9974,  0.9977],\n",
       "         [ 0.9979,  0.9977],\n",
       "         [ 0.9980,  0.9959],\n",
       "         [ 0.9979,  0.9962],\n",
       "         [ 0.9956,  0.9973]],\n",
       "\n",
       "        [[ 0.9972,  0.9952],\n",
       "         [ 0.9974,  0.9969],\n",
       "         [ 0.9979,  0.9981],\n",
       "         [ 0.9981,  0.9965],\n",
       "         [ 0.9970,  0.9964]],\n",
       "\n",
       "        [[ 0.9977,  0.9968],\n",
       "         [ 0.9979,  0.9972],\n",
       "         [ 0.9973,  0.9959],\n",
       "         [ 0.9977,  0.9971],\n",
       "         [ 0.9977,  0.9969]],\n",
       "\n",
       "        [[ 0.9984,  0.9970],\n",
       "         [ 0.9976,  0.9977],\n",
       "         [ 0.9978,  0.9974],\n",
       "         [ 0.9978,  0.9974],\n",
       "         [ 0.9984,  0.9977]],\n",
       "\n",
       "        [[ 0.9983,  0.9979],\n",
       "         [ 0.9976,  0.9961],\n",
       "         [ 0.9973,  0.9970],\n",
       "         [ 0.9976,  0.9976],\n",
       "         [ 0.9978,  0.9960]],\n",
       "\n",
       "        [[ 0.9981,  0.9978],\n",
       "         [ 0.9976,  0.9978],\n",
       "         [ 0.9985,  0.9975],\n",
       "         [ 0.9979,  0.9977],\n",
       "         [ 0.9975,  0.9978]],\n",
       "\n",
       "        [[ 0.9970,  0.9971],\n",
       "         [ 0.9981,  0.9982],\n",
       "         [ 0.9981,  0.9974],\n",
       "         [ 0.9979,  0.9976],\n",
       "         [ 0.9981,  0.9983]],\n",
       "\n",
       "        [[ 0.9981,  0.9980],\n",
       "         [ 0.9978,  0.9980],\n",
       "         [ 0.9980,  0.9979],\n",
       "         [ 0.9981,  0.9981],\n",
       "         [ 0.9976,  0.9981]],\n",
       "\n",
       "        [[ 0.9984,  0.9985],\n",
       "         [ 0.9976,  0.9978],\n",
       "         [ 0.9980,  0.9978],\n",
       "         [ 0.9981,  0.9979],\n",
       "         [ 0.9983,  0.9975]],\n",
       "\n",
       "        [[ 0.9980,  0.9977],\n",
       "         [ 0.9984,  0.9981],\n",
       "         [ 0.9983,  0.9980],\n",
       "         [ 0.9985,  0.9976],\n",
       "         [ 0.9982,  0.9980]],\n",
       "\n",
       "        [[ 0.9985,  0.9983],\n",
       "         [ 0.9984,  0.9982],\n",
       "         [ 0.9984,  0.9981],\n",
       "         [ 0.9984,  0.9981],\n",
       "         [ 0.9985,  0.9982]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ff6e831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1635, -1.8855],\n",
       "         [-0.3989,  0.6088],\n",
       "         [-0.0436,  0.0051],\n",
       "         [-0.3586,  0.9304],\n",
       "         [-0.0222, -4.6795]],\n",
       "\n",
       "        [[ 0.8535,  0.9678],\n",
       "         [ 0.9868,  0.9706],\n",
       "         [ 0.9754,  0.9802],\n",
       "         [ 0.8537,  0.9098],\n",
       "         [ 0.9723,  0.9493]],\n",
       "\n",
       "        [[ 0.9917,  0.9758],\n",
       "         [ 0.9852,  0.9925],\n",
       "         [ 0.9961,  0.9936],\n",
       "         [ 0.9860,  0.9926],\n",
       "         [ 0.9910,  0.9873]],\n",
       "\n",
       "        [[ 0.9938,  0.9966],\n",
       "         [ 0.9909,  0.9782],\n",
       "         [ 0.9950,  0.9776],\n",
       "         [ 0.9972,  0.9947],\n",
       "         [ 0.9952,  0.9837]],\n",
       "\n",
       "        [[ 0.9810,  0.9929],\n",
       "         [ 0.9970,  0.9875],\n",
       "         [ 0.9921,  0.9980],\n",
       "         [ 0.9821,  0.9968],\n",
       "         [ 0.9987,  0.9976]],\n",
       "\n",
       "        [[ 0.9861,  0.9955],\n",
       "         [ 0.9956,  0.9914],\n",
       "         [ 0.9986,  0.9979],\n",
       "         [ 0.9952,  0.9974],\n",
       "         [ 0.9985,  0.9951]],\n",
       "\n",
       "        [[ 0.9907,  0.9978],\n",
       "         [ 0.9975,  0.9977],\n",
       "         [ 0.9951,  0.9964],\n",
       "         [ 0.9980,  0.9970],\n",
       "         [ 0.9990,  0.9976]],\n",
       "\n",
       "        [[ 0.9990,  0.9961],\n",
       "         [ 0.9989,  0.9961],\n",
       "         [ 0.9972,  0.9949],\n",
       "         [ 0.9989,  0.9981],\n",
       "         [ 0.9992,  0.9972]],\n",
       "\n",
       "        [[ 0.9991,  0.9978],\n",
       "         [ 0.9987,  0.9982],\n",
       "         [ 0.9986,  0.9976],\n",
       "         [ 0.9958,  0.9967],\n",
       "         [ 0.9947,  0.9979]],\n",
       "\n",
       "        [[ 0.9985,  0.9977],\n",
       "         [ 0.9992,  0.9980],\n",
       "         [ 0.9992,  0.9940],\n",
       "         [ 0.9959,  0.9982],\n",
       "         [ 0.9980,  0.9975]],\n",
       "\n",
       "        [[ 0.9992,  0.9959],\n",
       "         [ 0.9988,  0.9986],\n",
       "         [ 0.9990,  0.9942],\n",
       "         [ 0.9981,  0.9984],\n",
       "         [ 0.9988,  0.9961]],\n",
       "\n",
       "        [[ 0.9992,  0.9987],\n",
       "         [ 0.9985,  0.9984],\n",
       "         [ 0.9992,  0.9976],\n",
       "         [ 0.9993,  0.9979],\n",
       "         [ 0.9992,  0.9962]],\n",
       "\n",
       "        [[ 0.9993,  0.9982],\n",
       "         [ 0.9989,  0.9980],\n",
       "         [ 0.9992,  0.9987],\n",
       "         [ 0.9979,  0.9984],\n",
       "         [ 0.9988,  0.9978]],\n",
       "\n",
       "        [[ 0.9985,  0.9943],\n",
       "         [ 0.9995,  0.9948],\n",
       "         [ 0.9988,  0.9969],\n",
       "         [ 0.9989,  0.9984],\n",
       "         [ 0.9993,  0.9964]],\n",
       "\n",
       "        [[ 0.9987,  0.9986],\n",
       "         [ 0.9991,  0.9979],\n",
       "         [ 0.9991,  0.9985],\n",
       "         [ 0.9989,  0.9985],\n",
       "         [ 0.9990,  0.9984]],\n",
       "\n",
       "        [[ 0.9992,  0.9975],\n",
       "         [ 0.9993,  0.9984],\n",
       "         [ 0.9992,  0.9977],\n",
       "         [ 0.9991,  0.9978],\n",
       "         [ 0.9994,  0.9984]],\n",
       "\n",
       "        [[ 0.9993,  0.9985],\n",
       "         [ 0.9987,  0.9984],\n",
       "         [ 0.9985,  0.9984],\n",
       "         [ 0.9987,  0.9972],\n",
       "         [ 0.9989,  0.9987]],\n",
       "\n",
       "        [[ 0.9995,  0.9987],\n",
       "         [ 0.9992,  0.9971],\n",
       "         [ 0.9989,  0.9986],\n",
       "         [ 0.9992,  0.9981],\n",
       "         [ 0.9989,  0.9979]],\n",
       "\n",
       "        [[ 0.9992,  0.9987],\n",
       "         [ 0.9990,  0.9986],\n",
       "         [ 0.9986,  0.9986],\n",
       "         [ 0.9993,  0.9983],\n",
       "         [ 0.9995,  0.9986]],\n",
       "\n",
       "        [[ 0.9994,  0.9987],\n",
       "         [ 0.9994,  0.9980],\n",
       "         [ 0.9993,  0.9987],\n",
       "         [ 0.9987,  0.9985],\n",
       "         [ 0.9994,  0.9987]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8c8ef4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1635, -1.8855],\n",
       "         [-0.3989,  0.6088],\n",
       "         [-0.0436,  0.0051],\n",
       "         [-0.3586,  0.9304],\n",
       "         [-0.0222, -4.6795]],\n",
       "\n",
       "        [[ 0.8535,  0.9678],\n",
       "         [ 0.9868,  0.9706],\n",
       "         [ 0.9754,  0.9802],\n",
       "         [ 0.8537,  0.9098],\n",
       "         [ 0.9723,  0.9493]],\n",
       "\n",
       "        [[ 0.9917,  0.9758],\n",
       "         [ 0.9852,  0.9925],\n",
       "         [ 0.9961,  0.9936],\n",
       "         [ 0.9860,  0.9926],\n",
       "         [ 0.9910,  0.9873]],\n",
       "\n",
       "        [[ 0.9938,  0.9966],\n",
       "         [ 0.9909,  0.9782],\n",
       "         [ 0.9950,  0.9776],\n",
       "         [ 0.9972,  0.9947],\n",
       "         [ 0.9952,  0.9837]],\n",
       "\n",
       "        [[ 0.9810,  0.9929],\n",
       "         [ 0.9970,  0.9875],\n",
       "         [ 0.9921,  0.9980],\n",
       "         [ 0.9821,  0.9968],\n",
       "         [ 0.9987,  0.9976]],\n",
       "\n",
       "        [[ 0.9861,  0.9955],\n",
       "         [ 0.9956,  0.9914],\n",
       "         [ 0.9986,  0.9979],\n",
       "         [ 0.9952,  0.9974],\n",
       "         [ 0.9985,  0.9951]],\n",
       "\n",
       "        [[ 0.9907,  0.9978],\n",
       "         [ 0.9975,  0.9977],\n",
       "         [ 0.9951,  0.9964],\n",
       "         [ 0.9980,  0.9970],\n",
       "         [ 0.9990,  0.9976]],\n",
       "\n",
       "        [[ 0.9990,  0.9961],\n",
       "         [ 0.9989,  0.9961],\n",
       "         [ 0.9972,  0.9949],\n",
       "         [ 0.9989,  0.9981],\n",
       "         [ 0.9992,  0.9972]],\n",
       "\n",
       "        [[ 0.9991,  0.9978],\n",
       "         [ 0.9987,  0.9982],\n",
       "         [ 0.9986,  0.9976],\n",
       "         [ 0.9958,  0.9967],\n",
       "         [ 0.9947,  0.9979]],\n",
       "\n",
       "        [[ 0.9985,  0.9977],\n",
       "         [ 0.9992,  0.9980],\n",
       "         [ 0.9992,  0.9940],\n",
       "         [ 0.9959,  0.9982],\n",
       "         [ 0.9980,  0.9975]],\n",
       "\n",
       "        [[ 0.9992,  0.9959],\n",
       "         [ 0.9988,  0.9986],\n",
       "         [ 0.9990,  0.9942],\n",
       "         [ 0.9981,  0.9984],\n",
       "         [ 0.9988,  0.9961]],\n",
       "\n",
       "        [[ 0.9992,  0.9987],\n",
       "         [ 0.9985,  0.9984],\n",
       "         [ 0.9992,  0.9976],\n",
       "         [ 0.9993,  0.9979],\n",
       "         [ 0.9992,  0.9962]],\n",
       "\n",
       "        [[ 0.9993,  0.9982],\n",
       "         [ 0.9989,  0.9980],\n",
       "         [ 0.9992,  0.9987],\n",
       "         [ 0.9979,  0.9984],\n",
       "         [ 0.9988,  0.9978]],\n",
       "\n",
       "        [[ 0.9985,  0.9943],\n",
       "         [ 0.9995,  0.9948],\n",
       "         [ 0.9988,  0.9969],\n",
       "         [ 0.9989,  0.9984],\n",
       "         [ 0.9993,  0.9964]],\n",
       "\n",
       "        [[ 0.9987,  0.9986],\n",
       "         [ 0.9991,  0.9979],\n",
       "         [ 0.9991,  0.9985],\n",
       "         [ 0.9989,  0.9985],\n",
       "         [ 0.9990,  0.9984]],\n",
       "\n",
       "        [[ 0.9992,  0.9975],\n",
       "         [ 0.9993,  0.9984],\n",
       "         [ 0.9992,  0.9977],\n",
       "         [ 0.9991,  0.9978],\n",
       "         [ 0.9994,  0.9984]],\n",
       "\n",
       "        [[ 0.9993,  0.9985],\n",
       "         [ 0.9987,  0.9984],\n",
       "         [ 0.9985,  0.9984],\n",
       "         [ 0.9987,  0.9972],\n",
       "         [ 0.9989,  0.9987]],\n",
       "\n",
       "        [[ 0.9995,  0.9987],\n",
       "         [ 0.9992,  0.9971],\n",
       "         [ 0.9989,  0.9986],\n",
       "         [ 0.9992,  0.9981],\n",
       "         [ 0.9989,  0.9979]],\n",
       "\n",
       "        [[ 0.9992,  0.9987],\n",
       "         [ 0.9990,  0.9986],\n",
       "         [ 0.9986,  0.9986],\n",
       "         [ 0.9993,  0.9983],\n",
       "         [ 0.9995,  0.9986]],\n",
       "\n",
       "        [[ 0.9994,  0.9987],\n",
       "         [ 0.9994,  0.9980],\n",
       "         [ 0.9993,  0.9987],\n",
       "         [ 0.9987,  0.9985],\n",
       "         [ 0.9994,  0.9987]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c07bf934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1),MSEa.mean(axis=1)))[1:,[1,3,5]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,1]+MSE.std(axis=1)[1:,1], y2=MSE.mean(axis=1)[1:,1]-MSE.std(axis=1)[1:,1],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,1]+MSE_p.std(axis=1)[1:,1], y2=MSE_p.mean(axis=1)[1:,1]-MSE_p.std(axis=1)[1:,1],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSEa.mean(axis=1)[1:,1]+MSEa.std(axis=1)[1:,1], y2=MSEa.mean(axis=1)[1:,1]-MSEa.std(axis=1)[1:,1],alpha=0.4)\n",
    "plt.legend(['$\\delta_a$','$f_1$','$\\delta_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03a34fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,np.hstack((R2.mean(axis=1),R2_p.mean(axis=1)))[:,[0,2]],'o') \n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf6a428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,np.hstack((R2.mean(axis=1),R2_p.mean(axis=1)))[:,[1,3]],'o') \n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f028b6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b9be6410>,\n",
       " <matplotlib.lines.Line2D at 0x2b9bb9050>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,MSE_p.mean(axis=1)-MSE.mean(axis=1),'o')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bbd3ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAGwCAYAAACjPMHLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3ZUlEQVR4nO3dfXxU1YH/8e/kkSDJIKRhEggELSWEAFIpEETFXYGomC262kAJ9KfSaosItjzVWqBbC1hr0VKwxSCKKNoKFuxuFFegUB4ihAlgMFgbCEJCLA+TIARDcn9/xMzeIZmQTGYyM8nn/XrdVzt3zj333EM68+25556xGIZhCAAAAJKkEH83AAAAIJAQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYBLm7wYEo5qaGp08eVLR0dGyWCz+bg4AAGgCwzBUUVGhhIQEhYS4Hx8iHHng5MmTSkxM9HczAACAB44fP64ePXq4fZ9w5IHo6GhJtZ0bExPj59YAAICmKC8vV2JiovN73B3CkQfqbqXFxMQQjgAACDJXmxLDhGwAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABNWyA4UNdXSsZ3S+VNSp25SrxFSSKi/WwUAQLtDOAoEBRulnDlS+cn/2xeTIKUvkVIy/NcuAADaIW6r+VvBRunNya7BSJLKS2r3F2z0T7sAAGinGDnyp5rq2hEjGQ28aUiySDlzpeS7uMXmQ9U1hnKLzqisolJx0R00tHcXhYY0/qOEQLDj7949X/dNMNcfzG1vDsKRPx3bWX/EyIUhlZ+oLdf75lZrVnuSc6hECzcVqMRR6dwXb+2g+XenKD013ivnCOYPk2BuuyRVX76sj/e8q4tnTyjq2u5KHjZWoWHe+djzZd2+rj/nUIn+a+NBJZ7PV5zOqUyddbzTID2ZMcB7f/dB2ve+7ptgrj+Y295cbSIcLV++XL/+9a9VUlKi/v37a+nSpbr5ZvdhYtu2bXr88cf10UcfKSEhQbNnz9bDDz/cii3+yvlT3i2HZsk5VKJHXs2rN25X6qjUI6/macWkb3rlw8SX4cuX9Qf7B+H+d19Wwq6F6q/Tzn2nNnfVybT5Gjx2SsDW7ev6cw6V6O3XXtCfwl9RQsQZ5/6Tl7roF69NliY+3OL+D9a+93XfBHP9wdx2TwT9nKM33nhDM2bM0BNPPKH9+/fr5ptv1h133KHi4uIGyxcVFenOO+/UzTffrP379+unP/2ppk+frrfeequVW67ap9K8Wa6Nqq4xtOvT0/qL/YR2fXpa1TUN3YZsfp0LNxW4vaEpSQs3FbToXHXhyxxcpP8LXzmHSjyu29f1Oz+oLv1A6yJ+qecjlmldxC/1p0s/0NuvveCVtvuy/v3vvqxBO6fra8Zpl/1fM05r0M7p2v/uywFZt6/rr64xtPXtVVoevlQ2nXF5z6YzWh6+VFvfXtWiv/tg7Xtf900w1x/MbfdU0IejZ599Vg8++KAeeugh9evXT0uXLlViYqJWrFjRYPkXXnhBPXv21NKlS9WvXz899NBDeuCBB/TMM8+4PcelS5dUXl7usnlFrxG1T6XJ3W0EixTTvbZcO5VzqEQjl3ygCSt367F1dk1YuVsjl3zQ4i/P3KIz9UKFmSGpxFGp3KIzbss0xhy+QlSj4SEFygjZqeEhBbKoRlLLwpcvw12wfxBWX76shF0LJUlX3qGrex2/a6GqL18OqLpbo/7cTz/X9KoXG61/elW2cj/93KP6g7nvfd03wVx/MLfdU0Edjr788kvt27dPY8aMcdk/ZswY7dy5s8Fjdu3aVa/82LFjtXfvXlVVVTV4zKJFi2S1Wp1bYmKidy4gJLT2cX1J9QPSV6/TF7fbydi+HBkpq3AfjDwpd6W68DU2JFc7Iqe7jI7siJyuMSG5LQpf5nB3ZfgKUU2Lwl2wfxB+vOddddPpenWbz2HTaX28592Aqrs16q8++nclWM40Wn+C5bSqj/7do/qDue993TfBXH8wt91TQR2O/vWvf6m6ulrdurnedurWrZtKS0sbPKa0tLTB8pcvX9a//vWvBo+ZN2+eHA6Hczt+/Lh3LkCqXcfo/lekmCvupcYk1O5vp+sc+fq2V1x0B6+Wu1JZRW0wWuFmdGRF+FKNDcn1OHzVHecufI0NyXUp1xzB/kF48ewJr5Zrrbpbo/44yzmvlrtSMPe9r/smmOsP5rZ7qk1MyLZYXD9lDcOot+9q5RvaXycyMlKRkZEtbGUjUjJqH9f34QrZgfJ4ZFM157ZX2vVdm13/0N5dFG/toFJHpSyq0dCQj52TgnNrkmUoRDZrbT95Iu6acM0Pf0VSw6MjNYY0P3yNjl3zI8/qj+7gDF9Xqgtfj1TNUFz08ObXHeQfhFHXdvdqudaquzXqv/6666UdTSzngWDue1/3TTDXH8xt91RQh6PY2FiFhobWGyUqKyurNzpUx2azNVg+LCxMXbs2/0vWa0JCffa4fms8ru5tvr7tFRpi0fy7U/T2ay/o5+GvKMFiejrC6KJfVE3Wt+9+2OMAOTT0Y4Va3N/SCrFICTqtbqEfS4prfv29rLouYo1kuA9fCyPW6Gu9nmx23cH+QZg8bKxObe6qrxkN34KpMaQyS1clDxsbUHW3Rv2hSTfpYpRNkRdK3dZ/qaNNUUk3eVR/MPe9r/smmOsP5rZ7Kqhvq0VEROjGG2/U5s2bXfZv3rxZI0Y0PIk5LS2tXvn33ntPQ4YMUXh4uM/a6i++fmLKV3x920uS0kM+1IqI52S7IsTYLGe0IuI5pYd86HHdoV+UebVcveOO72rS/IvQ47uaX/dXH1Tu7ljWGNLFKJtCW/hB6LP6w8J0Mm2+s64r65akkrT5Hq2L48u6W6N+hYQq6u5fy2KpeyzAVL9qR8+j7v61x6PWwdz3vu6boK4/mNvuoaAOR5L0+OOP68UXX9SqVat0+PBhzZw5U8XFxc51i+bNm6fJkyc7yz/88MM6duyYHn/8cR0+fFirVq1Sdna2fvKTn/jrEnymNR5X95W6216NPMen+Bbc9qpbndwio97/CEK+ql85c2vLecLXyzT4co2sNvBBOHjsFOWPeF6fW1xHg8ssXZU/4vkWrYfjy7pbo36lZMhy/yuyxCS47LbEdJfFC/Mcg7nvfd03QV1/MLfdAxajbsJNEFu+fLmefvpplZSUKDU1Vb/97W91yy23SJK+973v6ejRo9q6dauz/LZt2zRz5kznIpBz5sxp1iKQ5eXlslqtcjgciomJ8fbleM2uT09rwsrdVy33+tThHs3b8bW6US/J9QdW6gJTixZpLNouvTzu6uWmvOPZ7c6aamlpau1v5DUYTy21k+5nHPQsBPi6/ZJUsFFGzhxZTKu4GzHdZUlf7J0PKl/Xr+Bdpbk16ldNtW/nOQZx3/u6b4K6/mBuu5r+/d0mwlFrC5Zw9Bf7CT22zn7Vcs9l3qD/uMGzSYy+5rP5Ugf/LL314NXL3ZstDfhPz85R96PCkhqMdy35f0O+Dl/m8wTxByEAmDX1+zuoJ2Sjca0xb8fX0lPjNTrF5v0n7VpjdfK6ZRpy5rj+hl5MQu36VS0ZHalbI+vNyaoNWw2EL2+skeXDBwVapX4A8ADhqA0zP67uZmyhRY+rt5bQEIv3b/vVrU5+tZGXlq5O7stlGnwZvgCgHSMctWF1j6s/8mqeu7EFzb87JaDXO5Lkm1svrTXyUncuX42OtMIaWQDQ3jDnyAPBMueoTjCuc+RUsNHNyMgSr00Krl9/d0ZeAKANYkK2DwVbOJKCb4VsSaYJzVf+iXphQrMZk4IBoF1gQjZc+GTeji99tQ5Rw/OBDEmW2nWIku8K/EnHAICgEvSLQKKNOrbT9VZXPYZUfqK2HAAAXkQ4QmDy5QrQAAA0gttq8Aqvz2lqjXWIAABoAOEILeaTp+Faax0iAACuwG01tEjd75+Zg5EklToq9cireco5VOJZxXXrEElSvZ+f9fI6RAAAmBCO4LHqGkMLNxW4fZ5MkhZuKlB1jYerRdStAB1zxehTTIL3HuMHAOAK3FaDx3KLztQbMTIzJJU4KpVbdMbzZQRYARoA0MoIR/BYWYX7YORJObdYhwgA0Iq4rQaPxUV38Go5AAACAeEIHhvau4virR3qTZeuY1HtU2tDe3dpzWYBANAihCN4LDTEovl3p0hy+zyZ5t+dEvi/4QYAgAnhCC2SnhqvFZO+KZvV9daZzdpBKyZ90/N1jgAA8BMmZKPF0lPjNTr5a/p4z7u6ePaEoq7truRhtyo0jD8vAEDw4dsLLVewUaE5c9Tf/EOxexJqF3FkLSIAQJDhthpapmCj9OZkyRyMpNqf/Xhzcu37AAAEEcIRPFdTLeXMUcO/ffbVvpy5teUAAAgShCN47tjO+iNGLgyp/ERtOQAAggThCJ47f8q75QAACACEI3iuUzfvlgMAIAAQjuC5XiOkmATVXwKyjkWK6V5bDgCAIEE4gudCQmsf15fkdo3s9MW15QAACBKEI7RMSoZ0/ytSzBUrYcck1O5nnSMAQJBhEUi0XEqGlHxX7VNp50/VzjHqNYIRIwBAUCIcwTtCQqXeN/u7FQAAtBi31QAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATFghu72oqebnPQAAaALCUXtQsFHKmSOVn/y/fTEJUvoSfhgWAIArcFutrSvYKL052TUYSVJ5Se3+go3+aRcAAAEqqMPR2bNnlZWVJavVKqvVqqysLJ07d85t+aqqKs2ZM0cDBgzQNddco4SEBE2ePFknT550e0xQq6muHTGS0cCbX+3LmVtbDgAASArycDRx4kTZ7Xbl5OQoJydHdrtdWVlZbstfuHBBeXl5evLJJ5WXl6f169fryJEjyshoo7eWju2sP2LkwpDKT9SWAwAAkoJ4ztHhw4eVk5Oj3bt3a9iwYZKklStXKi0tTYWFherbt2+9Y6xWqzZv3uyy73e/+52GDh2q4uJi9ezZs8FzXbp0SZcuXXK+Li8v9+KV+ND5U94tBwBAOxC0I0e7du2S1Wp1BiNJGj58uKxWq3bubPpIiMPhkMViUefOnd2WWbRokfPWndVqVWJiYkua3no6dfNuOQAA2oGgDUelpaWKi4urtz8uLk6lpaVNqqOyslJz587VxIkTFRMT47bcvHnz5HA4nNvx48c9bner6jWi9qk0WdwUsEgx3WvLAQAASQEYjhYsWCCLxdLotnfvXkmSxVL/S98wjAb3X6mqqkqZmZmqqanR8uXLGy0bGRmpmJgYly0ohITWPq4vqX5A+up1+mLWOwIAwCTg5hxNmzZNmZmZjZZJSkrSgQMHdOpU/bkyn3/+ubp1a/w2UVVVle6//34VFRXpgw8+CJ6w44mUDOn+V9ysc7SYdY4AALhCwIWj2NhYxcbGXrVcWlqaHA6HcnNzNXToUEnSnj175HA4NGKE+9tEdcHok08+0ZYtW9S1a1evtT1gpWRIyXexQjYAAE1gMQyjoUVwgsIdd9yhkydP6g9/+IMk6fvf/7569eqlTZs2OcskJydr0aJFGj9+vC5fvqx7771XeXl5euedd1xGmLp06aKIiIgmnbe8vFxWq1UOh6NtjzoBANCGNPX7O+DmHDXH2rVrNWDAAI0ZM0ZjxozRwIEDtWbNGpcyhYWFcjgckqTPPvtMGzdu1GeffaYbbrhB8fHxzq05T7gBAIC2K6hHjvyFkSMAAIJPuxg5AgAA8DbCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIBJUIejs2fPKisrS1arVVarVVlZWTp37lyTj//BD34gi8WipUuX+qyNAAAguAR1OJo4caLsdrtycnKUk5Mju92urKysJh379ttva8+ePUpISPBxKwEAQDAJ83cDPHX48GHl5ORo9+7dGjZsmCRp5cqVSktLU2Fhofr27ev22BMnTmjatGl69913ddddd7VWkwEAQBAI2pGjXbt2yWq1OoORJA0fPlxWq1U7d+50e1xNTY2ysrI0a9Ys9e/fv0nnunTpksrLy102AADQNgVtOCotLVVcXFy9/XFxcSotLXV73JIlSxQWFqbp06c3+VyLFi1yzmuyWq1KTEz0qM0AACDwBVw4WrBggSwWS6Pb3r17JUkWi6Xe8YZhNLhfkvbt26fnnntOq1evdlumIfPmzZPD4XBux48f9+ziAABAwAu4OUfTpk1TZmZmo2WSkpJ04MABnTp1qt57n3/+ubp169bgcdu3b1dZWZl69uzp3FddXa0f//jHWrp0qY4ePdrgcZGRkYqMjGz6RQAAgKAVcOEoNjZWsbGxVy2XlpYmh8Oh3NxcDR06VJK0Z88eORwOjRgxosFjsrKydPvtt7vsGzt2rLKysvT//t//a3njAQBA0Au4cNRU/fr1U3p6uqZOnao//OEPkqTvf//7GjdunMuTasnJyVq0aJHGjx+vrl27qmvXri71hIeHy2azNfp0GwAAaD8Cbs5Rc6xdu1YDBgzQmDFjNGbMGA0cOFBr1qxxKVNYWCiHw+GnFgIAgGBjMQzD8Hcjgk15ebmsVqscDodiYmL83RwAANAETf3+DuqRIwAAAG8jHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYBHU4Onv2rLKysmS1WmW1WpWVlaVz585d9bjDhw8rIyNDVqtV0dHRGj58uIqLi33fYAAAEPCCOhxNnDhRdrtdOTk5ysnJkd1uV1ZWVqPHfPrppxo5cqSSk5O1detW5efn68knn1SHDh1aqdUAACCQWQzDMPzdCE8cPnxYKSkp2r17t4YNGyZJ2r17t9LS0vTxxx+rb9++DR6XmZmp8PBwrVmzxuNzl5eXy2q1yuFwKCYmxuN6AABA62nq93ezR44uXryoEydO1Nv/0UcfNbeqFtm1a5esVqszGEnS8OHDZbVatXPnzgaPqamp0V//+ld94xvf0NixYxUXF6dhw4bp7bffbvRcly5dUnl5ucsGAADapmaFoz//+c/6xje+oTvvvFMDBw7Unj17nO9d7XaWt5WWliouLq7e/ri4OJWWljZ4TFlZmc6fP6/FixcrPT1d7733nsaPH6977rlH27Ztc3uuRYsWOec1Wa1WJSYmeu06AABAYGlWOPrlL3+pvLw85efna9WqVXrggQf02muvSZK8dXduwYIFslgsjW579+6VJFkslnrHG4bR4H6pduRIkv7jP/5DM2fO1A033KC5c+dq3LhxeuGFF9y2ad68eXI4HM7t+PHjXrhSAAAQiMKaU7iqqkpf+9rXJElDhgzR3/72N91zzz36xz/+4TaQNNe0adOUmZnZaJmkpCQdOHBAp06dqvfe559/rm7dujV4XGxsrMLCwpSSkuKyv1+/ftqxY4fb80VGRioyMrIJrQcAAMGuWeEoLi5OBw4c0MCBAyVJXbt21ebNmzVlyhQdOHDAKw2KjY1VbGzsVculpaXJ4XAoNzdXQ4cOlSTt2bNHDodDI0aMaPCYiIgIfetb31JhYaHL/iNHjqhXr14tbzwAAAh6zbqttmbNmnrzfCIiIvT66683OmfHF/r166f09HRNnTpVu3fv1u7duzV16lSNGzfO5Um15ORkbdiwwfl61qxZeuONN7Ry5Ur94x//0LJly7Rp0yb98Ic/bNX2AwCAwNSscNSjRw/ZbLYG37vpppu80qDmWLt2rQYMGKAxY8ZozJgxGjhwYL1H9AsLC+VwOJyvx48frxdeeEFPP/20BgwYoBdffFFvvfWWRo4c2drNBwAAAahF6xwdO3ZMhYWFGjBggOLj4+u9f/LkSSUkJLSogYGIdY4AAAg+PlvnqM7rr7+ur3/960pPT9f111/vHLE5duyYFi9erGHDhqlnz56eVg8AAOAXHoej//qv/9Kjjz6qgwcPavTo0XrkkUf0xBNP6Prrr9fq1as1dOhQrV+/3pttBQAA8LlmPa1m9umnn+qxxx5Tr1699Pvf/149e/bUrl27dPDgQfXr18+bbQQAAGg1Ho8cVVVVKSoqSlLtRO2oqCg988wzBCMAABDUPA5HkvTaa6/p448/rq0oJETXXnutVxoFAADgLx6Ho5EjR2r+/Pnq37+/YmNjVVlZqeeee05vvvmmCgoKdPnyZW+2EwAAoFV4POfob3/7myTpk08+0b59+5SXl6d9+/bplVde0blz5xQeHq6+fft6beVsAACA1uBxOKrTp08f9enTx+X30IqKirR3717t37+/pdUDAAC0qhYtAtlesQgkAADBx+eLQAIAALRFhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACZBHY7Onj2rrKwsWa1WWa1WZWVl6dy5c40ec/78eU2bNk09evRQVFSU+vXrpxUrVrROgwEAQMAL6nA0ceJE2e125eTkKCcnR3a7XVlZWY0eM3PmTOXk5OjVV1/V4cOHNXPmTD366KP6y1/+0kqtBgAAgSxow9Hhw4eVk5OjF198UWlpaUpLS9PKlSv1zjvvqLCw0O1xu3bt0pQpUzRq1CglJSXp+9//vgYNGqS9e/e2YusBAECgCtpwtGvXLlmtVg0bNsy5b/jw4bJardq5c6fb40aOHKmNGzfqxIkTMgxDW7Zs0ZEjRzR27Fi3x1y6dEnl5eUuGwAAaJuCNhyVlpYqLi6u3v64uDiVlpa6Pe75559XSkqKevTooYiICKWnp2v58uUaOXKk22MWLVrknNdktVqVmJjolWsAAACBJ+DC0YIFC2SxWBrd6m6BWSyWescbhtHg/jrPP/+8du/erY0bN2rfvn36zW9+ox/+8Id6//333R4zb948ORwO53b8+PGWXygAAAhIYf5uwJWmTZumzMzMRsskJSXpwIEDOnXqVL33Pv/8c3Xr1q3B4y5evKif/vSn2rBhg+666y5J0sCBA2W32/XMM8/o9ttvb/C4yMhIRUZGNvNKAABAMAq4cBQbG6vY2NirlktLS5PD4VBubq6GDh0qSdqzZ48cDodGjBjR4DFVVVWqqqpSSIjrgFloaKhqampa3ngAABD0Au62WlP169dP6enpmjp1qnbv3q3du3dr6tSpGjdunPr27essl5ycrA0bNkiSYmJidOutt2rWrFnaunWrioqKtHr1ar3yyisaP368vy4FAAAEkIAbOWqOtWvXavr06RozZowkKSMjQ8uWLXMpU1hYKIfD4Xy9bt06zZs3T9/97nd15swZ9erVS0899ZQefvjhVm07AAAITBbDMAx/NyLYlJeXy2q1yuFwKCYmxt/NAQAATdDU7++gva0GAADgC4QjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAAJOgDkdPPfWURowYoY4dO6pz585NOsYwDC1YsEAJCQmKiorSqFGj9NFHH/m2oQAAIGgEdTj68ssvdd999+mRRx5p8jFPP/20nn32WS1btkwffvihbDabRo8erYqKCh+2FAAABIugDkcLFy7UzJkzNWDAgCaVNwxDS5cu1RNPPKF77rlHqampevnll3XhwgW99tprPm4tAAAIBkEdjpqrqKhIpaWlGjNmjHNfZGSkbr31Vu3cudPtcZcuXVJ5ebnLBgAA2qZ2FY5KS0slSd26dXPZ361bN+d7DVm0aJGsVqtzS0xM9Gk7AQCA/wRcOFqwYIEsFkuj2969e1t0DovF4vLaMIx6+8zmzZsnh8Ph3I4fP96i8wMAgMAV5u8GXGnatGnKzMxstExSUpJHddtsNkm1I0jx8fHO/WVlZfVGk8wiIyMVGRnp0TkBAEBwCbhwFBsbq9jYWJ/U3bt3b9lsNm3evFmDBw+WVPvE27Zt27RkyRKfnBMAAASXgLut1hzFxcWy2+0qLi5WdXW17Ha77Ha7zp8/7yyTnJysDRs2SKq9nTZjxgz96le/0oYNG3To0CF973vfU8eOHTVx4kR/XQYAAAggATdy1Bw///nP9fLLLztf140GbdmyRaNGjZIkFRYWyuFwOMvMnj1bFy9e1A9/+EOdPXtWw4YN03vvvafo6OhWbTsAAAhMFsMwDH83ItiUl5fLarXK4XAoJibG380BAABN0NTv76C+rQYAAOBthCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwAAACaEIwAAABPCEQAAgAnhCAAAwIRwBAAAYEI4AgAAMCEcAQAAmBCOAAAATAhHAAAAJoQjAAAAE8IRAACACeEIAADAhHAEAABgQjgCAAAwCfN3AwAACHTV1dWqqqrydzNwFeHh4QoNDW1xPYQjAADcMAxDpaWlOnfunL+bgibq3LmzbDabLBaLx3UQjgAAcKMuGMXFxaljx44t+sKFbxmGoQsXLqisrEySFB8f73FdhCMAABpQXV3tDEZdu3b1d3PQBFFRUZKksrIyxcXFeXyLjQnZAAA0oG6OUceOHf3cEjRH3b9XS+aIEY4AAGgEt9KCizf+vQhHAAAAJoQjAAAAE8IRAAA+VF1jaNenp/UX+wnt+vS0qmsMn59z1KhRslgsslgsstvtPj9fa1i9erXzmmbMmOHTcxGOAADwkZxDJRq55ANNWLlbj62za8LK3Rq55APlHCrx+bmnTp2qkpISpaam6ujRo27n4vTt21cRERE6ceJEk+qtq6uxbcGCBW7r37p161WPX716tbZu3aqkpCRnPd/5zndUUlKitLQ0j/ukqQhHAAD4QM6hEj3yap5KHJUu+0sdlXrk1TyfB6SOHTvKZrMpLMz9qj07duxQZWWl7rvvPq1evbpJ9SYmJqqkpMS5/fjHP1b//v1d9v3kJz9xW/+IESNcyt5///1KT0932fed73yn3nmjoqJks9kUERHR7L5oLsIRAABeVl1jaOGmAjV0A61u38JNBa1yi60x2dnZmjhxorKysrRq1SoZxtXbExoaKpvN5tw6deqksLCwevvc1R8REeFSNioqSpGRkfX2+RPhCAAAL8stOlNvxMjMkFTiqFRu0ZnWa9QVKioq9Kc//UmTJk3S6NGj9cUXX2jr1q1BU78vEY4AAPCysgr3wciTci2VlJRUb1Ro3bp16tOnj/r376/Q0FBlZmYqOzvba+dsaf2jRo3S0aNHvdae5uDnQwAA8LK46A5eLecL2dnZmjRpkvP1pEmTdMstt+jcuXPq3LlzwNfvS4wcAQDgZUN7d1G8tYPcrdVskRRv7aChvbu0ZrOcCgoKtGfPHs2ePVthYWEKCwvT8OHDdfHiRb3++usBX7+vEY4AAPCy0BCL5t+dIkn1AlLd6/l3pyg0xD8/TZKdna1bbrlF+fn5stvtzm327NleubXm6/p9jXAEAIAPpKfGa8Wkb8pmdb11ZrN20IpJ31R6arxf2lVVVaU1a9ZowoQJSk1Nddkeeugh7du3T/n5+QFbf2tgzhEAAD6Snhqv0Sk25RadUVlFpeKia2+l+WvESJI2btyo06dPa/z48fXe69OnjwYMGKDs7Gw9//zzAVl/ayAcAQDgQ6EhFqVd39XfzXC69957VV1d7fb9AwcONKu+BQsWuKyI3dz6m7r4ZGvithoAAG3Q8uXL1alTJx08eNDfTfGKtWvXqlOnTtq+fbvPzxXUI0dPPfWU/vrXv8putysiIkLnzp1rtHxVVZV+9rOf6b//+7/1z3/+U1arVbfffrsWL16shISE1mk0AAA+tnbtWl28eFGS1LNnz2Yfv337dt1xxx1u3z9//rzHbfNURkaGhg0bJkk+XwogqMPRl19+qfvuu09paWlNmv1+4cIF5eXl6cknn9SgQYN09uxZzZgxQxkZGdq7d28rtBgAAN/r3r17i44fMmSI7Ha7dxrjJdHR0YqOjm6VcwV1OFq4cKGkpt+vtFqt2rx5s8u+3/3udxo6dKiKi4vdputLly7p0qVLztfl5eWeNRgAgCAQFRWlr3/96/5uht+0+zlHDodDFoul0SG6RYsWyWq1OrfExMTWayAAAGhV7TocVVZWau7cuZo4caJiYmLclps3b54cDodzO378eCu2EgAAtKaAC0cLFiyQxWJpdPPG/KCqqiplZmaqpqZGy5cvb7RsZGSkYmJiXDYAANA2Bdyco2nTpikzM7PRMklJSS06R1VVle6//34VFRXpgw8+IOwAAACngAtHsbGxio2N9Vn9dcHok08+0ZYtW9S1a+AszAUAAPwv4G6rNUdxcbHsdruKi4tVXV3t/GE78/oLycnJ2rBhgyTp8uXL+s///E/t3btXa9euVXV1tUpLS1VaWqovv/zSX5cBAGjLaqqlou3SwT/X/meN+9WjvWXUqFHOqSiB9ki+p1avXu28phkzZvj0XEEdjn7+859r8ODBmj9/vs6fP6/Bgwdr8ODBLnOSCgsL5XA4JEmfffaZNm7cqM8++0w33HCD4uPjndvOnTv9dRkAgLaqYKO0NFV6eZz01oO1/7k0tXa/j02dOlUlJSVKTU3V0aNHZbHU/p7bW2+9pdDQUBUXFzd4XHJysqZPn+623rq6GtvMPyfSt29fRURE6MSJE5KkrVu3XvX41atXa+vWrS7TaL7zne+opKREaWlpLe+cqwi422rNsXr16quucWQYhvO/JyUlubwGAMBnCjZKb06WdMX3TnlJ7f77X5FSMnx2+o4dO8pms9Xbn5GRoa5du+rll1/Wk08+6fLe3//+dxUWFuqNN95wW29iYqJKSkqcr5955hnl5OTo/fffd+7r1KmTJGnHjh2qrKzUfffdp9WrV+uJJ57QiBEjXI5/7LHHVF5erpdeesm5z2q1as+ePS7njYqKUlRUlCIiIprYA54L6pEjAAACUk21lDNH9YKR9H/7cua2yi22K4WHhysrK0urV6+uN2CwatUq3XjjjRo0aJDb40NDQ2Wz2Zxbp06dFBYWVm+fJGVnZ2vixInKysrSqlWrZBiGIiIiXMpGRUUpMjKy3j5/IhwFiOoaQ7s+Pa2/2E9o16enVV3DCBcABK1jO6Xyk40UMKTyE7Xl/ODBBx/UP//5T23bts2574svvtCbb76pBx980CvnqKio0J/+9CdNmjRJo0eP1hdffKGtW7d6pW5fC+rbam1FzqESLdxUoBJHpXNfvLWD5t+dovTUeD+2DADgkfOnvFuuha6cVpKSkqJhw4bppZde0qhRoyRJb775pqqrqzVhwgSvnHPdunXq06eP+vfvL0nKzMxUdna2brvttiYdP2rUKB09etQrbWkuRo78LOdQiR55Nc8lGElSqaNSj7yap5xDJW6OBAAErE7dvFvOBx588EH9+c9/VkVFhaTaW2r33HOP137xPjs7W5MmTXK+njRpktavX69z5855pX5fIhz5UXWNoYWbChq7I62Fmwq4xQYAwabXCCkmQZLFTQGLFNO9tpyfZGZmymKx6I033tA//vEP7dixw2u31AoKCrRnzx7Nnj1bYWFhCgsL0/Dhw3Xx4kW9/vrrXjmHLxGO/Ci36Ey9ESMzQ1KJo1K5RWdar1EAgJYLCZXSl3z14sqA9NXr9MW15fwkOjpa9913n1566SWtWrVK1113nfMWW0tlZ2frlltuUX5+vnMNQrvdrtmzZys7O9sr5/AlwpEflVW4D0aelAMABJCUjNrH9WOumDsak+Dzx/ib6sEHH9TOnTu1YsUKPfDAA861kFqiqqpKa9as0YQJE5SamuqyPfTQQ9q3b5/y8/O90HrfYUK2H8VFd/BqOQBAgEnJkJLvqn0q7fyp2jlGvUb4dcTIbOTIkerbt68++eQTTZkyxSt1bty4UadPn9b48ePrvdenTx8NGDBA2dnZev75571yPl8gHPnR0N5dFG/toFJHZYPzjiySbNYOGtq7S2s3DQDgLSGhUu+b/d0Ktz7++OMWHb9gwQKXFbHvvfdeVVe7X7/pwIEDLq+vtpizP3BbzY9CQyyaf3eKJLd3pDX/7hSFhrR8mBMA0L4sX75cnTp10sGDB/3dFK9Yu3atOnXqpO3bt/v8XIwc+Vl6arxWTPpmvXWObKxzBADw0Nq1a3Xx4kVJUs+ePZt9/Pbt23XHHXe4fd/8A++tJSMjQ8OGDZMkry034A7hKACkp8ZrdIpNuUVnVFZRqbjo2ltpjBgBADzRvXv3Fh0/ZMgQ2e127zTGS6KjoxUdHd0q5yIcBYjQEIvSru/q72YAAKCoqCh9/etf93cz/IY5RwAANOLKH2dFYPPGvxfhCACABoSHh0uSLly44OeWoDnq/r3q/v08wW01AAAaEBoaqs6dO6usrEyS1LFjR68skgjfMAxDFy5cUFlZmTp37qzQUM/XkiIcAQDghs1mkyRnQELg69y5s/PfzVOEIwAA3LBYLIqPj1dcXJyqqqr83RxcRXh4eItGjOoQjgAAuIrQ0FCvfOkiODAhGwAAwIRwBAAAYEI4AgAAMGHOkQfqFpgqLy/3c0sAAEBT1X1vX22hSMKRByoqKiRJiYmJfm4JAABoroqKClmtVrfvWwzWRW+2mpoanTx5UtHR0e12QbDy8nIlJibq+PHjiomJ8Xdz/IZ+qEU/0Ad16Ida9EOtQOsHwzBUUVGhhIQEhYS4n1nEyJEHQkJC1KNHD383IyDExMQExB+8v9EPtegH+qAO/VCLfqgVSP3Q2IhRHSZkAwAAmBCOAAAATAhH8EhkZKTmz5+vyMhIfzfFr+iHWvQDfVCHfqhFP9QK1n5gQjYAAIAJI0cAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAS3Fi1apG9961uKjo5WXFycvv3tb6uwsNCljGEYWrBggRISEhQVFaVRo0bpo48+8lOLW8eiRYtksVg0Y8YM57720g8nTpzQpEmT1LVrV3Xs2FE33HCD9u3b53y/PfTD5cuX9bOf/Uy9e/dWVFSUrrvuOv3iF79QTU2Ns0xb7Ie//e1vuvvuu5WQkCCLxaK3337b5f2mXPOlS5f06KOPKjY2Vtdcc40yMjL02WefteJVtExjfVBVVaU5c+ZowIABuuaaa5SQkKDJkyfr5MmTLnUEex9IV/9bMPvBD34gi8WipUuXuuwP9H4gHMGtbdu26Uc/+pF2796tzZs36/LlyxozZoy++OILZ5mnn35azz77rJYtW6YPP/xQNptNo0ePdv7+XFvz4Ycf6o9//KMGDhzosr899MPZs2d10003KTw8XP/zP/+jgoIC/eY3v1Hnzp2dZdpDPyxZskQvvPCCli1bpsOHD+vpp5/Wr3/9a/3ud79zlmmL/fDFF19o0KBBWrZsWYPvN+WaZ8yYoQ0bNmjdunXasWOHzp8/r3Hjxqm6urq1LqNFGuuDCxcuKC8vT08++aTy8vK0fv16HTlyRBkZGS7lgr0PpKv/LdR5++23tWfPHiUkJNR7L+D7wQCaqKyszJBkbNu2zTAMw6ipqTFsNpuxePFiZ5nKykrDarUaL7zwgr+a6TMVFRVGnz59jM2bNxu33nqr8dhjjxmG0X76Yc6cOcbIkSPdvt9e+uGuu+4yHnjgAZd999xzjzFp0iTDMNpHP0gyNmzY4HzdlGs+d+6cER4ebqxbt85Z5sSJE0ZISIiRk5PTam33liv7oCG5ubmGJOPYsWOGYbS9PjAM9/3w2WefGd27dzcOHTpk9OrVy/jtb3/rfC8Y+oGRIzSZw+GQJHXp0kWSVFRUpNLSUo0ZM8ZZJjIyUrfeeqt27tzplzb60o9+9CPddddduv322132t5d+2Lhxo4YMGaL77rtPcXFxGjx4sFauXOl8v730w8iRI/W///u/OnLkiCQpPz9fO3bs0J133imp/fSDWVOued++faqqqnIpk5CQoNTU1DbbLw6HQxaLxTm62l76oKamRllZWZo1a5b69+9f7/1g6Ad+eBZNYhiGHn/8cY0cOVKpqamSpNLSUklSt27dXMp269ZNx44da/U2+tK6deuUl5enDz/8sN577aUf/vnPf2rFihV6/PHH9dOf/lS5ubmaPn26IiMjNXny5HbTD3PmzJHD4VBycrJCQ0NVXV2tp556ShMmTJDUfv4ezJpyzaWlpYqIiNC1115br0zd8W1JZWWl5s6dq4kTJzp/cLW99MGSJUsUFham6dOnN/h+MPQD4QhNMm3aNB04cEA7duyo957FYnF5bRhGvX3B7Pjx43rsscf03nvvqUOHDm7LtfV+qKmp0ZAhQ/SrX/1KkjR48GB99NFHWrFihSZPnuws19b74Y033tCrr76q1157Tf3795fdbteMGTOUkJCgKVOmOMu19X5oiCfX3Bb7paqqSpmZmaqpqdHy5cuvWr4t9cG+ffv03HPPKS8vr9nXFEj9wG01XNWjjz6qjRs3asuWLerRo4dzv81mk6R6Sb+srKze/4MMZvv27VNZWZluvPFGhYWFKSwsTNu2bdPzzz+vsLAw57W29X6Ij49XSkqKy75+/fqpuLhYUvv5e5g1a5bmzp2rzMxMDRgwQFlZWZo5c6YWLVokqf30g1lTrtlms+nLL7/U2bNn3ZZpC6qqqnT//ferqKhImzdvdo4aSe2jD7Zv366ysjL17NnT+Xl57Ngx/fjHP1ZSUpKk4OgHwhHcMgxD06ZN0/r16/XBBx+od+/eLu/37t1bNptNmzdvdu778ssvtW3bNo0YMaK1m+sz//7v/66DBw/Kbrc7tyFDhui73/2u7Ha7rrvuunbRDzfddFO9pRyOHDmiXr16SWo/fw8XLlxQSIjrR2doaKjzUf720g9mTbnmG2+8UeHh4S5lSkpKdOjQoTbTL3XB6JNPPtH777+vrl27urzfHvogKytLBw4ccPm8TEhI0KxZs/Tuu+9KCpJ+8NdMcAS+Rx55xLBarcbWrVuNkpIS53bhwgVnmcWLFxtWq9VYv369cfDgQWPChAlGfHy8UV5e7seW+575aTXDaB/9kJuba4SFhRlPPfWU8cknnxhr1641OnbsaLz66qvOMu2hH6ZMmWJ0797deOedd4yioiJj/fr1RmxsrDF79mxnmbbYDxUVFcb+/fuN/fv3G5KMZ5991ti/f7/zSaymXPPDDz9s9OjRw3j//feNvLw849/+7d+MQYMGGZcvX/bXZTVLY31QVVVlZGRkGD169DDsdrvLZ+alS5ecdQR7HxjG1f8WrnTl02qGEfj9QDiCW5Ia3F566SVnmZqaGmP+/PmGzWYzIiMjjVtuucU4ePCg/xrdSq4MR+2lHzZt2mSkpqYakZGRRnJysvHHP/7R5f320A/l5eXGY489ZvTs2dPo0KGDcd111xlPPPGEyxdgW+yHLVu2NPh5MGXKFMMwmnbNFy9eNKZNm2Z06dLFiIqKMsaNG2cUFxf74Wo801gfFBUVuf3M3LJli7OOYO8Dw7j638KVGgpHgd4PFsMwjNYYoQIAAAgGzDkCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADAhHAEAAJgQjgAAAEwIRwDaraNHj8pisWj9+vW65ZZbFBUVpRtvvFFHjx7V1q1bNXToUHXs2FG33Xabzpw54+/mAmglYf5uAAD4i91ulyQtX75cv/rVr9SpUyd9+9vfVlZWljp16qTf//73MgxDd955p7KzszVr1iz/NhhAqyAcAWi38vPzde2112rdunWKjY2VJN1222364IMPVFBQoGuuuUaS9K1vfUulpaX+bCqAVsRtNQDtlt1uV0ZGhjMYSVJxcbEmTJjgDEZ1+3r37u2PJgLwA8IRgHYrPz9fw4cPd9lnt9s1bNgw5+vKykodOXJEN9xwQyu3DoC/EI4AtEvl5eU6evSoBg8e7Nx37NgxnTlzxmXfRx99pOrqag0aNMgfzQTgB4QjAO1Sfn6+QkJCNHDgQOc+u92uzp07KykpyaXcddddp+joaD+0EoA/EI4AtEv5+flKTk5WVFSUc9/+/fvrjRDl5+dzSw1oZyyGYRj+bgQAAECgYOQIAADAhHAEAABgQjgCAAAwIRwBAACYEI4AAABMCEcAAAAmhCMAAAATwhEAAIAJ4QgAAMCEcAQAAGBCOAIAADD5/0vygO7ocNYYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,R2_p.mean(axis=1)-R2.mean(axis=1),'o')\n",
    "plt.legend(y_labels.values)\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xlabel('$m$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "392d603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE_p\n",
    "\n",
    "R2_p-R2\n",
    "\n",
    "plt.plot(x,R2.mean(axis=1),'o')\n",
    "plt.legend(y_labels.values)\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xlabel('$m$')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f6081e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[268.0523,  87.7354],\n",
       "        [201.0160, 129.8302],\n",
       "        [257.8859, 112.8064],\n",
       "        [207.9873,  87.8433],\n",
       "        [142.1023,  82.8272],\n",
       "        [197.1525, 122.3467],\n",
       "        [137.4087,  71.9399],\n",
       "        [118.2914, 102.6333],\n",
       "        [175.2412, 135.4287],\n",
       "        [334.2281, 107.9589],\n",
       "        [130.1062,  87.2561],\n",
       "        [136.7124,  76.5363],\n",
       "        [168.5923,  91.7037],\n",
       "        [160.2966, 103.2695],\n",
       "        [115.6363, 153.7247],\n",
       "        [237.0847,  78.4771],\n",
       "        [225.9848,  74.4345],\n",
       "        [292.9006, 103.6683],\n",
       "        [173.4247,  99.6053],\n",
       "        [267.0595, 137.4603],\n",
       "        [142.7117, 119.4908],\n",
       "        [119.4581, 165.6770],\n",
       "        [219.8924, 123.0268],\n",
       "        [276.5518, 156.1874],\n",
       "        [105.3259, 137.2492],\n",
       "        [224.6073,  99.1568],\n",
       "        [139.2359,  94.0267],\n",
       "        [193.0615, 106.7952],\n",
       "        [295.5942,  73.9571],\n",
       "        [299.6843,  72.6311],\n",
       "        [186.3310,  77.3549],\n",
       "        [184.6208, 125.7266],\n",
       "        [241.1693, 107.3718],\n",
       "        [110.3584,  96.6685],\n",
       "        [310.1577, 100.8897],\n",
       "        [108.7937,  92.2147]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13668c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d76d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec2e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b626b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    #('scaler', StandardScaler()),\n",
    "    ('preprocessor', PolynomialFeatures(degree=1, include_bias=False,interaction_only=False)),\n",
    "    ('lasso', LassoCV(n_alphas=1000,max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b84a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m0_mat(y_test,emulators,x_test,output):\n",
    "\n",
    "    m0=torch.zeros((y_test.shape[0],len(emulators)))\n",
    "    for i in range(len(emulators)):\n",
    "        m0[:,i]=(emulators[i].predict(x_test)[:,output]-y_train.mean(axis=0)[output])/y_train.std(axis=0)[output]\n",
    "\n",
    "\n",
    "    return m0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f336bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy(a,y_train,m0,output):\n",
    "    m_t = (m0-y_train.mean(axis=0))/y_train.std(axis=0)\n",
    "    y_t = (y_train-y_train.mean(axis=0))/y_train.std(axis=0)\n",
    "    a=torch.tensor(a)\n",
    "    res = ((a*m_t-y_t)**2).mean(axis=0).detach().numpy()\n",
    "    return res[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080fcbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9659, 0.9468], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.0535, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0522, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79863112]\n",
      "[1.00816414]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.4827, 0.9658], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.0535, 0.0261, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0522, 0.0536, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.8387051]\n",
      "[0.93769251]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9340, 0.9501], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.0535, 0.0261, 0.0517, 0.0000, 0.0000],\n",
      "         [0.0522, 0.0536, 0.0526, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.47338421]\n",
      "[0.52545486]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9146, 0.6669], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.0535, 0.0261, 0.0517, 0.0488, 0.0000],\n",
      "         [0.0522, 0.0536, 0.0526, 0.0339, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.61233422]\n",
      "[0.72326052]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9408, 0.8904], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.0535, 0.0261, 0.0517, 0.0488, 0.0520],\n",
      "         [0.0522, 0.0536, 0.0526, 0.0339, 0.0492]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.75615295]\n",
      "[0.84480653]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8867, 0.9628], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1020, 0.0261, 0.0517, 0.0488, 0.0520],\n",
      "         [0.1056, 0.0536, 0.0526, 0.0339, 0.0492]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02451192]\n",
      "[0.99590946]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([ 0.7210, -0.0018], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1020, 0.0640, 0.0517, 0.0488, 0.0520],\n",
      "         [0.1056, 0.0527, 0.0526, 0.0339, 0.0492]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0482902]\n",
      "[0.95258474]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9842, 0.9766], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1020, 0.0640, 0.1062, 0.0488, 0.0520],\n",
      "         [0.1056, 0.0527, 0.1067, 0.0339, 0.0492]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01844973]\n",
      "[0.9511421]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7958, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1020, 0.0640, 0.1062, 0.0929, 0.0520],\n",
      "         [0.1056, 0.0527, 0.1067, 0.0892, 0.0492]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.53051922]\n",
      "[0.72308886]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8876, 0.9939], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1020, 0.0640, 0.1062, 0.0929, 0.1012],\n",
      "         [0.1056, 0.0527, 0.1067, 0.0892, 0.1043]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.64797032]\n",
      "[0.7742821]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9727, 0.9738], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1554, 0.0640, 0.1062, 0.0929, 0.1012],\n",
      "         [0.1595, 0.0527, 0.1067, 0.0892, 0.1043]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.67104621]\n",
      "[0.64578143]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9301, 0.9526], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1554, 0.1154, 0.1062, 0.0929, 0.1012],\n",
      "         [0.1595, 0.1052, 0.1067, 0.0892, 0.1043]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01493795]\n",
      "[0.59225354]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9320, 0.9591], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1554, 0.1154, 0.1567, 0.0929, 0.1012],\n",
      "         [0.1595, 0.1052, 0.1599, 0.0892, 0.1043]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03676461]\n",
      "[0.83875139]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9126, 0.8501], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1554, 0.1154, 0.1567, 0.1422, 0.1012],\n",
      "         [0.1595, 0.1052, 0.1599, 0.1360, 0.1043]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01713269]\n",
      "[0.93441159]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9311, 0.9918], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1554, 0.1154, 0.1567, 0.1422, 0.1525],\n",
      "         [0.1595, 0.1052, 0.1599, 0.1360, 0.1594]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01367965]\n",
      "[0.90870103]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7629, 0.8869], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1975, 0.1154, 0.1567, 0.1422, 0.1525],\n",
      "         [0.2086, 0.1052, 0.1599, 0.1360, 0.1594]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.09060032]\n",
      "[0.98367516]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9817, 0.9825], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1975, 0.1699, 0.1567, 0.1422, 0.1525],\n",
      "         [0.2086, 0.1597, 0.1599, 0.1360, 0.1594]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99500604]\n",
      "[0.82786433]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8938, 0.9601], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1975, 0.1699, 0.2062, 0.1422, 0.1525],\n",
      "         [0.2086, 0.1597, 0.2132, 0.1360, 0.1594]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79141572]\n",
      "[0.80804595]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9534, 0.5774], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1975, 0.1699, 0.2062, 0.1950, 0.1525],\n",
      "         [0.2086, 0.1597, 0.2132, 0.1667, 0.1594]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98917329]\n",
      "[1.03459778]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8666, 0.6951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.1975, 0.1699, 0.2062, 0.1950, 0.2001],\n",
      "         [0.2086, 0.1597, 0.2132, 0.1667, 0.1970]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87150103]\n",
      "[1.00673721]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9907, 0.9701], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.2524, 0.1699, 0.2062, 0.1950, 0.2001],\n",
      "         [0.2622, 0.1597, 0.2132, 0.1667, 0.1970]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92245104]\n",
      "[0.88156064]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9851, 0.9628], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.2524, 0.2246, 0.2062, 0.1950, 0.2001],\n",
      "         [0.2622, 0.2131, 0.2132, 0.1667, 0.1970]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9606882]\n",
      "[0.97115052]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9817, 0.9678], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.2524, 0.2246, 0.2606, 0.1950, 0.2001],\n",
      "         [0.2622, 0.2131, 0.2664, 0.1667, 0.1970]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98222021]\n",
      "[0.96391186]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9723, 0.9597], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.2524, 0.2246, 0.2606, 0.2489, 0.2001],\n",
      "         [0.2622, 0.2131, 0.2664, 0.2197, 0.1970]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.73367088]\n",
      "[1.01478154]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9408, 0.9608], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.2524, 0.2246, 0.2606, 0.2489, 0.2520],\n",
      "         [0.2622, 0.2131, 0.2664, 0.2197, 0.2501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95299942]\n",
      "[0.99157828]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9573, 0.7318], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3053, 0.2246, 0.2606, 0.2489, 0.2520],\n",
      "         [0.3020, 0.2131, 0.2664, 0.2197, 0.2501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97011779]\n",
      "[0.71491913]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9889, 0.9913], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3053, 0.2795, 0.2606, 0.2489, 0.2520],\n",
      "         [0.3020, 0.2681, 0.2664, 0.2197, 0.2501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69935696]\n",
      "[1.0163229]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9682, 0.6597], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3053, 0.2795, 0.3141, 0.2489, 0.2520],\n",
      "         [0.3020, 0.2681, 0.3014, 0.2197, 0.2501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78519334]\n",
      "[0.59662238]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9199], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3053, 0.2795, 0.3141, 0.3041, 0.2520],\n",
      "         [0.3020, 0.2681, 0.3014, 0.2703, 0.2501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.59291455]\n",
      "[0.85055861]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9595, 0.9479], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3053, 0.2795, 0.3141, 0.3041, 0.3050],\n",
      "         [0.3020, 0.2681, 0.3014, 0.2703, 0.3026]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90732659]\n",
      "[0.46305683]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9262, 0.8934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3568, 0.2795, 0.3141, 0.3041, 0.3050],\n",
      "         [0.3515, 0.2681, 0.3014, 0.2703, 0.3026]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.27478737]\n",
      "[0.85610149]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([ 0.7783, -0.6515], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3568, 0.3208, 0.3141, 0.3041, 0.3050],\n",
      "         [0.3515, 0.2298, 0.3014, 0.2703, 0.3026]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86718528]\n",
      "[0.88556791]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8964, 0.9324], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3568, 0.3208, 0.3638, 0.3041, 0.3050],\n",
      "         [0.3515, 0.2298, 0.3531, 0.2703, 0.3026]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98618689]\n",
      "[0.98342549]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9410, 0.9787], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3568, 0.3208, 0.3638, 0.3556, 0.3050],\n",
      "         [0.3515, 0.2298, 0.3531, 0.3243, 0.3026]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98407243]\n",
      "[0.87642474]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9883, 0.9848], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.3568, 0.3208, 0.3638, 0.3556, 0.3597],\n",
      "         [0.3515, 0.2298, 0.3531, 0.3243, 0.3572]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.71970866]\n",
      "[0.5548851]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9406, 0.5360], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4072, 0.3208, 0.3638, 0.3556, 0.3597],\n",
      "         [0.3800, 0.2298, 0.3531, 0.3243, 0.3572]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02469037]\n",
      "[0.62198961]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.1081], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4072, 0.3761, 0.3638, 0.3556, 0.3597],\n",
      "         [0.3800, 0.2356, 0.3531, 0.3243, 0.3572]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.390796]\n",
      "[0.94900091]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9862, 0.7531], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4072, 0.3761, 0.4182, 0.3556, 0.3597],\n",
      "         [0.3800, 0.2356, 0.3947, 0.3243, 0.3572]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00753489]\n",
      "[0.86266894]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9393, 0.9724], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4072, 0.3761, 0.4182, 0.4068, 0.3597],\n",
      "         [0.3800, 0.2356, 0.3947, 0.3783, 0.3572]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92880182]\n",
      "[0.89600558]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7870, 0.5935], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4072, 0.3761, 0.4182, 0.4068, 0.4025],\n",
      "         [0.3800, 0.2356, 0.3947, 0.3783, 0.3898]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.64869163]\n",
      "[0.77522871]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9557, 0.9936], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4603, 0.3761, 0.4182, 0.4068, 0.4025],\n",
      "         [0.4349, 0.2356, 0.3947, 0.3783, 0.3898]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99379451]\n",
      "[0.99987673]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8377, 0.9301], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4603, 0.4221, 0.4182, 0.4068, 0.4025],\n",
      "         [0.4349, 0.2870, 0.3947, 0.3783, 0.3898]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.70828152]\n",
      "[0.89440375]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9695, 0.9400], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4603, 0.4221, 0.4718, 0.4068, 0.4025],\n",
      "         [0.4349, 0.2870, 0.4468, 0.3783, 0.3898]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.83474711]\n",
      "[0.87537529]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9541, 0.9735], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4603, 0.4221, 0.4718, 0.4596, 0.4025],\n",
      "         [0.4349, 0.2870, 0.4468, 0.4321, 0.3898]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69127021]\n",
      "[0.947304]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7739, 0.9752], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.4603, 0.4221, 0.4718, 0.4596, 0.4406],\n",
      "         [0.4349, 0.2870, 0.4468, 0.4321, 0.4439]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02596883]\n",
      "[0.27853161]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.7165], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5157, 0.4221, 0.4718, 0.4596, 0.4406],\n",
      "         [0.4743, 0.2870, 0.4468, 0.4321, 0.4439]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02047549]\n",
      "[0.97465262]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([-0.5158,  0.9687], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5157, 0.3927, 0.4718, 0.4596, 0.4406],\n",
      "         [0.4743, 0.3403, 0.4468, 0.4321, 0.4439]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.18462682]\n",
      "[0.86944951]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8407, 0.9116], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5157, 0.3927, 0.5181, 0.4596, 0.4406],\n",
      "         [0.4743, 0.3403, 0.4972, 0.4321, 0.4439]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95966309]\n",
      "[1.01801822]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8692, 0.9714], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5157, 0.3927, 0.5181, 0.5073, 0.4406],\n",
      "         [0.4743, 0.3403, 0.4972, 0.4855, 0.4439]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93193874]\n",
      "[0.82001138]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9779, 0.9754], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5157, 0.3927, 0.5181, 0.5073, 0.4949],\n",
      "         [0.4743, 0.3403, 0.4972, 0.4855, 0.4980]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.89951499]\n",
      "[1.01096088]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9393, 0.8928], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5675, 0.3927, 0.5181, 0.5073, 0.4949],\n",
      "         [0.5237, 0.3403, 0.4972, 0.4855, 0.4980]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02110679]\n",
      "[0.88560702]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9662, 0.9634], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5675, 0.4460, 0.5181, 0.5073, 0.4949],\n",
      "         [0.5237, 0.3931, 0.4972, 0.4855, 0.4980]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00722719]\n",
      "[0.86608372]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9657, 0.9424], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5675, 0.4460, 0.5715, 0.5073, 0.4949],\n",
      "         [0.5237, 0.3931, 0.5493, 0.4855, 0.4980]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00879293]\n",
      "[0.96655196]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8506, 0.9813], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5675, 0.4460, 0.5715, 0.5537, 0.4949],\n",
      "         [0.5237, 0.3931, 0.5493, 0.5399, 0.4980]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96175711]\n",
      "[1.03604443]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9803, 0.9799], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5675, 0.4460, 0.5715, 0.5537, 0.5492],\n",
      "         [0.5237, 0.3931, 0.5493, 0.5399, 0.5523]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88332934]\n",
      "[0.82031747]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.5384, 0.6911], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5965, 0.4460, 0.5715, 0.5537, 0.5492],\n",
      "         [0.5611, 0.3931, 0.5493, 0.5399, 0.5523]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95890958]\n",
      "[0.78577011]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9638, 0.9205], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5965, 0.4995, 0.5715, 0.5537, 0.5492],\n",
      "         [0.5611, 0.4438, 0.5493, 0.5399, 0.5523]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.33049067]\n",
      "[0.88521749]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8624, 0.8967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5965, 0.4995, 0.6191, 0.5537, 0.5492],\n",
      "         [0.5611, 0.4438, 0.5990, 0.5399, 0.5523]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.64927276]\n",
      "[0.94601648]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9796, 0.7906], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5965, 0.4995, 0.6191, 0.6080, 0.5492],\n",
      "         [0.5611, 0.4438, 0.5990, 0.5836, 0.5523]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.89332255]\n",
      "[0.9131974]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([-0.0496,  0.9494], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.5965, 0.4995, 0.6191, 0.6080, 0.5461],\n",
      "         [0.5611, 0.4438, 0.5990, 0.5836, 0.6050]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95000497]\n",
      "[1.03202866]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9902, 0.9858], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.6514, 0.4995, 0.6191, 0.6080, 0.5461],\n",
      "         [0.6158, 0.4438, 0.5990, 0.5836, 0.6050]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97111448]\n",
      "[0.74222352]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9882, 0.9495], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.6514, 0.5540, 0.6191, 0.6080, 0.5461],\n",
      "         [0.6158, 0.4960, 0.5990, 0.5836, 0.6050]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03628398]\n",
      "[0.8920945]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9716, 0.9326], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.6514, 0.5540, 0.6726, 0.6080, 0.5461],\n",
      "         [0.6158, 0.4960, 0.6506, 0.5836, 0.6050]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95082539]\n",
      "[0.86446731]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9924, 0.3295], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.6514, 0.5540, 0.6726, 0.6631, 0.5461],\n",
      "         [0.6158, 0.4960, 0.6506, 0.6017, 0.6050]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00104932]\n",
      "[1.07039756]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([ 0.9378, -0.4342], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.6514, 0.5540, 0.6726, 0.6631, 0.5981],\n",
      "         [0.6158, 0.4960, 0.6506, 0.6017, 0.5678]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98726696]\n",
      "[0.95670346]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9671, 0.9139], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7050, 0.5540, 0.6726, 0.6631, 0.5981],\n",
      "         [0.6665, 0.4960, 0.6506, 0.6017, 0.5678]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93170611]\n",
      "[0.77844481]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9638, 0.9877], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7050, 0.6055, 0.6726, 0.6631, 0.5981],\n",
      "         [0.6665, 0.5507, 0.6506, 0.6017, 0.5678]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.72114805]\n",
      "[0.8166301]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.5108, 0.9451], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7050, 0.6055, 0.6997, 0.6631, 0.5981],\n",
      "         [0.6665, 0.5507, 0.7028, 0.6017, 0.5678]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04512004]\n",
      "[1.07156669]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9243, 0.9633], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7050, 0.6055, 0.6997, 0.7141, 0.5981],\n",
      "         [0.6665, 0.5507, 0.7028, 0.6552, 0.5678]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04206741]\n",
      "[0.78217714]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.5218, 0.8174], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7050, 0.6055, 0.6997, 0.7141, 0.6252],\n",
      "         [0.6665, 0.5507, 0.7028, 0.6552, 0.6131]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03544904]\n",
      "[0.99038048]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9313, 0.5814], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7565, 0.6055, 0.6997, 0.7141, 0.6252],\n",
      "         [0.6963, 0.5507, 0.7028, 0.6552, 0.6131]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.31572928]\n",
      "[0.87684594]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8156, 0.9238], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7565, 0.6505, 0.6997, 0.7141, 0.6252],\n",
      "         [0.6963, 0.6012, 0.7028, 0.6552, 0.6131]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79878274]\n",
      "[0.86539273]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9828, 0.3623], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7565, 0.6505, 0.7541, 0.7141, 0.6252],\n",
      "         [0.6963, 0.6012, 0.7189, 0.6552, 0.6131]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.73911923]\n",
      "[0.63228143]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8452, 0.9622], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7565, 0.6505, 0.7541, 0.7607, 0.6252],\n",
      "         [0.6963, 0.6012, 0.7189, 0.7085, 0.6131]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96252354]\n",
      "[0.89646994]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7978, 0.7816], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.7565, 0.6505, 0.7541, 0.7607, 0.6643],\n",
      "         [0.6963, 0.6012, 0.7189, 0.7085, 0.6554]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86015235]\n",
      "[0.97658302]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8994, 0.9774], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8062, 0.6505, 0.7541, 0.7607, 0.6643],\n",
      "         [0.7503, 0.6012, 0.7189, 0.7085, 0.6554]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93794469]\n",
      "[0.96201746]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7113, 0.9157], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8062, 0.6896, 0.7541, 0.7607, 0.6643],\n",
      "         [0.7503, 0.6510, 0.7189, 0.7085, 0.6554]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.927289]\n",
      "[0.84302464]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.8613], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8062, 0.6896, 0.8092, 0.7607, 0.6643],\n",
      "         [0.7503, 0.6510, 0.7664, 0.7085, 0.6554]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98358704]\n",
      "[0.99527766]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9267], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8062, 0.6896, 0.8092, 0.8160, 0.6643],\n",
      "         [0.7503, 0.6510, 0.7664, 0.7594, 0.6554]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74650303]\n",
      "[0.7733197]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9825, 0.9626], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8062, 0.6896, 0.8092, 0.8160, 0.7188],\n",
      "         [0.7503, 0.6510, 0.7664, 0.7594, 0.7088]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90298417]\n",
      "[0.60160807]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9638, 0.9723], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8592, 0.6896, 0.8092, 0.8160, 0.7188],\n",
      "         [0.8026, 0.6510, 0.7664, 0.7594, 0.7088]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.85131562]\n",
      "[0.94758825]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8323, 0.9596], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8592, 0.7351, 0.8092, 0.8160, 0.7188],\n",
      "         [0.8026, 0.7042, 0.7664, 0.7594, 0.7088]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94477158]\n",
      "[0.79777072]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9864, 0.9762], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8592, 0.7351, 0.8640, 0.8160, 0.7188],\n",
      "         [0.8026, 0.7042, 0.8204, 0.7594, 0.7088]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.43271351]\n",
      "[0.42211033]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([-3.3549,  0.7029], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8592, 0.7351, 0.8640, 0.6265, 0.7188],\n",
      "         [0.8026, 0.7042, 0.8204, 0.7980, 0.7088]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.66107155]\n",
      "[0.40568969]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9792, 0.9542], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.8592, 0.7351, 0.8640, 0.6265, 0.7730],\n",
      "         [0.8026, 0.7042, 0.8204, 0.7980, 0.7617]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79114556]\n",
      "[0.69635837]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.7731, 0.9836], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7351, 0.8640, 0.6265, 0.7730],\n",
      "         [0.8570, 0.7042, 0.8204, 0.7980, 0.7617]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.4539057]\n",
      "[0.76930734]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9808, 0.2088], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.8640, 0.6265, 0.7730],\n",
      "         [0.8570, 0.7148, 0.8204, 0.7980, 0.7617]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.32131101]\n",
      "[0.48885286]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9794, 0.9768], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6265, 0.7730],\n",
      "         [0.8570, 0.7148, 0.8745, 0.7980, 0.7617]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97488139]\n",
      "[0.61715997]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8142, 0.9822], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7730],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.7617]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.91989349]\n",
      "[0.52753576]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.3711, 0.9911], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03220936]\n",
      "[0.99370491]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9935, 0.9761], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0551, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0539, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.48873537]\n",
      "[0.97895293]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9256], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0551, 0.0552, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0539, 0.0497, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.27656304]\n",
      "[0.95593548]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9664], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0551, 0.0552, 0.0552, 0.0000, 0.0000],\n",
      "         [0.0539, 0.0497, 0.0531, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.59861184]\n",
      "[0.60209902]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9790, 0.0818], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0551, 0.0552, 0.0552, 0.0539, 0.0000],\n",
      "         [0.0539, 0.0497, 0.0531, 0.0032, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.43041009]\n",
      "[0.93750936]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9882], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.0551, 0.0552, 0.0552, 0.0539, 0.0554],\n",
      "         [0.0539, 0.0497, 0.0531, 0.0032, 0.0547]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.4882373]\n",
      "[0.90603242]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9847, 0.9844], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1092, 0.0552, 0.0552, 0.0539, 0.0554],\n",
      "         [0.1084, 0.0497, 0.0531, 0.0032, 0.0547]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94056306]\n",
      "[0.77935863]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9325, 0.9814], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1092, 0.1066, 0.0552, 0.0539, 0.0554],\n",
      "         [0.1084, 0.1031, 0.0531, 0.0032, 0.0547]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78652719]\n",
      "[0.56017613]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9681, 0.9889], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1092, 0.1066, 0.1083, 0.0539, 0.0554],\n",
      "         [0.1084, 0.1031, 0.1079, 0.0032, 0.0547]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88685893]\n",
      "[0.88322963]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9808], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1092, 0.1066, 0.1083, 0.1092, 0.0554],\n",
      "         [0.1084, 0.1031, 0.1079, 0.0574, 0.0547]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79103144]\n",
      "[0.71597757]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9881, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1092, 0.1066, 0.1083, 0.1092, 0.1100],\n",
      "         [0.1084, 0.1031, 0.1079, 0.0574, 0.1098]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.61346412]\n",
      "[0.97542323]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9916, 0.9520], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1641, 0.1066, 0.1083, 0.1092, 0.1100],\n",
      "         [0.1607, 0.1031, 0.1079, 0.0574, 0.1098]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95964785]\n",
      "[0.84559845]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9910], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1641, 0.1619, 0.1083, 0.1092, 0.1100],\n",
      "         [0.1607, 0.1579, 0.1079, 0.0574, 0.1098]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95312687]\n",
      "[1.02262884]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9844, 0.9815], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1641, 0.1619, 0.1628, 0.1092, 0.1100],\n",
      "         [0.1607, 0.1579, 0.1622, 0.0574, 0.1098]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99412013]\n",
      "[1.00265439]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9924], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1641, 0.1619, 0.1628, 0.1643, 0.1100],\n",
      "         [0.1607, 0.1579, 0.1622, 0.1125, 0.1098]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99613637]\n",
      "[0.98497961]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9935], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.1641, 0.1619, 0.1628, 0.1643, 0.1652],\n",
      "         [0.1607, 0.1579, 0.1622, 0.1125, 0.1648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95025319]\n",
      "[0.9451004]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2194, 0.1619, 0.1628, 0.1643, 0.1652],\n",
      "         [0.2160, 0.1579, 0.1622, 0.1125, 0.1648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98511113]\n",
      "[0.80943775]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9913, 0.9869], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2194, 0.2168, 0.1628, 0.1643, 0.1652],\n",
      "         [0.2160, 0.2125, 0.1622, 0.1125, 0.1648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02545707]\n",
      "[0.95293785]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9903, 0.9899], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2194, 0.2168, 0.2175, 0.1643, 0.1652],\n",
      "         [0.2160, 0.2125, 0.2169, 0.1125, 0.1648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9184848]\n",
      "[0.81885431]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9888, 0.9685], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2194, 0.2168, 0.2175, 0.2189, 0.1652],\n",
      "         [0.2160, 0.2125, 0.2169, 0.1648, 0.1648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98474494]\n",
      "[0.88028691]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9932, 0.9792], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2194, 0.2168, 0.2175, 0.2189, 0.2203],\n",
      "         [0.2160, 0.2125, 0.2169, 0.1648, 0.2187]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.07090803]\n",
      "[0.96689556]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.8712], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2748, 0.2168, 0.2175, 0.2189, 0.2203],\n",
      "         [0.2643, 0.2125, 0.2169, 0.1648, 0.2187]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95414878]\n",
      "[0.70204599]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9915, 0.9266], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2748, 0.2717, 0.2175, 0.2189, 0.2203],\n",
      "         [0.2643, 0.2635, 0.2169, 0.1648, 0.2187]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.39191849]\n",
      "[0.98975471]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9936, 0.9839], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2748, 0.2717, 0.2726, 0.2189, 0.2203],\n",
      "         [0.2643, 0.2635, 0.2713, 0.1648, 0.2187]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87235097]\n",
      "[0.94001241]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9481, 0.9364], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2748, 0.2717, 0.2726, 0.2713, 0.2203],\n",
      "         [0.2643, 0.2635, 0.2713, 0.2162, 0.2187]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.71336415]\n",
      "[1.02683623]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9935, 0.9700], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.2748, 0.2717, 0.2726, 0.2713, 0.2753],\n",
      "         [0.2643, 0.2635, 0.2713, 0.2162, 0.2723]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9793999]\n",
      "[0.85734003]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9827, 0.9681], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3291, 0.2717, 0.2726, 0.2713, 0.2753],\n",
      "         [0.3179, 0.2635, 0.2713, 0.2162, 0.2723]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00575399]\n",
      "[0.98014489]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3291, 0.3271, 0.2726, 0.2713, 0.2753],\n",
      "         [0.3179, 0.3187, 0.2713, 0.2162, 0.2723]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97301644]\n",
      "[0.89359488]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9904, 0.9829], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3291, 0.3271, 0.3274, 0.2713, 0.2753],\n",
      "         [0.3179, 0.3187, 0.3258, 0.2162, 0.2723]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.76339873]\n",
      "[0.90770504]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9868, 0.8369], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3291, 0.3271, 0.3274, 0.3259, 0.2753],\n",
      "         [0.3179, 0.3187, 0.3258, 0.2614, 0.2723]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.37096688]\n",
      "[0.91700336]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9913, 0.9785], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3291, 0.3271, 0.3274, 0.3259, 0.3302],\n",
      "         [0.3179, 0.3187, 0.3258, 0.2614, 0.3265]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74053749]\n",
      "[0.96955736]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9861, 0.9872], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3836, 0.3271, 0.3274, 0.3259, 0.3302],\n",
      "         [0.3725, 0.3187, 0.3258, 0.2614, 0.3265]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01686089]\n",
      "[0.88843354]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9917], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3836, 0.3826, 0.3274, 0.3259, 0.3302],\n",
      "         [0.3725, 0.3736, 0.3258, 0.2614, 0.3265]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86212066]\n",
      "[0.80167876]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9845, 0.9891], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3836, 0.3826, 0.3819, 0.3259, 0.3302],\n",
      "         [0.3725, 0.3736, 0.3802, 0.2614, 0.3265]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01800017]\n",
      "[0.99441822]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.8770, 0.9905], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3836, 0.3826, 0.3819, 0.3728, 0.3302],\n",
      "         [0.3725, 0.3736, 0.3802, 0.3161, 0.3265]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78691893]\n",
      "[0.65204296]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9825, 0.9840], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.3836, 0.3826, 0.3819, 0.3728, 0.3842],\n",
      "         [0.3725, 0.3736, 0.3802, 0.3161, 0.3803]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.28968698]\n",
      "[0.90884346]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9920, 0.9497], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4384, 0.3826, 0.3819, 0.3728, 0.3842],\n",
      "         [0.4248, 0.3736, 0.3802, 0.3161, 0.3803]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03849429]\n",
      "[0.81594376]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9817, 0.9846], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4384, 0.4370, 0.3819, 0.3728, 0.3842],\n",
      "         [0.4248, 0.4278, 0.3802, 0.3161, 0.3803]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.06755805]\n",
      "[0.58454027]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9860, 0.9658], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4384, 0.4370, 0.4366, 0.3728, 0.3842],\n",
      "         [0.4248, 0.4278, 0.4338, 0.3161, 0.3803]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99284446]\n",
      "[0.6847953]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9623, 0.6932], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4384, 0.4370, 0.4366, 0.4256, 0.3842],\n",
      "         [0.4248, 0.4278, 0.4338, 0.3544, 0.3803]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.3723299]\n",
      "[0.92970626]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9891, 0.9952], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4384, 0.4370, 0.4366, 0.4256, 0.4390],\n",
      "         [0.4248, 0.4278, 0.4338, 0.3544, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.62339689]\n",
      "[0.92373275]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([ 0.9537, -0.2217], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4884, 0.4370, 0.4366, 0.4256, 0.4390],\n",
      "         [0.4112, 0.4278, 0.4338, 0.3544, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00885091]\n",
      "[0.99344724]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9884, 0.9676], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4884, 0.4918, 0.4366, 0.4256, 0.4390],\n",
      "         [0.4112, 0.4813, 0.4338, 0.3544, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.08078259]\n",
      "[0.68096842]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9870], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4884, 0.4918, 0.4919, 0.4256, 0.4390],\n",
      "         [0.4112, 0.4813, 0.4883, 0.3544, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99771233]\n",
      "[0.67797689]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9932, 0.9840], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4884, 0.4918, 0.4919, 0.4807, 0.4390],\n",
      "         [0.4112, 0.4813, 0.4883, 0.4089, 0.4355]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.7657334]\n",
      "[0.96764483]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9763, 0.9934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.4884, 0.4918, 0.4919, 0.4807, 0.4929],\n",
      "         [0.4112, 0.4813, 0.4883, 0.4089, 0.4904]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97728525]\n",
      "[0.70085212]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9556, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5410, 0.4918, 0.4919, 0.4807, 0.4929],\n",
      "         [0.4662, 0.4813, 0.4883, 0.4089, 0.4904]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.83016604]\n",
      "[0.7917344]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9842, 0.8310], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5410, 0.5463, 0.4919, 0.4807, 0.4929],\n",
      "         [0.4662, 0.5265, 0.4883, 0.4089, 0.4904]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.70835757]\n",
      "[0.84282612]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9810, 0.9684], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5410, 0.5463, 0.5461, 0.4807, 0.4929],\n",
      "         [0.4662, 0.5265, 0.5410, 0.4089, 0.4904]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.84674206]\n",
      "[0.8919627]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9792], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5410, 0.5463, 0.5461, 0.5361, 0.4929],\n",
      "         [0.4662, 0.5265, 0.5410, 0.4628, 0.4904]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94182307]\n",
      "[0.78536985]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9906, 0.9789], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5410, 0.5463, 0.5461, 0.5361, 0.5478],\n",
      "         [0.4662, 0.5265, 0.5410, 0.4628, 0.5442]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80888566]\n",
      "[0.90199475]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9869, 0.9931], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5954, 0.5463, 0.5461, 0.5361, 0.5478],\n",
      "         [0.5213, 0.5265, 0.5410, 0.4628, 0.5442]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0060799]\n",
      "[0.94719222]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9904, 0.9779], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5954, 0.6012, 0.5461, 0.5361, 0.5478],\n",
      "         [0.5213, 0.5804, 0.5410, 0.4628, 0.5442]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01300673]\n",
      "[1.03676594]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9881, 0.7478], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5954, 0.6012, 0.6007, 0.5361, 0.5478],\n",
      "         [0.5213, 0.5804, 0.5819, 0.4628, 0.5442]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.84187493]\n",
      "[1.01148149]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5954, 0.6012, 0.6007, 0.5913, 0.5478],\n",
      "         [0.5213, 0.5804, 0.5819, 0.5180, 0.5442]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01205423]\n",
      "[0.92801186]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.8635], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.5954, 0.6012, 0.6007, 0.5913, 0.6031],\n",
      "         [0.5213, 0.5804, 0.5819, 0.5180, 0.5919]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03037618]\n",
      "[0.82415411]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9862, 0.9840], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.6499, 0.6012, 0.6007, 0.5913, 0.6031],\n",
      "         [0.5753, 0.5804, 0.5819, 0.5180, 0.5919]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.62640529]\n",
      "[0.88879232]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9746], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.6499, 0.6565, 0.6007, 0.5913, 0.6031],\n",
      "         [0.5753, 0.6342, 0.5819, 0.5180, 0.5919]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74967717]\n",
      "[0.93544666]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9559, 0.9574], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.6499, 0.6565, 0.6533, 0.5913, 0.6031],\n",
      "         [0.5753, 0.6342, 0.6339, 0.5180, 0.5919]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94210722]\n",
      "[1.0174637]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9890, 0.9907], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.6499, 0.6565, 0.6533, 0.6461, 0.6031],\n",
      "         [0.5753, 0.6342, 0.6339, 0.5727, 0.5919]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95374007]\n",
      "[0.94523862]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9782], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.6499, 0.6565, 0.6533, 0.6461, 0.6581],\n",
      "         [0.5753, 0.6342, 0.6339, 0.5727, 0.6459]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01292694]\n",
      "[1.02447142]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9869], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7051, 0.6565, 0.6533, 0.6461, 0.6581],\n",
      "         [0.6300, 0.6342, 0.6339, 0.5727, 0.6459]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.83302918]\n",
      "[0.96992867]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9827], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7051, 0.7118, 0.6533, 0.6461, 0.6581],\n",
      "         [0.6300, 0.6887, 0.6339, 0.5727, 0.6459]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94613434]\n",
      "[1.05064766]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9821, 0.9404], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7051, 0.7118, 0.7077, 0.6461, 0.6581],\n",
      "         [0.6300, 0.6887, 0.6845, 0.5727, 0.6459]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96537337]\n",
      "[1.01285985]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9894, 0.5085], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7051, 0.7118, 0.7077, 0.7010, 0.6581],\n",
      "         [0.6300, 0.6887, 0.6845, 0.5999, 0.6459]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00871767]\n",
      "[0.98098809]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9879, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7051, 0.7118, 0.7077, 0.7010, 0.7126],\n",
      "         [0.6300, 0.6887, 0.6845, 0.5999, 0.7008]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94238721]\n",
      "[0.96707852]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9636], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7604, 0.7118, 0.7077, 0.7010, 0.7126],\n",
      "         [0.6831, 0.6887, 0.6845, 0.5999, 0.7008]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01099894]\n",
      "[1.00297791]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9720, 0.9582], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7604, 0.7656, 0.7077, 0.7010, 0.7126],\n",
      "         [0.6831, 0.7415, 0.6845, 0.5999, 0.7008]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.75695038]\n",
      "[0.84092325]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9860, 0.9779], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7604, 0.7656, 0.7622, 0.7010, 0.7126],\n",
      "         [0.6831, 0.7415, 0.7387, 0.5999, 0.7008]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.67262863]\n",
      "[0.86478456]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9549, 0.9561], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7604, 0.7656, 0.7622, 0.7526, 0.7126],\n",
      "         [0.6831, 0.7415, 0.7387, 0.6528, 0.7008]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69815329]\n",
      "[0.68079385]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9916], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.7604, 0.7656, 0.7622, 0.7526, 0.7680],\n",
      "         [0.6831, 0.7415, 0.7387, 0.6528, 0.7559]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93461322]\n",
      "[0.77117685]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9958], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8157, 0.7656, 0.7622, 0.7526, 0.7680],\n",
      "         [0.7384, 0.7415, 0.7387, 0.6528, 0.7559]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03588324]\n",
      "[0.95836329]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9938, 0.9791], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8157, 0.8207, 0.7622, 0.7526, 0.7680],\n",
      "         [0.7384, 0.7953, 0.7387, 0.6528, 0.7559]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98450707]\n",
      "[1.02911872]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9920, 0.9916], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8157, 0.8207, 0.8172, 0.7526, 0.7680],\n",
      "         [0.7384, 0.7953, 0.7936, 0.6528, 0.7559]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99396699]\n",
      "[0.67480035]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9934, 0.9801], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8157, 0.8207, 0.8172, 0.8077, 0.7680],\n",
      "         [0.7384, 0.7953, 0.7936, 0.7070, 0.7559]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95602397]\n",
      "[0.95108442]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9782, 0.9944], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8157, 0.8207, 0.8172, 0.8077, 0.8219],\n",
      "         [0.7384, 0.7953, 0.7936, 0.7070, 0.8106]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03893375]\n",
      "[1.02529658]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9909, 0.9650], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8701, 0.8207, 0.8172, 0.8077, 0.8219],\n",
      "         [0.7912, 0.7953, 0.7936, 0.7070, 0.8106]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96588815]\n",
      "[0.90398302]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9878], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8701, 0.8761, 0.8172, 0.8077, 0.8219],\n",
      "         [0.7912, 0.8498, 0.7936, 0.7070, 0.8106]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.500652]\n",
      "[1.02344857]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9905, 0.9930], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8701, 0.8761, 0.8721, 0.8077, 0.8219],\n",
      "         [0.7912, 0.8498, 0.8485, 0.7070, 0.8106]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74280781]\n",
      "[0.88748738]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9411], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8701, 0.8761, 0.8721, 0.8630, 0.8219],\n",
      "         [0.7912, 0.8498, 0.8485, 0.7577, 0.8106]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92040262]\n",
      "[0.79641979]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9634, 0.9525], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.8701, 0.8761, 0.8721, 0.8630, 0.8752],\n",
      "         [0.7912, 0.8498, 0.8485, 0.7577, 0.8630]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.81277794]\n",
      "[0.93603606]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9877], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9254, 0.8761, 0.8721, 0.8630, 0.8752],\n",
      "         [0.8460, 0.8498, 0.8485, 0.7577, 0.8630]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9439445]\n",
      "[0.89690529]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9936], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9254, 0.9313, 0.8721, 0.8630, 0.8752],\n",
      "         [0.8460, 0.9049, 0.8485, 0.7577, 0.8630]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.91347557]\n",
      "[0.75943496]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9740, 0.9214], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9254, 0.9313, 0.9236, 0.8630, 0.8752],\n",
      "         [0.8460, 0.9049, 0.8988, 0.7577, 0.8630]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.44989315]\n",
      "[0.46597785]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9946], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9254, 0.9313, 0.9236, 0.9180, 0.8752],\n",
      "         [0.8460, 0.9049, 0.8988, 0.8125, 0.8630]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97396497]\n",
      "[0.9135926]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9323], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9254, 0.9313, 0.9236, 0.9180, 0.9304],\n",
      "         [0.8460, 0.9049, 0.8988, 0.8125, 0.9135]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.28713025]\n",
      "[0.71368437]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9844, 0.9874], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9313, 0.9236, 0.9180, 0.9304],\n",
      "         [0.9007, 0.9049, 0.8988, 0.8125, 0.9135]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87989002]\n",
      "[0.97062061]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9911, 0.9898], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9236, 0.9180, 0.9304],\n",
      "         [0.9007, 0.9593, 0.8988, 0.8125, 0.9135]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.52976791]\n",
      "[0.72659124]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9952, 0.9800], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9180, 0.9304],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8125, 0.9135]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90011196]\n",
      "[0.6206295]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9914, 0.9930], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9304],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9135]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.34286646]\n",
      "[0.70817167]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.56515688]\n",
      "[0.56052402]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9914], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0553, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.50956053]\n",
      "[0.97487816]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9975], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0553, 0.0553, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0553, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.34640305]\n",
      "[0.86796278]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0553, 0.0553, 0.0553, 0.0000, 0.0000],\n",
      "         [0.0549, 0.0553, 0.0553, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.56063756]\n",
      "[0.56676788]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9635], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0553, 0.0553, 0.0553, 0.0553, 0.0000],\n",
      "         [0.0549, 0.0553, 0.0553, 0.0508, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68656625]\n",
      "[0.87842358]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9933], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.0553, 0.0553, 0.0553, 0.0553, 0.0554],\n",
      "         [0.0549, 0.0553, 0.0553, 0.0508, 0.0550]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87975714]\n",
      "[0.96863103]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9942, 0.9937], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1105, 0.0553, 0.0553, 0.0553, 0.0554],\n",
      "         [0.1099, 0.0553, 0.0553, 0.0508, 0.0550]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.07544694]\n",
      "[0.90971752]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9697], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1105, 0.1106, 0.0553, 0.0553, 0.0554],\n",
      "         [0.1099, 0.1086, 0.0553, 0.0508, 0.0550]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97505984]\n",
      "[0.88469542]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9931], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1105, 0.1106, 0.1103, 0.0553, 0.0554],\n",
      "         [0.1099, 0.1086, 0.1101, 0.0508, 0.0550]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90765783]\n",
      "[1.06859986]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9897, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1105, 0.1106, 0.1103, 0.1102, 0.0554],\n",
      "         [0.1099, 0.1086, 0.1101, 0.1060, 0.0550]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.76575306]\n",
      "[0.61250452]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9837, 0.9753], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1105, 0.1106, 0.1103, 0.1102, 0.1099],\n",
      "         [0.1099, 0.1086, 0.1101, 0.1060, 0.1091]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87383597]\n",
      "[0.85592144]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9879], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1656, 0.1106, 0.1103, 0.1102, 0.1099],\n",
      "         [0.1644, 0.1086, 0.1101, 0.1060, 0.1091]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98798528]\n",
      "[1.00477873]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9882], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1656, 0.1660, 0.1103, 0.1102, 0.1099],\n",
      "         [0.1644, 0.1631, 0.1101, 0.1060, 0.1091]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.55760733]\n",
      "[0.9022822]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9934, 0.9922], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1656, 0.1660, 0.1654, 0.1102, 0.1099],\n",
      "         [0.1644, 0.1631, 0.1649, 0.1060, 0.1091]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05404253]\n",
      "[0.81940192]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1656, 0.1660, 0.1654, 0.1656, 0.1099],\n",
      "         [0.1644, 0.1631, 0.1649, 0.1613, 0.1091]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95433666]\n",
      "[0.94568094]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9903], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.1656, 0.1660, 0.1654, 0.1656, 0.1651],\n",
      "         [0.1644, 0.1631, 0.1649, 0.1613, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.94331421]\n",
      "[0.81631404]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9860, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2200, 0.1660, 0.1654, 0.1656, 0.1651],\n",
      "         [0.2195, 0.1631, 0.1649, 0.1613, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92490095]\n",
      "[0.99067333]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9885], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2200, 0.2214, 0.1654, 0.1656, 0.1651],\n",
      "         [0.2195, 0.2179, 0.1649, 0.1613, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99556617]\n",
      "[1.01470388]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9864, 0.9916], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2200, 0.2214, 0.2198, 0.1656, 0.1651],\n",
      "         [0.2195, 0.2179, 0.2199, 0.1613, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.7468028]\n",
      "[0.94335654]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2200, 0.2214, 0.2198, 0.2210, 0.1651],\n",
      "         [0.2195, 0.2179, 0.2199, 0.2166, 0.1638]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92099503]\n",
      "[1.04240453]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2200, 0.2214, 0.2198, 0.2210, 0.2205],\n",
      "         [0.2195, 0.2179, 0.2199, 0.2166, 0.2191]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.08183476]\n",
      "[1.01770893]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9820], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2750, 0.2214, 0.2198, 0.2210, 0.2205],\n",
      "         [0.2738, 0.2179, 0.2199, 0.2166, 0.2191]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96618763]\n",
      "[0.79115136]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9911], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2750, 0.2766, 0.2198, 0.2210, 0.2205],\n",
      "         [0.2738, 0.2729, 0.2199, 0.2166, 0.2191]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96290207]\n",
      "[0.77858176]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9812], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2750, 0.2766, 0.2751, 0.2210, 0.2205],\n",
      "         [0.2738, 0.2729, 0.2741, 0.2166, 0.2191]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99868923]\n",
      "[0.97550223]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9811], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2750, 0.2766, 0.2751, 0.2760, 0.2205],\n",
      "         [0.2738, 0.2729, 0.2741, 0.2710, 0.2191]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04580477]\n",
      "[0.97014784]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9857, 0.9920], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.2750, 0.2766, 0.2751, 0.2760, 0.2750],\n",
      "         [0.2738, 0.2729, 0.2741, 0.2710, 0.2741]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98750471]\n",
      "[0.82053925]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9890, 0.9842], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3299, 0.2766, 0.2751, 0.2760, 0.2750],\n",
      "         [0.3284, 0.2729, 0.2741, 0.2710, 0.2741]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0151009]\n",
      "[1.0114253]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9916, 0.9946], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3299, 0.3316, 0.2751, 0.2760, 0.2750],\n",
      "         [0.3284, 0.3281, 0.2741, 0.2710, 0.2741]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0275126]\n",
      "[0.95219366]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9955], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3299, 0.3316, 0.3305, 0.2760, 0.2750],\n",
      "         [0.3284, 0.3281, 0.3293, 0.2710, 0.2741]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.56659589]\n",
      "[0.76106102]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9946], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3299, 0.3316, 0.3305, 0.3313, 0.2750],\n",
      "         [0.3284, 0.3281, 0.3293, 0.3262, 0.2741]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.77118529]\n",
      "[0.88579612]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9911, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3299, 0.3316, 0.3305, 0.3313, 0.3300],\n",
      "         [0.3284, 0.3281, 0.3293, 0.3262, 0.3292]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97310458]\n",
      "[0.92984666]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3851, 0.3316, 0.3305, 0.3313, 0.3300],\n",
      "         [0.3838, 0.3281, 0.3293, 0.3262, 0.3292]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92469549]\n",
      "[0.96599089]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9883], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3851, 0.3869, 0.3305, 0.3313, 0.3300],\n",
      "         [0.3838, 0.3825, 0.3293, 0.3262, 0.3292]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05266738]\n",
      "[0.90718244]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9928], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3851, 0.3869, 0.3858, 0.3313, 0.3300],\n",
      "         [0.3838, 0.3825, 0.3844, 0.3262, 0.3292]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02909634]\n",
      "[0.59097812]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9959], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3851, 0.3869, 0.3858, 0.3866, 0.3300],\n",
      "         [0.3838, 0.3825, 0.3844, 0.3814, 0.3292]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90547488]\n",
      "[0.82624024]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9871], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.3851, 0.3869, 0.3858, 0.3866, 0.3855],\n",
      "         [0.3838, 0.3825, 0.3844, 0.3814, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97921377]\n",
      "[1.01364537]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9815], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4406, 0.3869, 0.3858, 0.3866, 0.3855],\n",
      "         [0.4381, 0.3825, 0.3844, 0.3814, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99388052]\n",
      "[0.8326766]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9840, 0.9784], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4406, 0.4413, 0.3858, 0.3866, 0.3855],\n",
      "         [0.4381, 0.4367, 0.3844, 0.3814, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.70303445]\n",
      "[0.9441925]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9873], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4406, 0.4413, 0.4411, 0.3866, 0.3855],\n",
      "         [0.4381, 0.4367, 0.4390, 0.3814, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.6825095]\n",
      "[0.96003411]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9924, 0.9897], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4406, 0.4413, 0.4411, 0.4416, 0.3855],\n",
      "         [0.4381, 0.4367, 0.4390, 0.4362, 0.3839]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78452736]\n",
      "[0.97680713]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9914, 0.9882], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4406, 0.4413, 0.4411, 0.4416, 0.4405],\n",
      "         [0.4381, 0.4367, 0.4390, 0.4362, 0.4387]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68418475]\n",
      "[0.98616789]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9912, 0.9799], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4956, 0.4413, 0.4411, 0.4416, 0.4405],\n",
      "         [0.4921, 0.4367, 0.4390, 0.4362, 0.4387]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05736904]\n",
      "[0.65691223]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9663], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4956, 0.4966, 0.4411, 0.4416, 0.4405],\n",
      "         [0.4921, 0.4901, 0.4390, 0.4362, 0.4387]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87129928]\n",
      "[0.96543181]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9937, 0.9962], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4956, 0.4966, 0.4962, 0.4416, 0.4405],\n",
      "         [0.4921, 0.4901, 0.4943, 0.4362, 0.4387]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05083674]\n",
      "[0.58458024]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9931, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4956, 0.4966, 0.4962, 0.4967, 0.4405],\n",
      "         [0.4921, 0.4901, 0.4943, 0.4915, 0.4387]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01818559]\n",
      "[0.9923293]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9941], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.4956, 0.4966, 0.4962, 0.4967, 0.4958],\n",
      "         [0.4921, 0.4901, 0.4943, 0.4915, 0.4936]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86094106]\n",
      "[0.53287885]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9898], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.5510, 0.4966, 0.4962, 0.4967, 0.4958],\n",
      "         [0.5469, 0.4901, 0.4943, 0.4915, 0.4936]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98535312]\n",
      "[0.98099127]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9954, 0.9416], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.5510, 0.5517, 0.4962, 0.4967, 0.4958],\n",
      "         [0.5469, 0.5416, 0.4943, 0.4915, 0.4936]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79270335]\n",
      "[0.78575604]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9787], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.5510, 0.5517, 0.5516, 0.4967, 0.4958],\n",
      "         [0.5469, 0.5416, 0.5479, 0.4915, 0.4936]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.53395104]\n",
      "[0.79182012]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.8966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.5510, 0.5517, 0.5516, 0.5521, 0.4958],\n",
      "         [0.5469, 0.5416, 0.5479, 0.5407, 0.4936]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.60397798]\n",
      "[0.8554107]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9918, 0.9911], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.5510, 0.5517, 0.5516, 0.5521, 0.5509],\n",
      "         [0.5469, 0.5416, 0.5479, 0.5407, 0.5484]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.75297036]\n",
      "[0.9470919]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9952], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6064, 0.5517, 0.5516, 0.5521, 0.5509],\n",
      "         [0.6021, 0.5416, 0.5479, 0.5407, 0.5484]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99607417]\n",
      "[0.92747411]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.7351], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6064, 0.6072, 0.5516, 0.5521, 0.5509],\n",
      "         [0.6021, 0.5822, 0.5479, 0.5407, 0.5484]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0364306]\n",
      "[0.99791669]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9958], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6064, 0.6072, 0.6069, 0.5521, 0.5509],\n",
      "         [0.6021, 0.5822, 0.6030, 0.5407, 0.5484]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9089085]\n",
      "[0.93652359]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6064, 0.6072, 0.6069, 0.6074, 0.5509],\n",
      "         [0.6021, 0.5822, 0.6030, 0.5961, 0.5484]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04856805]\n",
      "[0.97118701]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9993], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6064, 0.6072, 0.6069, 0.6074, 0.6061],\n",
      "         [0.6021, 0.5822, 0.6030, 0.5961, 0.6039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.66416026]\n",
      "[0.97414772]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9842], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6618, 0.6072, 0.6069, 0.6074, 0.6061],\n",
      "         [0.6565, 0.5822, 0.6030, 0.5961, 0.6039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78419515]\n",
      "[0.49224175]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9903, 0.9570], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6618, 0.6620, 0.6069, 0.6074, 0.6061],\n",
      "         [0.6565, 0.6346, 0.6030, 0.5961, 0.6039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90917653]\n",
      "[0.99354478]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9933], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6618, 0.6620, 0.6624, 0.6074, 0.6061],\n",
      "         [0.6565, 0.6346, 0.6581, 0.5961, 0.6039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79225777]\n",
      "[0.50143475]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9927], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6618, 0.6620, 0.6624, 0.6626, 0.6061],\n",
      "         [0.6565, 0.6346, 0.6581, 0.6509, 0.6039]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.62136623]\n",
      "[0.77673473]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9904], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.6618, 0.6620, 0.6624, 0.6626, 0.6614],\n",
      "         [0.6565, 0.6346, 0.6581, 0.6509, 0.6571]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.52151741]\n",
      "[0.80232379]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9936, 0.9898], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7169, 0.6620, 0.6624, 0.6626, 0.6614],\n",
      "         [0.7111, 0.6346, 0.6581, 0.6509, 0.6571]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.84513267]\n",
      "[0.95046905]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9914], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7169, 0.7175, 0.6624, 0.6626, 0.6614],\n",
      "         [0.7111, 0.6894, 0.6581, 0.6509, 0.6571]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97152556]\n",
      "[1.06699589]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9849], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7169, 0.7175, 0.7177, 0.6626, 0.6614],\n",
      "         [0.7111, 0.6894, 0.7126, 0.6509, 0.6571]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97238774]\n",
      "[1.03666262]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9855], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7169, 0.7175, 0.7177, 0.7179, 0.6614],\n",
      "         [0.7111, 0.6894, 0.7126, 0.7051, 0.6571]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88323897]\n",
      "[0.98985822]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9551], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7169, 0.7175, 0.7177, 0.7179, 0.7166],\n",
      "         [0.7111, 0.6894, 0.7126, 0.7051, 0.7097]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.73270935]\n",
      "[0.5678194]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9876, 0.9918], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7717, 0.7175, 0.7177, 0.7179, 0.7166],\n",
      "         [0.7661, 0.6894, 0.7126, 0.7051, 0.7097]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00777934]\n",
      "[0.61521869]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7717, 0.7728, 0.7177, 0.7179, 0.7166],\n",
      "         [0.7661, 0.7446, 0.7126, 0.7051, 0.7097]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01503105]\n",
      "[0.48763498]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9917], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7717, 0.7728, 0.7730, 0.7179, 0.7166],\n",
      "         [0.7661, 0.7446, 0.7676, 0.7051, 0.7097]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99227056]\n",
      "[0.96505438]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9887], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7717, 0.7728, 0.7730, 0.7733, 0.7166],\n",
      "         [0.7661, 0.7446, 0.7676, 0.7599, 0.7097]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93670871]\n",
      "[0.97139539]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.7717, 0.7728, 0.7730, 0.7733, 0.7720],\n",
      "         [0.7661, 0.7446, 0.7676, 0.7599, 0.7648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0303957]\n",
      "[0.79616415]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9810, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8260, 0.7728, 0.7730, 0.7733, 0.7720],\n",
      "         [0.8213, 0.7446, 0.7676, 0.7599, 0.7648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.32830594]\n",
      "[0.91941681]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9473], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8260, 0.8280, 0.7730, 0.7733, 0.7720],\n",
      "         [0.8213, 0.7966, 0.7676, 0.7599, 0.7648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86647699]\n",
      "[0.49357252]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9455], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8260, 0.8280, 0.8283, 0.7733, 0.7720],\n",
      "         [0.8213, 0.7966, 0.8198, 0.7599, 0.7648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.73539019]\n",
      "[0.71502741]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9964, 0.9827], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8260, 0.8280, 0.8283, 0.8287, 0.7720],\n",
      "         [0.8213, 0.7966, 0.8198, 0.8141, 0.7648]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.62119998]\n",
      "[0.62055513]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9757, 0.9876], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8260, 0.8280, 0.8283, 0.8287, 0.8258],\n",
      "         [0.8213, 0.7966, 0.8198, 0.8141, 0.8192]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79764256]\n",
      "[0.8022582]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9769], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8814, 0.8280, 0.8283, 0.8287, 0.8258],\n",
      "         [0.8754, 0.7966, 0.8198, 0.8141, 0.8192]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95980942]\n",
      "[0.86947228]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9895, 0.9936], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8814, 0.8829, 0.8283, 0.8287, 0.8258],\n",
      "         [0.8754, 0.8516, 0.8198, 0.8141, 0.8192]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.54184431]\n",
      "[1.001021]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.8617], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8814, 0.8829, 0.8837, 0.8287, 0.8258],\n",
      "         [0.8754, 0.8516, 0.8672, 0.8141, 0.8192]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95976634]\n",
      "[0.80693978]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9883], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8814, 0.8829, 0.8837, 0.8841, 0.8258],\n",
      "         [0.8754, 0.8516, 0.8672, 0.8688, 0.8192]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.54011965]\n",
      "[0.99425272]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9489], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.8814, 0.8829, 0.8837, 0.8841, 0.8812],\n",
      "         [0.8754, 0.8516, 0.8672, 0.8688, 0.8717]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99113584]\n",
      "[1.01032308]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9954], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9368, 0.8829, 0.8837, 0.8841, 0.8812],\n",
      "         [0.9306, 0.8516, 0.8672, 0.8688, 0.8717]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.54974983]\n",
      "[0.45190368]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9968], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9368, 0.9379, 0.8837, 0.8841, 0.8812],\n",
      "         [0.9306, 0.9069, 0.8672, 0.8688, 0.8717]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.72483403]\n",
      "[0.84286366]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9958], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9368, 0.9379, 0.9390, 0.8841, 0.8812],\n",
      "         [0.9306, 0.9069, 0.9223, 0.8688, 0.8717]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80969099]\n",
      "[0.85061807]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9368, 0.9379, 0.9390, 0.9394, 0.8812],\n",
      "         [0.9306, 0.9069, 0.9223, 0.9237, 0.8717]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.84567992]\n",
      "[0.45120333]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9922, 0.9926], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9368, 0.9379, 0.9390, 0.9394, 0.9358],\n",
      "         [0.9306, 0.9069, 0.9223, 0.9237, 0.9264]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.6743449]\n",
      "[0.33996011]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9379, 0.9390, 0.9394, 0.9358],\n",
      "         [0.9859, 0.9069, 0.9223, 0.9237, 0.9264]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.57447593]\n",
      "[0.79650551]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9390, 0.9394, 0.9358],\n",
      "         [0.9859, 0.9623, 0.9223, 0.9237, 0.9264]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.65159569]\n",
      "[0.66772168]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9922], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9394, 0.9358],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9237, 0.9264]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69609898]\n",
      "[0.86085849]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9917, 0.9914], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9358],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9264]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.32668209]\n",
      "[0.76429816]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.8490], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02123632]\n",
      "[1.00078278]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9940, 0.9985], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0551, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0554, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.35792871]\n",
      "[0.8690169]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9969], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0551, 0.0554, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0554, 0.0553, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68688143]\n",
      "[0.60808041]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9710], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0551, 0.0554, 0.0554, 0.0000, 0.0000],\n",
      "         [0.0554, 0.0553, 0.0539, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92011376]\n",
      "[0.86352414]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9955, 0.9910], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0551, 0.0554, 0.0554, 0.0552, 0.0000],\n",
      "         [0.0554, 0.0553, 0.0539, 0.0549, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.39767768]\n",
      "[0.9585959]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9962], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.0551, 0.0554, 0.0554, 0.0552, 0.0554],\n",
      "         [0.0554, 0.0553, 0.0539, 0.0549, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.963432]\n",
      "[0.91740419]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9899, 0.9779], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1099, 0.0554, 0.0554, 0.0552, 0.0554],\n",
      "         [0.1093, 0.0553, 0.0539, 0.0549, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90280092]\n",
      "[0.88183171]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9883], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1099, 0.1108, 0.0554, 0.0552, 0.0554],\n",
      "         [0.1093, 0.1099, 0.0539, 0.0549, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0543004]\n",
      "[0.94440001]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9898], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1099, 0.1108, 0.1107, 0.0552, 0.0554],\n",
      "         [0.1093, 0.1099, 0.1087, 0.0549, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04554358]\n",
      "[0.88929274]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1099, 0.1108, 0.1107, 0.1106, 0.0554],\n",
      "         [0.1093, 0.1099, 0.1087, 0.1102, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98549174]\n",
      "[0.95320169]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9938], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1099, 0.1108, 0.1107, 0.1106, 0.1107],\n",
      "         [0.1093, 0.1099, 0.1087, 0.1102, 0.1102]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00846986]\n",
      "[1.00334761]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9835], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1653, 0.1108, 0.1107, 0.1106, 0.1107],\n",
      "         [0.1635, 0.1099, 0.1087, 0.1102, 0.1102]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97784209]\n",
      "[0.89527514]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9883], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1653, 0.1663, 0.1107, 0.1106, 0.1107],\n",
      "         [0.1635, 0.1647, 0.1087, 0.1102, 0.1102]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.77640784]\n",
      "[1.07311795]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9920], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1653, 0.1663, 0.1660, 0.1106, 0.1107],\n",
      "         [0.1635, 0.1647, 0.1637, 0.1102, 0.1102]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00145472]\n",
      "[0.69660652]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9989], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1653, 0.1663, 0.1660, 0.1660, 0.1107],\n",
      "         [0.1635, 0.1647, 0.1637, 0.1656, 0.1102]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96115196]\n",
      "[1.04055707]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9925], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.1653, 0.1663, 0.1660, 0.1660, 0.1662],\n",
      "         [0.1635, 0.1647, 0.1637, 0.1656, 0.1652]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9689515]\n",
      "[1.00624601]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9935, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2204, 0.1663, 0.1660, 0.1660, 0.1662],\n",
      "         [0.2189, 0.1647, 0.1637, 0.1656, 0.1652]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9222248]\n",
      "[1.02142657]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2204, 0.2216, 0.1660, 0.1660, 0.1662],\n",
      "         [0.2189, 0.2201, 0.1637, 0.1656, 0.1652]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05860894]\n",
      "[0.92871115]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2204, 0.2216, 0.2215, 0.1660, 0.1662],\n",
      "         [0.2189, 0.2201, 0.2190, 0.1656, 0.1652]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88187011]\n",
      "[0.92126825]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9935], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2204, 0.2216, 0.2215, 0.2215, 0.1662],\n",
      "         [0.2189, 0.2201, 0.2190, 0.2208, 0.1652]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99138115]\n",
      "[0.94291884]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9903], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2204, 0.2216, 0.2215, 0.2215, 0.2216],\n",
      "         [0.2189, 0.2201, 0.2190, 0.2208, 0.2195]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00641448]\n",
      "[1.03257616]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2758, 0.2216, 0.2215, 0.2215, 0.2216],\n",
      "         [0.2741, 0.2201, 0.2190, 0.2208, 0.2195]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87878025]\n",
      "[0.97319784]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9872], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2758, 0.2770, 0.2215, 0.2215, 0.2216],\n",
      "         [0.2741, 0.2748, 0.2190, 0.2208, 0.2195]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9487017]\n",
      "[0.84490275]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9965], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2758, 0.2770, 0.2769, 0.2215, 0.2216],\n",
      "         [0.2741, 0.2748, 0.2742, 0.2208, 0.2195]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.85795017]\n",
      "[0.92118902]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9872], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2758, 0.2770, 0.2769, 0.2768, 0.2216],\n",
      "         [0.2741, 0.2748, 0.2742, 0.2755, 0.2195]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.82326346]\n",
      "[0.9041701]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9589], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.2758, 0.2770, 0.2769, 0.2768, 0.2770],\n",
      "         [0.2741, 0.2748, 0.2742, 0.2755, 0.2725]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78777645]\n",
      "[0.8774589]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9879], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3311, 0.2770, 0.2769, 0.2768, 0.2770],\n",
      "         [0.3288, 0.2748, 0.2742, 0.2755, 0.2725]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80503506]\n",
      "[0.61557925]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9641], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3311, 0.3324, 0.2769, 0.2768, 0.2770],\n",
      "         [0.3288, 0.3283, 0.2742, 0.2755, 0.2725]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.71707248]\n",
      "[0.87866105]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9821], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3311, 0.3324, 0.3322, 0.2768, 0.2770],\n",
      "         [0.3288, 0.3283, 0.3287, 0.2755, 0.2725]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.75185094]\n",
      "[0.76927512]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9927, 0.9868], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3311, 0.3324, 0.3322, 0.3318, 0.2770],\n",
      "         [0.3288, 0.3283, 0.3287, 0.3302, 0.2725]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03341174]\n",
      "[0.97027764]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3311, 0.3324, 0.3322, 0.3318, 0.3324],\n",
      "         [0.3288, 0.3283, 0.3287, 0.3302, 0.3278]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98303101]\n",
      "[0.64967256]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3864, 0.3324, 0.3322, 0.3318, 0.3324],\n",
      "         [0.3841, 0.3283, 0.3287, 0.3302, 0.3278]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87791524]\n",
      "[0.8466943]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9942], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3864, 0.3879, 0.3322, 0.3318, 0.3324],\n",
      "         [0.3841, 0.3830, 0.3287, 0.3302, 0.3278]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.06014982]\n",
      "[0.94075426]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3864, 0.3879, 0.3876, 0.3318, 0.3324],\n",
      "         [0.3841, 0.3830, 0.3840, 0.3302, 0.3278]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01451323]\n",
      "[0.96385292]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9909, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3864, 0.3879, 0.3876, 0.3866, 0.3324],\n",
      "         [0.3841, 0.3830, 0.3840, 0.3856, 0.3278]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88663167]\n",
      "[0.89388458]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9982], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.3864, 0.3879, 0.3876, 0.3866, 0.3877],\n",
      "         [0.3841, 0.3830, 0.3840, 0.3856, 0.3831]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.84207454]\n",
      "[0.75981892]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9958, 0.9727], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4417, 0.3879, 0.3876, 0.3866, 0.3877],\n",
      "         [0.4381, 0.3830, 0.3840, 0.3856, 0.3831]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.4702359]\n",
      "[1.04007471]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9888], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4417, 0.4433, 0.3876, 0.3866, 0.3877],\n",
      "         [0.4381, 0.4377, 0.3840, 0.3856, 0.3831]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.65124023]\n",
      "[0.97971377]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4417, 0.4433, 0.4430, 0.3866, 0.3877],\n",
      "         [0.4381, 0.4377, 0.4389, 0.3856, 0.3831]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.35215118]\n",
      "[0.95327628]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9877], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4417, 0.4433, 0.4430, 0.4420, 0.3877],\n",
      "         [0.4381, 0.4377, 0.4389, 0.4403, 0.3831]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.50777928]\n",
      "[1.01320844]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9796], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4417, 0.4433, 0.4430, 0.4420, 0.4432],\n",
      "         [0.4381, 0.4377, 0.4389, 0.4403, 0.4370]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.7394565]\n",
      "[0.97264329]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9929], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4970, 0.4433, 0.4430, 0.4420, 0.4432],\n",
      "         [0.4931, 0.4377, 0.4389, 0.4403, 0.4370]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03723143]\n",
      "[0.64091163]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9943], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4970, 0.4985, 0.4430, 0.4420, 0.4432],\n",
      "         [0.4931, 0.4928, 0.4389, 0.4403, 0.4370]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80881178]\n",
      "[0.73103628]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9942], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4970, 0.4985, 0.4983, 0.4420, 0.4432],\n",
      "         [0.4931, 0.4928, 0.4939, 0.4403, 0.4370]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88254269]\n",
      "[0.91337162]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9878], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4970, 0.4985, 0.4983, 0.4973, 0.4432],\n",
      "         [0.4931, 0.4928, 0.4939, 0.4946, 0.4370]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98781514]\n",
      "[0.78563088]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9945, 0.9761], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.4970, 0.4985, 0.4983, 0.4973, 0.4983],\n",
      "         [0.4931, 0.4928, 0.4939, 0.4946, 0.4911]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.50363715]\n",
      "[0.86069225]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9928], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.5524, 0.4985, 0.4983, 0.4973, 0.4983],\n",
      "         [0.5480, 0.4928, 0.4939, 0.4946, 0.4911]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.06595226]\n",
      "[0.97882921]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9948], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.5524, 0.5539, 0.4983, 0.4973, 0.4983],\n",
      "         [0.5480, 0.5480, 0.4939, 0.4946, 0.4911]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74762347]\n",
      "[0.75350584]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9972, 0.9954], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.5524, 0.5539, 0.5536, 0.4973, 0.4983],\n",
      "         [0.5480, 0.5480, 0.5491, 0.4946, 0.4911]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74068161]\n",
      "[0.96925372]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9936], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.5524, 0.5539, 0.5536, 0.5527, 0.4983],\n",
      "         [0.5480, 0.5480, 0.5491, 0.5496, 0.4911]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90049517]\n",
      "[0.78663885]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9846], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.5524, 0.5539, 0.5536, 0.5527, 0.5537],\n",
      "         [0.5480, 0.5480, 0.5491, 0.5496, 0.5458]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.8362896]\n",
      "[0.973938]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9654], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6076, 0.5539, 0.5536, 0.5527, 0.5537],\n",
      "         [0.6014, 0.5480, 0.5491, 0.5496, 0.5458]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99944715]\n",
      "[0.83784978]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9931], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6076, 0.6091, 0.5536, 0.5527, 0.5537],\n",
      "         [0.6014, 0.6031, 0.5491, 0.5496, 0.5458]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97325142]\n",
      "[0.64033423]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9823], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6076, 0.6091, 0.6091, 0.5527, 0.5537],\n",
      "         [0.6014, 0.6031, 0.6034, 0.5496, 0.5458]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.67636373]\n",
      "[0.96945017]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9946, 0.9947], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6076, 0.6091, 0.6091, 0.6079, 0.5537],\n",
      "         [0.6014, 0.6031, 0.6034, 0.6048, 0.5458]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.8448336]\n",
      "[0.79708912]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9886], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6076, 0.6091, 0.6091, 0.6079, 0.6089],\n",
      "         [0.6014, 0.6031, 0.6034, 0.6048, 0.6006]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.87468919]\n",
      "[0.90186393]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6629, 0.6091, 0.6091, 0.6079, 0.6089],\n",
      "         [0.6565, 0.6031, 0.6034, 0.6048, 0.6006]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.83764771]\n",
      "[0.55383108]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9932], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6629, 0.6644, 0.6091, 0.6079, 0.6089],\n",
      "         [0.6565, 0.6577, 0.6034, 0.6048, 0.6006]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.63895129]\n",
      "[0.8433439]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6629, 0.6644, 0.6643, 0.6079, 0.6089],\n",
      "         [0.6565, 0.6577, 0.6586, 0.6048, 0.6006]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.06348786]\n",
      "[1.00656874]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9939], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6629, 0.6644, 0.6643, 0.6632, 0.6089],\n",
      "         [0.6565, 0.6577, 0.6586, 0.6597, 0.6006]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93741474]\n",
      "[0.70764935]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9942], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.6629, 0.6644, 0.6643, 0.6632, 0.6642],\n",
      "         [0.6565, 0.6577, 0.6586, 0.6597, 0.6556]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68464671]\n",
      "[0.82173423]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9982], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7183, 0.6644, 0.6643, 0.6632, 0.6642],\n",
      "         [0.7119, 0.6577, 0.6586, 0.6597, 0.6556]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.91061438]\n",
      "[0.93862069]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7183, 0.7196, 0.6643, 0.6632, 0.6642],\n",
      "         [0.7119, 0.7131, 0.6586, 0.6597, 0.6556]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9559068]\n",
      "[0.75867588]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9913], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7183, 0.7196, 0.7197, 0.6632, 0.6642],\n",
      "         [0.7119, 0.7131, 0.7133, 0.6597, 0.6556]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93138924]\n",
      "[0.92042112]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9969], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7183, 0.7196, 0.7197, 0.7186, 0.6642],\n",
      "         [0.7119, 0.7131, 0.7133, 0.7150, 0.6556]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.90903642]\n",
      "[0.95653532]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7183, 0.7196, 0.7197, 0.7186, 0.7197],\n",
      "         [0.7119, 0.7131, 0.7133, 0.7150, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0260023]\n",
      "[0.97849663]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7738, 0.7196, 0.7197, 0.7186, 0.7197],\n",
      "         [0.7673, 0.7131, 0.7133, 0.7150, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92128268]\n",
      "[1.01152967]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7738, 0.7752, 0.7197, 0.7186, 0.7197],\n",
      "         [0.7673, 0.7684, 0.7133, 0.7150, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00870182]\n",
      "[0.87235742]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7738, 0.7752, 0.7752, 0.7186, 0.7197],\n",
      "         [0.7673, 0.7684, 0.7686, 0.7150, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.63987104]\n",
      "[1.00050539]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7738, 0.7752, 0.7752, 0.7740, 0.7197],\n",
      "         [0.7673, 0.7684, 0.7686, 0.7703, 0.7109]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.85453794]\n",
      "[0.92364294]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9908], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.7738, 0.7752, 0.7752, 0.7740, 0.7751],\n",
      "         [0.7673, 0.7684, 0.7686, 0.7703, 0.7659]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99283172]\n",
      "[0.53403497]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9874, 0.9827], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8284, 0.7752, 0.7752, 0.7740, 0.7751],\n",
      "         [0.8215, 0.7684, 0.7686, 0.7703, 0.7659]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.54719124]\n",
      "[0.82781585]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9896], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8284, 0.8304, 0.7752, 0.7740, 0.7751],\n",
      "         [0.8215, 0.8230, 0.7686, 0.7703, 0.7659]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.54213419]\n",
      "[0.83558205]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9928, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8284, 0.8304, 0.8303, 0.7740, 0.7751],\n",
      "         [0.8215, 0.8230, 0.8239, 0.7703, 0.7659]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.79717276]\n",
      "[0.87884865]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9878, 0.9966], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8284, 0.8304, 0.8303, 0.8287, 0.7751],\n",
      "         [0.8215, 0.8230, 0.8239, 0.8255, 0.7659]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00989456]\n",
      "[0.98403966]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9941, 0.9762], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8284, 0.8304, 0.8303, 0.8287, 0.8302],\n",
      "         [0.8215, 0.8230, 0.8239, 0.8255, 0.8197]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95642854]\n",
      "[1.00496185]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9904], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8838, 0.8304, 0.8303, 0.8287, 0.8302],\n",
      "         [0.8763, 0.8230, 0.8239, 0.8255, 0.8197]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.76845881]\n",
      "[0.88583398]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9952], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8838, 0.8858, 0.8303, 0.8287, 0.8302],\n",
      "         [0.8763, 0.8781, 0.8239, 0.8255, 0.8197]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93940917]\n",
      "[0.82942064]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9948, 0.9925], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8838, 0.8858, 0.8854, 0.8287, 0.8302],\n",
      "         [0.8763, 0.8781, 0.8789, 0.8255, 0.8197]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97317139]\n",
      "[0.97623243]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9928], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8838, 0.8858, 0.8854, 0.8842, 0.8302],\n",
      "         [0.8763, 0.8781, 0.8789, 0.8806, 0.8197]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97343463]\n",
      "[0.80857549]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.8838, 0.8858, 0.8854, 0.8842, 0.8857],\n",
      "         [0.8763, 0.8781, 0.8789, 0.8806, 0.8750]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99668536]\n",
      "[0.96381325]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9392, 0.8858, 0.8854, 0.8842, 0.8857],\n",
      "         [0.9315, 0.8781, 0.8789, 0.8806, 0.8750]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88149839]\n",
      "[0.74285436]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9392, 0.9411, 0.8854, 0.8842, 0.8857],\n",
      "         [0.9315, 0.9333, 0.8789, 0.8806, 0.8750]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78361995]\n",
      "[0.87033355]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9982], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9392, 0.9411, 0.9409, 0.8842, 0.8857],\n",
      "         [0.9315, 0.9333, 0.9342, 0.8806, 0.8750]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.91098413]\n",
      "[0.9200193]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9966, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9392, 0.9411, 0.9409, 0.9394, 0.8857],\n",
      "         [0.9315, 0.9333, 0.9342, 0.9357, 0.8750]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.88187237]\n",
      "[0.79698431]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9959, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9392, 0.9411, 0.9409, 0.9394, 0.9410],\n",
      "         [0.9315, 0.9333, 0.9342, 0.9357, 0.9302]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.37469511]\n",
      "[0.52774006]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9411, 0.9409, 0.9394, 0.9410],\n",
      "         [0.9869, 0.9333, 0.9342, 0.9357, 0.9302]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.91056707]\n",
      "[0.5558445]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9973, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9409, 0.9394, 0.9410],\n",
      "         [0.9869, 0.9886, 0.9342, 0.9357, 0.9302]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92897353]\n",
      "[0.57969563]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0034915325231850147, tolerance: 0.0030497878324240446\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9394, 0.9410],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9357, 0.9302]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.86769032]\n",
      "[0.95113531]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9410],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9302]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.61585836]\n",
      "[0.82410765]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.03833727]\n",
      "[1.01890801]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0553, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0551, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.46713837]\n",
      "[0.8194393]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0553, 0.0552, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0551, 0.0552, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78665261]\n",
      "[1.00377885]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9820], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0553, 0.0552, 0.0554, 0.0000, 0.0000],\n",
      "         [0.0551, 0.0552, 0.0544, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69465238]\n",
      "[0.81950254]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9976], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0553, 0.0552, 0.0554, 0.0555, 0.0000],\n",
      "         [0.0551, 0.0552, 0.0544, 0.0554, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68433669]\n",
      "[0.80903389]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9933], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.0553, 0.0552, 0.0554, 0.0555, 0.0555],\n",
      "         [0.0551, 0.0552, 0.0544, 0.0554, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80188924]\n",
      "[0.98224481]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1108, 0.0552, 0.0554, 0.0555, 0.0555],\n",
      "         [0.1105, 0.0552, 0.0544, 0.0554, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96173083]\n",
      "[0.77566875]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9967, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1108, 0.1104, 0.0554, 0.0555, 0.0555],\n",
      "         [0.1105, 0.1104, 0.0544, 0.0554, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.82084395]\n",
      "[0.89622961]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9965], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1108, 0.1104, 0.1109, 0.0555, 0.0555],\n",
      "         [0.1105, 0.1104, 0.1097, 0.0554, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.61922455]\n",
      "[0.97694116]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1108, 0.1104, 0.1109, 0.1109, 0.0555],\n",
      "         [0.1105, 0.1104, 0.1097, 0.1106, 0.0551]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00986786]\n",
      "[1.01124927]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9958], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1108, 0.1104, 0.1109, 0.1109, 0.1109],\n",
      "         [0.1105, 0.1104, 0.1097, 0.1106, 0.1103]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93346574]\n",
      "[0.94842517]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1662, 0.1104, 0.1109, 0.1109, 0.1109],\n",
      "         [0.1657, 0.1104, 0.1097, 0.1106, 0.1103]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96584008]\n",
      "[0.85584863]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9997, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1662, 0.1660, 0.1109, 0.1109, 0.1109],\n",
      "         [0.1657, 0.1657, 0.1097, 0.1106, 0.1103]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.0074941]\n",
      "[0.94386029]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9929], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1662, 0.1660, 0.1663, 0.1109, 0.1109],\n",
      "         [0.1657, 0.1657, 0.1647, 0.1106, 0.1103]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95549885]\n",
      "[0.90949425]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1662, 0.1660, 0.1663, 0.1663, 0.1109],\n",
      "         [0.1657, 0.1657, 0.1647, 0.1660, 0.1103]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.7218917]\n",
      "[0.85195552]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.1662, 0.1660, 0.1663, 0.1663, 0.1664],\n",
      "         [0.1657, 0.1657, 0.1647, 0.1660, 0.1657]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95619712]\n",
      "[0.98785904]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9985], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2217, 0.1660, 0.1663, 0.1663, 0.1664],\n",
      "         [0.2212, 0.1657, 0.1647, 0.1660, 0.1657]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04158002]\n",
      "[0.99758887]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2217, 0.2214, 0.1663, 0.1663, 0.1664],\n",
      "         [0.2212, 0.2211, 0.1647, 0.1660, 0.1657]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92818415]\n",
      "[1.01224415]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2217, 0.2214, 0.2216, 0.1663, 0.1664],\n",
      "         [0.2212, 0.2211, 0.2197, 0.1660, 0.1657]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95090652]\n",
      "[0.92243188]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9971], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2217, 0.2214, 0.2216, 0.2217, 0.1664],\n",
      "         [0.2212, 0.2211, 0.2197, 0.2212, 0.1657]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93398409]\n",
      "[1.00994525]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2217, 0.2214, 0.2216, 0.2217, 0.2218],\n",
      "         [0.2212, 0.2211, 0.2197, 0.2212, 0.2210]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.89308705]\n",
      "[0.89059301]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9917], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2772, 0.2214, 0.2216, 0.2217, 0.2218],\n",
      "         [0.2762, 0.2211, 0.2197, 0.2212, 0.2210]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.82388634]\n",
      "[1.01085508]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2772, 0.2769, 0.2216, 0.2217, 0.2218],\n",
      "         [0.2762, 0.2763, 0.2197, 0.2212, 0.2210]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.92769317]\n",
      "[0.5849368]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9955], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2772, 0.2769, 0.2771, 0.2217, 0.2218],\n",
      "         [0.2762, 0.2763, 0.2749, 0.2212, 0.2210]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.76541196]\n",
      "[1.01561338]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9901], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2772, 0.2769, 0.2771, 0.2771, 0.2218],\n",
      "         [0.2762, 0.2763, 0.2749, 0.2762, 0.2210]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95414838]\n",
      "[0.59475657]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.2772, 0.2769, 0.2771, 0.2771, 0.2771],\n",
      "         [0.2762, 0.2763, 0.2749, 0.2762, 0.2763]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01434929]\n",
      "[0.80278103]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3327, 0.2769, 0.2771, 0.2771, 0.2771],\n",
      "         [0.3314, 0.2763, 0.2749, 0.2762, 0.2763]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01097849]\n",
      "[0.66997973]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9937, 0.9939], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3327, 0.3319, 0.2771, 0.2771, 0.2771],\n",
      "         [0.3314, 0.3315, 0.2749, 0.2762, 0.2763]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.77009427]\n",
      "[0.66810719]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3327, 0.3319, 0.3325, 0.2771, 0.2771],\n",
      "         [0.3314, 0.3315, 0.3303, 0.2762, 0.2763]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.82568936]\n",
      "[0.90444171]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3327, 0.3319, 0.3325, 0.3325, 0.2771],\n",
      "         [0.3314, 0.3315, 0.3303, 0.3314, 0.2763]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.70760508]\n",
      "[0.88878316]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9969], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3327, 0.3319, 0.3325, 0.3325, 0.3325],\n",
      "         [0.3314, 0.3315, 0.3303, 0.3314, 0.3316]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00985458]\n",
      "[0.98578251]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9994], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3882, 0.3319, 0.3325, 0.3325, 0.3325],\n",
      "         [0.3869, 0.3315, 0.3303, 0.3314, 0.3316]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.80339113]\n",
      "[0.90749912]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9975, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3882, 0.3873, 0.3325, 0.3325, 0.3325],\n",
      "         [0.3869, 0.3867, 0.3303, 0.3314, 0.3316]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78477984]\n",
      "[0.90046715]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3882, 0.3873, 0.3880, 0.3325, 0.3325],\n",
      "         [0.3869, 0.3867, 0.3855, 0.3314, 0.3316]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00339942]\n",
      "[1.00065747]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9907], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3882, 0.3873, 0.3880, 0.3880, 0.3325],\n",
      "         [0.3869, 0.3867, 0.3855, 0.3864, 0.3316]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02500947]\n",
      "[1.01223036]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9990], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.3882, 0.3873, 0.3880, 0.3880, 0.3879],\n",
      "         [0.3869, 0.3867, 0.3855, 0.3864, 0.3871]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.04330431]\n",
      "[0.61373452]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4436, 0.3873, 0.3880, 0.3880, 0.3879],\n",
      "         [0.4422, 0.3867, 0.3855, 0.3864, 0.3871]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96676126]\n",
      "[0.78511717]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4436, 0.4427, 0.3880, 0.3880, 0.3879],\n",
      "         [0.4422, 0.4421, 0.3855, 0.3864, 0.3871]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.06929997]\n",
      "[0.60824577]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9845, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4436, 0.4427, 0.4425, 0.3880, 0.3879],\n",
      "         [0.4422, 0.4421, 0.4406, 0.3864, 0.3871]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.68570235]\n",
      "[1.01010182]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9323], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4436, 0.4427, 0.4425, 0.4434, 0.3879],\n",
      "         [0.4422, 0.4421, 0.4406, 0.4377, 0.3871]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01172265]\n",
      "[0.7956665]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9452], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4436, 0.4427, 0.4425, 0.4434, 0.4434],\n",
      "         [0.4422, 0.4421, 0.4406, 0.4377, 0.4395]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.99219271]\n",
      "[0.75065713]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9961, 0.9931], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4989, 0.4427, 0.4425, 0.4434, 0.4434],\n",
      "         [0.4972, 0.4421, 0.4406, 0.4377, 0.4395]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.09831348]\n",
      "[0.60676386]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9923, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4989, 0.4978, 0.4425, 0.4434, 0.4434],\n",
      "         [0.4972, 0.4975, 0.4406, 0.4377, 0.4395]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01995472]\n",
      "[1.01179715]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9942], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4989, 0.4978, 0.4979, 0.4434, 0.4434],\n",
      "         [0.4972, 0.4975, 0.4953, 0.4377, 0.4395]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05450858]\n",
      "[0.65221009]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9992], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4989, 0.4978, 0.4979, 0.4988, 0.4434],\n",
      "         [0.4972, 0.4975, 0.4953, 0.4932, 0.4395]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.10294758]\n",
      "[0.77232199]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9957, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.4989, 0.4978, 0.4979, 0.4988, 0.4986],\n",
      "         [0.4972, 0.4975, 0.4953, 0.4932, 0.4949]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.09908586]\n",
      "[0.71899191]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9672], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.5543, 0.4978, 0.4979, 0.4988, 0.4986],\n",
      "         [0.5502, 0.4975, 0.4953, 0.4932, 0.4949]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.05198985]\n",
      "[0.98091832]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.5543, 0.5532, 0.4979, 0.4988, 0.4986],\n",
      "         [0.5502, 0.5527, 0.4953, 0.4932, 0.4949]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69966117]\n",
      "[0.95106246]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9922], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.5543, 0.5532, 0.5533, 0.4988, 0.4986],\n",
      "         [0.5502, 0.5527, 0.5502, 0.4932, 0.4949]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.78513138]\n",
      "[0.85311823]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9947], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.5543, 0.5532, 0.5533, 0.5543, 0.4986],\n",
      "         [0.5502, 0.5527, 0.5502, 0.5483, 0.4949]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98923049]\n",
      "[0.98196197]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.5543, 0.5532, 0.5533, 0.5543, 0.5538],\n",
      "         [0.5502, 0.5527, 0.5502, 0.5483, 0.5501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.8308957]\n",
      "[0.92931166]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6097, 0.5532, 0.5533, 0.5543, 0.5538],\n",
      "         [0.6056, 0.5527, 0.5502, 0.5483, 0.5501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.75389571]\n",
      "[0.87420687]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9878], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6097, 0.6086, 0.5533, 0.5543, 0.5538],\n",
      "         [0.6056, 0.6074, 0.5502, 0.5483, 0.5501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.01345123]\n",
      "[0.93937351]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9933], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6097, 0.6086, 0.6087, 0.5543, 0.5538],\n",
      "         [0.6056, 0.6074, 0.6053, 0.5483, 0.5501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97921366]\n",
      "[0.94564517]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9994], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6097, 0.6086, 0.6087, 0.6097, 0.5538],\n",
      "         [0.6056, 0.6074, 0.6053, 0.6038, 0.5501]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.66424449]\n",
      "[0.96982424]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9969, 0.9976], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6097, 0.6086, 0.6087, 0.6097, 0.6091],\n",
      "         [0.6056, 0.6074, 0.6053, 0.6038, 0.6055]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.89821296]\n",
      "[0.82115842]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9949, 0.9947], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6649, 0.6086, 0.6087, 0.6097, 0.6091],\n",
      "         [0.6606, 0.6074, 0.6053, 0.6038, 0.6055]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.6099122]\n",
      "[0.84555656]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9968, 0.9930], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6649, 0.6639, 0.6087, 0.6097, 0.6091],\n",
      "         [0.6606, 0.6624, 0.6053, 0.6038, 0.6055]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.69340864]\n",
      "[0.94907486]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6649, 0.6639, 0.6641, 0.6097, 0.6091],\n",
      "         [0.6606, 0.6624, 0.6605, 0.6038, 0.6055]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.81917066]\n",
      "[0.58159688]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9982], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6649, 0.6639, 0.6641, 0.6650, 0.6091],\n",
      "         [0.6606, 0.6624, 0.6605, 0.6591, 0.6055]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95010858]\n",
      "[1.04525574]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9896], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.6649, 0.6639, 0.6641, 0.6650, 0.6645],\n",
      "         [0.6606, 0.6624, 0.6605, 0.6591, 0.6603]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98073361]\n",
      "[1.02106302]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7204, 0.6639, 0.6641, 0.6650, 0.6645],\n",
      "         [0.7159, 0.6624, 0.6605, 0.6591, 0.6603]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00414991]\n",
      "[1.01903009]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9943], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7204, 0.7193, 0.6641, 0.6650, 0.6645],\n",
      "         [0.7159, 0.7173, 0.6605, 0.6591, 0.6603]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96668154]\n",
      "[0.94011047]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7204, 0.7193, 0.7195, 0.6650, 0.6645],\n",
      "         [0.7159, 0.7173, 0.7159, 0.6591, 0.6603]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.96926144]\n",
      "[1.04472448]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9968], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7204, 0.7193, 0.7195, 0.7205, 0.6645],\n",
      "         [0.7159, 0.7173, 0.7159, 0.7143, 0.6603]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93502963]\n",
      "[0.89464629]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7204, 0.7193, 0.7195, 0.7205, 0.7199],\n",
      "         [0.7159, 0.7173, 0.7159, 0.7143, 0.7155]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95098198]\n",
      "[0.9156427]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9830], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7758, 0.7193, 0.7195, 0.7205, 0.7199],\n",
      "         [0.7705, 0.7173, 0.7159, 0.7143, 0.7155]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.02571621]\n",
      "[0.81122885]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9923], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7758, 0.7748, 0.7195, 0.7205, 0.7199],\n",
      "         [0.7705, 0.7724, 0.7159, 0.7143, 0.7155]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97421243]\n",
      "[0.985366]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9988], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7758, 0.7748, 0.7750, 0.7205, 0.7199],\n",
      "         [0.7705, 0.7724, 0.7713, 0.7143, 0.7155]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.89386871]\n",
      "[0.78064508]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7758, 0.7748, 0.7750, 0.7759, 0.7199],\n",
      "         [0.7705, 0.7724, 0.7713, 0.7694, 0.7155]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9892978]\n",
      "[1.03858944]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9981, 0.9778], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.7758, 0.7748, 0.7750, 0.7759, 0.7753],\n",
      "         [0.7705, 0.7724, 0.7713, 0.7694, 0.7698]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[1.00062404]\n",
      "[0.48604502]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8312, 0.7748, 0.7750, 0.7759, 0.7753],\n",
      "         [0.8259, 0.7724, 0.7713, 0.7694, 0.7698]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.35412205]\n",
      "[0.88662545]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9847, 0.9830], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8312, 0.8293, 0.7750, 0.7759, 0.7753],\n",
      "         [0.8259, 0.8266, 0.7713, 0.7694, 0.7698]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.48725965]\n",
      "[0.77149087]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9971, 0.9876], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8312, 0.8293, 0.8303, 0.7759, 0.7753],\n",
      "         [0.8259, 0.8266, 0.8260, 0.7694, 0.7698]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.97125079]\n",
      "[0.65537899]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8312, 0.8293, 0.8303, 0.8314, 0.7753],\n",
      "         [0.8259, 0.8266, 0.8260, 0.8244, 0.7698]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.66847047]\n",
      "[0.90394473]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9979, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8312, 0.8293, 0.8303, 0.8314, 0.8307],\n",
      "         [0.8259, 0.8266, 0.8260, 0.8244, 0.8250]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.95843274]\n",
      "[1.00803977]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9962], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8867, 0.8293, 0.8303, 0.8314, 0.8307],\n",
      "         [0.8811, 0.8266, 0.8260, 0.8244, 0.8250]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.9328863]\n",
      "[0.97562759]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9985], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8867, 0.8848, 0.8303, 0.8314, 0.8307],\n",
      "         [0.8811, 0.8820, 0.8260, 0.8244, 0.8250]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93262286]\n",
      "[1.00116466]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9959], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8867, 0.8848, 0.8858, 0.8314, 0.8307],\n",
      "         [0.8811, 0.8820, 0.8810, 0.8244, 0.8250]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93666078]\n",
      "[0.98704361]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9973], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8867, 0.8848, 0.8858, 0.8869, 0.8307],\n",
      "         [0.8811, 0.8820, 0.8810, 0.8798, 0.8250]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.93243084]\n",
      "[1.02025971]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.8867, 0.8848, 0.8858, 0.8869, 0.8861],\n",
      "         [0.8811, 0.8820, 0.8810, 0.8798, 0.8800]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.98544163]\n",
      "[0.99000512]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9968], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9422, 0.8848, 0.8858, 0.8869, 0.8861],\n",
      "         [0.9363, 0.8820, 0.8810, 0.8798, 0.8800]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.7294335]\n",
      "[0.71309887]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9970, 0.9992], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9422, 0.9402, 0.8858, 0.8869, 0.8861],\n",
      "         [0.9363, 0.9375, 0.8810, 0.8798, 0.8800]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.6225189]\n",
      "[0.63314067]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9422, 0.9402, 0.9412, 0.8869, 0.8861],\n",
      "         [0.9363, 0.9375, 0.9362, 0.8798, 0.8800]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.5250365]\n",
      "[0.71104025]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9422, 0.9402, 0.9412, 0.9423, 0.8861],\n",
      "         [0.9363, 0.9375, 0.9362, 0.9351, 0.8800]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.4364774]\n",
      "[0.6177744]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9422, 0.9402, 0.9412, 0.9423, 0.9416],\n",
      "         [0.9363, 0.9375, 0.9362, 0.9351, 0.9352]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.53090161]\n",
      "[0.67112222]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9852], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9402, 0.9412, 0.9423, 0.9416],\n",
      "         [0.9909, 0.9375, 0.9362, 0.9351, 0.9352]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.74261461]\n",
      "[0.82003199]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9975], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9412, 0.9423, 0.9416],\n",
      "         [0.9909, 0.9928, 0.9362, 0.9351, 0.9352]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.59563816]\n",
      "[0.81987242]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9963, 0.9988], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9423, 0.9416],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9351, 0.9352]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.57573738]\n",
      "[0.62232997]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9972], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9416],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9352]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.85663256]\n",
      "[0.95385127]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9998, 0.9976], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.61096153]\n",
      "[0.77700608]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0555, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0553, 0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.73506472]\n",
      "[0.85650547]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9945], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0555, 0.0555, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0553, 0.0552, 0.0000, 0.0000, 0.0000]]])\n",
      "[0.48398088]\n",
      "[0.96534715]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9978, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0555, 0.0555, 0.0554, 0.0000, 0.0000],\n",
      "         [0.0553, 0.0552, 0.0552, 0.0000, 0.0000]]])\n",
      "[0.8376821]\n",
      "[1.01117746]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9987], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0555, 0.0555, 0.0554, 0.0555, 0.0000],\n",
      "         [0.0553, 0.0552, 0.0552, 0.0554, 0.0000]]])\n",
      "[0.69631792]\n",
      "[0.99020992]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9989], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.0555, 0.0555, 0.0554, 0.0555, 0.0554],\n",
      "         [0.0553, 0.0552, 0.0552, 0.0554, 0.0555]]])\n",
      "[0.36283789]\n",
      "[0.79829166]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9943], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1110, 0.0555, 0.0554, 0.0555, 0.0554],\n",
      "         [0.1104, 0.0552, 0.0552, 0.0554, 0.0555]]])\n",
      "[0.98886603]\n",
      "[1.00006295]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9988], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1110, 0.1109, 0.0554, 0.0555, 0.0554],\n",
      "         [0.1104, 0.1106, 0.0552, 0.0554, 0.0555]]])\n",
      "[0.98085566]\n",
      "[0.90854118]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9950], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1110, 0.1109, 0.1109, 0.0555, 0.0554],\n",
      "         [0.1104, 0.1106, 0.1103, 0.0554, 0.0555]]])\n",
      "[0.96670252]\n",
      "[0.95046906]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1110, 0.1109, 0.1109, 0.1110, 0.0554],\n",
      "         [0.1104, 0.1106, 0.1103, 0.1108, 0.0555]]])\n",
      "[1.05278168]\n",
      "[0.9547483]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9985], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1110, 0.1109, 0.1109, 0.1110, 0.1109],\n",
      "         [0.1104, 0.1106, 0.1103, 0.1108, 0.1108]]])\n",
      "[1.00557343]\n",
      "[1.01981021]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9982], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1664, 0.1109, 0.1109, 0.1110, 0.1109],\n",
      "         [0.1658, 0.1106, 0.1103, 0.1108, 0.1108]]])\n",
      "[1.01335927]\n",
      "[0.94510674]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1664, 0.1664, 0.1109, 0.1110, 0.1109],\n",
      "         [0.1658, 0.1658, 0.1103, 0.1108, 0.1108]]])\n",
      "[0.9660178]\n",
      "[0.97651099]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9985], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1664, 0.1664, 0.1663, 0.1110, 0.1109],\n",
      "         [0.1658, 0.1658, 0.1658, 0.1108, 0.1108]]])\n",
      "[1.00290428]\n",
      "[0.79205414]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9963], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1664, 0.1664, 0.1663, 0.1664, 0.1109],\n",
      "         [0.1658, 0.1658, 0.1658, 0.1660, 0.1108]]])\n",
      "[1.01956289]\n",
      "[0.92294438]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9992], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.1664, 0.1664, 0.1663, 0.1664, 0.1664],\n",
      "         [0.1658, 0.1658, 0.1658, 0.1660, 0.1662]]])\n",
      "[0.95884489]\n",
      "[0.95436659]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9989], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2218, 0.1664, 0.1663, 0.1664, 0.1664],\n",
      "         [0.2212, 0.1658, 0.1658, 0.1660, 0.1662]]])\n",
      "[0.78226711]\n",
      "[0.92351203]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9973], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2218, 0.2218, 0.1663, 0.1664, 0.1664],\n",
      "         [0.2212, 0.2211, 0.1658, 0.1660, 0.1662]]])\n",
      "[1.02929503]\n",
      "[0.93977284]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2218, 0.2218, 0.2219, 0.1664, 0.1664],\n",
      "         [0.2212, 0.2211, 0.2211, 0.1660, 0.1662]]])\n",
      "[0.9803134]\n",
      "[1.01948668]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9954], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2218, 0.2218, 0.2219, 0.2219, 0.1664],\n",
      "         [0.2212, 0.2211, 0.2211, 0.2212, 0.1662]]])\n",
      "[0.96256827]\n",
      "[0.94323514]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2218, 0.2218, 0.2219, 0.2219, 0.2218],\n",
      "         [0.2212, 0.2211, 0.2211, 0.2212, 0.2214]]])\n",
      "[1.04452407]\n",
      "[0.67737461]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9853], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2773, 0.2218, 0.2219, 0.2219, 0.2218],\n",
      "         [0.2758, 0.2211, 0.2211, 0.2212, 0.2214]]])\n",
      "[1.01329386]\n",
      "[0.94574867]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9930], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2773, 0.2772, 0.2219, 0.2219, 0.2218],\n",
      "         [0.2758, 0.2761, 0.2211, 0.2212, 0.2214]]])\n",
      "[0.7508828]\n",
      "[0.8322872]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9877], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2773, 0.2772, 0.2773, 0.2219, 0.2218],\n",
      "         [0.2758, 0.2761, 0.2759, 0.2212, 0.2214]]])\n",
      "[1.0060614]\n",
      "[0.9752746]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2773, 0.2772, 0.2773, 0.2774, 0.2218],\n",
      "         [0.2758, 0.2761, 0.2759, 0.2766, 0.2214]]])\n",
      "[1.00396866]\n",
      "[0.77822074]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.2773, 0.2772, 0.2773, 0.2774, 0.2773],\n",
      "         [0.2758, 0.2761, 0.2759, 0.2766, 0.2767]]])\n",
      "[0.5877165]\n",
      "[0.86724361]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3327, 0.2772, 0.2773, 0.2774, 0.2773],\n",
      "         [0.3311, 0.2761, 0.2759, 0.2766, 0.2767]]])\n",
      "[0.98511085]\n",
      "[0.96260831]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9997, 0.9978], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3327, 0.3328, 0.2773, 0.2774, 0.2773],\n",
      "         [0.3311, 0.3315, 0.2759, 0.2766, 0.2767]]])\n",
      "[0.73148597]\n",
      "[0.89199834]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9962], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3327, 0.3328, 0.3328, 0.2774, 0.2773],\n",
      "         [0.3311, 0.3315, 0.3312, 0.2766, 0.2767]]])\n",
      "[0.99125359]\n",
      "[0.95501882]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9949], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3327, 0.3328, 0.3328, 0.3329, 0.2773],\n",
      "         [0.3311, 0.3315, 0.3312, 0.3318, 0.2767]]])\n",
      "[0.37510529]\n",
      "[0.87513397]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9960], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3327, 0.3328, 0.3328, 0.3329, 0.3327],\n",
      "         [0.3311, 0.3315, 0.3312, 0.3318, 0.3320]]])\n",
      "[1.01202708]\n",
      "[0.9690901]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3882, 0.3328, 0.3328, 0.3329, 0.3327],\n",
      "         [0.3864, 0.3315, 0.3312, 0.3318, 0.3320]]])\n",
      "[0.93158844]\n",
      "[0.51581094]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9995, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3882, 0.3883, 0.3328, 0.3329, 0.3327],\n",
      "         [0.3864, 0.3868, 0.3312, 0.3318, 0.3320]]])\n",
      "[1.03059279]\n",
      "[0.91734582]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9969], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3882, 0.3883, 0.3882, 0.3329, 0.3327],\n",
      "         [0.3864, 0.3868, 0.3865, 0.3318, 0.3320]]])\n",
      "[1.04955857]\n",
      "[0.98248225]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9977], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3882, 0.3883, 0.3882, 0.3883, 0.3327],\n",
      "         [0.3864, 0.3868, 0.3865, 0.3871, 0.3320]]])\n",
      "[1.02669589]\n",
      "[0.59558405]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.3882, 0.3883, 0.3882, 0.3883, 0.3881],\n",
      "         [0.3864, 0.3868, 0.3865, 0.3871, 0.3874]]])\n",
      "[0.80382738]\n",
      "[0.67435153]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9961], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4436, 0.3883, 0.3882, 0.3883, 0.3881],\n",
      "         [0.4417, 0.3868, 0.3865, 0.3871, 0.3874]]])\n",
      "[0.68510821]\n",
      "[0.97792001]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4436, 0.4437, 0.3882, 0.3883, 0.3881],\n",
      "         [0.4417, 0.4421, 0.3865, 0.3871, 0.3874]]])\n",
      "[0.67169745]\n",
      "[0.96923574]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9977, 0.9942], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4436, 0.4437, 0.4436, 0.3883, 0.3881],\n",
      "         [0.4417, 0.4421, 0.4417, 0.3871, 0.3874]]])\n",
      "[0.52546968]\n",
      "[1.03474031]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9956, 0.9917], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4436, 0.4437, 0.4436, 0.4436, 0.3881],\n",
      "         [0.4417, 0.4421, 0.4417, 0.4421, 0.3874]]])\n",
      "[0.55323788]\n",
      "[1.04062943]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9965], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4436, 0.4437, 0.4436, 0.4436, 0.4435],\n",
      "         [0.4417, 0.4421, 0.4417, 0.4421, 0.4426]]])\n",
      "[0.3122882]\n",
      "[0.92907245]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4991, 0.4437, 0.4436, 0.4436, 0.4435],\n",
      "         [0.4968, 0.4421, 0.4417, 0.4421, 0.4426]]])\n",
      "[1.05723966]\n",
      "[0.66714745]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9951], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4991, 0.4990, 0.4436, 0.4436, 0.4435],\n",
      "         [0.4968, 0.4972, 0.4417, 0.4421, 0.4426]]])\n",
      "[0.82324023]\n",
      "[0.94399028]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9947], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4991, 0.4990, 0.4990, 0.4436, 0.4435],\n",
      "         [0.4968, 0.4972, 0.4968, 0.4421, 0.4426]]])\n",
      "[1.03200738]\n",
      "[0.64852415]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9960, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4991, 0.4990, 0.4990, 0.4988, 0.4435],\n",
      "         [0.4968, 0.4972, 0.4968, 0.4973, 0.4426]]])\n",
      "[0.96286145]\n",
      "[0.88972375]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9944, 0.9995], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.4991, 0.4990, 0.4990, 0.4988, 0.4987],\n",
      "         [0.4968, 0.4972, 0.4968, 0.4973, 0.4981]]])\n",
      "[1.03430045]\n",
      "[0.77192311]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9955], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.5545, 0.4990, 0.4990, 0.4988, 0.4987],\n",
      "         [0.5520, 0.4972, 0.4968, 0.4973, 0.4981]]])\n",
      "[0.8890094]\n",
      "[0.9511629]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9980, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.5545, 0.5544, 0.4990, 0.4988, 0.4987],\n",
      "         [0.5520, 0.5525, 0.4968, 0.4973, 0.4981]]])\n",
      "[0.84719384]\n",
      "[0.81940073]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9939], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.5545, 0.5544, 0.5545, 0.4988, 0.4987],\n",
      "         [0.5520, 0.5525, 0.5518, 0.4973, 0.4981]]])\n",
      "[1.03439384]\n",
      "[0.97421255]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9940], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.5545, 0.5544, 0.5545, 0.5542, 0.4987],\n",
      "         [0.5520, 0.5525, 0.5518, 0.5524, 0.4981]]])\n",
      "[1.0815063]\n",
      "[1.02741401]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9910], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.5545, 0.5544, 0.5545, 0.5542, 0.5542],\n",
      "         [0.5520, 0.5525, 0.5518, 0.5524, 0.5529]]])\n",
      "[1.05528998]\n",
      "[0.95818965]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9988, 0.9974], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6099, 0.5544, 0.5545, 0.5542, 0.5542],\n",
      "         [0.6073, 0.5525, 0.5518, 0.5524, 0.5529]]])\n",
      "[0.76795703]\n",
      "[0.93209034]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9911], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6099, 0.6099, 0.5545, 0.5542, 0.5542],\n",
      "         [0.6073, 0.6074, 0.5518, 0.5524, 0.5529]]])\n",
      "[1.04171008]\n",
      "[0.98653591]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9948], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6099, 0.6099, 0.6099, 0.5542, 0.5542],\n",
      "         [0.6073, 0.6074, 0.6070, 0.5524, 0.5529]]])\n",
      "[0.98016148]\n",
      "[0.97570769]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6099, 0.6099, 0.6099, 0.6096, 0.5542],\n",
      "         [0.6073, 0.6074, 0.6070, 0.6076, 0.5529]]])\n",
      "[0.88760144]\n",
      "[0.92884387]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9918], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6099, 0.6099, 0.6099, 0.6096, 0.6097],\n",
      "         [0.6073, 0.6074, 0.6070, 0.6076, 0.6078]]])\n",
      "[1.00311765]\n",
      "[0.856782]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9990, 0.9903], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6653, 0.6099, 0.6099, 0.6096, 0.6097],\n",
      "         [0.6621, 0.6074, 0.6070, 0.6076, 0.6078]]])\n",
      "[1.00088583]\n",
      "[1.04035829]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9957], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6653, 0.6653, 0.6099, 0.6096, 0.6097],\n",
      "         [0.6621, 0.6626, 0.6070, 0.6076, 0.6078]]])\n",
      "[1.08273961]\n",
      "[0.98679451]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9979], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6653, 0.6653, 0.6653, 0.6096, 0.6097],\n",
      "         [0.6621, 0.6626, 0.6624, 0.6076, 0.6078]]])\n",
      "[0.62970127]\n",
      "[0.80869697]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9965, 0.9973], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6653, 0.6653, 0.6653, 0.6649, 0.6097],\n",
      "         [0.6621, 0.6626, 0.6624, 0.6628, 0.6078]]])\n",
      "[0.61164855]\n",
      "[0.80182378]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9983, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.6653, 0.6653, 0.6653, 0.6649, 0.6651],\n",
      "         [0.6621, 0.6626, 0.6624, 0.6628, 0.6632]]])\n",
      "[0.79636981]\n",
      "[0.55490447]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9984, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7208, 0.6653, 0.6653, 0.6649, 0.6651],\n",
      "         [0.7175, 0.6626, 0.6624, 0.6628, 0.6632]]])\n",
      "[0.97534896]\n",
      "[0.77437117]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9990], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7208, 0.7208, 0.6653, 0.6649, 0.6651],\n",
      "         [0.7175, 0.7180, 0.6624, 0.6628, 0.6632]]])\n",
      "[1.02379084]\n",
      "[0.99456388]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9971], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7208, 0.7208, 0.7207, 0.6649, 0.6651],\n",
      "         [0.7175, 0.7180, 0.7176, 0.6628, 0.6632]]])\n",
      "[1.00826419]\n",
      "[0.76859301]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9985, 0.9970], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7208, 0.7208, 0.7207, 0.7204, 0.6651],\n",
      "         [0.7175, 0.7180, 0.7176, 0.7181, 0.6632]]])\n",
      "[1.03189968]\n",
      "[1.01269058]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9967], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7208, 0.7208, 0.7207, 0.7204, 0.7206],\n",
      "         [0.7175, 0.7180, 0.7176, 0.7181, 0.7185]]])\n",
      "[0.94918934]\n",
      "[0.92551122]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9987], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7762, 0.7208, 0.7207, 0.7204, 0.7206],\n",
      "         [0.7730, 0.7180, 0.7176, 0.7181, 0.7185]]])\n",
      "[0.85845999]\n",
      "[0.98266467]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9934], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7762, 0.7763, 0.7207, 0.7204, 0.7206],\n",
      "         [0.7730, 0.7731, 0.7176, 0.7181, 0.7185]]])\n",
      "[1.02081466]\n",
      "[1.00901923]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9977], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7762, 0.7763, 0.7762, 0.7204, 0.7206],\n",
      "         [0.7730, 0.7731, 0.7730, 0.7181, 0.7185]]])\n",
      "[0.75557928]\n",
      "[0.8640533]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9977], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7762, 0.7763, 0.7762, 0.7758, 0.7206],\n",
      "         [0.7730, 0.7731, 0.7730, 0.7734, 0.7185]]])\n",
      "[0.97751955]\n",
      "[0.98841653]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9928], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.7762, 0.7763, 0.7762, 0.7758, 0.7760],\n",
      "         [0.7730, 0.7731, 0.7730, 0.7734, 0.7736]]])\n",
      "[0.94602168]\n",
      "[1.01825156]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9987, 0.9954], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8316, 0.7763, 0.7762, 0.7758, 0.7760],\n",
      "         [0.8280, 0.7731, 0.7730, 0.7734, 0.7736]]])\n",
      "[0.68543841]\n",
      "[0.93717666]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9962, 0.9973], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8316, 0.8315, 0.7762, 0.7758, 0.7760],\n",
      "         [0.8280, 0.8283, 0.7730, 0.7734, 0.7736]]])\n",
      "[0.87147946]\n",
      "[0.51011079]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9939, 0.9940], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8316, 0.8315, 0.8313, 0.7758, 0.7760],\n",
      "         [0.8280, 0.8283, 0.8279, 0.7734, 0.7736]]])\n",
      "[0.66244305]\n",
      "[0.81604711]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9982, 0.9863], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8316, 0.8315, 0.8313, 0.8312, 0.7760],\n",
      "         [0.8280, 0.8283, 0.8279, 0.8281, 0.7736]]])\n",
      "[0.98401657]\n",
      "[0.71274381]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9976, 0.9961], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8316, 0.8315, 0.8313, 0.8312, 0.8314],\n",
      "         [0.8280, 0.8283, 0.8279, 0.8281, 0.8288]]])\n",
      "[0.6942011]\n",
      "[0.71245273]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9964], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8872, 0.8315, 0.8313, 0.8312, 0.8314],\n",
      "         [0.8833, 0.8283, 0.8279, 0.8281, 0.8288]]])\n",
      "[0.98109766]\n",
      "[0.97420142]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9969], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8872, 0.8870, 0.8313, 0.8312, 0.8314],\n",
      "         [0.8833, 0.8836, 0.8279, 0.8281, 0.8288]]])\n",
      "[0.94590724]\n",
      "[0.7574992]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9987], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8872, 0.8870, 0.8868, 0.8312, 0.8314],\n",
      "         [0.8833, 0.8836, 0.8833, 0.8281, 0.8288]]])\n",
      "[0.98942456]\n",
      "[1.00126693]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9993, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8872, 0.8870, 0.8868, 0.8867, 0.8314],\n",
      "         [0.8833, 0.8836, 0.8833, 0.8835, 0.8288]]])\n",
      "[0.96094422]\n",
      "[0.82575449]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9986, 0.9986], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.8872, 0.8870, 0.8868, 0.8867, 0.8868],\n",
      "         [0.8833, 0.8836, 0.8833, 0.8835, 0.8842]]])\n",
      "[0.77850045]\n",
      "[0.87515988]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9956], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9426, 0.8870, 0.8868, 0.8867, 0.8868],\n",
      "         [0.9384, 0.8836, 0.8833, 0.8835, 0.8842]]])\n",
      "[0.37026153]\n",
      "[0.54717125]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9994, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9426, 0.9425, 0.8868, 0.8867, 0.8868],\n",
      "         [0.9384, 0.9390, 0.8833, 0.8835, 0.8842]]])\n",
      "[0.51381083]\n",
      "[0.56936436]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9983], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9426, 0.9425, 0.9423, 0.8867, 0.8868],\n",
      "         [0.9384, 0.9390, 0.9387, 0.8835, 0.8842]]])\n",
      "[0.76347406]\n",
      "[0.72912092]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9996, 0.9991], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9426, 0.9425, 0.9423, 0.9422, 0.8868],\n",
      "         [0.9384, 0.9390, 0.9387, 0.9389, 0.8842]]])\n",
      "[0.95145361]\n",
      "[0.90887278]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9974, 0.9980], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9426, 0.9425, 0.9423, 0.9422, 0.9422],\n",
      "         [0.9384, 0.9390, 0.9387, 0.9389, 0.9395]]])\n",
      "[0.88732093]\n",
      "[0.75511007]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "17\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9997, 0.9989], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9981, 0.9425, 0.9423, 0.9422, 0.9422],\n",
      "         [0.9938, 0.9390, 0.9387, 0.9389, 0.9395]]])\n",
      "[0.51953133]\n",
      "[0.62686766]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9992, 0.9993], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9981, 0.9980, 0.9423, 0.9422, 0.9422],\n",
      "         [0.9938, 0.9944, 0.9387, 0.9389, 0.9395]]])\n",
      "[0.68850541]\n",
      "[0.59258246]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9989, 0.9998], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9981, 0.9980, 0.9978, 0.9422, 0.9422],\n",
      "         [0.9938, 0.9944, 0.9942, 0.9389, 0.9395]]])\n",
      "[0.88267527]\n",
      "[0.82765662]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9996], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9981, 0.9980, 0.9978, 0.9977, 0.9422],\n",
      "         [0.9938, 0.9944, 0.9942, 0.9944, 0.9395]]])\n",
      "[0.93825198]\n",
      "[0.61221476]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "tensor([0.9991, 0.9984], dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[0.9012, 0.7896, 0.9177, 0.6712, 0.7927],\n",
      "         [0.8570, 0.7148, 0.8745, 0.8524, 0.8167]],\n",
      "\n",
      "        [[0.9799, 0.9862, 0.9788, 0.9730, 0.9857],\n",
      "         [0.9007, 0.9593, 0.9532, 0.8676, 0.9686]],\n",
      "\n",
      "        [[0.9922, 0.9934, 0.9941, 0.9944, 0.9910],\n",
      "         [0.9859, 0.9623, 0.9774, 0.9785, 0.9729]],\n",
      "\n",
      "        [[0.9947, 0.9965, 0.9963, 0.9947, 0.9963],\n",
      "         [0.9869, 0.9886, 0.9896, 0.9910, 0.9856]],\n",
      "\n",
      "        [[0.9977, 0.9957, 0.9966, 0.9978, 0.9971],\n",
      "         [0.9909, 0.9928, 0.9915, 0.9905, 0.9906]],\n",
      "\n",
      "        [[0.9981, 0.9980, 0.9978, 0.9977, 0.9976],\n",
      "         [0.9938, 0.9944, 0.9942, 0.9944, 0.9949]]])\n",
      "[1.07048079]\n",
      "[1.01155653]\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "reps=5\n",
    "nn=[10,20,30,40,50,60]\n",
    "R2=torch.zeros(7,len(nn),2,reps)\n",
    "ISE=torch.zeros(7,len(nn),2,reps)\n",
    "Ti=torch.zeros(7,len(nn),reps)\n",
    "\n",
    "for num, n in enumerate(nn):\n",
    "    for k in range(len(emulators)):\n",
    "        emulators2=emulators.copy()\n",
    "        emulators2.pop(k)\n",
    "        print(len(emulators2))\n",
    "\n",
    "        X_train = train_input[k]\n",
    "        y_train = train_output[k]\n",
    "        X_test = test_input[k]\n",
    "        y_test = test_output[k]\n",
    "        \n",
    "        for i in range(reps):\n",
    "\n",
    "            b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "\n",
    "            start = time.time()\n",
    "            model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_f.R2_sample(X_test,y_test,1000)\n",
    "            R2[0,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[0,num,:,i]+=model_f.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[0,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "\n",
    "            em=np.random.randint(len(emulators2))\n",
    "            start = time.time()\n",
    "            model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=torch.tensor([[1],[1]]))\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_1.R2_sample(X_test,y_test,1000)\n",
    "            R2[1,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[1,num,:,i]+=model_dc_1.ISE(X_test,y_test)/(len(emulators))\n",
    "            print(model_dc_1.R2(X_test,y_test))\n",
    "            print(R2[1])\n",
    "\n",
    "            Ti[1,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            m0 = emulators2[em].predict(X_train[b,:])\n",
    "            a_d=np.zeros((y_train.shape[1],1))\n",
    "            for l in range(y_train.shape[1]):\n",
    "                result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l), method='Nelder-Mead', tol=1e-8)\n",
    "                print(result.x)\n",
    "                a_d[l]=result.x\n",
    "            a_d=torch.tensor(a_d)\n",
    "            model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=a_d)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_reg.R2_sample(X_test,y_test,1000)\n",
    "            R2[2,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[2,num,:,i]+=model_dc_reg.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[2,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]])\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_learned.R2_sample(X_test,y_test,1000)\n",
    "            R2[3,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[3,num,:,i]+=model_dc_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[3,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_all.R2_sample(X_test,y_test,1000)\n",
    "            R2[4,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[4,num,:,i]+=model_dc_all.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[4,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "            for j in range(y_train.shape[1]):\n",
    "                m0=m0_mat(y_train[b],emulators2,X_train[b],j)\n",
    "                # fit to an order-3 polynomial data\n",
    "                y_t=(y_train[b,j]-y_train.mean(axis=0)[j])/y_train.std(axis=0)[j]\n",
    "                model = model.fit(m0.detach().numpy(), y_t.detach().numpy())\n",
    "                a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "\n",
    "\n",
    "            model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_lasso.R2_sample(X_test,y_test,1000)\n",
    "            R2[5,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[5,num,:,i]+=model_dc_lasso.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[5,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_lasso_learned.R2_sample(X_test,y_test,1000)\n",
    "            R2[6,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[6,num,:,i]+=model_dc_lasso_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[6,num,i]+=(end-start)/(len(emulators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073930e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5583,  0.2519,  0.5579,  0.4666,  0.4992],\n",
       "          [ 0.6666,  0.6846,  0.7979,  0.6686,  0.5016]],\n",
       "\n",
       "         [[ 0.9227,  0.9138,  0.8764,  0.9349,  0.9162],\n",
       "          [ 0.8904,  0.9109,  0.9352,  0.9164,  0.8955]],\n",
       "\n",
       "         [[ 0.9797,  0.9800,  0.9842,  0.9777,  0.9684],\n",
       "          [ 0.9644,  0.9522,  0.9681,  0.9592,  0.9550]],\n",
       "\n",
       "         [[ 0.9869,  0.9879,  0.9906,  0.9895,  0.9848],\n",
       "          [ 0.9752,  0.9776,  0.9786,  0.9800,  0.9800]],\n",
       "\n",
       "         [[ 0.9922,  0.9904,  0.9920,  0.9941,  0.9937],\n",
       "          [ 0.9870,  0.9880,  0.9859,  0.9847,  0.9854]],\n",
       "\n",
       "         [[ 0.9952,  0.9935,  0.9943,  0.9946,  0.9955],\n",
       "          [ 0.9885,  0.9897,  0.9897,  0.9881,  0.9885]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9012,  0.7896,  0.9177,  0.6712,  0.7927],\n",
       "          [ 0.8570,  0.7148,  0.8745,  0.8524,  0.8167]],\n",
       "\n",
       "         [[ 0.9799,  0.9862,  0.9788,  0.9730,  0.9857],\n",
       "          [ 0.9007,  0.9593,  0.9532,  0.8676,  0.9686]],\n",
       "\n",
       "         [[ 0.9922,  0.9934,  0.9941,  0.9944,  0.9910],\n",
       "          [ 0.9859,  0.9623,  0.9774,  0.9785,  0.9729]],\n",
       "\n",
       "         [[ 0.9947,  0.9965,  0.9963,  0.9947,  0.9963],\n",
       "          [ 0.9869,  0.9886,  0.9896,  0.9910,  0.9856]],\n",
       "\n",
       "         [[ 0.9977,  0.9957,  0.9966,  0.9978,  0.9971],\n",
       "          [ 0.9909,  0.9928,  0.9915,  0.9905,  0.9906]],\n",
       "\n",
       "         [[ 0.9981,  0.9980,  0.9978,  0.9977,  0.9976],\n",
       "          [ 0.9938,  0.9944,  0.9942,  0.9944,  0.9949]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8943,  0.6545,  0.8941,  0.8909,  0.8223],\n",
       "          [ 0.8701,  0.8028,  0.9144,  0.8512,  0.8279]],\n",
       "\n",
       "         [[ 0.9881,  0.9852,  0.9679,  0.9624,  0.9720],\n",
       "          [ 0.9017,  0.9571,  0.9515,  0.8836,  0.9682]],\n",
       "\n",
       "         [[ 0.9936,  0.9927,  0.9935,  0.9938,  0.9922],\n",
       "          [ 0.9878,  0.9627,  0.9803,  0.9823,  0.9705]],\n",
       "\n",
       "         [[ 0.9963,  0.9955,  0.9958,  0.9955,  0.9952],\n",
       "          [ 0.9880,  0.9892,  0.9896,  0.9910,  0.9853]],\n",
       "\n",
       "         [[ 0.9967,  0.9965,  0.9970,  0.9978,  0.9971],\n",
       "          [ 0.9906,  0.9930,  0.9923,  0.9909,  0.9872]],\n",
       "\n",
       "         [[ 0.9976,  0.9977,  0.9975,  0.9976,  0.9975],\n",
       "          [ 0.9941,  0.9937,  0.9942,  0.9943,  0.9956]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9186,  0.9368,  0.9280,  0.8048,  0.8628],\n",
       "          [ 0.8564,  0.8496,  0.9042,  0.8610,  0.8383]],\n",
       "\n",
       "         [[ 0.9830,  0.9890,  0.9874,  0.9810,  0.9813],\n",
       "          [ 0.9011,  0.9657,  0.9628,  0.9208,  0.9780]],\n",
       "\n",
       "         [[ 0.9933,  0.9945,  0.9942,  0.9952,  0.9906],\n",
       "          [ 0.9879,  0.9862,  0.9779,  0.9829,  0.9778]],\n",
       "\n",
       "         [[ 0.9964,  0.9967,  0.9969,  0.9930,  0.9962],\n",
       "          [ 0.9902,  0.9925,  0.9925,  0.9920,  0.9903]],\n",
       "\n",
       "         [[ 0.9978,  0.9964,  0.9977,  0.9980,  0.9973],\n",
       "          [ 0.9908,  0.9936,  0.9944,  0.9944,  0.9922]],\n",
       "\n",
       "         [[ 0.9982,  0.9982,  0.9978,  0.9978,  0.9979],\n",
       "          [ 0.9958,  0.9954,  0.9956,  0.9947,  0.9957]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8055,  0.7943,  0.8495,  0.7410,  0.8290],\n",
       "          [-0.5147,  0.7064,  0.6844,  0.7600,  0.6917]],\n",
       "\n",
       "         [[ 0.9739,  0.9800,  0.9851,  0.9739,  0.9831],\n",
       "          [ 0.9755,  0.9676,  0.9717,  0.9450,  0.9776]],\n",
       "\n",
       "         [[ 0.9928,  0.9934,  0.9934,  0.9909,  0.9922],\n",
       "          [ 0.9914,  0.9910,  0.9850,  0.9874,  0.9862]],\n",
       "\n",
       "         [[ 0.9949,  0.9957,  0.9958,  0.9951,  0.9943],\n",
       "          [ 0.9937,  0.9944,  0.9950,  0.9960,  0.9925]],\n",
       "\n",
       "         [[ 0.9971,  0.9958,  0.9977,  0.9956,  0.9967],\n",
       "          [ 0.9950,  0.9949,  0.9948,  0.9955,  0.9963]],\n",
       "\n",
       "         [[ 0.9978,  0.9969,  0.9976,  0.9978,  0.9972],\n",
       "          [ 0.9962,  0.9964,  0.9961,  0.9964,  0.9962]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9401,  0.6123,  0.9159,  0.8066,  0.8835],\n",
       "          [ 0.9320,  0.9371,  0.9428,  0.9066,  0.8551]],\n",
       "\n",
       "         [[ 0.9875,  0.9948,  0.9775,  0.9785,  0.9804],\n",
       "          [ 0.9462,  0.9747,  0.9686,  0.9739,  0.9862]],\n",
       "\n",
       "         [[ 0.9946,  0.9960,  0.9961,  0.9958,  0.9937],\n",
       "          [ 0.9936,  0.9878,  0.9883,  0.9861,  0.9858]],\n",
       "\n",
       "         [[ 0.9968,  0.9973,  0.9977,  0.9973,  0.9958],\n",
       "          [ 0.9948,  0.9947,  0.9958,  0.9959,  0.9949]],\n",
       "\n",
       "         [[ 0.9979,  0.9977,  0.9979,  0.9975,  0.9981],\n",
       "          [ 0.9957,  0.9965,  0.9959,  0.9957,  0.9963]],\n",
       "\n",
       "         [[ 0.9986,  0.9985,  0.9984,  0.9983,  0.9982],\n",
       "          [ 0.9964,  0.9967,  0.9973,  0.9967,  0.9973]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9074,  0.9490,  0.9519,  0.9196,  0.8799],\n",
       "          [ 0.9197,  0.9252,  0.8927,  0.9334,  0.8933]],\n",
       "\n",
       "         [[ 0.9919,  0.9953,  0.9940,  0.9925,  0.9908],\n",
       "          [ 0.9795,  0.9831,  0.9881,  0.9868,  0.9895]],\n",
       "\n",
       "         [[ 0.9966,  0.9966,  0.9964,  0.9976,  0.9955],\n",
       "          [ 0.9944,  0.9942,  0.9911,  0.9924,  0.9895]],\n",
       "\n",
       "         [[ 0.9961,  0.9980,  0.9980,  0.9968,  0.9957],\n",
       "          [ 0.9952,  0.9957,  0.9963,  0.9967,  0.9946]],\n",
       "\n",
       "         [[ 0.9984,  0.9981,  0.9982,  0.9976,  0.9984],\n",
       "          [ 0.9966,  0.9965,  0.9955,  0.9963,  0.9965]],\n",
       "\n",
       "         [[ 0.9988,  0.9984,  0.9986,  0.9987,  0.9986],\n",
       "          [ 0.9972,  0.9970,  0.9975,  0.9968,  0.9973]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34c8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e746d_row0_col0, #T_e746d_row0_col1 {\n",
       "  background-color: pink;\n",
       "}\n",
       "#T_e746d_row5_col0, #T_e746d_row6_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e746d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e746d_level0_col0\" class=\"col_heading level0 col0\" >A_TAT</th>\n",
       "      <th id=\"T_e746d_level0_col1\" class=\"col_heading level0 col1\" >V_TAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row0\" class=\"row_heading level0 row0\" >$f_1$</th>\n",
       "      <td id=\"T_e746d_row0_col0\" class=\"data row0 col0\" >0.987944</td>\n",
       "      <td id=\"T_e746d_row0_col1\" class=\"data row0 col1\" >0.978288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row1\" class=\"row_heading level0 row1\" >$f_\\delta$, a=1</th>\n",
       "      <td id=\"T_e746d_row1_col0\" class=\"data row1 col0\" >0.995699</td>\n",
       "      <td id=\"T_e746d_row1_col1\" class=\"data row1 col1\" >0.988347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row2\" class=\"row_heading level0 row2\" >$f_\\delta$, regression a</th>\n",
       "      <td id=\"T_e746d_row2_col0\" class=\"data row2 col0\" >0.995654</td>\n",
       "      <td id=\"T_e746d_row2_col1\" class=\"data row2 col1\" >0.988613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row3\" class=\"row_heading level0 row3\" >$f_\\delta$, learned a</th>\n",
       "      <td id=\"T_e746d_row3_col0\" class=\"data row3 col0\" >0.995839</td>\n",
       "      <td id=\"T_e746d_row3_col1\" class=\"data row3 col1\" >0.991494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row4\" class=\"row_heading level0 row4\" >$f_{\\delta c}$, all</th>\n",
       "      <td id=\"T_e746d_row4_col0\" class=\"data row4 col0\" >0.995177</td>\n",
       "      <td id=\"T_e746d_row4_col1\" class=\"data row4 col1\" >0.994305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row5\" class=\"row_heading level0 row5\" >$f_{\\delta c}$, lasso</th>\n",
       "      <td id=\"T_e746d_row5_col0\" class=\"data row5 col0\" >0.997002</td>\n",
       "      <td id=\"T_e746d_row5_col1\" class=\"data row5 col1\" >0.995219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e746d_level0_row6\" class=\"row_heading level0 row6\" >$f_{\\delta c}$, lasso indicator</th>\n",
       "      <td id=\"T_e746d_row6_col0\" class=\"data row6 col0\" >0.996931</td>\n",
       "      <td id=\"T_e746d_row6_col1\" class=\"data row6 col1\" >0.995699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a7a028d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame((R2[:,3].mean(axis=2)))\n",
    "\n",
    "results.index=['$f_1$','$f_\\delta$, a=1','$f_\\delta$, regression a','$f_\\delta$, learned a','$f_{\\delta c}$, all','$f_{\\delta c}$, lasso','$f_{\\delta c}$, lasso indicator']\n",
    "\n",
    "results.columns=['A_TAT','V_TAT']\n",
    "\n",
    "results.style.highlight_min(color = 'pink', axis = 0).highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df34a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o=0\n",
    "lim=0\n",
    "y_lim=[0.7,1.01]\n",
    "plt.plot(nn[lim:],R2.mean(axis=3)[:,lim:,o].T)\n",
    "plt.ylim(y_lim)\n",
    "plt.legend(['$f_1$','$f_\\delta$, a=1','$f_\\delta$, regression a','$f_\\delta$, learned a','$f_{\\delta c}$, all','$f_{\\delta c}$, lasso','$f_{\\delta c}$, lasso indicator'])\n",
    "for i in range(7):\n",
    "    plt.fill_between(nn[lim:], R2.mean(axis=3)[i,lim:,o]+R2.std(axis=3)[i,lim:,o], R2.mean(axis=3)[i,lim:,o]-R2.std(axis=3)[i,lim:,o],alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2324ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_save = R2.reshape(7,len(nn)*reps*y_train.shape[1])\n",
    "\n",
    "np.savetxt(\"DiscrepR2TrainNVaryDefinitive.csv\", R2_save.detach().numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f45d3",
   "metadata": {},
   "source": [
    "# Atrial Stiffness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "536502d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes=['01','02','03','04','05','06']\n",
    "\n",
    "Ys=[]\n",
    "Xs=[]\n",
    "\n",
    "for i in range(len(meshes)):\n",
    "    val=meshes[i]\n",
    "    \n",
    "    inputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val+\"/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    outputData = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "    \n",
    "\n",
    "    Xs.append(torch.tensor(inputData[0:200]))\n",
    "    Ys.append(torch.tensor(outputData[0:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c07884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_input=[]\n",
    "test_input = []\n",
    "train_output=[]\n",
    "test_output = []\n",
    "emulators=[]\n",
    "\n",
    "for i in range(len(meshes)):\n",
    "\n",
    "    X=Xs[i]\n",
    "    y=Ys[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=seed+i\n",
    "    )\n",
    "    train_input.append(X_train)\n",
    "    test_input.append(X_test)\n",
    "    train_output.append(y_train)\n",
    "    test_output.append(y_test)\n",
    "    emulator = GPE.ensemble(X_train,y_train,mean_func=\"linear\",training_iter=500)\n",
    "    emulators.append(emulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee48433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -9.0876,  -1.7839, -13.9763,  -6.8036,  -5.3839, -28.4096,   0.7142],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.5159,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2980,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-2.3310,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.1354,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.9003,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-4.7392,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1186,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "[0.42850708]\n",
      "[0.16977268]\n",
      "[0.18070077]\n",
      "[0.48470408]\n",
      "[0.06471149]\n",
      "[0.30723889]\n",
      "[0.00915806]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.5460,  0.7232, -0.4243,  0.7317,  0.4467, -0.9929,  0.9197],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.5159,  0.0892,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2980,  0.1193,  0.0000,  0.0000,  0.0000],\n",
      "         [-2.3310, -0.0738,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.1354,  0.1175,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.9003,  0.0718,  0.0000,  0.0000,  0.0000],\n",
      "         [-4.7392, -0.1692,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1186,  0.1523,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "[0.44011486]\n",
      "[0.35291706]\n",
      "[0.31281794]\n",
      "[0.64680969]\n",
      "[0.07741194]\n",
      "[0.17071068]\n",
      "[0.03316094]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-1.1040, -0.8396, -0.2666,  0.5166,  0.1814, -3.6879,  0.8796],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.5159,  0.0892, -0.1893,  0.0000,  0.0000],\n",
      "         [-0.2980,  0.1193, -0.1452,  0.0000,  0.0000],\n",
      "         [-2.3310, -0.0738, -0.0516,  0.0000,  0.0000],\n",
      "         [-1.1354,  0.1175,  0.0817,  0.0000,  0.0000],\n",
      "         [-0.9003,  0.0718,  0.0278,  0.0000,  0.0000],\n",
      "         [-4.7392, -0.1692, -0.6288,  0.0000,  0.0000],\n",
      "         [ 0.1186,  0.1523,  0.1439,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n",
      "[0.64439529]\n",
      "[0.08674326]\n",
      "[0.04759069]\n",
      "[0.66768465]\n",
      "[0.56556691]\n",
      "[0.17467271]\n",
      "[0.21179094]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 2.9886e-02, -9.8268e-01, -7.7263e+00, -8.4969e+01, -2.2269e+00,\n",
      "        -2.5796e+00, -1.3139e-01], dtype=torch.float64,\n",
      "       grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.5159e+00,  8.9238e-02, -1.8929e-01, -3.1074e-04,  0.0000e+00],\n",
      "         [-2.9798e-01,  1.1934e-01, -1.4525e-01, -1.6743e-01,  0.0000e+00],\n",
      "         [-2.3310e+00, -7.3837e-02, -5.1640e-02, -1.2959e+00,  0.0000e+00],\n",
      "         [-1.1354e+00,  1.1755e-01,  8.1675e-02, -1.4165e+01,  0.0000e+00],\n",
      "         [-9.0030e-01,  7.1777e-02,  2.7786e-02, -3.7606e-01,  0.0000e+00],\n",
      "         [-4.7392e+00, -1.6921e-01, -6.2883e-01, -4.3527e-01,  0.0000e+00],\n",
      "         [ 1.1855e-01,  1.5228e-01,  1.4393e-01, -2.3658e-02,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.02861606]\n",
      "[0.00496223]\n",
      "[0.03694755]\n",
      "[0.71150105]\n",
      "[0.03157613]\n",
      "[0.0565942]\n",
      "[0.12495688]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-0.1265,  0.6150, -0.2116,  0.6184, -0.1561, -0.0845,  0.6877],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.5159e+00,  8.9238e-02, -1.8929e-01, -3.1074e-04, -2.8553e-02],\n",
      "         [-2.9798e-01,  1.1934e-01, -1.4525e-01, -1.6743e-01,  8.3507e-02],\n",
      "         [-2.3310e+00, -7.3837e-02, -5.1640e-02, -1.2959e+00, -3.9182e-02],\n",
      "         [-1.1354e+00,  1.1755e-01,  8.1675e-02, -1.4165e+01,  9.0978e-02],\n",
      "         [-9.0030e-01,  7.1777e-02,  2.7786e-02, -3.7606e-01, -3.3002e-02],\n",
      "         [-4.7392e+00, -1.6921e-01, -6.2883e-01, -4.3527e-01, -2.7121e-02],\n",
      "         [ 1.1855e-01,  1.5228e-01,  1.4393e-01, -2.3658e-02,  1.1002e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.07271767]\n",
      "[0.04698787]\n",
      "[0.04238831]\n",
      "[0.74447277]\n",
      "[0.06359182]\n",
      "[0.13098816]\n",
      "[0.18652486]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-0.9011, -0.5603, -1.2820,  0.7567,  0.8196, -3.8143,  0.6895],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.6736e+00,  8.9238e-02, -1.8929e-01, -3.1074e-04, -2.8553e-02],\n",
      "         [-3.9845e-01,  1.1934e-01, -1.4525e-01, -1.6743e-01,  8.3507e-02],\n",
      "         [-2.5616e+00, -7.3837e-02, -5.1640e-02, -1.2959e+00, -3.9182e-02],\n",
      "         [-1.0136e+00,  1.1755e-01,  8.1675e-02, -1.4165e+01,  9.0978e-02],\n",
      "         [-7.7255e-01,  7.1777e-02,  2.7786e-02, -3.7606e-01, -3.3002e-02],\n",
      "         [-5.3844e+00, -1.6921e-01, -6.2883e-01, -4.3527e-01, -2.7121e-02],\n",
      "         [ 2.3120e-01,  1.5228e-01,  1.4393e-01, -2.3658e-02,  1.1002e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.13029052]\n",
      "[0.88796357]\n",
      "[1.04526361]\n",
      "[0.87840017]\n",
      "[0.56479376]\n",
      "[0.71230068]\n",
      "[0.34944377]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.5147, -0.1967,  0.4627,  0.4926,  0.3607, -0.8251,  0.6441],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.6736e+00,  1.6980e-01, -1.8929e-01, -3.1074e-04, -2.8553e-02],\n",
      "         [-3.9845e-01,  8.1723e-02, -1.4525e-01, -1.6743e-01,  8.3507e-02],\n",
      "         [-2.5616e+00, -3.7197e-03, -5.1640e-02, -1.2959e+00, -3.9182e-02],\n",
      "         [-1.0136e+00,  1.9827e-01,  8.1675e-02, -1.4165e+01,  9.0978e-02],\n",
      "         [-7.7255e-01,  1.2487e-01,  2.7786e-02, -3.7606e-01, -3.3002e-02],\n",
      "         [-5.3844e+00, -3.1508e-01, -6.2883e-01, -4.3527e-01, -2.7121e-02],\n",
      "         [ 2.3120e-01,  2.5773e-01,  1.4393e-01, -2.3658e-02,  1.1002e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.02008228]\n",
      "[0.92773732]\n",
      "[0.5248596]\n",
      "[0.97486199]\n",
      "[0.75069551]\n",
      "[0.97609093]\n",
      "[0.56423686]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -3.3725, -27.0962, -12.8221,  -3.0624,  -4.5058,  -1.8377,   0.3056],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.6736e+00,  1.6980e-01, -7.6336e-01, -3.1074e-04, -2.8553e-02],\n",
      "         [-3.9845e-01,  8.1723e-02, -4.6718e+00, -1.6743e-01,  8.3507e-02],\n",
      "         [-2.5616e+00, -3.7197e-03, -2.2151e+00, -1.2959e+00, -3.9182e-02],\n",
      "         [-1.0136e+00,  1.9827e-01, -4.3525e-01, -1.4165e+01,  9.0978e-02],\n",
      "         [-7.7255e-01,  1.2487e-01, -7.3310e-01, -3.7606e-01, -3.3002e-02],\n",
      "         [-5.3844e+00, -3.1508e-01, -9.5026e-01, -4.3527e-01, -2.7121e-02],\n",
      "         [ 2.3120e-01,  2.5773e-01,  1.9112e-01, -2.3658e-02,  1.1002e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.07645264]\n",
      "[0.82026949]\n",
      "[1.0644201]\n",
      "[0.96888561]\n",
      "[0.48250508]\n",
      "[1.02134132]\n",
      "[0.63585567]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -3.9390,  -7.8289, -45.9384,  -9.2830, -11.6866, -23.0289, -14.8757],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.6736e+00,  1.6980e-01, -7.6336e-01, -7.4473e-01, -2.8553e-02],\n",
      "         [-3.9845e-01,  8.1723e-02, -4.6718e+00, -1.6129e+00,  8.3507e-02],\n",
      "         [-2.5616e+00, -3.7197e-03, -2.2151e+00, -9.0295e+00, -3.9182e-02],\n",
      "         [-1.0136e+00,  1.9827e-01, -4.3525e-01, -1.5751e+01,  9.0978e-02],\n",
      "         [-7.7255e-01,  1.2487e-01, -7.3310e-01, -2.3574e+00, -3.3002e-02],\n",
      "         [-5.3844e+00, -3.1508e-01, -9.5026e-01, -4.3203e+00, -2.7121e-02],\n",
      "         [ 2.3120e-01,  2.5773e-01,  1.9112e-01, -2.5165e+00,  1.1002e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.45529429]\n",
      "[1.65206165]\n",
      "[0.40189023]\n",
      "[1.41990188]\n",
      "[0.35982506]\n",
      "[1.27250719]\n",
      "[0.07092059]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-0.0077, -4.5067, -1.4140,  0.6690, -5.5467, -0.7967, -4.5380],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.6736e+00,  1.6980e-01, -7.6336e-01, -7.4473e-01, -3.7971e-02],\n",
      "         [-3.9845e-01,  8.1723e-02, -4.6718e+00, -1.6129e+00, -6.7470e-01],\n",
      "         [-2.5616e+00, -3.7197e-03, -2.2151e+00, -9.0295e+00, -2.9150e-01],\n",
      "         [-1.0136e+00,  1.9827e-01, -4.3525e-01, -1.5751e+01,  1.9450e-01],\n",
      "         [-7.7255e-01,  1.2487e-01, -7.3310e-01, -2.3574e+00, -9.7383e-01],\n",
      "         [-5.3844e+00, -3.1508e-01, -9.5026e-01, -4.3203e+00, -1.7452e-01],\n",
      "         [ 2.3120e-01,  2.5773e-01,  1.9112e-01, -2.5165e+00, -6.4878e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.54948695]\n",
      "[0.1307068]\n",
      "[0.45193608]\n",
      "[1.68455612]\n",
      "[0.571211]\n",
      "[0.52624828]\n",
      "[0.03160185]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-1.8201, -0.8780,  0.0804,  0.5079, -5.1852, -0.5305,  0.0234],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.9893e+00,  1.6980e-01, -7.6336e-01, -7.4473e-01, -3.7971e-02],\n",
      "         [-5.5799e-01,  8.1723e-02, -4.6718e+00, -1.6129e+00, -6.7470e-01],\n",
      "         [-2.5574e+00, -3.7197e-03, -2.2151e+00, -9.0295e+00, -2.9150e-01],\n",
      "         [-9.3094e-01,  1.9827e-01, -4.3525e-01, -1.5751e+01,  1.9450e-01],\n",
      "         [-1.6622e+00,  1.2487e-01, -7.3310e-01, -2.3574e+00, -9.7383e-01],\n",
      "         [-5.5121e+00, -3.1508e-01, -9.5026e-01, -4.3203e+00, -1.7452e-01],\n",
      "         [ 2.2975e-01,  2.5773e-01,  1.9112e-01, -2.5165e+00, -6.4878e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.2223029]\n",
      "[1.03344418]\n",
      "[1.17388989]\n",
      "[1.47676235]\n",
      "[1.14969611]\n",
      "[0.9811797]\n",
      "[0.44833741]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -0.5592,  -0.6650,  -0.0874,   0.5549,  -0.5536, -48.9892,  -0.4980],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9893,   0.0641,  -0.7634,  -0.7447,  -0.0380],\n",
      "         [ -0.5580,  -0.0368,  -4.6718,  -1.6129,  -0.6747],\n",
      "         [ -2.5574,  -0.0292,  -2.2151,  -9.0295,  -0.2915],\n",
      "         [ -0.9309,   0.2890,  -0.4353, -15.7510,   0.1945],\n",
      "         [ -1.6622,   0.0210,  -0.7331,  -2.3574,  -0.9738],\n",
      "         [ -5.5121,  -8.5128,  -0.9503,  -4.3203,  -0.1745],\n",
      "         [  0.2297,   0.1709,   0.1911,  -2.5165,  -0.6488]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.13373025]\n",
      "[1.32248917]\n",
      "[1.11305912]\n",
      "[0.92121302]\n",
      "[1.17055445]\n",
      "[1.04957312]\n",
      "[0.52580177]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-1.4955, -1.4294,  0.1148,  0.2980, -1.3630, -3.6188, -2.2182],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9893,   0.0641,  -1.0452,  -0.7447,  -0.0380],\n",
      "         [ -0.5580,  -0.0368,  -4.9599,  -1.6129,  -0.6747],\n",
      "         [ -2.5574,  -0.0292,  -2.2142,  -9.0295,  -0.2915],\n",
      "         [ -0.9309,   0.2890,  -0.4061, -15.7510,   0.1945],\n",
      "         [ -1.6622,   0.0210,  -0.9823,  -2.3574,  -0.9738],\n",
      "         [ -5.5121,  -8.5128,  -1.5887,  -4.3203,  -0.1745],\n",
      "         [  0.2297,   0.1709,  -0.2005,  -2.5165,  -0.6488]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.9599092]\n",
      "[1.01336825]\n",
      "[0.84972161]\n",
      "[0.96835811]\n",
      "[0.75670898]\n",
      "[0.73550715]\n",
      "[0.27096455]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8759, 0.8812, 0.4617, 0.5173, 0.7389, 0.8296, 0.9020],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9893,   0.0641,  -1.0452,  -0.6012,  -0.0380],\n",
      "         [ -0.5580,  -0.0368,  -4.9599,  -1.4674,  -0.6747],\n",
      "         [ -2.5574,  -0.0292,  -2.2142,  -8.9586,  -0.2915],\n",
      "         [ -0.9309,   0.2890,  -0.4061, -15.6657,   0.1945],\n",
      "         [ -1.6622,   0.0210,  -0.9823,  -2.2393,  -0.9738],\n",
      "         [ -5.5121,  -8.5128,  -1.5887,  -4.1893,  -0.1745],\n",
      "         [  0.2297,   0.1709,  -0.2005,  -2.3671,  -0.6488]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.75894311]\n",
      "[1.19966229]\n",
      "[1.06858971]\n",
      "[0.98402007]\n",
      "[0.76041896]\n",
      "[0.65378435]\n",
      "[0.33374144]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.0101, -2.1094, -5.7402, -2.1136, -1.0794,  0.7227,  0.7524],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9893,   0.0641,  -1.0452,  -0.6012,  -0.0393],\n",
      "         [ -0.5580,  -0.0368,  -4.9599,  -1.4674,  -1.0300],\n",
      "         [ -2.5574,  -0.0292,  -2.2142,  -8.9586,  -1.2533],\n",
      "         [ -0.9309,   0.2890,  -0.4061, -15.6657,  -0.1989],\n",
      "         [ -1.6622,   0.0210,  -0.9823,  -2.2393,  -1.1578],\n",
      "         [ -5.5121,  -8.5128,  -1.5887,  -4.1893,  -0.0557],\n",
      "         [  0.2297,   0.1709,  -0.2005,  -2.3671,  -0.5255]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.02600945]\n",
      "[-0.00712538]\n",
      "[0.0440953]\n",
      "[1.80280321]\n",
      "[0.00164515]\n",
      "[0.07408324]\n",
      "[0.02372122]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.2507, -3.5920, -1.2771, -1.5240, -0.1049,  0.5904, -0.7743],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9530,   0.0641,  -1.0452,  -0.6012,  -0.0393],\n",
      "         [ -1.1628,  -0.0368,  -4.9599,  -1.4674,  -1.0300],\n",
      "         [ -2.7801,  -0.0292,  -2.2142,  -8.9586,  -1.2533],\n",
      "         [ -1.1951,   0.2890,  -0.4061, -15.6657,  -0.1989],\n",
      "         [ -1.6912,   0.0210,  -0.9823,  -2.2393,  -1.1578],\n",
      "         [ -5.4192,  -8.5128,  -1.5887,  -4.1893,  -0.0557],\n",
      "         [  0.0974,   0.1709,  -0.2005,  -2.3671,  -0.5255]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.12159441]\n",
      "[0.03086853]\n",
      "[0.17833149]\n",
      "[0.587976]\n",
      "[0.06118822]\n",
      "[0.1205446]\n",
      "[0.23965024]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -4.4481, -15.6362,  -5.2597,  -7.6927, -10.4462,  -0.7631,  -2.3826],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9530,  -0.6824,  -1.0452,  -0.6012,  -0.0393],\n",
      "         [ -1.1628,  -2.6534,  -4.9599,  -1.4674,  -1.0300],\n",
      "         [ -2.7801,  -0.9098,  -2.2142,  -8.9586,  -1.2533],\n",
      "         [ -1.1951,  -0.9967,  -0.4061, -15.6657,  -0.1989],\n",
      "         [ -1.6912,  -1.7323,  -0.9823,  -2.2393,  -1.1578],\n",
      "         [ -5.4192,  -8.6466,  -1.5887,  -4.1893,  -0.0557],\n",
      "         [  0.0974,  -0.2318,  -0.2005,  -2.3671,  -0.5255]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.093986]\n",
      "[0.19462666]\n",
      "[0.02443466]\n",
      "[0.1126737]\n",
      "[0.02831467]\n",
      "[0.16848996]\n",
      "[0.06810595]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-1.1429e+02, -3.3096e+01, -4.1948e+02, -6.2976e+00,  2.4170e-01,\n",
      "        -4.2526e+01, -5.3397e+01], dtype=torch.float64,\n",
      "       grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.9530e+00, -6.8238e-01, -2.0111e+01, -6.0120e-01, -3.9328e-02],\n",
      "         [-1.1628e+00, -2.6534e+00, -1.0484e+01, -1.4674e+00, -1.0300e+00],\n",
      "         [-2.7801e+00, -9.0976e-01, -7.2283e+01, -8.9586e+00, -1.2533e+00],\n",
      "         [-1.1951e+00, -9.9669e-01, -1.4569e+00, -1.5666e+01, -1.9887e-01],\n",
      "         [-1.6912e+00, -1.7323e+00, -9.4971e-01, -2.2393e+00, -1.1578e+00],\n",
      "         [-5.4192e+00, -8.6466e+00, -8.7190e+00, -4.1893e+00, -5.5703e-02],\n",
      "         [ 9.7369e-02, -2.3182e-01, -9.0961e+00, -2.3671e+00, -5.2546e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.04617866]\n",
      "[0.18357426]\n",
      "[0.00443144]\n",
      "[0.0333105]\n",
      "[0.05584475]\n",
      "[0.03238173]\n",
      "[0.85556338]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.1938, -0.4693,  0.6190,  0.5562,  0.5081,  0.3070,  0.8376],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.9530e+00, -6.8238e-01, -2.0111e+01, -5.9788e-01, -3.9328e-02],\n",
      "         [-1.1628e+00, -2.6534e+00, -1.0484e+01, -1.5772e+00, -1.0300e+00],\n",
      "         [-2.7801e+00, -9.0976e-01, -7.2283e+01, -8.8736e+00, -1.2533e+00],\n",
      "         [-1.1951e+00, -9.9669e-01, -1.4569e+00, -1.5581e+01, -1.9887e-01],\n",
      "         [-1.6912e+00, -1.7323e+00, -9.4971e-01, -2.1775e+00, -1.1578e+00],\n",
      "         [-5.4192e+00, -8.6466e+00, -8.7190e+00, -4.1631e+00, -5.5703e-02],\n",
      "         [ 9.7369e-02, -2.3182e-01, -9.0961e+00, -2.2306e+00, -5.2546e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.04022648]\n",
      "[0.01869117]\n",
      "[0.06738706]\n",
      "[0.35855708]\n",
      "[0.02742423]\n",
      "[0.07474823]\n",
      "[0.1309245]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -2.1043,  -1.4666,  -2.1456, -13.0647,  -4.6588,  -3.6519,  -5.0345],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.9530,  -0.6824, -20.1109,  -0.5979,  -0.3950],\n",
      "         [ -1.1628,  -2.6534, -10.4843,  -1.5772,  -1.2840],\n",
      "         [ -2.7801,  -0.9098, -72.2828,  -8.8736,  -1.6200],\n",
      "         [ -1.1951,  -0.9967,  -1.4569, -15.5815,  -2.3964],\n",
      "         [ -1.6912,  -1.7323,  -0.9497,  -2.1775,  -1.9525],\n",
      "         [ -5.4192,  -8.6466,  -8.7190,  -4.1631,  -0.6713],\n",
      "         [  0.0974,  -0.2318,  -9.0961,  -2.2306,  -1.3710]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.02837794]\n",
      "[-0.01931925]\n",
      "[0.02790187]\n",
      "[0.28639597]\n",
      "[0.00327114]\n",
      "[0.14100475]\n",
      "[0.09565693]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.7856, -0.1464, -0.4788, -0.4424,  0.6392,  0.4986,  0.8500],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.8233,  -0.6824, -20.1109,  -0.5979,  -0.3950],\n",
      "         [ -1.1877,  -2.6534, -10.4843,  -1.5772,  -1.2840],\n",
      "         [ -2.8644,  -0.9098, -72.2828,  -8.8736,  -1.6200],\n",
      "         [ -1.2723,  -0.9967,  -1.4569, -15.5815,  -2.3964],\n",
      "         [ -1.5888,  -1.7323,  -0.9497,  -2.1775,  -1.9525],\n",
      "         [ -5.3403,  -8.6466,  -8.7190,  -4.1631,  -0.6713],\n",
      "         [  0.2379,  -0.2318,  -9.0961,  -2.2306,  -1.3710]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.37187161]\n",
      "[0.14164157]\n",
      "[0.11595056]\n",
      "[0.44432908]\n",
      "[0.03590506]\n",
      "[0.44437426]\n",
      "[0.0212642]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-3.5449, -3.9422, -6.4219, -0.1840, -0.7939, -2.9104,  0.2943],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.8233,  -1.3061, -20.1109,  -0.5979,  -0.3950],\n",
      "         [ -1.1877,  -3.3354, -10.4843,  -1.5772,  -1.2840],\n",
      "         [ -2.8644,  -2.0310, -72.2828,  -8.8736,  -1.6200],\n",
      "         [ -1.2723,  -1.0388,  -1.4569, -15.5815,  -2.3964],\n",
      "         [ -1.5888,  -1.8891,  -0.9497,  -2.1775,  -1.9525],\n",
      "         [ -5.3403,  -9.1803,  -8.7190,  -4.1631,  -0.6713],\n",
      "         [  0.2379,  -0.1890,  -9.0961,  -2.2306,  -1.3710]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.0870387]\n",
      "[0.09508985]\n",
      "[0.11081348]\n",
      "[0.53238232]\n",
      "[1.89823918]\n",
      "[1.70403277]\n",
      "[0.25674953]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.0134,  0.4340, -3.0033, -1.6794, -0.3272,  0.4908,  0.9357],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.8233,  -1.3061, -20.1128,  -0.5979,  -0.3950],\n",
      "         [ -1.1877,  -3.3354, -10.4144,  -1.5772,  -1.2840],\n",
      "         [ -2.8644,  -2.0310, -72.7936,  -8.8736,  -1.6200],\n",
      "         [ -1.2723,  -1.0388,  -1.7385, -15.5815,  -2.3964],\n",
      "         [ -1.5888,  -1.8891,  -1.0156,  -2.1775,  -1.9525],\n",
      "         [ -5.3403,  -9.1803,  -8.6396,  -4.1631,  -0.6713],\n",
      "         [  0.2379,  -0.1890,  -8.9415,  -2.2306,  -1.3710]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.44508698]\n",
      "[0.08639242]\n",
      "[0.22692524]\n",
      "[0.48468619]\n",
      "[0.32815288]\n",
      "[0.21465635]\n",
      "[0.03568206]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -6.7260,   0.3728,  -2.8444,   0.5183,  -6.7835, -80.8901,  -2.4390],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.8233,  -1.3061, -20.1128,  -1.7299,  -0.3950],\n",
      "         [ -1.1877,  -3.3354, -10.4144,  -1.5197,  -1.2840],\n",
      "         [ -2.8644,  -2.0310, -72.7936,  -9.3572,  -1.6200],\n",
      "         [ -1.2723,  -1.0388,  -1.7385, -15.4982,  -2.3964],\n",
      "         [ -1.5888,  -1.8891,  -1.0156,  -3.3190,  -1.9525],\n",
      "         [ -5.3403,  -9.1803,  -8.6396, -17.6866,  -0.6713],\n",
      "         [  0.2379,  -0.1890,  -8.9415,  -2.6413,  -1.3710]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.24969766]\n",
      "[0.05726541]\n",
      "[0.0794225]\n",
      "[0.2864663]\n",
      "[1.93992311]\n",
      "[1.17877238]\n",
      "[0.26881902]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.2933,  0.1265, -3.6262, -2.7459, -5.8919, -0.6997,  0.4026],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.8233,  -1.3061, -20.1128,  -1.7299,  -0.3805],\n",
      "         [ -1.1877,  -3.3354, -10.4144,  -1.5197,  -1.2777],\n",
      "         [ -2.8644,  -2.0310, -72.7936,  -9.3572,  -2.3357],\n",
      "         [ -1.2723,  -1.0388,  -1.7385, -15.4982,  -2.8747],\n",
      "         [ -1.5888,  -1.8891,  -1.0156,  -3.3190,  -2.9550],\n",
      "         [ -5.3403,  -9.1803,  -8.6396, -17.6866,  -0.8475],\n",
      "         [  0.2379,  -0.1890,  -8.9415,  -2.6413,  -1.3194]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.51690834]\n",
      "[0.32208738]\n",
      "[0.26289084]\n",
      "[0.5283942]\n",
      "[0.19525998]\n",
      "[0.49129982]\n",
      "[0.1694067]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6805,  0.4406, -0.3171,  0.8583, -9.5466, -1.4022,  0.6088],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.3061, -20.1128,  -1.7299,  -0.3805],\n",
      "         [ -1.1192,  -3.3354, -10.4144,  -1.5197,  -1.2777],\n",
      "         [ -2.9225,  -2.0310, -72.7936,  -9.3572,  -2.3357],\n",
      "         [ -1.1343,  -1.0388,  -1.7385, -15.4982,  -2.8747],\n",
      "         [ -3.1955,  -1.8891,  -1.0156,  -3.3190,  -2.9550],\n",
      "         [ -5.5799,  -9.1803,  -8.6396, -17.6866,  -0.8475],\n",
      "         [  0.3381,  -0.1890,  -8.9415,  -2.6413,  -1.3194]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.16722734]\n",
      "[1.01227756]\n",
      "[0.70057038]\n",
      "[1.06654775]\n",
      "[0.39109629]\n",
      "[0.60871071]\n",
      "[0.01950765]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.7626,  0.6268, -0.0332,  0.3281, -4.1906, -1.2206,  0.2983],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.1128,  -1.7299,  -0.3805],\n",
      "         [ -1.1192,  -3.2352, -10.4144,  -1.5197,  -1.2777],\n",
      "         [ -2.9225,  -2.0566, -72.7936,  -9.3572,  -2.3357],\n",
      "         [ -1.1343,  -0.9854,  -1.7385, -15.4982,  -2.8747],\n",
      "         [ -3.1955,  -2.6328,  -1.0156,  -3.3190,  -2.9550],\n",
      "         [ -5.5799,  -9.3941,  -8.6396, -17.6866,  -0.8475],\n",
      "         [  0.3381,  -0.1431,  -8.9415,  -2.6413,  -1.3194]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.89446774]\n",
      "[1.0803753]\n",
      "[0.90863949]\n",
      "[0.78449876]\n",
      "[1.19923744]\n",
      "[1.01769571]\n",
      "[0.82837117]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -5.2869,  -2.6783,  -6.1776,  -1.6678,  -0.3701, -24.8489,  -4.3627],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -1.7299,  -0.3805],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.5197,  -1.2777],\n",
      "         [ -2.9225,  -2.0566, -73.8253,  -9.3572,  -2.3357],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -15.4982,  -2.8747],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -3.3190,  -2.9550],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.6866,  -0.8475],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -2.6413,  -1.3194]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.80224752]\n",
      "[0.82240349]\n",
      "[0.40737712]\n",
      "[0.61016257]\n",
      "[0.84480228]\n",
      "[0.87678608]\n",
      "[0.49163966]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ -8.1717,  -0.6281, -31.2821,  -7.4206,  -5.4186,  -1.7935,  -3.8388],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -0.3805],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.2777],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -2.3357],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -2.8747],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9550],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -0.8475],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.3194]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.79953251]\n",
      "[0.93108516]\n",
      "[0.33224576]\n",
      "[0.97285615]\n",
      "[0.61338463]\n",
      "[0.79583521]\n",
      "[0.33812692]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([-6.7244, -0.9733, -5.6126, -1.5493, -0.0678, -4.6641, -0.8753],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.06753412]\n",
      "[-0.00210624]\n",
      "[0.12207116]\n",
      "[1.73398405]\n",
      "[-0.00217742]\n",
      "[0.08100743]\n",
      "[0.09760005]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8407, 0.8562, 0.8567, 0.8610, 0.6903, 0.6076, 0.9493],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.1365,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1396,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1344,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1378,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1128,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0884,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1567,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.48678024]\n",
      "[0.02027401]\n",
      "[0.04018183]\n",
      "[0.8352402]\n",
      "[0.31689832]\n",
      "[0.04516649]\n",
      "[0.11265719]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7549, 0.4645, 0.7203, 0.8640, 0.6839, 0.7537, 0.9336],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.1365,   0.1224,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1396,   0.0748,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1344,   0.1160,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1378,   0.1406,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1128,   0.1114,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0884,   0.1194,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1567,   0.1537,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.02988786]\n",
      "[0.01539893]\n",
      "[0.02362704]\n",
      "[0.14436269]\n",
      "[0.03109449]\n",
      "[0.08020165]\n",
      "[0.09087409]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.3667,  0.4313,  0.2338,  0.5438,  0.5501, -0.2800,  0.9027],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 1.3647e-01,  1.2243e-01,  4.4471e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3964e-01,  7.4815e-02,  4.4581e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3443e-01,  1.1603e-01, -5.1384e-03,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3778e-01,  1.4057e-01,  5.8175e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1284e-01,  1.1141e-01,  7.3503e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 8.8413e-02,  1.1937e-01, -7.4798e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.5669e-01,  1.5369e-01,  1.4673e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.08993642]\n",
      "[0.0593278]\n",
      "[0.07933902]\n",
      "[0.72921224]\n",
      "[0.03813742]\n",
      "[0.14108795]\n",
      "[0.20134647]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8749, 0.7657, 0.8487, 0.9103, 0.7130, 0.7869, 0.9638],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 1.3647e-01,  1.2243e-01,  4.4471e-02,  1.3846e-01,  0.0000e+00],\n",
      "         [ 1.3964e-01,  7.4815e-02,  4.4581e-02,  1.1398e-01,  0.0000e+00],\n",
      "         [ 1.3443e-01,  1.1603e-01, -5.1384e-03,  1.3440e-01,  0.0000e+00],\n",
      "         [ 1.3778e-01,  1.4057e-01,  5.8175e-02,  1.4664e-01,  0.0000e+00],\n",
      "         [ 1.1284e-01,  1.1141e-01,  7.3503e-02,  1.1276e-01,  0.0000e+00],\n",
      "         [ 8.8413e-02,  1.1937e-01, -7.4798e-02,  1.1775e-01,  0.0000e+00],\n",
      "         [ 1.5669e-01,  1.5369e-01,  1.4673e-01,  1.5928e-01,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.48877575]\n",
      "[0.28176903]\n",
      "[0.33036919]\n",
      "[0.64979236]\n",
      "[0.06505375]\n",
      "[0.33640006]\n",
      "[0.02875275]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7660, 0.7687, 0.5146, 0.7317, 0.6976, 0.7185, 0.9459],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 1.3647e-01,  1.2243e-01,  4.4471e-02,  1.3846e-01,  1.1880e-01],\n",
      "         [ 1.3964e-01,  7.4815e-02,  4.4581e-02,  1.1398e-01,  1.1427e-01],\n",
      "         [ 1.3443e-01,  1.1603e-01, -5.1384e-03,  1.3440e-01,  7.7610e-02],\n",
      "         [ 1.3778e-01,  1.4057e-01,  5.8175e-02,  1.4664e-01,  1.0748e-01],\n",
      "         [ 1.1284e-01,  1.1141e-01,  7.3503e-02,  1.1276e-01,  1.0674e-01],\n",
      "         [ 8.8413e-02,  1.1937e-01, -7.4798e-02,  1.1775e-01,  9.9964e-02],\n",
      "         [ 1.5669e-01,  1.5369e-01,  1.4673e-01,  1.5928e-01,  1.5447e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.06462405]\n",
      "[0.02361037]\n",
      "[0.06712862]\n",
      "[0.81683831]\n",
      "[0.02210141]\n",
      "[0.10578768]\n",
      "[0.13772177]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.8296,  0.9020, -0.7002,  0.8115,  0.5256,  0.6164,  0.9526],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 2.6966e-01,  1.2243e-01,  4.4471e-02,  1.3846e-01,  1.1880e-01],\n",
      "         [ 2.8038e-01,  7.4815e-02,  4.4581e-02,  1.1398e-01,  1.1427e-01],\n",
      "         [-3.2841e-03,  1.1603e-01, -5.1384e-03,  1.3440e-01,  7.7610e-02],\n",
      "         [ 2.7086e-01,  1.4057e-01,  5.8175e-02,  1.4664e-01,  1.0748e-01],\n",
      "         [ 1.7148e-01,  1.1141e-01,  7.3503e-02,  1.1276e-01,  1.0674e-01],\n",
      "         [ 1.8011e-01,  1.1937e-01, -7.4798e-02,  1.1775e-01,  9.9964e-02],\n",
      "         [ 3.1440e-01,  1.5369e-01,  1.4673e-01,  1.5928e-01,  1.5447e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.26103902]\n",
      "[0.10827204]\n",
      "[0.58715234]\n",
      "[1.69695888]\n",
      "[0.23418756]\n",
      "[0.95062301]\n",
      "[0.04678736]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7548, 0.4550, 0.7461, 0.6447, 0.7267, 0.5476, 0.8277],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 2.6966e-01,  2.3537e-01,  4.4471e-02,  1.3846e-01,  1.1880e-01],\n",
      "         [ 2.8038e-01,  1.3773e-01,  4.4581e-02,  1.1398e-01,  1.1427e-01],\n",
      "         [-3.2841e-03,  2.2478e-01, -5.1384e-03,  1.3440e-01,  7.7610e-02],\n",
      "         [ 2.7086e-01,  2.1950e-01,  5.8175e-02,  1.4664e-01,  1.0748e-01],\n",
      "         [ 1.7148e-01,  2.1585e-01,  7.3503e-02,  1.1276e-01,  1.0674e-01],\n",
      "         [ 1.8011e-01,  1.8685e-01, -7.4798e-02,  1.1775e-01,  9.9964e-02],\n",
      "         [ 3.1440e-01,  2.8409e-01,  1.4673e-01,  1.5928e-01,  1.5447e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.04337353]\n",
      "[0.02727942]\n",
      "[0.02011746]\n",
      "[0.52408721]\n",
      "[0.00855577]\n",
      "[0.15192741]\n",
      "[0.06487831]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.0781,  0.3257, -0.0357,  0.7626,  0.2667, -0.5539,  0.7664],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 2.6966e-01,  2.3537e-01,  3.3457e-02,  1.3846e-01,  1.1880e-01],\n",
      "         [ 2.8038e-01,  1.3773e-01,  8.0757e-02,  1.1398e-01,  1.1427e-01],\n",
      "         [-3.2841e-03,  2.2478e-01, -4.7600e-02,  1.3440e-01,  7.7610e-02],\n",
      "         [ 2.7086e-01,  2.1950e-01,  1.6940e-01,  1.4664e-01,  1.0748e-01],\n",
      "         [ 1.7148e-01,  2.1585e-01,  8.9606e-02,  1.1276e-01,  1.0674e-01],\n",
      "         [ 1.8011e-01,  1.8685e-01, -2.6397e-01,  1.1775e-01,  9.9964e-02],\n",
      "         [ 3.1440e-01,  2.8409e-01,  2.6808e-01,  1.5928e-01,  1.5447e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[2.09295063]\n",
      "[1.18465052]\n",
      "[0.65564006]\n",
      "[1.70624804]\n",
      "[0.48156195]\n",
      "[0.94541316]\n",
      "[0.03833585]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.4250,  0.6683,  0.1773,  0.8247, -0.6545,  0.2295,  0.8998],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 2.6966e-01,  2.3537e-01,  3.3457e-02,  1.5817e-01,  1.1880e-01],\n",
      "         [ 2.8038e-01,  1.3773e-01,  8.0757e-02,  1.8391e-01,  1.1427e-01],\n",
      "         [-3.2841e-03,  2.2478e-01, -4.7600e-02,  1.0439e-01,  7.7610e-02],\n",
      "         [ 2.7086e-01,  2.1950e-01,  1.6940e-01,  2.7009e-01,  1.0748e-01],\n",
      "         [ 1.7148e-01,  2.1585e-01,  8.9606e-02, -6.9823e-02,  1.0674e-01],\n",
      "         [ 1.8011e-01,  1.8685e-01, -2.6397e-01,  1.3101e-01,  9.9964e-02],\n",
      "         [ 3.1440e-01,  2.8409e-01,  2.6808e-01,  2.9374e-01,  1.5447e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.69875276]\n",
      "[1.60643547]\n",
      "[0.67117455]\n",
      "[1.59227076]\n",
      "[0.51694791]\n",
      "[0.78852496]\n",
      "[0.04686707]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6968, 0.7176, 0.6032, 0.7515, 0.6070, 0.5912, 0.9045],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 2.6966e-01,  2.3537e-01,  3.3457e-02,  1.5817e-01,  2.2860e-01],\n",
      "         [ 2.8038e-01,  1.3773e-01,  8.0757e-02,  1.8391e-01,  2.3139e-01],\n",
      "         [-3.2841e-03,  2.2478e-01, -4.7600e-02,  1.0439e-01,  1.5891e-01],\n",
      "         [ 2.7086e-01,  2.1950e-01,  1.6940e-01,  2.7009e-01,  2.2826e-01],\n",
      "         [ 1.7148e-01,  2.1585e-01,  8.9606e-02, -6.9823e-02,  1.9659e-01],\n",
      "         [ 1.8011e-01,  1.8685e-01, -2.6397e-01,  1.3101e-01,  1.8450e-01],\n",
      "         [ 3.1440e-01,  2.8409e-01,  2.6808e-01,  2.9374e-01,  3.0310e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.83003266]\n",
      "[0.71995571]\n",
      "[0.61962114]\n",
      "[0.94127292]\n",
      "[0.51911389]\n",
      "[0.46526092]\n",
      "[0.24697493]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8382, 0.6012, 0.6842, 0.7191, 0.7742, 0.6989, 0.9555],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0517e-01,  2.3537e-01,  3.3457e-02,  1.5817e-01,  2.2860e-01],\n",
      "         [ 3.7544e-01,  1.3773e-01,  8.0757e-02,  1.8391e-01,  2.3139e-01],\n",
      "         [ 1.0124e-01,  2.2478e-01, -4.7600e-02,  1.0439e-01,  1.5891e-01],\n",
      "         [ 3.8276e-01,  2.1950e-01,  1.6940e-01,  2.7009e-01,  2.2826e-01],\n",
      "         [ 2.9787e-01,  2.1585e-01,  8.9606e-02, -6.9823e-02,  1.9659e-01],\n",
      "         [ 2.8277e-01,  1.8685e-01, -2.6397e-01,  1.3101e-01,  1.8450e-01],\n",
      "         [ 4.7174e-01,  2.8409e-01,  2.6808e-01,  2.9374e-01,  3.0310e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.23707335]\n",
      "[0.10378951]\n",
      "[0.37566919]\n",
      "[1.41906959]\n",
      "[0.13401207]\n",
      "[0.77640194]\n",
      "[0.03246373]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8923, 0.8154, 0.8694, 0.9536, 0.6640, 0.8303, 0.9440],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0517e-01,  3.7885e-01,  3.3457e-02,  1.5817e-01,  2.2860e-01],\n",
      "         [ 3.7544e-01,  2.6410e-01,  8.0757e-02,  1.8391e-01,  2.3139e-01],\n",
      "         [ 1.0124e-01,  3.6795e-01, -4.7600e-02,  1.0439e-01,  1.5891e-01],\n",
      "         [ 3.8276e-01,  3.7623e-01,  1.6940e-01,  2.7009e-01,  2.2826e-01],\n",
      "         [ 2.9787e-01,  3.1166e-01,  8.9606e-02, -6.9823e-02,  1.9659e-01],\n",
      "         [ 2.8277e-01,  3.1650e-01, -2.6397e-01,  1.3101e-01,  1.8450e-01],\n",
      "         [ 4.7174e-01,  4.3976e-01,  2.6808e-01,  2.9374e-01,  3.0310e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.57861342]\n",
      "[0.91600027]\n",
      "[0.25470186]\n",
      "[1.01955743]\n",
      "[0.22283571]\n",
      "[0.67522717]\n",
      "[0.0132134]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9437, 0.9495, 0.6459, 0.8545, 0.3448, 0.7684, 0.9483],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0517e-01,  3.7885e-01,  1.8725e-01,  1.5817e-01,  2.2860e-01],\n",
      "         [ 3.7544e-01,  2.6410e-01,  2.3618e-01,  1.8391e-01,  2.3139e-01],\n",
      "         [ 1.0124e-01,  3.6795e-01,  4.7080e-02,  1.0439e-01,  1.5891e-01],\n",
      "         [ 3.8276e-01,  3.7623e-01,  3.0460e-01,  2.7009e-01,  2.2826e-01],\n",
      "         [ 2.9787e-01,  3.1166e-01,  1.1607e-01, -6.9823e-02,  1.9659e-01],\n",
      "         [ 2.8277e-01,  3.1650e-01, -1.5410e-01,  1.3101e-01,  1.8450e-01],\n",
      "         [ 4.7174e-01,  4.3976e-01,  4.2270e-01,  2.9374e-01,  3.0310e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.88341227]\n",
      "[0.99833322]\n",
      "[0.73622344]\n",
      "[0.95410813]\n",
      "[1.02881117]\n",
      "[1.0145263]\n",
      "[0.4934236]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8307, 0.1125, 0.6815, 0.8036, 0.3758, 0.7595, 0.9240],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0517e-01,  3.7885e-01,  1.8725e-01,  2.8369e-01,  2.2860e-01],\n",
      "         [ 3.7544e-01,  2.6410e-01,  2.3618e-01,  1.7121e-01,  2.3139e-01],\n",
      "         [ 1.0124e-01,  3.6795e-01,  4.7080e-02,  2.0329e-01,  1.5891e-01],\n",
      "         [ 3.8276e-01,  3.7623e-01,  3.0460e-01,  3.8475e-01,  2.2826e-01],\n",
      "         [ 2.9787e-01,  3.1166e-01,  1.1607e-01, -1.9391e-02,  1.9659e-01],\n",
      "         [ 2.8277e-01,  3.1650e-01, -1.5410e-01,  2.4041e-01,  1.8450e-01],\n",
      "         [ 4.7174e-01,  4.3976e-01,  4.2270e-01,  4.4218e-01,  3.0310e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.08075962]\n",
      "[0.04321774]\n",
      "[0.03718721]\n",
      "[1.5052973]\n",
      "[0.02310004]\n",
      "[0.22014848]\n",
      "[0.02568086]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6981, 0.6090, 0.9006, 0.8804, 0.7662, 0.6590, 0.8878],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0517e-01,  3.7885e-01,  1.8725e-01,  2.8369e-01,  3.2987e-01],\n",
      "         [ 3.7544e-01,  2.6410e-01,  2.3618e-01,  1.7121e-01,  3.2470e-01],\n",
      "         [ 1.0124e-01,  3.6795e-01,  4.7080e-02,  2.0329e-01,  2.9649e-01],\n",
      "         [ 3.8276e-01,  3.7623e-01,  3.0460e-01,  3.8475e-01,  3.6533e-01],\n",
      "         [ 2.9787e-01,  3.1166e-01,  1.1607e-01, -1.9391e-02,  3.1390e-01],\n",
      "         [ 2.8277e-01,  3.1650e-01, -1.5410e-01,  2.4041e-01,  2.7867e-01],\n",
      "         [ 4.7174e-01,  4.3976e-01,  4.2270e-01,  4.4218e-01,  4.4730e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.82060382]\n",
      "[1.41383176]\n",
      "[0.8076784]\n",
      "[1.53998309]\n",
      "[0.17211368]\n",
      "[0.56394629]\n",
      "[0.02078767]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.1684,  0.6066, -0.7596,  0.5446,  0.6013, -0.7934,  0.9494],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0990e-01,  3.7885e-01,  1.8725e-01,  2.8369e-01,  3.2987e-01],\n",
      "         [ 4.4917e-01,  2.6410e-01,  2.3618e-01,  1.7121e-01,  3.2470e-01],\n",
      "         [-6.1993e-02,  3.6795e-01,  4.7080e-02,  2.0329e-01,  2.9649e-01],\n",
      "         [ 4.5284e-01,  3.7623e-01,  3.0460e-01,  3.8475e-01,  3.6533e-01],\n",
      "         [ 3.9020e-01,  3.1166e-01,  1.1607e-01, -1.9391e-02,  3.1390e-01],\n",
      "         [ 1.2561e-01,  3.1650e-01, -1.5410e-01,  2.4041e-01,  2.7867e-01],\n",
      "         [ 6.2812e-01,  4.3976e-01,  4.2270e-01,  4.4218e-01,  4.4730e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.04141875]\n",
      "[0.10675017]\n",
      "[0.01571136]\n",
      "[0.24378251]\n",
      "[0.03251447]\n",
      "[0.02379043]\n",
      "[0.88771597]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.5111, 0.6064, 0.4446, 0.5019, 0.6149, 0.5240, 0.9459],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0990e-01,  4.4555e-01,  1.8725e-01,  2.8369e-01,  3.2987e-01],\n",
      "         [ 4.4917e-01,  3.4504e-01,  2.3618e-01,  1.7121e-01,  3.2470e-01],\n",
      "         [-6.1993e-02,  4.3197e-01,  4.7080e-02,  2.0329e-01,  2.9649e-01],\n",
      "         [ 4.5284e-01,  4.4103e-01,  3.0460e-01,  3.8475e-01,  3.6533e-01],\n",
      "         [ 3.9020e-01,  4.0261e-01,  1.1607e-01, -1.9391e-02,  3.1390e-01],\n",
      "         [ 1.2561e-01,  3.8834e-01, -1.5410e-01,  2.4041e-01,  2.7867e-01],\n",
      "         [ 6.2812e-01,  5.9563e-01,  4.2270e-01,  4.4218e-01,  4.4730e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.05137508]\n",
      "[0.02211621]\n",
      "[0.05135512]\n",
      "[0.33266055]\n",
      "[0.00455116]\n",
      "[0.07750037]\n",
      "[0.13797808]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.2987, 0.8613, 0.4983, 0.7361, 0.5682, 0.2564, 0.9723],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0990e-01,  4.4555e-01,  2.2406e-01,  2.8369e-01,  3.2987e-01],\n",
      "         [ 4.4917e-01,  3.4504e-01,  3.6306e-01,  1.7121e-01,  3.2470e-01],\n",
      "         [-6.1993e-02,  4.3197e-01,  9.6470e-02,  2.0329e-01,  2.9649e-01],\n",
      "         [ 4.5284e-01,  4.4103e-01,  4.1571e-01,  3.8475e-01,  3.6533e-01],\n",
      "         [ 3.9020e-01,  4.0261e-01,  1.9738e-01, -1.9391e-02,  3.1390e-01],\n",
      "         [ 1.2561e-01,  3.8834e-01, -1.7137e-01,  2.4041e-01,  2.7867e-01],\n",
      "         [ 6.2812e-01,  5.9563e-01,  5.8261e-01,  4.4218e-01,  4.4730e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.07082808]\n",
      "[0.20255007]\n",
      "[0.01985003]\n",
      "[0.45526603]\n",
      "[0.03528001]\n",
      "[0.00630587]\n",
      "[0.96372545]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6672, -0.0646,  0.5902,  0.7543,  0.8379,  0.7791,  0.8015],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0990e-01,  4.4555e-01,  2.2406e-01,  3.7162e-01,  3.2987e-01],\n",
      "         [ 4.4917e-01,  3.4504e-01,  3.6306e-01,  7.6302e-02,  3.2470e-01],\n",
      "         [-6.1993e-02,  4.3197e-01,  9.6470e-02,  2.8790e-01,  2.9649e-01],\n",
      "         [ 4.5284e-01,  4.4103e-01,  4.1571e-01,  5.0056e-01,  3.6533e-01],\n",
      "         [ 3.9020e-01,  4.0261e-01,  1.9738e-01,  1.0706e-01,  3.1390e-01],\n",
      "         [ 1.2561e-01,  3.8834e-01, -1.7137e-01,  3.5075e-01,  2.7867e-01],\n",
      "         [ 6.2812e-01,  5.9563e-01,  5.8261e-01,  5.6287e-01,  4.4730e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.12248166]\n",
      "[0.14522436]\n",
      "[0.05182291]\n",
      "[0.25815277]\n",
      "[0.0280159]\n",
      "[0.32991433]\n",
      "[0.05299037]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6561,  0.7694,  0.5410, -0.3339,  0.5072,  0.4655,  0.9534],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 4.0990e-01,  4.4555e-01,  2.2406e-01,  3.7162e-01,  4.2975e-01],\n",
      "         [ 4.4917e-01,  3.4504e-01,  3.6306e-01,  7.6302e-02,  4.4281e-01],\n",
      "         [-6.1993e-02,  4.3197e-01,  9.6470e-02,  2.8790e-01,  3.6956e-01],\n",
      "         [ 4.5284e-01,  4.4103e-01,  4.1571e-01,  5.0056e-01,  2.8579e-01],\n",
      "         [ 3.9020e-01,  4.0261e-01,  1.9738e-01,  1.0706e-01,  3.7616e-01],\n",
      "         [ 1.2561e-01,  3.8834e-01, -1.7137e-01,  3.5075e-01,  3.3729e-01],\n",
      "         [ 6.2812e-01,  5.9563e-01,  5.8261e-01,  5.6287e-01,  6.0314e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.09488247]\n",
      "[0.01692163]\n",
      "[0.08421654]\n",
      "[0.41055438]\n",
      "[0.01690857]\n",
      "[0.20595028]\n",
      "[0.09394705]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7798, 0.8675, 0.5377, 0.6201, 0.6789, 0.7009, 0.9577],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 5.2571e-01,  4.4555e-01,  2.2406e-01,  3.7162e-01,  4.2975e-01],\n",
      "         [ 5.8241e-01,  3.4504e-01,  3.6306e-01,  7.6302e-02,  4.4281e-01],\n",
      "         [-9.4632e-03,  4.3197e-01,  9.6470e-02,  2.8790e-01,  3.6956e-01],\n",
      "         [ 5.4544e-01,  4.4103e-01,  4.1571e-01,  5.0056e-01,  2.8579e-01],\n",
      "         [ 4.8687e-01,  4.0261e-01,  1.9738e-01,  1.0706e-01,  3.7616e-01],\n",
      "         [ 2.2615e-01,  3.8834e-01, -1.7137e-01,  3.5075e-01,  3.3729e-01],\n",
      "         [ 7.8415e-01,  5.9563e-01,  5.8261e-01,  5.6287e-01,  6.0314e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.09812788]\n",
      "[0.25023948]\n",
      "[0.01823575]\n",
      "[0.3286931]\n",
      "[0.09067584]\n",
      "[0.10988243]\n",
      "[0.82384686]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8174, 0.7679, 0.0915, 0.7960, 0.6468, 0.5616, 0.8881],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 5.2571e-01,  5.7165e-01,  2.2406e-01,  3.7162e-01,  4.2975e-01],\n",
      "         [ 5.8241e-01,  4.5116e-01,  3.6306e-01,  7.6302e-02,  4.4281e-01],\n",
      "         [-9.4632e-03,  3.9527e-01,  9.6470e-02,  2.8790e-01,  3.6956e-01],\n",
      "         [ 5.4544e-01,  5.6237e-01,  4.1571e-01,  5.0056e-01,  2.8579e-01],\n",
      "         [ 4.8687e-01,  4.9784e-01,  1.9738e-01,  1.0706e-01,  3.7616e-01],\n",
      "         [ 2.2615e-01,  4.6219e-01, -1.7137e-01,  3.5075e-01,  3.3729e-01],\n",
      "         [ 7.8415e-01,  7.3988e-01,  5.8261e-01,  5.6287e-01,  6.0314e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.09028549]\n",
      "[0.12490922]\n",
      "[0.18185536]\n",
      "[0.56804216]\n",
      "[1.76755795]\n",
      "[1.18830307]\n",
      "[0.33671865]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6760,  0.8462, -1.7127,  0.8133,  0.8059, -0.0206,  0.9167],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 5.2571e-01,  5.7165e-01,  3.2971e-01,  3.7162e-01,  4.2975e-01],\n",
      "         [ 5.8241e-01,  4.5116e-01,  4.8956e-01,  7.6302e-02,  4.4281e-01],\n",
      "         [-9.4632e-03,  3.9527e-01, -3.2967e-01,  2.8790e-01,  3.6956e-01],\n",
      "         [ 5.4544e-01,  5.6237e-01,  5.4350e-01,  5.0056e-01,  2.8579e-01],\n",
      "         [ 4.8687e-01,  4.9784e-01,  3.1981e-01,  1.0706e-01,  3.7616e-01],\n",
      "         [ 2.2615e-01,  4.6219e-01, -2.3961e-01,  3.5075e-01,  3.3729e-01],\n",
      "         [ 7.8415e-01,  7.3988e-01,  7.3260e-01,  5.6287e-01,  6.0314e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.6926658]\n",
      "[0.03797917]\n",
      "[0.05775997]\n",
      "[0.5446889]\n",
      "[1.20985186]\n",
      "[-0.20198648]\n",
      "[0.16475993]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.3742,  0.4867, -0.3117,  0.5371,  0.7218,  0.5683,  0.8573],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 5.2571e-01,  5.7165e-01,  3.2971e-01,  4.0932e-01,  4.2975e-01],\n",
      "         [ 5.8241e-01,  4.5116e-01,  4.8956e-01,  1.4858e-01,  4.4281e-01],\n",
      "         [-9.4632e-03,  3.9527e-01, -3.2967e-01,  2.0320e-01,  3.6956e-01],\n",
      "         [ 5.4544e-01,  5.6237e-01,  5.4350e-01,  5.7459e-01,  2.8579e-01],\n",
      "         [ 4.8687e-01,  4.9784e-01,  3.1981e-01,  2.1596e-01,  3.7616e-01],\n",
      "         [ 2.2615e-01,  4.6219e-01, -2.3961e-01,  4.3001e-01,  3.3729e-01],\n",
      "         [ 7.8415e-01,  7.3988e-01,  7.3260e-01,  7.0037e-01,  6.0314e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.44105107]\n",
      "[0.0960249]\n",
      "[0.24474813]\n",
      "[0.56819853]\n",
      "[0.25665673]\n",
      "[0.35245889]\n",
      "[0.05094847]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6629, 0.7896, 0.0682, 0.7391, 0.7131, 0.4323, 0.8616],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 5.2571e-01,  5.7165e-01,  3.2971e-01,  4.0932e-01,  5.2554e-01],\n",
      "         [ 5.8241e-01,  4.5116e-01,  4.8956e-01,  1.4858e-01,  5.6294e-01],\n",
      "         [-9.4632e-03,  3.9527e-01, -3.2967e-01,  2.0320e-01,  3.0674e-01],\n",
      "         [ 5.4544e-01,  5.6237e-01,  5.4350e-01,  5.7459e-01,  3.8597e-01],\n",
      "         [ 4.8687e-01,  4.9784e-01,  3.1981e-01,  2.1596e-01,  4.7452e-01],\n",
      "         [ 2.2615e-01,  4.6219e-01, -2.3961e-01,  4.3001e-01,  3.7914e-01],\n",
      "         [ 7.8415e-01,  7.3988e-01,  7.3260e-01,  7.0037e-01,  7.4204e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.91908208]\n",
      "[0.12446064]\n",
      "[0.16673474]\n",
      "[0.61202213]\n",
      "[0.93795764]\n",
      "[1.11684642]\n",
      "[0.29967482]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6715,  0.3942,  0.6644,  0.7423, -0.2034,  0.1459,  0.9222],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.5716,   0.3297,   0.4093,   0.5255],\n",
      "         [  0.6315,   0.4512,   0.4896,   0.1486,   0.5629],\n",
      "         [  0.0954,   0.3953,  -0.3297,   0.2032,   0.3067],\n",
      "         [  0.6531,   0.5624,   0.5435,   0.5746,   0.3860],\n",
      "         [  0.4433,   0.4978,   0.3198,   0.2160,   0.4745],\n",
      "         [  0.2356,   0.4622,  -0.2396,   0.4300,   0.3791],\n",
      "         [  0.9316,   0.7399,   0.7326,   0.7004,   0.7420]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.23511732]\n",
      "[0.17017639]\n",
      "[0.13213762]\n",
      "[0.51857252]\n",
      "[0.05148525]\n",
      "[0.71146455]\n",
      "[0.23378105]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9372, 0.8511, 0.6386, 0.9472, 0.7328, 0.8174, 0.9275],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.3297,   0.4093,   0.5255],\n",
      "         [  0.6315,   0.5897,   0.4896,   0.1486,   0.5629],\n",
      "         [  0.0954,   0.4934,  -0.3297,   0.2032,   0.3067],\n",
      "         [  0.6531,   0.7175,   0.5435,   0.5746,   0.3860],\n",
      "         [  0.4433,   0.5996,   0.3198,   0.2160,   0.4745],\n",
      "         [  0.2356,   0.5903,  -0.2396,   0.4300,   0.3791],\n",
      "         [  0.9316,   0.8929,   0.7326,   0.7004,   0.7420]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.30210599]\n",
      "[0.15081581]\n",
      "[0.34926467]\n",
      "[1.53539121]\n",
      "[0.22717496]\n",
      "[0.86608779]\n",
      "[0.09347999]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7161, 0.5245, 0.7043, 0.4398, 0.4714, 0.6571, 0.8375],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.4093,   0.5255],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.1486,   0.5629],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.2032,   0.3067],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.5746,   0.3860],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2160,   0.4745],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.4300,   0.3791],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.7004,   0.7420]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.09138154]\n",
      "[0.03540537]\n",
      "[0.08780202]\n",
      "[1.20354667]\n",
      "[0.02027068]\n",
      "[0.30542021]\n",
      "[0.13182698]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7606, 0.6734, 0.8773, 0.8804, 0.2730, 0.7063, 0.8900],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.5255],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.5629],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.3067],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.3860],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.4745],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.3791],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.7420]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.48618612]\n",
      "[1.9342872]\n",
      "[0.62206129]\n",
      "[1.58279976]\n",
      "[0.37614649]\n",
      "[1.09738457]\n",
      "[0.05123414]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8968, 0.8808, 0.8821, 0.9282, 0.8509, 0.7390, 0.9516],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.98745344]\n",
      "[0.78818604]\n",
      "[0.62929433]\n",
      "[0.72426986]\n",
      "[0.83692937]\n",
      "[0.98002925]\n",
      "[0.07136138]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8659, 0.7132, 0.8775, 0.9047, 0.8301, 0.8224, 0.9806],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.1400,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1076,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1423,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1454,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1329,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1208,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1623,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.51240692]\n",
      "[0.24831183]\n",
      "[0.37468364]\n",
      "[0.58364706]\n",
      "[0.10586649]\n",
      "[0.33473775]\n",
      "[0.02583257]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.4312, 0.6101, 0.5821, 0.7286, 0.5345, 0.0747, 0.9264],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 1.4004e-01,  6.5241e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0755e-01,  9.0513e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4231e-01,  8.8764e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4543e-01,  1.1111e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3288e-01,  8.4816e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2082e-01, -9.2914e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.6235e-01,  1.5242e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.27885423]\n",
      "[0.30074886]\n",
      "[0.17229]\n",
      "[0.51758273]\n",
      "[-0.00279943]\n",
      "[0.1460552]\n",
      "[0.02331558]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6766, 0.4777, 0.5617, 0.8664, 0.7949, 0.6991, 0.9361],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 1.4004e-01,  6.5241e-02,  1.0238e-01,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0755e-01,  9.0513e-02,  6.3331e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4231e-01,  8.8764e-02,  8.5693e-02,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.4543e-01,  1.1111e-01,  1.3813e-01,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3288e-01,  8.4816e-02,  1.2298e-01,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2082e-01, -9.2914e-03,  1.0193e-01,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.6235e-01,  1.5242e-01,  1.5237e-01,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.42902482]\n",
      "[0.37873339]\n",
      "[0.21442044]\n",
      "[0.53883205]\n",
      "[0.09856434]\n",
      "[0.27081597]\n",
      "[0.02164655]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8972, 0.9246, 0.8116, 0.8852, 0.8163, 0.5208, 0.9693],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 1.4004e-01,  6.5241e-02,  1.0238e-01,  1.4640e-01,  0.0000e+00],\n",
      "         [ 1.0755e-01,  9.0513e-02,  6.3331e-02,  1.5045e-01,  0.0000e+00],\n",
      "         [ 1.4231e-01,  8.8764e-02,  8.5693e-02,  1.2881e-01,  0.0000e+00],\n",
      "         [ 1.4543e-01,  1.1111e-01,  1.3813e-01,  1.4534e-01,  0.0000e+00],\n",
      "         [ 1.3288e-01,  8.4816e-02,  1.2298e-01,  1.2649e-01,  0.0000e+00],\n",
      "         [ 1.2082e-01, -9.2914e-03,  1.0193e-01,  7.3380e-02,  0.0000e+00],\n",
      "         [ 1.6235e-01,  1.5242e-01,  1.5237e-01,  1.5963e-01,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.77972167]\n",
      "[0.04185706]\n",
      "[0.05504222]\n",
      "[0.85006257]\n",
      "[0.45297707]\n",
      "[0.23292363]\n",
      "[0.17048108]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7586, 0.8113, 0.6494, 0.6613, 0.7570, 0.7395, 0.9407],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 1.4004e-01,  6.5241e-02,  1.0238e-01,  1.4640e-01,  1.1330e-01],\n",
      "         [ 1.0755e-01,  9.0513e-02,  6.3331e-02,  1.5045e-01,  1.2119e-01],\n",
      "         [ 1.4231e-01,  8.8764e-02,  8.5693e-02,  1.2881e-01,  9.0697e-02],\n",
      "         [ 1.4543e-01,  1.1111e-01,  1.3813e-01,  1.4534e-01,  6.9593e-02],\n",
      "         [ 1.3288e-01,  8.4816e-02,  1.2298e-01,  1.2649e-01,  1.1953e-01],\n",
      "         [ 1.2082e-01, -9.2914e-03,  1.0193e-01,  7.3380e-02,  1.1181e-01],\n",
      "         [ 1.6235e-01,  1.5242e-01,  1.5237e-01,  1.5963e-01,  1.4454e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.08310563]\n",
      "[0.02224516]\n",
      "[0.11186942]\n",
      "[0.93537436]\n",
      "[0.02683095]\n",
      "[0.10724435]\n",
      "[0.2124614]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8818, 0.8916, 0.6957, 0.8023, 0.7004, 0.7234, 0.9560],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 2.6356e-01,  6.5241e-02,  1.0238e-01,  1.4640e-01,  1.1330e-01],\n",
      "         [ 2.5199e-01,  9.0513e-02,  6.3331e-02,  1.5045e-01,  1.2119e-01],\n",
      "         [ 1.7720e-01,  8.8764e-02,  8.5693e-02,  1.2881e-01,  9.0697e-02],\n",
      "         [ 2.7097e-01,  1.1111e-01,  1.3813e-01,  1.4534e-01,  6.9593e-02],\n",
      "         [ 1.9785e-01,  8.4816e-02,  1.2298e-01,  1.2649e-01,  1.1953e-01],\n",
      "         [ 1.3700e-01, -9.2914e-03,  1.0193e-01,  7.3380e-02,  1.1181e-01],\n",
      "         [ 3.1763e-01,  1.5242e-01,  1.5237e-01,  1.5963e-01,  1.4454e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.96829841]\n",
      "[0.67973381]\n",
      "[0.86813464]\n",
      "[1.03659005]\n",
      "[0.79922714]\n",
      "[0.90091577]\n",
      "[0.36533729]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7631, 0.8514, 0.7868, 0.8971, 0.8165, 0.6077, 0.8484],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 2.6356e-01,  1.8651e-01,  1.0238e-01,  1.4640e-01,  1.1330e-01],\n",
      "         [ 2.5199e-01,  2.2641e-01,  6.3331e-02,  1.5045e-01,  1.2119e-01],\n",
      "         [ 1.7720e-01,  2.0662e-01,  8.5693e-02,  1.2881e-01,  9.0697e-02],\n",
      "         [ 2.7097e-01,  2.5579e-01,  1.3813e-01,  1.4534e-01,  6.9593e-02],\n",
      "         [ 1.9785e-01,  2.1325e-01,  1.2298e-01,  1.2649e-01,  1.1953e-01],\n",
      "         [ 1.3700e-01,  7.7273e-02,  1.0193e-01,  7.3380e-02,  1.1181e-01],\n",
      "         [ 3.1763e-01,  2.9208e-01,  1.5237e-01,  1.5963e-01,  1.4454e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.99911411]\n",
      "[0.83352295]\n",
      "[0.68580816]\n",
      "[1.03452712]\n",
      "[0.62724668]\n",
      "[0.81040276]\n",
      "[0.45060351]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8535, 0.9623, 0.6337, 0.9282, 0.8549, 0.7184, 0.9483],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 2.6356e-01,  1.8651e-01,  2.3341e-01,  1.4640e-01,  1.1330e-01],\n",
      "         [ 2.5199e-01,  2.2641e-01,  2.1703e-01,  1.5045e-01,  1.2119e-01],\n",
      "         [ 1.7720e-01,  2.0662e-01,  1.4587e-01,  1.2881e-01,  9.0697e-02],\n",
      "         [ 2.7097e-01,  2.5579e-01,  2.8692e-01,  1.4534e-01,  6.9593e-02],\n",
      "         [ 1.9785e-01,  2.1325e-01,  2.5000e-01,  1.2649e-01,  1.1953e-01],\n",
      "         [ 1.3700e-01,  7.7273e-02,  1.4833e-01,  7.3380e-02,  1.1181e-01],\n",
      "         [ 3.1763e-01,  2.9208e-01,  3.0503e-01,  1.5963e-01,  1.4454e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.99008054]\n",
      "[0.75955093]\n",
      "[0.90181191]\n",
      "[1.08290073]\n",
      "[0.66908586]\n",
      "[0.87377897]\n",
      "[0.85579921]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6256, 0.5669, 0.5602, 0.7934, 0.6893, 0.7779, 0.8514],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 2.6356e-01,  1.8651e-01,  2.3341e-01,  2.2532e-01,  1.1330e-01],\n",
      "         [ 2.5199e-01,  2.2641e-01,  2.1703e-01,  2.1723e-01,  1.2119e-01],\n",
      "         [ 1.7720e-01,  2.0662e-01,  1.4587e-01,  1.7655e-01,  9.0697e-02],\n",
      "         [ 2.7097e-01,  2.5579e-01,  2.8692e-01,  2.5699e-01,  6.9593e-02],\n",
      "         [ 1.9785e-01,  2.1325e-01,  2.5000e-01,  2.1505e-01,  1.1953e-01],\n",
      "         [ 1.3700e-01,  7.7273e-02,  1.4833e-01,  1.7990e-01,  1.1181e-01],\n",
      "         [ 3.1763e-01,  2.9208e-01,  3.0503e-01,  2.9089e-01,  1.4454e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.13538554]\n",
      "[0.05541719]\n",
      "[0.08774401]\n",
      "[0.63937453]\n",
      "[0.02304463]\n",
      "[0.25712527]\n",
      "[0.12494203]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7696, 0.8001, 0.7304, 0.8206, 0.6600, 0.6552, 0.8729],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.2636,   0.1865,   0.2334,   0.2253,   0.2177],\n",
      "         [  0.2520,   0.2264,   0.2170,   0.2172,   0.2298],\n",
      "         [  0.1772,   0.2066,   0.1459,   0.1765,   0.1744],\n",
      "         [  0.2710,   0.2558,   0.2869,   0.2570,   0.1867],\n",
      "         [  0.1978,   0.2132,   0.2500,   0.2150,   0.2054],\n",
      "         [  0.1370,   0.0773,   0.1483,   0.1799,   0.1856],\n",
      "         [  0.3176,   0.2921,   0.3050,   0.2909,   0.2809]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.17571526]\n",
      "[0.1534348]\n",
      "[0.0693115]\n",
      "[1.2772532]\n",
      "[0.01043046]\n",
      "[0.35402076]\n",
      "[0.09168679]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8970, 0.8681, 0.8340, 0.8871, 0.7740, 0.8329, 0.9772],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4043,   0.1865,   0.2334,   0.2253,   0.2177],\n",
      "         [  0.3871,   0.2264,   0.2170,   0.2172,   0.2298],\n",
      "         [  0.3070,   0.2066,   0.1459,   0.1765,   0.1744],\n",
      "         [  0.4114,   0.2558,   0.2869,   0.2570,   0.1867],\n",
      "         [  0.3121,   0.2132,   0.2500,   0.2150,   0.2054],\n",
      "         [  0.2624,   0.0773,   0.1483,   0.1799,   0.1856],\n",
      "         [  0.4756,   0.2921,   0.3050,   0.2909,   0.2809]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.15982503]\n",
      "[0.13531295]\n",
      "[0.05424655]\n",
      "[0.72425222]\n",
      "[0.03033151]\n",
      "[0.47158145]\n",
      "[0.06093718]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9358, 0.9520, 0.8415, 0.9765, 0.8965, 0.8365, 0.9491],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4043,   0.3402,   0.2334,   0.2253,   0.2177],\n",
      "         [  0.3871,   0.3832,   0.2170,   0.2172,   0.2298],\n",
      "         [  0.3070,   0.3420,   0.1459,   0.1765,   0.1744],\n",
      "         [  0.4114,   0.4168,   0.2869,   0.2570,   0.1867],\n",
      "         [  0.3121,   0.3558,   0.2500,   0.2150,   0.2054],\n",
      "         [  0.2624,   0.2041,   0.1483,   0.1799,   0.1856],\n",
      "         [  0.4756,   0.4486,   0.3050,   0.2909,   0.2809]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.85899958]\n",
      "[1.03022344]\n",
      "[0.87044259]\n",
      "[0.85259463]\n",
      "[0.87653842]\n",
      "[0.66081174]\n",
      "[0.30186609]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9388, 0.8896, 0.8950, 0.9436, 0.7592, 0.7619, 0.9562],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4043,   0.3402,   0.3854,   0.2253,   0.2177],\n",
      "         [  0.3871,   0.3832,   0.3581,   0.2172,   0.2298],\n",
      "         [  0.3070,   0.3420,   0.2874,   0.1765,   0.1744],\n",
      "         [  0.4114,   0.4168,   0.4361,   0.2570,   0.1867],\n",
      "         [  0.3121,   0.3558,   0.3587,   0.2150,   0.2054],\n",
      "         [  0.2624,   0.2041,   0.2628,   0.1799,   0.1856],\n",
      "         [  0.4756,   0.4486,   0.4633,   0.2909,   0.2809]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.50231991]\n",
      "[0.24500941]\n",
      "[0.22639448]\n",
      "[1.32753334]\n",
      "[0.17693265]\n",
      "[0.53469883]\n",
      "[0.02546377]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9460, 0.8948, 0.9334, 0.9670, 0.8605, 0.7076, 0.9725],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4043,   0.3402,   0.3854,   0.3807,   0.2177],\n",
      "         [  0.3871,   0.3832,   0.3581,   0.3640,   0.2298],\n",
      "         [  0.3070,   0.3420,   0.2874,   0.3293,   0.1744],\n",
      "         [  0.4114,   0.4168,   0.4361,   0.4156,   0.1867],\n",
      "         [  0.3121,   0.3558,   0.3587,   0.3488,   0.2054],\n",
      "         [  0.2624,   0.2041,   0.2628,   0.2903,   0.1856],\n",
      "         [  0.4756,   0.4486,   0.4633,   0.4507,   0.2809]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.14262296]\n",
      "[1.01019498]\n",
      "[1.08864671]\n",
      "[1.10042053]\n",
      "[0.96874237]\n",
      "[0.93047191]\n",
      "[0.13427213]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9035, 0.8833, 0.8340, 0.8959, 0.6427, 0.8438, 0.9515],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4043,   0.3402,   0.3854,   0.3807,   0.3661],\n",
      "         [  0.3871,   0.3832,   0.3581,   0.3640,   0.3671],\n",
      "         [  0.3070,   0.3420,   0.2874,   0.3293,   0.3059],\n",
      "         [  0.4114,   0.4168,   0.4361,   0.4156,   0.3315],\n",
      "         [  0.3121,   0.3558,   0.3587,   0.3488,   0.2858],\n",
      "         [  0.2624,   0.2041,   0.2628,   0.2903,   0.3121],\n",
      "         [  0.4756,   0.4486,   0.4633,   0.4507,   0.4377]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.35075494]\n",
      "[0.41606634]\n",
      "[0.5565349]\n",
      "[1.31332552]\n",
      "[0.34563085]\n",
      "[0.6074622]\n",
      "[0.04450679]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7846, 0.4582, 0.6865, 0.8027, 0.7330, 0.7809, 0.9141],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4987,   0.3402,   0.3854,   0.3807,   0.3661],\n",
      "         [  0.3986,   0.3832,   0.3581,   0.3640,   0.3671],\n",
      "         [  0.3874,   0.3420,   0.2874,   0.3293,   0.3059],\n",
      "         [  0.5159,   0.4168,   0.4361,   0.4156,   0.3315],\n",
      "         [  0.4087,   0.3558,   0.3587,   0.3488,   0.2858],\n",
      "         [  0.3332,   0.2041,   0.2628,   0.2903,   0.3121],\n",
      "         [  0.6017,   0.4486,   0.4633,   0.4507,   0.4377]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.14152322]\n",
      "[0.06740237]\n",
      "[0.1364127]\n",
      "[0.56601328]\n",
      "[0.05883992]\n",
      "[0.19506315]\n",
      "[0.22509392]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8828, 0.7505, 0.7856, 0.7402, 0.7088, 0.7364, 0.9298],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4987,   0.4837,   0.3854,   0.3807,   0.3661],\n",
      "         [  0.3986,   0.4947,   0.3581,   0.3640,   0.3671],\n",
      "         [  0.3874,   0.4637,   0.2874,   0.3293,   0.3059],\n",
      "         [  0.5159,   0.5298,   0.4361,   0.4156,   0.3315],\n",
      "         [  0.4087,   0.4644,   0.3587,   0.3488,   0.2858],\n",
      "         [  0.3332,   0.3144,   0.2628,   0.2903,   0.3121],\n",
      "         [  0.6017,   0.6014,   0.4633,   0.4507,   0.4377]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.0279155]\n",
      "[0.01489329]\n",
      "[0.04554824]\n",
      "[0.36788654]\n",
      "[0.0337967]\n",
      "[0.08192811]\n",
      "[0.13182323]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8284, 0.8763, 0.6891, 0.7373, 0.8632, 0.7571, 0.9387],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4987,   0.4837,   0.5093,   0.3807,   0.3661],\n",
      "         [  0.3986,   0.4947,   0.4759,   0.3640,   0.3671],\n",
      "         [  0.3874,   0.4637,   0.3802,   0.3293,   0.3059],\n",
      "         [  0.5159,   0.5298,   0.5389,   0.4156,   0.3315],\n",
      "         [  0.4087,   0.4644,   0.4875,   0.3488,   0.2858],\n",
      "         [  0.3332,   0.3144,   0.3737,   0.2903,   0.3121],\n",
      "         [  0.6017,   0.6014,   0.6141,   0.4507,   0.4377]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.06113793]\n",
      "[0.02529342]\n",
      "[0.08884058]\n",
      "[0.6074095]\n",
      "[0.02386796]\n",
      "[0.11954872]\n",
      "[0.16155103]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6010, 0.8621, 0.6451, 0.7577, 0.8380, 0.6135, 0.9496],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4987,   0.4837,   0.5093,   0.4698,   0.3661],\n",
      "         [  0.3986,   0.4947,   0.4759,   0.5020,   0.3671],\n",
      "         [  0.3874,   0.4637,   0.3802,   0.4071,   0.3059],\n",
      "         [  0.5159,   0.5298,   0.5389,   0.5290,   0.3315],\n",
      "         [  0.4087,   0.4644,   0.4875,   0.4785,   0.2858],\n",
      "         [  0.3332,   0.3144,   0.3737,   0.3789,   0.3121],\n",
      "         [  0.6017,   0.6014,   0.6141,   0.6056,   0.4377]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.08160334]\n",
      "[0.17058998]\n",
      "[0.01659732]\n",
      "[0.28581403]\n",
      "[0.0656862]\n",
      "[0.08260006]\n",
      "[0.89464241]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8139, 0.6923, 0.6506, 0.7958, 0.6478, 0.7022, 0.8843],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.4987,   0.4837,   0.5093,   0.4698,   0.4879],\n",
      "         [  0.3986,   0.4947,   0.4759,   0.5020,   0.4544],\n",
      "         [  0.3874,   0.4637,   0.3802,   0.4071,   0.3650],\n",
      "         [  0.5159,   0.5298,   0.5389,   0.5290,   0.4427],\n",
      "         [  0.4087,   0.4644,   0.4875,   0.4785,   0.3643],\n",
      "         [  0.3332,   0.3144,   0.3737,   0.3789,   0.4093],\n",
      "         [  0.6017,   0.6014,   0.6141,   0.6056,   0.5703]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.13193817]\n",
      "[0.08498847]\n",
      "[0.14848625]\n",
      "[0.58358746]\n",
      "[0.05535254]\n",
      "[0.14810907]\n",
      "[0.27001837]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8899, 0.8646, 0.6525, 0.6838, 0.6684, 0.7922, 0.9455],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.6364,   0.4837,   0.5093,   0.4698,   0.4879],\n",
      "         [  0.5314,   0.4947,   0.4759,   0.5020,   0.4544],\n",
      "         [  0.4564,   0.4637,   0.3802,   0.4071,   0.3650],\n",
      "         [  0.5921,   0.5298,   0.5389,   0.5290,   0.4427],\n",
      "         [  0.4965,   0.4644,   0.4875,   0.4785,   0.3643],\n",
      "         [  0.4566,   0.3144,   0.3737,   0.3789,   0.4093],\n",
      "         [  0.7567,   0.6014,   0.6141,   0.6056,   0.5703]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.59411328]\n",
      "[0.18380329]\n",
      "[0.21927824]\n",
      "[0.63189389]\n",
      "[0.27842823]\n",
      "[0.42977049]\n",
      "[0.11110902]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7495, 0.7657, 0.4465, 0.6535, 0.7659, 0.7676, 0.9555],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.6364,   0.5851,   0.5093,   0.4698,   0.4879],\n",
      "         [  0.5314,   0.5837,   0.4759,   0.5020,   0.4544],\n",
      "         [  0.4564,   0.5093,   0.3802,   0.4071,   0.3650],\n",
      "         [  0.5921,   0.6076,   0.5389,   0.5290,   0.4427],\n",
      "         [  0.4965,   0.5800,   0.4875,   0.4785,   0.3643],\n",
      "         [  0.4566,   0.4230,   0.3737,   0.3789,   0.4093],\n",
      "         [  0.7567,   0.7546,   0.6141,   0.6056,   0.5703]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.07773117]\n",
      "[0.32215365]\n",
      "[0.00910057]\n",
      "[0.33443339]\n",
      "[0.08131734]\n",
      "[0.05286492]\n",
      "[0.88095022]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8875, 0.8644, 0.5530, 0.7559, 0.7293, 0.5365, 0.9534],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.6364,   0.5851,   0.6430,   0.4698,   0.4879],\n",
      "         [  0.5314,   0.5837,   0.6127,   0.5020,   0.4544],\n",
      "         [  0.4564,   0.5093,   0.4194,   0.4071,   0.3650],\n",
      "         [  0.5921,   0.6076,   0.6445,   0.5290,   0.4427],\n",
      "         [  0.4965,   0.5800,   0.5928,   0.4785,   0.3643],\n",
      "         [  0.4566,   0.4230,   0.4404,   0.3789,   0.4093],\n",
      "         [  0.7567,   0.7546,   0.7697,   0.6056,   0.5703]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.94458037]\n",
      "[0.10269996]\n",
      "[0.11034412]\n",
      "[0.57557063]\n",
      "[1.53330488]\n",
      "[0.82774625]\n",
      "[0.30612082]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8849, 0.7556, 0.2045, 0.7464, 0.8242, 0.6258, 0.9241],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.6364,   0.5851,   0.6430,   0.6042,   0.4879],\n",
      "         [  0.5314,   0.5837,   0.6127,   0.6179,   0.4544],\n",
      "         [  0.4564,   0.5093,   0.4194,   0.3929,   0.3650],\n",
      "         [  0.5921,   0.6076,   0.6445,   0.6342,   0.4427],\n",
      "         [  0.4965,   0.5800,   0.5928,   0.5974,   0.3643],\n",
      "         [  0.4566,   0.4230,   0.4404,   0.4544,   0.4093],\n",
      "         [  0.7567,   0.7546,   0.7697,   0.7547,   0.5703]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.94791438]\n",
      "[0.12064157]\n",
      "[0.10697415]\n",
      "[0.62146225]\n",
      "[1.34537451]\n",
      "[1.16806383]\n",
      "[0.2872286]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7472, 0.8157, 0.0197, 0.7700, 0.8376, 0.1727, 0.9324],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.6364,   0.5851,   0.6430,   0.6042,   0.5939],\n",
      "         [  0.5314,   0.5837,   0.6127,   0.6179,   0.5770],\n",
      "         [  0.4564,   0.5093,   0.4194,   0.3929,   0.3182],\n",
      "         [  0.5921,   0.6076,   0.6445,   0.6342,   0.5502],\n",
      "         [  0.4965,   0.5800,   0.5928,   0.5974,   0.4897],\n",
      "         [  0.4566,   0.4230,   0.4404,   0.4544,   0.3535],\n",
      "         [  0.7567,   0.7546,   0.7697,   0.7547,   0.7219]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.78617008]\n",
      "[0.07334242]\n",
      "[0.08993421]\n",
      "[0.72552967]\n",
      "[1.17685006]\n",
      "[0.51686392]\n",
      "[0.28053973]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8563, 0.8728, 0.8491, 0.9598, 0.7814, 0.5975, 0.9390],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.5851,   0.6430,   0.6042,   0.5939],\n",
      "         [  0.6716,   0.5837,   0.6127,   0.6179,   0.5770],\n",
      "         [  0.5927,   0.5093,   0.4194,   0.3929,   0.3182],\n",
      "         [  0.7462,   0.6076,   0.6445,   0.6342,   0.5502],\n",
      "         [  0.6062,   0.5800,   0.5928,   0.5974,   0.4897],\n",
      "         [  0.5458,   0.4230,   0.4404,   0.4544,   0.3535],\n",
      "         [  0.9115,   0.7546,   0.7697,   0.7547,   0.7219]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.8861914]\n",
      "[0.95326809]\n",
      "[0.76388804]\n",
      "[0.85634263]\n",
      "[0.85487643]\n",
      "[0.98031542]\n",
      "[0.26732501]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8451, 0.8123, 0.8038, 0.9498, 0.8026, 0.7412, 0.9417],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.6430,   0.6042,   0.5939],\n",
      "         [  0.6716,   0.7077,   0.6127,   0.6179,   0.5770],\n",
      "         [  0.5927,   0.6307,   0.4194,   0.3929,   0.3182],\n",
      "         [  0.7462,   0.7643,   0.6445,   0.6342,   0.5502],\n",
      "         [  0.6062,   0.6770,   0.5928,   0.5974,   0.4897],\n",
      "         [  0.5458,   0.5308,   0.4404,   0.4544,   0.3535],\n",
      "         [  0.9115,   0.9076,   0.7697,   0.7547,   0.7219]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.8783399]\n",
      "[0.99140417]\n",
      "[0.83878057]\n",
      "[0.79743333]\n",
      "[0.97712586]\n",
      "[0.84777373]\n",
      "[0.79835]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8919, 0.9105, 0.7759, 0.9650, 0.6966, 0.8110, 0.9378],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.6042,   0.5939],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.6179,   0.5770],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.3929,   0.3182],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.6342,   0.5502],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.5974,   0.4897],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.4544,   0.3535],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.7547,   0.7219]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.81581567]\n",
      "[0.9735367]\n",
      "[0.7339906]\n",
      "[0.81719201]\n",
      "[0.8130016]\n",
      "[0.81924256]\n",
      "[0.67790926]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9048, 0.8746, 0.8677, 0.9388, 0.6948, 0.7206, 0.9571],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.5939],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.5770],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.3182],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.5502],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.4897],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.3535],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.7219]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.93190794]\n",
      "[0.82929968]\n",
      "[0.78450425]\n",
      "[0.85229145]\n",
      "[0.85216777]\n",
      "[0.80603878]\n",
      "[0.20191619]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8881, 0.9362, 0.8678, 0.9634, 0.6328, 0.8068, 0.9374],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.7870766]\n",
      "[0.95296795]\n",
      "[0.73023332]\n",
      "[0.82154954]\n",
      "[0.999247]\n",
      "[0.78914169]\n",
      "[0.64860566]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8821, 0.8030, 0.7893, 0.8902, 0.8130, 0.6531, 0.9837],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.1408,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1226,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1201,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1395,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1218,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0913,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1615,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.4025655]\n",
      "[0.41839952]\n",
      "[0.20842984]\n",
      "[0.47293733]\n",
      "[0.10643423]\n",
      "[0.3094505]\n",
      "[0.0188977]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8459, 0.6204, 0.6580, 0.7786, 0.7405, 0.6394, 0.9817],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.1408,   0.1326,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1226,   0.0910,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1201,   0.0961,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1395,   0.1245,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1218,   0.1124,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0913,   0.0748,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1615,   0.1607,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.37751738]\n",
      "[0.48833143]\n",
      "[0.18985925]\n",
      "[0.46711179]\n",
      "[0.12264433]\n",
      "[0.19449943]\n",
      "[0.03164604]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7762, 0.6460, 0.7654, 0.8369, 0.7645, 0.6749, 0.9659],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.1408,   0.1326,   0.1262,   0.0000,   0.0000],\n",
      "         [  0.1226,   0.0910,   0.1030,   0.0000,   0.0000],\n",
      "         [  0.1201,   0.0961,   0.1242,   0.0000,   0.0000],\n",
      "         [  0.1395,   0.1245,   0.1351,   0.0000,   0.0000],\n",
      "         [  0.1218,   0.1124,   0.1225,   0.0000,   0.0000],\n",
      "         [  0.0913,   0.0748,   0.1040,   0.0000,   0.0000],\n",
      "         [  0.1615,   0.1607,   0.1596,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.39621596]\n",
      "[0.21981562]\n",
      "[0.14872993]\n",
      "[0.36641334]\n",
      "[0.11514083]\n",
      "[0.19831455]\n",
      "[0.01291161]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8754, 0.6701, 0.8301, 0.7386, 0.6955, 0.8707, 0.9025],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.1408,   0.1326,   0.1262,   0.1375,   0.0000],\n",
      "         [  0.1226,   0.0910,   0.1030,   0.0989,   0.0000],\n",
      "         [  0.1201,   0.0961,   0.1242,   0.1195,   0.0000],\n",
      "         [  0.1395,   0.1245,   0.1351,   0.1056,   0.0000],\n",
      "         [  0.1218,   0.1124,   0.1225,   0.1119,   0.0000],\n",
      "         [  0.0913,   0.0748,   0.1040,   0.1378,   0.0000],\n",
      "         [  0.1615,   0.1607,   0.1596,   0.1471,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.03862543]\n",
      "[0.00611077]\n",
      "[0.08499306]\n",
      "[1.06451755]\n",
      "[0.01702779]\n",
      "[0.07331281]\n",
      "[0.14247851]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8272, 0.8212, 0.8554, 0.9076, 0.8491, 0.6894, 0.9647],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.1408,   0.1326,   0.1262,   0.1375,   0.1295],\n",
      "         [  0.1226,   0.0910,   0.1030,   0.0989,   0.1281],\n",
      "         [  0.1201,   0.0961,   0.1242,   0.1195,   0.1223],\n",
      "         [  0.1395,   0.1245,   0.1351,   0.1056,   0.1409],\n",
      "         [  0.1218,   0.1124,   0.1225,   0.1119,   0.1354],\n",
      "         [  0.0913,   0.0748,   0.1040,   0.1378,   0.1043],\n",
      "         [  0.1615,   0.1607,   0.1596,   0.1471,   0.1589]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.52540168]\n",
      "[0.33536528]\n",
      "[0.21605337]\n",
      "[0.49510689]\n",
      "[0.11825651]\n",
      "[0.37694103]\n",
      "[0.01493503]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7471, 0.8150, 0.5597, 0.8766, 0.7443, 0.4945, 0.9504],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 2.4455e-01,  1.3260e-01,  1.2625e-01,  1.3749e-01,  1.2953e-01],\n",
      "         [ 2.2652e-01,  9.0950e-02,  1.0301e-01,  9.8855e-02,  1.2813e-01],\n",
      "         [ 1.3508e-01,  9.6077e-02,  1.2418e-01,  1.1954e-01,  1.2226e-01],\n",
      "         [ 2.7342e-01,  1.2454e-01,  1.3511e-01,  1.0561e-01,  1.4094e-01],\n",
      "         [ 2.0362e-01,  1.1243e-01,  1.2249e-01,  1.1186e-01,  1.3537e-01],\n",
      "         [ 5.8697e-02,  7.4835e-02,  1.0402e-01,  1.3777e-01,  1.0431e-01],\n",
      "         [ 3.1520e-01,  1.6075e-01,  1.5963e-01,  1.4710e-01,  1.5893e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.78797321]\n",
      "[1.58159381]\n",
      "[0.54156923]\n",
      "[1.29190636]\n",
      "[0.27921859]\n",
      "[1.13572488]\n",
      "[0.03734971]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7208, 0.7975, 0.6325, 0.9152, 0.6481, 0.7954, 0.8773],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 2.4455e-01,  2.4327e-01,  1.2625e-01,  1.3749e-01,  1.2953e-01],\n",
      "         [ 2.2652e-01,  2.1621e-01,  1.0301e-01,  9.8855e-02,  1.2813e-01],\n",
      "         [ 1.3508e-01,  1.7564e-01,  1.2418e-01,  1.1954e-01,  1.2226e-01],\n",
      "         [ 2.7342e-01,  2.7112e-01,  1.3511e-01,  1.0561e-01,  1.4094e-01],\n",
      "         [ 2.0362e-01,  1.8706e-01,  1.2249e-01,  1.1186e-01,  1.3537e-01],\n",
      "         [ 5.8697e-02,  1.9826e-01,  1.0402e-01,  1.3777e-01,  1.0431e-01],\n",
      "         [ 3.1520e-01,  3.0397e-01,  1.5963e-01,  1.4710e-01,  1.5893e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.06885]\n",
      "[0.0342411]\n",
      "[0.02742624]\n",
      "[0.49028546]\n",
      "[0.01490691]\n",
      "[0.10109079]\n",
      "[0.05404896]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8336, 0.6900, 0.2576, 0.9205, 0.6379, 0.4932, 0.9465],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 2.4455e-01,  2.4327e-01,  2.4994e-01,  1.3749e-01,  1.2953e-01],\n",
      "         [ 2.2652e-01,  2.1621e-01,  2.0844e-01,  9.8855e-02,  1.2813e-01],\n",
      "         [ 1.3508e-01,  1.7564e-01,  1.1928e-01,  1.1954e-01,  1.2226e-01],\n",
      "         [ 2.7342e-01,  2.7112e-01,  2.8106e-01,  1.0561e-01,  1.4094e-01],\n",
      "         [ 2.0362e-01,  1.8706e-01,  2.1261e-01,  1.1186e-01,  1.3537e-01],\n",
      "         [ 5.8697e-02,  1.9826e-01,  1.4535e-01,  1.3777e-01,  1.0431e-01],\n",
      "         [ 3.1520e-01,  3.0397e-01,  3.1227e-01,  1.4710e-01,  1.5893e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.47502161]\n",
      "[0.34652985]\n",
      "[0.88062191]\n",
      "[1.72665617]\n",
      "[0.31810187]\n",
      "[1.30042099]\n",
      "[0.0986125]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6729,  0.7127,  0.5581,  0.8255, -0.0858,  0.4825,  0.9104],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 2.4455e-01,  2.4327e-01,  2.4994e-01,  2.0888e-01,  1.2953e-01],\n",
      "         [ 2.2652e-01,  2.1621e-01,  2.0844e-01,  1.8845e-01,  1.2813e-01],\n",
      "         [ 1.3508e-01,  1.7564e-01,  1.1928e-01,  1.5983e-01,  1.2226e-01],\n",
      "         [ 2.7342e-01,  2.7112e-01,  2.8106e-01,  2.2314e-01,  1.4094e-01],\n",
      "         [ 2.0362e-01,  1.8706e-01,  2.1261e-01,  5.2315e-02,  1.3537e-01],\n",
      "         [ 5.8697e-02,  1.9826e-01,  1.4535e-01,  1.7769e-01,  1.0431e-01],\n",
      "         [ 3.1520e-01,  3.0397e-01,  3.1227e-01,  2.9160e-01,  1.5893e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[0.13936189]\n",
      "[0.07423184]\n",
      "[0.07061949]\n",
      "[0.60648384]\n",
      "[0.0345412]\n",
      "[0.3974506]\n",
      "[0.111263]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7899, 0.9357, 0.6255, 0.9289, 0.8528, 0.6551, 0.9258],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 2.4455e-01,  2.4327e-01,  2.4994e-01,  2.0888e-01,  2.5343e-01],\n",
      "         [ 2.2652e-01,  2.1621e-01,  2.0844e-01,  1.8845e-01,  2.7910e-01],\n",
      "         [ 1.3508e-01,  1.7564e-01,  1.1928e-01,  1.5983e-01,  2.0154e-01],\n",
      "         [ 2.7342e-01,  2.7112e-01,  2.8106e-01,  2.2314e-01,  2.8976e-01],\n",
      "         [ 2.0362e-01,  1.8706e-01,  2.1261e-01,  5.2315e-02,  2.4773e-01],\n",
      "         [ 5.8697e-02,  1.9826e-01,  1.4535e-01,  1.7769e-01,  1.9764e-01],\n",
      "         [ 3.1520e-01,  3.0397e-01,  3.1227e-01,  2.9160e-01,  3.1089e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.11507387]\n",
      "[0.74907694]\n",
      "[0.89721121]\n",
      "[1.08657089]\n",
      "[0.88807824]\n",
      "[0.8769918]\n",
      "[0.45562104]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9215, 0.9048, 0.8395, 0.8882, 0.6720, 0.7227, 0.9669],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 3.9419e-01,  2.4327e-01,  2.4994e-01,  2.0888e-01,  2.5343e-01],\n",
      "         [ 3.7376e-01,  2.1621e-01,  2.0844e-01,  1.8845e-01,  2.7910e-01],\n",
      "         [ 2.6971e-01,  1.7564e-01,  1.1928e-01,  1.5983e-01,  2.0154e-01],\n",
      "         [ 4.1861e-01,  2.7112e-01,  2.8106e-01,  2.2314e-01,  2.8976e-01],\n",
      "         [ 3.0349e-01,  1.8706e-01,  2.1261e-01,  5.2315e-02,  2.4773e-01],\n",
      "         [ 1.6630e-01,  1.9826e-01,  1.4535e-01,  1.7769e-01,  1.9764e-01],\n",
      "         [ 4.7481e-01,  3.0397e-01,  3.1227e-01,  2.9160e-01,  3.1089e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.27408052]\n",
      "[0.22716031]\n",
      "[0.492585]\n",
      "[1.27860918]\n",
      "[0.25546186]\n",
      "[0.76098909]\n",
      "[0.03847826]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8966, 0.8777, 0.8338, 0.9410, 0.7592, 0.5569, 0.9796],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 3.9419e-01,  3.8885e-01,  2.4994e-01,  2.0888e-01,  2.5343e-01],\n",
      "         [ 3.7376e-01,  3.5322e-01,  2.0844e-01,  1.8845e-01,  2.7910e-01],\n",
      "         [ 2.6971e-01,  3.0595e-01,  1.1928e-01,  1.5983e-01,  2.0154e-01],\n",
      "         [ 4.1861e-01,  4.2161e-01,  2.8106e-01,  2.2314e-01,  2.8976e-01],\n",
      "         [ 3.0349e-01,  3.0521e-01,  2.1261e-01,  5.2315e-02,  2.4773e-01],\n",
      "         [ 1.6630e-01,  2.6635e-01,  1.4535e-01,  1.7769e-01,  1.9764e-01],\n",
      "         [ 4.7481e-01,  4.6455e-01,  3.1227e-01,  2.9160e-01,  3.1089e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.5204221]\n",
      "[0.27528202]\n",
      "[0.33225551]\n",
      "[1.45120215]\n",
      "[0.24109393]\n",
      "[0.89574072]\n",
      "[0.03431782]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9388, 0.9548, 0.9482, 0.9563, 0.8474, 0.8698, 0.9786],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[-1.7148e+00, -1.1841e+00, -2.0996e+01, -3.0956e+00, -1.5254e+00],\n",
      "         [-1.1192e+00, -3.2352e+00, -1.0864e+01, -1.6272e+00, -1.4525e+00],\n",
      "         [-2.9225e+00, -2.0566e+00, -7.3825e+01, -1.4582e+01, -3.2874e+00],\n",
      "         [-1.1343e+00, -9.8539e-01, -2.0169e+00, -1.6740e+01, -3.1631e+00],\n",
      "         [-3.1955e+00, -2.6328e+00, -1.0915e+00, -4.2357e+00, -2.9870e+00],\n",
      "         [-5.5799e+00, -9.3941e+00, -1.2787e+01, -1.7994e+01, -1.6477e+00],\n",
      "         [ 3.3806e-01, -1.4310e-01, -9.6709e+00, -3.2836e+00, -1.4765e+00]],\n",
      "\n",
      "        [[ 6.2678e-01,  7.2484e-01,  4.3697e-01,  5.2936e-01,  6.7263e-01],\n",
      "         [ 6.3152e-01,  5.8972e-01,  5.6745e-01,  2.5268e-01,  7.0835e-01],\n",
      "         [ 9.5386e-02,  4.9341e-01, -2.2128e-01,  3.4601e-01,  4.5045e-01],\n",
      "         [ 6.5308e-01,  7.1745e-01,  5.9535e-01,  7.1745e-01,  5.3870e-01],\n",
      "         [ 4.4327e-01,  5.9961e-01,  3.8306e-01,  2.4207e-01,  6.0800e-01],\n",
      "         [ 2.3560e-01,  5.9028e-01, -1.4246e-01,  5.3229e-01,  4.9588e-01],\n",
      "         [ 9.3157e-01,  8.9289e-01,  8.6789e-01,  8.4747e-01,  8.9972e-01]],\n",
      "\n",
      "        [[ 7.7589e-01,  7.1792e-01,  7.8510e-01,  7.5089e-01,  7.3983e-01],\n",
      "         [ 6.7163e-01,  7.0767e-01,  7.5905e-01,  7.5979e-01,  7.2974e-01],\n",
      "         [ 5.9267e-01,  6.3069e-01,  5.3405e-01,  5.2817e-01,  4.5284e-01],\n",
      "         [ 7.4621e-01,  7.6427e-01,  8.0237e-01,  7.8709e-01,  7.0862e-01],\n",
      "         [ 6.0618e-01,  6.7702e-01,  6.7475e-01,  6.9709e-01,  5.7688e-01],\n",
      "         [ 5.4582e-01,  5.3085e-01,  5.5479e-01,  5.6769e-01,  4.8230e-01],\n",
      "         [ 9.1146e-01,  9.0756e-01,  9.2361e-01,  9.1238e-01,  8.7680e-01]],\n",
      "\n",
      "        [[ 3.9419e-01,  3.8885e-01,  4.0460e-01,  2.0888e-01,  2.5343e-01],\n",
      "         [ 3.7376e-01,  3.5322e-01,  3.6379e-01,  1.8845e-01,  2.7910e-01],\n",
      "         [ 2.6971e-01,  3.0595e-01,  2.7452e-01,  1.5983e-01,  2.0154e-01],\n",
      "         [ 4.1861e-01,  4.2161e-01,  4.3764e-01,  2.2314e-01,  2.8976e-01],\n",
      "         [ 3.0349e-01,  3.0521e-01,  3.4598e-01,  5.2315e-02,  2.4773e-01],\n",
      "         [ 1.6630e-01,  2.6635e-01,  2.7688e-01,  1.7769e-01,  1.9764e-01],\n",
      "         [ 4.7481e-01,  4.6455e-01,  4.7397e-01,  2.9160e-01,  3.1089e-01]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n",
      "[1.03418695]\n",
      "[1.07442789]\n",
      "[1.17692364]\n",
      "[1.1634885]\n",
      "[1.01883643]\n",
      "[0.74738135]\n",
      "[0.20465383]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9408, 0.8868, 0.8796, 0.9344, 0.7678, 0.9228, 0.9739],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.3942,   0.3888,   0.4046,   0.3568,   0.2534],\n",
      "         [  0.3738,   0.3532,   0.3638,   0.3215,   0.2791],\n",
      "         [  0.2697,   0.3060,   0.2745,   0.2985,   0.2015],\n",
      "         [  0.4186,   0.4216,   0.4376,   0.3708,   0.2898],\n",
      "         [  0.3035,   0.3052,   0.3460,   0.1645,   0.2477],\n",
      "         [  0.1663,   0.2664,   0.2769,   0.3190,   0.1976],\n",
      "         [  0.4748,   0.4645,   0.4740,   0.4507,   0.3109]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.10219966]\n",
      "[0.08976463]\n",
      "[0.04933195]\n",
      "[0.54626462]\n",
      "[0.02527084]\n",
      "[0.31891236]\n",
      "[0.03352556]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9277, 0.9086, 0.8626, 0.9608, 0.8255, 0.5757, 0.9123],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.3942,   0.3888,   0.4046,   0.3568,   0.3967],\n",
      "         [  0.3738,   0.3532,   0.3638,   0.3215,   0.4194],\n",
      "         [  0.2697,   0.3060,   0.2745,   0.2985,   0.3328],\n",
      "         [  0.4186,   0.4216,   0.4376,   0.3708,   0.4449],\n",
      "         [  0.3035,   0.3052,   0.3460,   0.1645,   0.3750],\n",
      "         [  0.1663,   0.2664,   0.2769,   0.3190,   0.2565],\n",
      "         [  0.4748,   0.4645,   0.4740,   0.4507,   0.4591]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.75333622]\n",
      "[1.01883183]\n",
      "[0.99882255]\n",
      "[1.56357613]\n",
      "[0.23387719]\n",
      "[0.7879611]\n",
      "[0.02040617]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6574, 0.5335, 0.5840, 0.5033, 0.7611, 0.7750, 0.8505],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.4778,   0.3888,   0.4046,   0.3568,   0.3967],\n",
      "         [  0.4113,   0.3532,   0.3638,   0.3215,   0.4194],\n",
      "         [  0.3366,   0.3060,   0.2745,   0.2985,   0.3328],\n",
      "         [  0.4842,   0.4216,   0.4376,   0.3708,   0.4449],\n",
      "         [  0.3997,   0.3052,   0.3460,   0.1645,   0.3750],\n",
      "         [  0.2694,   0.2664,   0.2769,   0.3190,   0.2565],\n",
      "         [  0.5943,   0.4645,   0.4740,   0.4507,   0.4591]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.1433275]\n",
      "[0.11314362]\n",
      "[0.0706263]\n",
      "[0.34069418]\n",
      "[0.02413885]\n",
      "[0.30660861]\n",
      "[0.11323082]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7612, 0.8426, 0.6719, 0.6566, 0.8428, 0.7043, 0.9269],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.4778,   0.4986,   0.4046,   0.3568,   0.3967],\n",
      "         [  0.4113,   0.4787,   0.3638,   0.3215,   0.4194],\n",
      "         [  0.3366,   0.3939,   0.2745,   0.2985,   0.3328],\n",
      "         [  0.4842,   0.5141,   0.4376,   0.3708,   0.4449],\n",
      "         [  0.3997,   0.4288,   0.3460,   0.1645,   0.3750],\n",
      "         [  0.2694,   0.3666,   0.2769,   0.3190,   0.2565],\n",
      "         [  0.5943,   0.6168,   0.4740,   0.4507,   0.4591]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.07957271]\n",
      "[0.04009429]\n",
      "[0.07313421]\n",
      "[0.22992675]\n",
      "[0.01924314]\n",
      "[0.2087582]\n",
      "[0.03854116]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8437, 0.7370, 0.4112, 0.6966, 0.8271, 0.8030, 0.7944],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.4778,   0.4986,   0.5324,   0.3568,   0.3967],\n",
      "         [  0.4113,   0.4787,   0.4672,   0.3215,   0.4194],\n",
      "         [  0.3366,   0.3939,   0.3141,   0.2985,   0.3328],\n",
      "         [  0.4842,   0.5141,   0.5412,   0.3708,   0.4449],\n",
      "         [  0.3997,   0.4288,   0.4745,   0.1645,   0.3750],\n",
      "         [  0.2694,   0.3666,   0.3874,   0.3190,   0.2565],\n",
      "         [  0.5943,   0.6168,   0.6006,   0.4507,   0.4591]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.09019388]\n",
      "[0.03250095]\n",
      "[0.10476985]\n",
      "[0.49920191]\n",
      "[0.03723115]\n",
      "[0.13111947]\n",
      "[0.22958012]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8433, 0.7009, 0.7140, 0.7563, 0.8496, 0.7949, 0.8810],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.4778,   0.4986,   0.5324,   0.4595,   0.3967],\n",
      "         [  0.4113,   0.4787,   0.4672,   0.4196,   0.4194],\n",
      "         [  0.3366,   0.3939,   0.3141,   0.3789,   0.3328],\n",
      "         [  0.4842,   0.5141,   0.5412,   0.4835,   0.4449],\n",
      "         [  0.3997,   0.4288,   0.4745,   0.2785,   0.3750],\n",
      "         [  0.2694,   0.3666,   0.3874,   0.4169,   0.2565],\n",
      "         [  0.5943,   0.6168,   0.6006,   0.5887,   0.4591]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.18254372]\n",
      "[0.11733496]\n",
      "[0.09810731]\n",
      "[0.36946404]\n",
      "[0.02092464]\n",
      "[0.35707803]\n",
      "[0.10645892]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8703, 0.8498, 0.7000, 0.8475, 0.8297, 0.7976, 0.9102],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.4778,   0.4986,   0.5324,   0.4595,   0.5193],\n",
      "         [  0.4113,   0.4787,   0.4672,   0.4196,   0.5441],\n",
      "         [  0.3366,   0.3939,   0.3141,   0.3789,   0.4166],\n",
      "         [  0.4842,   0.5141,   0.5412,   0.4835,   0.5693],\n",
      "         [  0.3997,   0.4288,   0.4745,   0.2785,   0.4883],\n",
      "         [  0.2694,   0.3666,   0.3874,   0.4169,   0.3582],\n",
      "         [  0.5943,   0.6168,   0.6006,   0.5887,   0.6037]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.13196666]\n",
      "[0.08080704]\n",
      "[0.13361424]\n",
      "[0.53108224]\n",
      "[0.04892763]\n",
      "[0.20205287]\n",
      "[0.2474573]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9121, 0.8876, 0.0917, 0.7827, 0.7452, 0.7784, 0.9531],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.6114,   0.4986,   0.5324,   0.4595,   0.5193],\n",
      "         [  0.5392,   0.4787,   0.4672,   0.4196,   0.5441],\n",
      "         [  0.2996,   0.3939,   0.3141,   0.3789,   0.4166],\n",
      "         [  0.5892,   0.5141,   0.5412,   0.4835,   0.5693],\n",
      "         [  0.4983,   0.4288,   0.4745,   0.2785,   0.4883],\n",
      "         [  0.3814,   0.3666,   0.3874,   0.4169,   0.3582],\n",
      "         [  0.7483,   0.6168,   0.6006,   0.5887,   0.6037]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.45102182]\n",
      "[0.20080987]\n",
      "[0.2886548]\n",
      "[0.46862557]\n",
      "[0.0802635]\n",
      "[0.76499848]\n",
      "[0.08789203]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8221, 0.6911, 0.4338, 0.8052, 0.8685, 0.8728, 0.9755],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.6114,   0.6252,   0.5324,   0.4595,   0.5193],\n",
      "         [  0.5392,   0.5884,   0.4672,   0.4196,   0.5441],\n",
      "         [  0.2996,   0.4266,   0.3141,   0.3789,   0.4166],\n",
      "         [  0.5892,   0.6258,   0.5412,   0.4835,   0.5693],\n",
      "         [  0.4983,   0.5657,   0.4745,   0.2785,   0.4883],\n",
      "         [  0.3814,   0.4974,   0.3874,   0.4169,   0.3582],\n",
      "         [  0.7483,   0.7771,   0.6006,   0.5887,   0.6037]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.49606515]\n",
      "[0.08889655]\n",
      "[0.28214582]\n",
      "[0.59155366]\n",
      "[0.21673222]\n",
      "[0.26958858]\n",
      "[0.038617]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.6437,  0.8770, -0.6170,  0.5033,  0.7834, -0.0225,  0.8938],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.6114,   0.6252,   0.6247,   0.4595,   0.5193],\n",
      "         [  0.5392,   0.5884,   0.6002,   0.4196,   0.5441],\n",
      "         [  0.2996,   0.4266,   0.1515,   0.3789,   0.4166],\n",
      "         [  0.5892,   0.6258,   0.5989,   0.4835,   0.5693],\n",
      "         [  0.4983,   0.5657,   0.5929,   0.2785,   0.4883],\n",
      "         [  0.3814,   0.4974,   0.3399,   0.4169,   0.3582],\n",
      "         [  0.7483,   0.7771,   0.7452,   0.5887,   0.6037]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.80670248]\n",
      "[0.09909374]\n",
      "[0.07644913]\n",
      "[0.73872699]\n",
      "[1.18274359]\n",
      "[0.5124512]\n",
      "[0.22888795]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8380, 0.8962, 0.6583, 0.8188, 0.8839, 0.7864, 0.9550],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.6114,   0.6252,   0.6247,   0.5864,   0.5193],\n",
      "         [  0.5392,   0.5884,   0.6002,   0.5544,   0.5441],\n",
      "         [  0.2996,   0.4266,   0.1515,   0.4278,   0.4166],\n",
      "         [  0.5892,   0.6258,   0.5989,   0.6010,   0.5693],\n",
      "         [  0.4983,   0.5657,   0.5929,   0.4114,   0.4883],\n",
      "         [  0.3814,   0.4974,   0.3399,   0.5296,   0.3582],\n",
      "         [  0.7483,   0.7771,   0.7452,   0.7372,   0.6037]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.48818046]\n",
      "[0.14379967]\n",
      "[0.2814378]\n",
      "[0.57570997]\n",
      "[0.17296336]\n",
      "[0.79535505]\n",
      "[0.08201899]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8967, 0.8894, 0.3246, 0.7778, 0.8211, 0.8017, 0.9692],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.6114,   0.6252,   0.6247,   0.5864,   0.6609],\n",
      "         [  0.5392,   0.5884,   0.6002,   0.5544,   0.6845],\n",
      "         [  0.2996,   0.4266,   0.1515,   0.4278,   0.4151],\n",
      "         [  0.5892,   0.6258,   0.5989,   0.6010,   0.6813],\n",
      "         [  0.4983,   0.5657,   0.5929,   0.4114,   0.6041],\n",
      "         [  0.3814,   0.4974,   0.3399,   0.5296,   0.4830],\n",
      "         [  0.7483,   0.7771,   0.7452,   0.7372,   0.7612]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.40986762]\n",
      "[0.1208521]\n",
      "[0.36449529]\n",
      "[0.50642732]\n",
      "[0.12903694]\n",
      "[0.59969355]\n",
      "[0.07970008]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9136, 0.8877, 0.8599, 0.9594, 0.8850, 0.6797, 0.9576],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.6252,   0.6247,   0.5864,   0.6609],\n",
      "         [  0.6832,   0.5884,   0.6002,   0.5544,   0.6845],\n",
      "         [  0.4343,   0.4266,   0.1515,   0.4278,   0.4151],\n",
      "         [  0.7432,   0.6258,   0.5989,   0.6010,   0.6813],\n",
      "         [  0.6222,   0.5657,   0.5929,   0.4114,   0.6041],\n",
      "         [  0.4786,   0.4974,   0.3399,   0.5296,   0.4830],\n",
      "         [  0.9055,   0.7771,   0.7452,   0.7372,   0.7612]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.94592704]\n",
      "[0.91268345]\n",
      "[0.90836605]\n",
      "[0.87492432]\n",
      "[0.9768584]\n",
      "[1.01386982]\n",
      "[0.27732182]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9211, 0.8084, 0.8836, 0.9404, 0.7674, 0.7024, 0.9636],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.6247,   0.5864,   0.6609],\n",
      "         [  0.6832,   0.7200,   0.6002,   0.5544,   0.6845],\n",
      "         [  0.4343,   0.5658,   0.1515,   0.4278,   0.4151],\n",
      "         [  0.7432,   0.7796,   0.5989,   0.6010,   0.6813],\n",
      "         [  0.6222,   0.6793,   0.5929,   0.4114,   0.6041],\n",
      "         [  0.4786,   0.5967,   0.3399,   0.5296,   0.4830],\n",
      "         [  0.9055,   0.9360,   0.7452,   0.7372,   0.7612]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.89748698]\n",
      "[0.91593859]\n",
      "[0.85573162]\n",
      "[0.86460127]\n",
      "[0.82331666]\n",
      "[0.93160402]\n",
      "[0.24383163]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8800, 0.9101, 0.8664, 0.9538, 0.7922, 0.6765, 0.9406],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.5864,   0.6609],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.5544,   0.6845],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.4278,   0.4151],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.6010,   0.6813],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.4114,   0.6041],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.5296,   0.4830],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.7372,   0.7612]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.89410571]\n",
      "[0.89814751]\n",
      "[0.78394586]\n",
      "[0.85447891]\n",
      "[0.87399294]\n",
      "[0.90643076]\n",
      "[0.24117444]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9129, 0.9043, 0.8113, 0.9452, 0.8733, 0.7227, 0.9422],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.6609],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.6845],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.4151],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.6813],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.6041],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.4830],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.7612]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.91895603]\n",
      "[0.85211251]\n",
      "[0.77004353]\n",
      "[0.79465433]\n",
      "[0.77024881]\n",
      "[0.82088678]\n",
      "[0.28755121]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8535, 0.8436, 0.9108, 0.9591, 0.8956, 0.7707, 0.9156],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.8311049]\n",
      "[0.75573502]\n",
      "[0.66964394]\n",
      "[0.88131951]\n",
      "[0.92329692]\n",
      "[0.63215707]\n",
      "[0.19856577]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8855, 0.8176, 0.8288, 0.8050, 0.6423, 0.8823, 0.9229],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.1375,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1278,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1238,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1245,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1023,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1286,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1506,   0.0000,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.06109698]\n",
      "[0.03249756]\n",
      "[0.07210588]\n",
      "[0.71612455]\n",
      "[0.01973256]\n",
      "[0.10045489]\n",
      "[0.16244369]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7940, 0.6968, 0.8296, 0.9011, 0.7206, 0.6797, 0.9681],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.1375,   0.1267,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1278,   0.1122,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1238,   0.1340,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1245,   0.1386,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1023,   0.1145,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1286,   0.1026,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1506,   0.1602,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.43338537]\n",
      "[0.20248918]\n",
      "[0.19951279]\n",
      "[0.4821078]\n",
      "[0.04624547]\n",
      "[0.33629289]\n",
      "[0.01154209]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9276, 0.9355, 0.8680, 0.8689, 0.8303, 0.7225, 0.9730],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.1375,   0.1267,   0.1482,   0.0000,   0.0000],\n",
      "         [  0.1278,   0.1122,   0.1493,   0.0000,   0.0000],\n",
      "         [  0.1238,   0.1340,   0.1336,   0.0000,   0.0000],\n",
      "         [  0.1245,   0.1386,   0.1343,   0.0000,   0.0000],\n",
      "         [  0.1023,   0.1145,   0.1308,   0.0000,   0.0000],\n",
      "         [  0.1286,   0.1026,   0.1023,   0.0000,   0.0000],\n",
      "         [  0.1506,   0.1602,   0.1611,   0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.77064]\n",
      "[0.06968173]\n",
      "[0.06717952]\n",
      "[0.75538816]\n",
      "[0.44534484]\n",
      "[0.16845062]\n",
      "[0.19959654]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8648, 0.8771, 0.8692, 0.8907, 0.8513, 0.7876, 0.9735],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.1375,   0.1267,   0.1482,   0.1375,   0.0000],\n",
      "         [  0.1278,   0.1122,   0.1493,   0.1382,   0.0000],\n",
      "         [  0.1238,   0.1340,   0.1336,   0.1292,   0.0000],\n",
      "         [  0.1245,   0.1386,   0.1343,   0.1410,   0.0000],\n",
      "         [  0.1023,   0.1145,   0.1308,   0.1373,   0.0000],\n",
      "         [  0.1286,   0.1026,   0.1023,   0.1193,   0.0000],\n",
      "         [  0.1506,   0.1602,   0.1611,   0.1599,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.53876239]\n",
      "[0.32490396]\n",
      "[0.29096393]\n",
      "[0.52497387]\n",
      "[0.19511542]\n",
      "[0.40010748]\n",
      "[0.02165219]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8742, 0.7305, 0.8052, 0.7648, 0.7940, 0.8244, 0.9455],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.1375,   0.1267,   0.1482,   0.1375,   0.1365],\n",
      "         [  0.1278,   0.1122,   0.1493,   0.1382,   0.1061],\n",
      "         [  0.1238,   0.1340,   0.1336,   0.1292,   0.1129],\n",
      "         [  0.1245,   0.1386,   0.1343,   0.1410,   0.1103],\n",
      "         [  0.1023,   0.1145,   0.1308,   0.1373,   0.1257],\n",
      "         [  0.1286,   0.1026,   0.1023,   0.1193,   0.1259],\n",
      "         [  0.1506,   0.1602,   0.1611,   0.1599,   0.1528]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.07054089]\n",
      "[0.03595638]\n",
      "[0.08798174]\n",
      "[0.91533029]\n",
      "[0.02185151]\n",
      "[0.09396567]\n",
      "[0.15750508]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8037, 0.7728, 0.1496, 0.9090, 0.4923, 0.6627, 0.9439],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.2532,   0.1267,   0.1482,   0.1375,   0.1365],\n",
      "         [  0.2383,   0.1122,   0.1493,   0.1382,   0.1061],\n",
      "         [  0.0973,   0.1340,   0.1336,   0.1292,   0.1129],\n",
      "         [  0.2622,   0.1386,   0.1343,   0.1410,   0.1103],\n",
      "         [  0.1494,   0.1145,   0.1308,   0.1373,   0.1257],\n",
      "         [  0.2062,   0.1026,   0.1023,   0.1193,   0.1259],\n",
      "         [  0.3043,   0.1602,   0.1611,   0.1599,   0.1528]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.57845891]\n",
      "[0.30467334]\n",
      "[0.82690642]\n",
      "[1.67363467]\n",
      "[0.41769488]\n",
      "[1.20873051]\n",
      "[0.09954467]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.4785, 0.8069, 0.6953, 0.8843, 0.5938, 0.6016, 0.8683],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.2532,   0.1878,   0.1482,   0.1375,   0.1365],\n",
      "         [  0.2383,   0.2331,   0.1493,   0.1382,   0.1061],\n",
      "         [  0.0973,   0.2213,   0.1336,   0.1292,   0.1129],\n",
      "         [  0.2622,   0.2669,   0.1343,   0.1410,   0.1103],\n",
      "         [  0.1494,   0.1751,   0.1308,   0.1373,   0.1257],\n",
      "         [  0.2062,   0.1891,   0.1023,   0.1193,   0.1259],\n",
      "         [  0.3043,   0.2950,   0.1611,   0.1599,   0.1528]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.0943231]\n",
      "[0.03650244]\n",
      "[0.04944443]\n",
      "[1.15165954]\n",
      "[0.0208738]\n",
      "[0.1067268]\n",
      "[0.08451934]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9217, 0.8838, 0.7838, 0.9449, 0.8898, 0.7927, 0.9630],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.2532,   0.1878,   0.2931,   0.1375,   0.1365],\n",
      "         [  0.2383,   0.2331,   0.2917,   0.1382,   0.1061],\n",
      "         [  0.0973,   0.2213,   0.2471,   0.1292,   0.1129],\n",
      "         [  0.2622,   0.2669,   0.2885,   0.1410,   0.1103],\n",
      "         [  0.1494,   0.1751,   0.2566,   0.1373,   0.1257],\n",
      "         [  0.2062,   0.1891,   0.2072,   0.1193,   0.1259],\n",
      "         [  0.3043,   0.2950,   0.3192,   0.1599,   0.1528]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.91278799]\n",
      "[0.7420375]\n",
      "[0.72661676]\n",
      "[1.05405731]\n",
      "[0.73038282]\n",
      "[0.86796806]\n",
      "[0.36025236]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9130, 0.9132, 0.6214, 0.9190, 0.6309, 0.8741, 0.9564],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.2532,   0.1878,   0.2931,   0.2764,   0.1365],\n",
      "         [  0.2383,   0.2331,   0.2917,   0.2739,   0.1061],\n",
      "         [  0.0973,   0.2213,   0.2471,   0.2043,   0.1129],\n",
      "         [  0.2622,   0.2669,   0.2885,   0.2872,   0.1103],\n",
      "         [  0.1494,   0.1751,   0.2566,   0.1913,   0.1257],\n",
      "         [  0.2062,   0.1891,   0.2072,   0.2335,   0.1259],\n",
      "         [  0.3043,   0.2950,   0.3192,   0.3170,   0.1528]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.51225246]\n",
      "[1.42277892]\n",
      "[0.36483744]\n",
      "[1.39348488]\n",
      "[0.36397643]\n",
      "[0.91276405]\n",
      "[0.02776382]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6476, 0.7283, 0.6222, 0.9455, 0.5774, 0.6756, 0.9303],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.2532,   0.1878,   0.2931,   0.2764,   0.2170],\n",
      "         [  0.2383,   0.2331,   0.2917,   0.2739,   0.2108],\n",
      "         [  0.0973,   0.2213,   0.2471,   0.2043,   0.1724],\n",
      "         [  0.2622,   0.2669,   0.2885,   0.2872,   0.2516],\n",
      "         [  0.1494,   0.1751,   0.2566,   0.1913,   0.1880],\n",
      "         [  0.2062,   0.1891,   0.2072,   0.2335,   0.2030],\n",
      "         [  0.3043,   0.2950,   0.3192,   0.3170,   0.3043]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.11450942]\n",
      "[0.07947797]\n",
      "[0.06017903]\n",
      "[0.65113077]\n",
      "[0.01723155]\n",
      "[0.27060145]\n",
      "[0.0790013]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9321, 0.9617, 0.9561, 0.9701, 0.8813, 0.7059, 0.9747],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.4049,   0.1878,   0.2931,   0.2764,   0.2170],\n",
      "         [  0.3947,   0.2331,   0.2917,   0.2739,   0.2108],\n",
      "         [  0.2534,   0.2213,   0.2471,   0.2043,   0.1724],\n",
      "         [  0.4213,   0.2669,   0.2885,   0.2872,   0.2516],\n",
      "         [  0.2896,   0.1751,   0.2566,   0.1913,   0.1880],\n",
      "         [  0.3080,   0.1891,   0.2072,   0.2335,   0.2030],\n",
      "         [  0.4652,   0.2950,   0.3192,   0.3170,   0.3043]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.05714516]\n",
      "[1.02423697]\n",
      "[1.0989669]\n",
      "[1.09541577]\n",
      "[0.98453904]\n",
      "[0.89476073]\n",
      "[0.27002026]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8618, 0.8806, 0.8387, 0.9127, 0.7860, 0.7471, 0.9628],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.4049,   0.3187,   0.2931,   0.2764,   0.2170],\n",
      "         [  0.3947,   0.3686,   0.2917,   0.2739,   0.2108],\n",
      "         [  0.2534,   0.3401,   0.2471,   0.2043,   0.1724],\n",
      "         [  0.4213,   0.4079,   0.2885,   0.2872,   0.2516],\n",
      "         [  0.2896,   0.2945,   0.2566,   0.1913,   0.1880],\n",
      "         [  0.3080,   0.2918,   0.2072,   0.2335,   0.2030],\n",
      "         [  0.4652,   0.4520,   0.3192,   0.3170,   0.3043]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.59807575]\n",
      "[0.35624244]\n",
      "[0.49243636]\n",
      "[1.49774852]\n",
      "[0.26465588]\n",
      "[1.03364875]\n",
      "[0.04829712]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9635, 0.9356, 0.9254, 0.9050, 0.8506, 0.7500, 0.9738],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.4049,   0.3187,   0.4495,   0.2764,   0.2170],\n",
      "         [  0.3947,   0.3686,   0.4423,   0.2739,   0.2108],\n",
      "         [  0.2534,   0.3401,   0.3928,   0.2043,   0.1724],\n",
      "         [  0.4213,   0.4079,   0.4347,   0.2872,   0.2516],\n",
      "         [  0.2896,   0.2945,   0.3889,   0.1913,   0.1880],\n",
      "         [  0.3080,   0.2918,   0.3054,   0.2335,   0.2030],\n",
      "         [  0.4652,   0.4520,   0.4790,   0.3170,   0.3043]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.76046191]\n",
      "[1.08920332]\n",
      "[0.47813609]\n",
      "[1.43483443]\n",
      "[0.29155655]\n",
      "[0.83558342]\n",
      "[0.01923997]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9322, 0.9020, 0.9179, 0.9221, 0.8237, 0.8816, 0.9723],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.4049,   0.3187,   0.4495,   0.4251,   0.2170],\n",
      "         [  0.3947,   0.3686,   0.4423,   0.4143,   0.2108],\n",
      "         [  0.2534,   0.3401,   0.3928,   0.3443,   0.1724],\n",
      "         [  0.4213,   0.4079,   0.4347,   0.4169,   0.2516],\n",
      "         [  0.2896,   0.2945,   0.3889,   0.3172,   0.1880],\n",
      "         [  0.3080,   0.2918,   0.3054,   0.3700,   0.2030],\n",
      "         [  0.4652,   0.4520,   0.4790,   0.4751,   0.3043]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.14116884]\n",
      "[0.06735008]\n",
      "[0.07715621]\n",
      "[1.20971928]\n",
      "[0.02503762]\n",
      "[0.39716672]\n",
      "[0.04960227]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9231, 0.9594, 0.9430, 0.9554, 0.8807, 0.6535, 0.9687],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.4049,   0.3187,   0.4495,   0.4251,   0.3683],\n",
      "         [  0.3947,   0.3686,   0.4423,   0.4143,   0.3675],\n",
      "         [  0.2534,   0.3401,   0.3928,   0.3443,   0.3254],\n",
      "         [  0.4213,   0.4079,   0.4347,   0.4169,   0.4057],\n",
      "         [  0.2896,   0.2945,   0.3889,   0.3172,   0.3284],\n",
      "         [  0.3080,   0.2918,   0.3054,   0.3700,   0.2962],\n",
      "         [  0.4652,   0.4520,   0.4790,   0.4751,   0.4635]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.08872456]\n",
      "[1.03074754]\n",
      "[1.10560763]\n",
      "[1.13605651]\n",
      "[0.99023606]\n",
      "[0.9451829]\n",
      "[0.2468443]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9058, 0.8791, 0.8254, 0.8439, 0.7407, 0.8363, 0.9590],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.5465,   0.3187,   0.4495,   0.4251,   0.3683],\n",
      "         [  0.5316,   0.3686,   0.4423,   0.4143,   0.3675],\n",
      "         [  0.3751,   0.3401,   0.3928,   0.3443,   0.3254],\n",
      "         [  0.5546,   0.4079,   0.4347,   0.4169,   0.4057],\n",
      "         [  0.3868,   0.2945,   0.3889,   0.3172,   0.3284],\n",
      "         [  0.4345,   0.2918,   0.3054,   0.3700,   0.2962],\n",
      "         [  0.6230,   0.4520,   0.4790,   0.4751,   0.4635]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.06766953]\n",
      "[0.02789246]\n",
      "[0.06157395]\n",
      "[0.31369373]\n",
      "[0.0197897]\n",
      "[0.16433146]\n",
      "[0.09844738]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8708, 0.8667, 0.6422, 0.7566, 0.7731, 0.7915, 0.9556],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.5465,   0.4509,   0.4495,   0.4251,   0.3683],\n",
      "         [  0.5316,   0.4955,   0.4423,   0.4143,   0.3675],\n",
      "         [  0.3751,   0.4250,   0.3928,   0.3443,   0.3254],\n",
      "         [  0.5546,   0.5161,   0.4347,   0.4169,   0.4057],\n",
      "         [  0.3868,   0.4071,   0.3889,   0.3172,   0.3284],\n",
      "         [  0.4345,   0.4093,   0.3054,   0.3700,   0.2962],\n",
      "         [  0.6230,   0.6088,   0.4790,   0.4751,   0.4635]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.11295395]\n",
      "[0.07223752]\n",
      "[0.09668045]\n",
      "[0.38457901]\n",
      "[0.01916273]\n",
      "[0.2150111]\n",
      "[0.13864319]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7790, 0.7896, 0.6752, 0.8307, 0.7662, 0.7288, 0.8985],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.5465,   0.4509,   0.5699,   0.4251,   0.3683],\n",
      "         [  0.5316,   0.4955,   0.5600,   0.4143,   0.3675],\n",
      "         [  0.3751,   0.4250,   0.4846,   0.3443,   0.3254],\n",
      "         [  0.5546,   0.5161,   0.5571,   0.4169,   0.4057],\n",
      "         [  0.3868,   0.4071,   0.5039,   0.3172,   0.3284],\n",
      "         [  0.4345,   0.4093,   0.4133,   0.3700,   0.2962],\n",
      "         [  0.6230,   0.6088,   0.6229,   0.4751,   0.4635]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.09917383]\n",
      "[0.04415978]\n",
      "[0.11471508]\n",
      "[0.49132754]\n",
      "[0.04528883]\n",
      "[0.16106811]\n",
      "[0.23465642]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8484, 0.8473, 0.7571, 0.7663, 0.8260, 0.7962, 0.9284],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.5465,   0.4509,   0.5699,   0.5469,   0.3683],\n",
      "         [  0.5316,   0.4955,   0.5600,   0.5245,   0.3675],\n",
      "         [  0.3751,   0.4250,   0.4846,   0.4595,   0.3254],\n",
      "         [  0.5546,   0.5161,   0.5571,   0.5247,   0.4057],\n",
      "         [  0.3868,   0.4071,   0.5039,   0.4333,   0.3284],\n",
      "         [  0.4345,   0.4093,   0.4133,   0.4849,   0.2962],\n",
      "         [  0.6230,   0.6088,   0.6229,   0.6221,   0.4635]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.09705949]\n",
      "[0.08313929]\n",
      "[0.0505674]\n",
      "[0.26697959]\n",
      "[0.02317965]\n",
      "[0.21895643]\n",
      "[0.09202839]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.4437, 0.6643, 0.5929, 0.5677, 0.8554, 0.8594, 0.9172],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.5465,   0.4509,   0.5699,   0.5469,   0.4151],\n",
      "         [  0.5316,   0.4955,   0.5600,   0.5245,   0.4412],\n",
      "         [  0.3751,   0.4250,   0.4846,   0.4595,   0.3941],\n",
      "         [  0.5546,   0.5161,   0.5571,   0.5247,   0.4841],\n",
      "         [  0.3868,   0.4071,   0.5039,   0.4333,   0.4507],\n",
      "         [  0.4345,   0.4093,   0.4133,   0.4849,   0.4227],\n",
      "         [  0.6230,   0.6088,   0.6229,   0.6221,   0.6052]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.12595742]\n",
      "[0.08858596]\n",
      "[0.07008049]\n",
      "[0.30176959]\n",
      "[0.01816264]\n",
      "[0.24020995]\n",
      "[0.10040068]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8436, 0.9141, 0.3575, 0.8357, 0.8574, 0.7864, 0.9619],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.6709,   0.4509,   0.5699,   0.5469,   0.4151],\n",
      "         [  0.6726,   0.4955,   0.5600,   0.5245,   0.4412],\n",
      "         [  0.3554,   0.4250,   0.4846,   0.4595,   0.3941],\n",
      "         [  0.6777,   0.5161,   0.5571,   0.5247,   0.4841],\n",
      "         [  0.5096,   0.4071,   0.5039,   0.4333,   0.4507],\n",
      "         [  0.5353,   0.4093,   0.4133,   0.4849,   0.4227],\n",
      "         [  0.7768,   0.6088,   0.6229,   0.6221,   0.6052]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.46522427]\n",
      "[0.19874998]\n",
      "[0.43916757]\n",
      "[0.50766556]\n",
      "[0.2337302]\n",
      "[0.7423122]\n",
      "[0.09637242]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8263, 0.8331, 0.3773, 0.8068, 0.7855, 0.5587, 0.9378],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.6709,   0.5755,   0.5699,   0.5469,   0.4151],\n",
      "         [  0.6726,   0.6252,   0.5600,   0.5245,   0.4412],\n",
      "         [  0.3554,   0.4470,   0.4846,   0.4595,   0.3941],\n",
      "         [  0.6777,   0.6325,   0.5571,   0.5247,   0.4841],\n",
      "         [  0.5096,   0.5219,   0.5039,   0.4333,   0.4507],\n",
      "         [  0.5353,   0.4815,   0.4133,   0.4849,   0.4227],\n",
      "         [  0.7768,   0.7612,   0.6229,   0.6221,   0.6052]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.94164199]\n",
      "[0.11094469]\n",
      "[0.1330915]\n",
      "[0.730654]\n",
      "[1.31137936]\n",
      "[0.93303862]\n",
      "[0.34458214]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9011, 0.8841, 0.6477, 0.8548, 0.9106, 0.5827, 0.9700],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.6709,   0.5755,   0.7079,   0.5469,   0.4151],\n",
      "         [  0.6726,   0.6252,   0.6952,   0.5245,   0.4412],\n",
      "         [  0.3554,   0.4470,   0.5583,   0.4595,   0.3941],\n",
      "         [  0.6777,   0.6325,   0.6847,   0.5247,   0.4841],\n",
      "         [  0.5096,   0.5219,   0.6406,   0.4333,   0.4507],\n",
      "         [  0.5353,   0.4815,   0.4876,   0.4849,   0.4227],\n",
      "         [  0.7768,   0.7612,   0.7815,   0.6221,   0.6052]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.90670781]\n",
      "[0.12535583]\n",
      "[0.10238077]\n",
      "[0.7645274]\n",
      "[1.32277114]\n",
      "[0.90311065]\n",
      "[0.26918812]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9122, 0.8611, 0.6632, 0.7556, 0.9065, 0.7588, 0.9548],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.6709,   0.5755,   0.7079,   0.6848,   0.4151],\n",
      "         [  0.6726,   0.6252,   0.6952,   0.6560,   0.4412],\n",
      "         [  0.3554,   0.4470,   0.5583,   0.5197,   0.3941],\n",
      "         [  0.6777,   0.6325,   0.6847,   0.6299,   0.4841],\n",
      "         [  0.5096,   0.5219,   0.6406,   0.5743,   0.4507],\n",
      "         [  0.5353,   0.4815,   0.4876,   0.5934,   0.4227],\n",
      "         [  0.7768,   0.7612,   0.7815,   0.7774,   0.6052]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.06179815]\n",
      "[0.18134512]\n",
      "[0.01716977]\n",
      "[0.32521496]\n",
      "[0.0584179]\n",
      "[0.06362197]\n",
      "[0.92884933]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([ 0.7919,  0.8241, -0.1020,  0.8204,  0.8519,  0.2925,  0.9574],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.6709,   0.5755,   0.7079,   0.6848,   0.5323],\n",
      "         [  0.6726,   0.6252,   0.6952,   0.6560,   0.5692],\n",
      "         [  0.3554,   0.4470,   0.5583,   0.5197,   0.2959],\n",
      "         [  0.6777,   0.6325,   0.6847,   0.6299,   0.5911],\n",
      "         [  0.5096,   0.5219,   0.6406,   0.5743,   0.5757],\n",
      "         [  0.5353,   0.4815,   0.4876,   0.5934,   0.4421],\n",
      "         [  0.7768,   0.7612,   0.7815,   0.7774,   0.7579]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.49957275]\n",
      "[0.17931039]\n",
      "[0.34040875]\n",
      "[0.50374347]\n",
      "[0.1832406]\n",
      "[0.42031754]\n",
      "[0.04481311]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8939, 0.9550, 0.8510, 0.9681, 0.7083, 0.8007, 0.9484],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.5755,   0.7079,   0.6848,   0.5323],\n",
      "         [  0.8285,   0.6252,   0.6952,   0.6560,   0.5692],\n",
      "         [  0.4826,   0.4470,   0.5583,   0.5197,   0.2959],\n",
      "         [  0.8369,   0.6325,   0.6847,   0.6299,   0.5911],\n",
      "         [  0.5904,   0.5219,   0.6406,   0.5743,   0.5757],\n",
      "         [  0.6566,   0.4815,   0.4876,   0.5934,   0.4421],\n",
      "         [  0.9327,   0.7612,   0.7815,   0.7774,   0.7579]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.81740645]\n",
      "[0.93862671]\n",
      "[0.77398058]\n",
      "[0.83613675]\n",
      "[0.85721097]\n",
      "[0.92248914]\n",
      "[0.75284765]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9335, 0.8380, 0.7493, 0.9330, 0.8402, 0.8886, 0.9687],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.7079,   0.6848,   0.5323],\n",
      "         [  0.8285,   0.7598,   0.6952,   0.6560,   0.5692],\n",
      "         [  0.4826,   0.5615,   0.5583,   0.5197,   0.2959],\n",
      "         [  0.8369,   0.7837,   0.6847,   0.6299,   0.5911],\n",
      "         [  0.5904,   0.6486,   0.6406,   0.5743,   0.5757],\n",
      "         [  0.6566,   0.6234,   0.4876,   0.5934,   0.4421],\n",
      "         [  0.9327,   0.9207,   0.7815,   0.7774,   0.7579]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.42263334]\n",
      "[0.19500685]\n",
      "[0.43096873]\n",
      "[1.46442041]\n",
      "[0.23713499]\n",
      "[0.80175201]\n",
      "[0.1418373]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8906, 0.8447, 0.8426, 0.9067, 0.7858, 0.7290, 0.9437],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.6848,   0.5323],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.6560,   0.5692],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.5197,   0.2959],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.6299,   0.5911],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.5743,   0.5757],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.5934,   0.4421],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.7774,   0.7579]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[1.45581942]\n",
      "[1.66812749]\n",
      "[0.68534491]\n",
      "[1.58238494]\n",
      "[0.30958706]\n",
      "[1.09153821]\n",
      "[0.04756957]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9060, 0.9369, 0.8868, 0.9657, 0.7350, 0.8217, 0.9528],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.5323],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.5692],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.2959],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.5911],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.5757],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.4421],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.7579]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.79924622]\n",
      "[0.89633752]\n",
      "[0.78642654]\n",
      "[0.81024923]\n",
      "[0.81014892]\n",
      "[0.78112398]\n",
      "[0.70173311]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8844, 0.9433, 0.9041, 0.9735, 0.7028, 0.8086, 0.9340],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.87303306]\n",
      "[1.00781679]\n",
      "[0.78768069]\n",
      "[0.8269091]\n",
      "[0.99795601]\n",
      "[0.89195585]\n",
      "[0.77137153]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8728, 0.9153, 0.8630, 0.8319, 0.8264, 0.7043, 0.9771],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.1353,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1437,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1259,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1236,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1279,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0993,   0.0000,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1609,   0.0000,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.50637662]\n",
      "[0.30555928]\n",
      "[0.24734409]\n",
      "[0.49529023]\n",
      "[0.15384236]\n",
      "[0.33767109]\n",
      "[0.01641765]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8723, 0.9115, 0.8815, 0.9195, 0.8450, 0.7514, 0.9730],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.1353,   0.1406,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1437,   0.1468,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1259,   0.1361,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1236,   0.1430,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1279,   0.1359,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.0993,   0.1149,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.1609,   0.1607,   0.0000,   0.0000,   0.0000]]])\n",
      "[0.49545859]\n",
      "[0.2689647]\n",
      "[0.30225554]\n",
      "[0.59279098]\n",
      "[0.12215343]\n",
      "[0.24007558]\n",
      "[0.01664211]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9379, 0.8965, 0.7646, 0.9062, 0.8170, 0.7045, 0.9836],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.1353,   0.1406,   0.1488,   0.0000,   0.0000],\n",
      "         [  0.1437,   0.1468,   0.1396,   0.0000,   0.0000],\n",
      "         [  0.1259,   0.1361,   0.1151,   0.0000,   0.0000],\n",
      "         [  0.1236,   0.1430,   0.1415,   0.0000,   0.0000],\n",
      "         [  0.1279,   0.1359,   0.1288,   0.0000,   0.0000],\n",
      "         [  0.0993,   0.1149,   0.1014,   0.0000,   0.0000],\n",
      "         [  0.1609,   0.1607,   0.1616,   0.0000,   0.0000]]])\n",
      "[0.38466799]\n",
      "[0.42059928]\n",
      "[0.28467721]\n",
      "[0.57698693]\n",
      "[0.09971113]\n",
      "[0.19600564]\n",
      "[0.03748663]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8580, 0.6717, 0.7962, 0.9009, 0.8173, 0.8519, 0.9441],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.1353,   0.1406,   0.1488,   0.1388,   0.0000],\n",
      "         [  0.1437,   0.1468,   0.1396,   0.1033,   0.0000],\n",
      "         [  0.1259,   0.1361,   0.1151,   0.1240,   0.0000],\n",
      "         [  0.1236,   0.1430,   0.1415,   0.1413,   0.0000],\n",
      "         [  0.1279,   0.1359,   0.1288,   0.1301,   0.0000],\n",
      "         [  0.0993,   0.1149,   0.1014,   0.1320,   0.0000],\n",
      "         [  0.1609,   0.1607,   0.1616,   0.1551,   0.0000]]])\n",
      "[0.04683058]\n",
      "[0.01455749]\n",
      "[0.07316558]\n",
      "[0.74371817]\n",
      "[0.02326372]\n",
      "[0.08666937]\n",
      "[0.12609362]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8404, 0.7868, 0.8903, 0.8487, 0.8615, 0.7610, 0.9646],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.1353,   0.1406,   0.1488,   0.1388,   0.1323],\n",
      "         [  0.1437,   0.1468,   0.1396,   0.1033,   0.1243],\n",
      "         [  0.1259,   0.1361,   0.1151,   0.1240,   0.1277],\n",
      "         [  0.1236,   0.1430,   0.1415,   0.1413,   0.1268],\n",
      "         [  0.1279,   0.1359,   0.1288,   0.1301,   0.1390],\n",
      "         [  0.0993,   0.1149,   0.1014,   0.1320,   0.1152],\n",
      "         [  0.1609,   0.1607,   0.1616,   0.1551,   0.1571]]])\n",
      "[0.45878588]\n",
      "[0.26513487]\n",
      "[0.32251921]\n",
      "[0.57054374]\n",
      "[0.16828287]\n",
      "[0.28662616]\n",
      "[0.02139747]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8692, 0.9458, 0.8122, 0.9507, 0.8837, 0.8627, 0.9186],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.2724,   0.1406,   0.1488,   0.1388,   0.1323],\n",
      "         [  0.2961,   0.1468,   0.1396,   0.1033,   0.1243],\n",
      "         [  0.2418,   0.1361,   0.1151,   0.1240,   0.1277],\n",
      "         [  0.2782,   0.1430,   0.1415,   0.1413,   0.1268],\n",
      "         [  0.2498,   0.1359,   0.1288,   0.1301,   0.1390],\n",
      "         [  0.2281,   0.1149,   0.1014,   0.1320,   0.1152],\n",
      "         [  0.3099,   0.1607,   0.1616,   0.1551,   0.1571]]])\n",
      "[1.03923018]\n",
      "[0.9028543]\n",
      "[0.74707417]\n",
      "[1.13382905]\n",
      "[0.77296035]\n",
      "[0.80932582]\n",
      "[0.79818587]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8472, 0.8876, 0.6595, 0.9373, 0.6208, 0.8549, 0.9770],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.2724,   0.2702,   0.1488,   0.1388,   0.1323],\n",
      "         [  0.2961,   0.2822,   0.1396,   0.1033,   0.1243],\n",
      "         [  0.2418,   0.2257,   0.1151,   0.1240,   0.1277],\n",
      "         [  0.2782,   0.2918,   0.1415,   0.1413,   0.1268],\n",
      "         [  0.2498,   0.1963,   0.1288,   0.1301,   0.1390],\n",
      "         [  0.2281,   0.2246,   0.1014,   0.1320,   0.1152],\n",
      "         [  0.3099,   0.3195,   0.1616,   0.1551,   0.1571]]])\n",
      "[1.62870839]\n",
      "[1.5875119]\n",
      "[0.3298151]\n",
      "[1.40661871]\n",
      "[0.32525665]\n",
      "[0.84154561]\n",
      "[0.02968318]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7600, 0.8732, 0.7608, 0.9008, 0.6590, 0.7201, 0.9243],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.2724,   0.2702,   0.2532,   0.1388,   0.1323],\n",
      "         [  0.2961,   0.2822,   0.2754,   0.1033,   0.1243],\n",
      "         [  0.2418,   0.2257,   0.2052,   0.1240,   0.1277],\n",
      "         [  0.2782,   0.2918,   0.2747,   0.1413,   0.1268],\n",
      "         [  0.2498,   0.1963,   0.2137,   0.1301,   0.1390],\n",
      "         [  0.2281,   0.2246,   0.1926,   0.1320,   0.1152],\n",
      "         [  0.3099,   0.3195,   0.3062,   0.1551,   0.1571]]])\n",
      "[0.15075074]\n",
      "[0.08817591]\n",
      "[0.06964356]\n",
      "[1.01092688]\n",
      "[0.01894608]\n",
      "[0.35232043]\n",
      "[0.1039875]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7981, 0.9232, 0.5931, 0.9096, 0.6309, 0.6734, 0.9682],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.2724,   0.2702,   0.2532,   0.2627,   0.1323],\n",
      "         [  0.2961,   0.2822,   0.2754,   0.2478,   0.1243],\n",
      "         [  0.2418,   0.2257,   0.2052,   0.1959,   0.1277],\n",
      "         [  0.2782,   0.2918,   0.2747,   0.2853,   0.1268],\n",
      "         [  0.2498,   0.1963,   0.2137,   0.1955,   0.1390],\n",
      "         [  0.2281,   0.2246,   0.1926,   0.2142,   0.1152],\n",
      "         [  0.3099,   0.3195,   0.3062,   0.3131,   0.1571]]])\n",
      "[1.73425348]\n",
      "[1.57018927]\n",
      "[0.4615416]\n",
      "[1.35533556]\n",
      "[0.4581574]\n",
      "[1.18314176]\n",
      "[0.03481445]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9245, 0.9515, 0.8180, 0.9361, 0.8820, 0.8545, 0.9695],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.2724,   0.2702,   0.2532,   0.2627,   0.2784],\n",
      "         [  0.2961,   0.2822,   0.2754,   0.2478,   0.2789],\n",
      "         [  0.2418,   0.2257,   0.2052,   0.1959,   0.2411],\n",
      "         [  0.2782,   0.2918,   0.2747,   0.2853,   0.2774],\n",
      "         [  0.2498,   0.1963,   0.2137,   0.1955,   0.2759],\n",
      "         [  0.2281,   0.2246,   0.1926,   0.2142,   0.2381],\n",
      "         [  0.3099,   0.3195,   0.3062,   0.3131,   0.3153]]])\n",
      "[0.91670077]\n",
      "[0.73888932]\n",
      "[0.79302539]\n",
      "[1.04479031]\n",
      "[0.73228374]\n",
      "[0.85586826]\n",
      "[0.41792453]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8923, 0.9210, 0.9267, 0.9175, 0.8643, 0.7922, 0.9437],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.4134,   0.2702,   0.2532,   0.2627,   0.2784],\n",
      "         [  0.4447,   0.2822,   0.2754,   0.2478,   0.2789],\n",
      "         [  0.3849,   0.2257,   0.2052,   0.1959,   0.2411],\n",
      "         [  0.4215,   0.2918,   0.2747,   0.2853,   0.2774],\n",
      "         [  0.3855,   0.1963,   0.2137,   0.1955,   0.2759],\n",
      "         [  0.3385,   0.2246,   0.1926,   0.2142,   0.2381],\n",
      "         [  0.4645,   0.3195,   0.3062,   0.3131,   0.3153]]])\n",
      "[1.86145487]\n",
      "[1.51861001]\n",
      "[0.84629884]\n",
      "[1.56513154]\n",
      "[0.25156617]\n",
      "[1.07416911]\n",
      "[0.02086842]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9649, 0.9521, 0.9092, 0.9262, 0.7820, 0.8836, 0.9738],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.4134,   0.4235,   0.2532,   0.2627,   0.2784],\n",
      "         [  0.4447,   0.4320,   0.2754,   0.2478,   0.2789],\n",
      "         [  0.3849,   0.3695,   0.2052,   0.1959,   0.2411],\n",
      "         [  0.4215,   0.4380,   0.2747,   0.2853,   0.2774],\n",
      "         [  0.3855,   0.3178,   0.2137,   0.1955,   0.2759],\n",
      "         [  0.3385,   0.3591,   0.1926,   0.2142,   0.2381],\n",
      "         [  0.4645,   0.4789,   0.3062,   0.3131,   0.3153]]])\n",
      "[0.15147468]\n",
      "[0.11778679]\n",
      "[0.05467035]\n",
      "[0.53493621]\n",
      "[0.03015393]\n",
      "[0.52362401]\n",
      "[0.05105766]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9358, 0.9560, 0.8056, 0.9536, 0.7708, 0.8939, 0.9574],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.4134,   0.4235,   0.4053,   0.2627,   0.2784],\n",
      "         [  0.4447,   0.4320,   0.4306,   0.2478,   0.2789],\n",
      "         [  0.3849,   0.3695,   0.3336,   0.1959,   0.2411],\n",
      "         [  0.4215,   0.4380,   0.4294,   0.2853,   0.2774],\n",
      "         [  0.3855,   0.3178,   0.3296,   0.1955,   0.2759],\n",
      "         [  0.3385,   0.3591,   0.3312,   0.2142,   0.2381],\n",
      "         [  0.4645,   0.4789,   0.4636,   0.3131,   0.3153]]])\n",
      "[1.32432995]\n",
      "[0.21870187]\n",
      "[0.41661458]\n",
      "[1.50749058]\n",
      "[0.18137813]\n",
      "[0.63030705]\n",
      "[0.03422566]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9473, 0.9542, 0.9306, 0.9561, 0.8789, 0.8096, 0.9719],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.4134,   0.4235,   0.4053,   0.4191,   0.2784],\n",
      "         [  0.4447,   0.4320,   0.4306,   0.4048,   0.2789],\n",
      "         [  0.3849,   0.3695,   0.3336,   0.3486,   0.2411],\n",
      "         [  0.4215,   0.4380,   0.4294,   0.4426,   0.2774],\n",
      "         [  0.3855,   0.3178,   0.3296,   0.3351,   0.2759],\n",
      "         [  0.3385,   0.3591,   0.3312,   0.3389,   0.2381],\n",
      "         [  0.4645,   0.4789,   0.4636,   0.4740,   0.3153]]])\n",
      "[1.00447246]\n",
      "[1.04848191]\n",
      "[1.03643248]\n",
      "[1.02706106]\n",
      "[0.9797846]\n",
      "[0.86779999]\n",
      "[0.16226901]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9376, 0.9421, 0.9056, 0.9346, 0.8130, 0.9006, 0.9777],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.4134,   0.4235,   0.4053,   0.4191,   0.4279],\n",
      "         [  0.4447,   0.4320,   0.4306,   0.4048,   0.4294],\n",
      "         [  0.3849,   0.3695,   0.3336,   0.3486,   0.3850],\n",
      "         [  0.4215,   0.4380,   0.4294,   0.4426,   0.4199],\n",
      "         [  0.3855,   0.3178,   0.3296,   0.3351,   0.4005],\n",
      "         [  0.3385,   0.3591,   0.3312,   0.3389,   0.3802],\n",
      "         [  0.4645,   0.4789,   0.4636,   0.4740,   0.4743]]])\n",
      "[0.08763258]\n",
      "[0.05735593]\n",
      "[0.04264209]\n",
      "[1.05918316]\n",
      "[0.02122396]\n",
      "[0.28438902]\n",
      "[0.04140599]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8202, 0.8390, 0.8717, 0.8473, 0.8760, 0.7509, 0.9501],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.5362,   0.4235,   0.4053,   0.4191,   0.4279],\n",
      "         [  0.5568,   0.4320,   0.4306,   0.4048,   0.4294],\n",
      "         [  0.5126,   0.3695,   0.3336,   0.3486,   0.3850],\n",
      "         [  0.5456,   0.4380,   0.4294,   0.4426,   0.4199],\n",
      "         [  0.5217,   0.3178,   0.3296,   0.3351,   0.4005],\n",
      "         [  0.4413,   0.3591,   0.3312,   0.3389,   0.3802],\n",
      "         [  0.6164,   0.4789,   0.4636,   0.4740,   0.4743]]])\n",
      "[0.09461352]\n",
      "[0.0442874]\n",
      "[0.09818073]\n",
      "[0.50338873]\n",
      "[0.04037575]\n",
      "[0.15212996]\n",
      "[0.27100685]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8714, 0.9032, 0.8018, 0.8298, 0.8164, 0.6976, 0.9675],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.5362,   0.5579,   0.4053,   0.4191,   0.4279],\n",
      "         [  0.5568,   0.5689,   0.4306,   0.4048,   0.4294],\n",
      "         [  0.5126,   0.4912,   0.3336,   0.3486,   0.3850],\n",
      "         [  0.5456,   0.5670,   0.4294,   0.4426,   0.4199],\n",
      "         [  0.5217,   0.4305,   0.3296,   0.3351,   0.4005],\n",
      "         [  0.4413,   0.4599,   0.3312,   0.3389,   0.3802],\n",
      "         [  0.6164,   0.6357,   0.4636,   0.4740,   0.4743]]])\n",
      "[0.15080419]\n",
      "[0.08909571]\n",
      "[0.09755479]\n",
      "[0.36079898]\n",
      "[0.02271132]\n",
      "[0.35420229]\n",
      "[0.14253775]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8421, 0.7956, 0.7134, 0.7725, 0.7844, 0.5895, 0.9612],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.5362,   0.5579,   0.5333,   0.4191,   0.4279],\n",
      "         [  0.5568,   0.5689,   0.5524,   0.4048,   0.4294],\n",
      "         [  0.5126,   0.4912,   0.4386,   0.3486,   0.3850],\n",
      "         [  0.5456,   0.5670,   0.5420,   0.4426,   0.4199],\n",
      "         [  0.5217,   0.4305,   0.4344,   0.3351,   0.4005],\n",
      "         [  0.4413,   0.4599,   0.4127,   0.3389,   0.3802],\n",
      "         [  0.6164,   0.6357,   0.6197,   0.4740,   0.4743]]])\n",
      "[0.12940099]\n",
      "[0.06675622]\n",
      "[0.09235374]\n",
      "[0.35689947]\n",
      "[0.0253621]\n",
      "[0.30688407]\n",
      "[0.16710192]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.6986, 0.8622, 0.7454, 0.8669, 0.8773, 0.7800, 0.9783],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.5362,   0.5579,   0.5333,   0.5214,   0.4279],\n",
      "         [  0.5568,   0.5689,   0.5524,   0.5410,   0.4294],\n",
      "         [  0.5126,   0.4912,   0.4386,   0.4439,   0.3850],\n",
      "         [  0.5456,   0.5670,   0.5420,   0.5721,   0.4199],\n",
      "         [  0.5217,   0.4305,   0.4344,   0.4709,   0.4005],\n",
      "         [  0.4413,   0.4599,   0.4127,   0.4493,   0.3802],\n",
      "         [  0.6164,   0.6357,   0.6197,   0.6337,   0.4743]]])\n",
      "[0.07029603]\n",
      "[0.24464717]\n",
      "[0.0163489]\n",
      "[0.3198633]\n",
      "[0.05215768]\n",
      "[0.08488725]\n",
      "[0.96870946]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8634, 0.8190, 0.8260, 0.8389, 0.7849, 0.8943, 0.9487],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.5362,   0.5579,   0.5333,   0.5214,   0.5524],\n",
      "         [  0.5568,   0.5689,   0.5524,   0.5410,   0.5540],\n",
      "         [  0.5126,   0.4912,   0.4386,   0.4439,   0.4982],\n",
      "         [  0.5456,   0.5670,   0.5420,   0.5721,   0.5305],\n",
      "         [  0.5217,   0.4305,   0.4344,   0.4709,   0.5012],\n",
      "         [  0.4413,   0.4599,   0.4127,   0.4493,   0.5159],\n",
      "         [  0.6164,   0.6357,   0.6197,   0.6337,   0.6264]]])\n",
      "[0.13091599]\n",
      "[0.07334752]\n",
      "[0.07823339]\n",
      "[0.32334844]\n",
      "[0.01952754]\n",
      "[0.26788532]\n",
      "[0.10005937]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8961, 0.8332, 0.5096, 0.7289, 0.8864, 0.8770, 0.9349],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.6663,   0.5579,   0.5333,   0.5214,   0.5524],\n",
      "         [  0.6799,   0.5689,   0.5524,   0.5410,   0.5540],\n",
      "         [  0.5423,   0.4912,   0.4386,   0.4439,   0.4982],\n",
      "         [  0.6478,   0.5670,   0.5420,   0.5721,   0.5305],\n",
      "         [  0.6570,   0.4305,   0.4344,   0.4709,   0.5012],\n",
      "         [  0.5634,   0.4599,   0.4127,   0.4493,   0.5159],\n",
      "         [  0.7651,   0.6357,   0.6197,   0.6337,   0.6264]]])\n",
      "[0.08522691]\n",
      "[0.15789888]\n",
      "[0.02588735]\n",
      "[0.39712844]\n",
      "[0.07439873]\n",
      "[0.07620783]\n",
      "[0.98786029]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.7922, 0.8592, 0.4868, 0.8406, 0.8783, 0.6149, 0.9601],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.6663,   0.6797,   0.5333,   0.5214,   0.5524],\n",
      "         [  0.6799,   0.7017,   0.5524,   0.5410,   0.5540],\n",
      "         [  0.5423,   0.5245,   0.4386,   0.4439,   0.4982],\n",
      "         [  0.6478,   0.6911,   0.5420,   0.5721,   0.5305],\n",
      "         [  0.6570,   0.5642,   0.4344,   0.4709,   0.5012],\n",
      "         [  0.5634,   0.5354,   0.4127,   0.4493,   0.5159],\n",
      "         [  0.7651,   0.7884,   0.6197,   0.6337,   0.6264]]])\n",
      "[0.58977323]\n",
      "[0.21970921]\n",
      "[0.27124005]\n",
      "[0.43793328]\n",
      "[0.27141379]\n",
      "[0.57146329]\n",
      "[0.04819385]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9145, 0.8583, 0.6892, 0.8871, 0.8743, 0.8618, 0.9765],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.6663,   0.6797,   0.6758,   0.5214,   0.5524],\n",
      "         [  0.6799,   0.7017,   0.6889,   0.5410,   0.5540],\n",
      "         [  0.5423,   0.5245,   0.5219,   0.4439,   0.4982],\n",
      "         [  0.6478,   0.6911,   0.6755,   0.5721,   0.5305],\n",
      "         [  0.6570,   0.5642,   0.5725,   0.4709,   0.5012],\n",
      "         [  0.5634,   0.5354,   0.5366,   0.4493,   0.5159],\n",
      "         [  0.7651,   0.7884,   0.7794,   0.6337,   0.6264]]])\n",
      "[0.48612046]\n",
      "[0.1472635]\n",
      "[0.23670529]\n",
      "[0.48414001]\n",
      "[0.22888138]\n",
      "[0.44050232]\n",
      "[0.03540915]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8992, 0.8766, 0.5400, 0.9115, 0.8632, 0.7303, 0.9723],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.6663,   0.6797,   0.6758,   0.6622,   0.5524],\n",
      "         [  0.6799,   0.7017,   0.6889,   0.6784,   0.5540],\n",
      "         [  0.5423,   0.5245,   0.5219,   0.5015,   0.4982],\n",
      "         [  0.6478,   0.6911,   0.6755,   0.7137,   0.5305],\n",
      "         [  0.6570,   0.5642,   0.5725,   0.6012,   0.5012],\n",
      "         [  0.5634,   0.5354,   0.5366,   0.5512,   0.5159],\n",
      "         [  0.7651,   0.7884,   0.7794,   0.7917,   0.6264]]])\n",
      "[0.57643014]\n",
      "[0.21156527]\n",
      "[0.23331184]\n",
      "[0.59615867]\n",
      "[0.25297331]\n",
      "[0.46097798]\n",
      "[0.1156767]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8760, 0.8772, 0.0378, 0.6912, 0.8610, 0.7559, 0.9728],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.6663,   0.6797,   0.6758,   0.6622,   0.6846],\n",
      "         [  0.6799,   0.7017,   0.6889,   0.6784,   0.6856],\n",
      "         [  0.5423,   0.5245,   0.5219,   0.5015,   0.4673],\n",
      "         [  0.6478,   0.6911,   0.6755,   0.7137,   0.6237],\n",
      "         [  0.6570,   0.5642,   0.5725,   0.6012,   0.6336],\n",
      "         [  0.5634,   0.5354,   0.5366,   0.5512,   0.6211],\n",
      "         [  0.7651,   0.7884,   0.7794,   0.7917,   0.7833]]])\n",
      "[0.10715771]\n",
      "[0.33159249]\n",
      "[0.0197274]\n",
      "[0.382551]\n",
      "[0.0900454]\n",
      "[0.11822554]\n",
      "[0.92871586]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9567, 0.8587, 0.8067, 0.9281, 0.5900, 0.8749, 0.9704],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.8180,   0.6797,   0.6758,   0.6622,   0.6846],\n",
      "         [  0.8157,   0.7017,   0.6889,   0.6784,   0.6856],\n",
      "         [  0.6619,   0.5245,   0.5219,   0.5015,   0.4673],\n",
      "         [  0.7941,   0.6911,   0.6755,   0.7137,   0.6237],\n",
      "         [  0.7122,   0.5642,   0.5725,   0.6012,   0.6336],\n",
      "         [  0.6945,   0.5354,   0.5366,   0.5512,   0.6211],\n",
      "         [  0.9247,   0.7884,   0.7794,   0.7917,   0.7833]]])\n",
      "[1.41675444]\n",
      "[0.24371413]\n",
      "[0.44155784]\n",
      "[1.45378398]\n",
      "[0.26089476]\n",
      "[0.74008987]\n",
      "[0.14834033]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9067, 0.8935, 0.8809, 0.8907, 0.7977, 0.7969, 0.9539],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.8180,   0.8234,   0.6758,   0.6622,   0.6846],\n",
      "         [  0.8157,   0.8459,   0.6889,   0.6784,   0.6856],\n",
      "         [  0.6619,   0.6625,   0.5219,   0.5015,   0.4673],\n",
      "         [  0.7941,   0.8301,   0.6755,   0.7137,   0.6237],\n",
      "         [  0.7122,   0.6747,   0.5725,   0.6012,   0.6336],\n",
      "         [  0.6945,   0.6588,   0.5366,   0.5512,   0.6211],\n",
      "         [  0.9247,   0.9435,   0.7794,   0.7917,   0.7833]]])\n",
      "[0.10853332]\n",
      "[0.03323938]\n",
      "[0.10343785]\n",
      "[1.12715287]\n",
      "[0.02280728]\n",
      "[0.19340472]\n",
      "[0.14759011]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8891, 0.9157, 0.8950, 0.9405, 0.8916, 0.8023, 0.9625],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.8180,   0.8234,   0.8209,   0.6622,   0.6846],\n",
      "         [  0.8157,   0.8459,   0.8386,   0.6784,   0.6856],\n",
      "         [  0.6619,   0.6625,   0.6668,   0.5015,   0.4673],\n",
      "         [  0.7941,   0.8301,   0.8298,   0.7137,   0.6237],\n",
      "         [  0.7122,   0.6747,   0.6974,   0.6012,   0.6336],\n",
      "         [  0.6945,   0.6588,   0.6621,   0.5512,   0.6211],\n",
      "         [  0.9247,   0.9435,   0.9380,   0.7917,   0.7833]]])\n",
      "[0.92758152]\n",
      "[0.86330696]\n",
      "[0.68388785]\n",
      "[0.89206254]\n",
      "[0.91026449]\n",
      "[0.72562835]\n",
      "[0.19317769]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.8721, 0.7618, 0.9061, 0.9153, 0.5831, 0.6935, 0.9306],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.8180,   0.8234,   0.8209,   0.8019,   0.6846],\n",
      "         [  0.8157,   0.8459,   0.8386,   0.7986,   0.6856],\n",
      "         [  0.6619,   0.6625,   0.6668,   0.6450,   0.4673],\n",
      "         [  0.7941,   0.8301,   0.8298,   0.8624,   0.6237],\n",
      "         [  0.7122,   0.6747,   0.6974,   0.6730,   0.6336],\n",
      "         [  0.6945,   0.6588,   0.6621,   0.6533,   0.6211],\n",
      "         [  0.9247,   0.9435,   0.9380,   0.9437,   0.7833]]])\n",
      "[1.79186475]\n",
      "[1.85555563]\n",
      "[0.95505196]\n",
      "[1.41362753]\n",
      "[0.33102971]\n",
      "[1.36017382]\n",
      "[0.05831114]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "tensor([0.9207, 0.8904, 0.9067, 0.9356, 0.8385, 0.7727, 0.9440],\n",
      "       dtype=torch.float64, grad_fn=<RsubBackward1>)\n",
      "tensor([[[ -1.7148,  -1.1841, -20.9964,  -3.0956,  -1.5254],\n",
      "         [ -1.1192,  -3.2352, -10.8636,  -1.6272,  -1.4525],\n",
      "         [ -2.9225,  -2.0566, -73.8253, -14.5816,  -3.2874],\n",
      "         [ -1.1343,  -0.9854,  -2.0169, -16.7396,  -3.1631],\n",
      "         [ -3.1955,  -2.6328,  -1.0915,  -4.2357,  -2.9870],\n",
      "         [ -5.5799,  -9.3941, -12.7869, -17.9943,  -1.6477],\n",
      "         [  0.3381,  -0.1431,  -9.6709,  -3.2836,  -1.4765]],\n",
      "\n",
      "        [[  0.6268,   0.7248,   0.4370,   0.5294,   0.6726],\n",
      "         [  0.6315,   0.5897,   0.5674,   0.2527,   0.7083],\n",
      "         [  0.0954,   0.4934,  -0.2213,   0.3460,   0.4504],\n",
      "         [  0.6531,   0.7175,   0.5954,   0.7175,   0.5387],\n",
      "         [  0.4433,   0.5996,   0.3831,   0.2421,   0.6080],\n",
      "         [  0.2356,   0.5903,  -0.1425,   0.5323,   0.4959],\n",
      "         [  0.9316,   0.8929,   0.8679,   0.8475,   0.8997]],\n",
      "\n",
      "        [[  0.7759,   0.7179,   0.7851,   0.7509,   0.7398],\n",
      "         [  0.6716,   0.7077,   0.7590,   0.7598,   0.7297],\n",
      "         [  0.5927,   0.6307,   0.5341,   0.5282,   0.4528],\n",
      "         [  0.7462,   0.7643,   0.8024,   0.7871,   0.7086],\n",
      "         [  0.6062,   0.6770,   0.6747,   0.6971,   0.5769],\n",
      "         [  0.5458,   0.5308,   0.5548,   0.5677,   0.4823],\n",
      "         [  0.9115,   0.9076,   0.9236,   0.9124,   0.8768]],\n",
      "\n",
      "        [[  0.7599,   0.7748,   0.7682,   0.7339,   0.7985],\n",
      "         [  0.6832,   0.7200,   0.7480,   0.6997,   0.8210],\n",
      "         [  0.4343,   0.5658,   0.2892,   0.5553,   0.5600],\n",
      "         [  0.7432,   0.7796,   0.7531,   0.7550,   0.8365],\n",
      "         [  0.6222,   0.6793,   0.7085,   0.5369,   0.7334],\n",
      "         [  0.4786,   0.5967,   0.4421,   0.6346,   0.6028],\n",
      "         [  0.9055,   0.9360,   0.9006,   0.8910,   0.9115]],\n",
      "\n",
      "        [[  0.8138,   0.7265,   0.8510,   0.8324,   0.6764],\n",
      "         [  0.8285,   0.7598,   0.8276,   0.8099,   0.7236],\n",
      "         [  0.4826,   0.5615,   0.6888,   0.6575,   0.4296],\n",
      "         [  0.8369,   0.7837,   0.8300,   0.7883,   0.7506],\n",
      "         [  0.5904,   0.6486,   0.7523,   0.6774,   0.6660],\n",
      "         [  0.6566,   0.6234,   0.5971,   0.7226,   0.5693],\n",
      "         [  0.9327,   0.9207,   0.9364,   0.9339,   0.9118]],\n",
      "\n",
      "        [[  0.8180,   0.8234,   0.8209,   0.8019,   0.8323],\n",
      "         [  0.8157,   0.8459,   0.8386,   0.7986,   0.8284],\n",
      "         [  0.6619,   0.6625,   0.6668,   0.6450,   0.6114],\n",
      "         [  0.7941,   0.8301,   0.8298,   0.8624,   0.7737],\n",
      "         [  0.7122,   0.6747,   0.6974,   0.6730,   0.7603],\n",
      "         [  0.6945,   0.6588,   0.6621,   0.6533,   0.7391],\n",
      "         [  0.9247,   0.9435,   0.9380,   0.9437,   0.9383]]])\n",
      "[1.53329401]\n",
      "[1.61639087]\n",
      "[0.81647532]\n",
      "[1.36927962]\n",
      "[0.2425125]\n",
      "[0.91654456]\n",
      "[0.04919384]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mean = torch.tensor(R2_score.mean(axis=0))\n",
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_std = torch.tensor(R2_score.std(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "reps=5\n",
    "nn=[10,20,30,40,50,60]\n",
    "R2=torch.zeros(7,len(nn),7,reps)\n",
    "ISE=torch.zeros(7,len(nn),7,reps)\n",
    "Ti=torch.zeros(7,len(nn),reps)\n",
    "\n",
    "for num, n in enumerate(nn):\n",
    "    for k in range(len(emulators)):\n",
    "        emulators2=emulators.copy()\n",
    "        emulators2.pop(k)\n",
    "        print(len(emulators2))\n",
    "\n",
    "        X_train = train_input[k]\n",
    "        y_train = train_output[k]\n",
    "        X_test = test_input[k]\n",
    "        y_test = test_output[k]\n",
    "        \n",
    "        for i in range(reps):\n",
    "\n",
    "            b=np.random.choice(range(X_train.shape[0]),n,replace=False)\n",
    "\n",
    "            start = time.time()\n",
    "            model_f=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"linear\",training_iter=500)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_f.R2_sample(X_test,y_test,1000)\n",
    "            R2[0,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[0,num,:,i]+=model_f.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[0,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "\n",
    "            em=np.random.randint(len(emulators2))\n",
    "            start = time.time()\n",
    "            model_dc_1 = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=torch.tensor([[1],[1],[1],[1],[1],[1],[1]]))\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_1.R2_sample(X_test,y_test,1000)\n",
    "            R2[1,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[1,num,:,i]+=model_dc_1.ISE(X_test,y_test)/(len(emulators))\n",
    "            print(model_dc_1.R2(X_test,y_test))\n",
    "            print(R2[1])\n",
    "\n",
    "            Ti[1,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            m0 = emulators2[em].predict(X_train[b,:])\n",
    "            a_d=np.zeros((y_train.shape[1],1))\n",
    "            for l in range(y_train.shape[1]):\n",
    "                result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l), method='Nelder-Mead', tol=1e-8)\n",
    "                print(result.x)\n",
    "                a_d[l]=result.x\n",
    "            a_d=torch.tensor(a_d)\n",
    "            model_dc_reg = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]],a=a_d)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_reg.R2_sample(X_test,y_test,1000)\n",
    "            R2[2,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[2,num,:,i]+=model_dc_reg.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[2,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_learned = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=[emulators2[em]])\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_learned.R2_sample(X_test,y_test,1000)\n",
    "            R2[3,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[3,num,:,i]+=model_dc_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[3,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_all = GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_all.R2_sample(X_test,y_test,1000)\n",
    "            R2[4,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[4,num,:,i]+=model_dc_all.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[4,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            a_d=torch.zeros((y_train.shape[1],len(emulators2)))\n",
    "            for j in range(y_train.shape[1]):\n",
    "                m0=m0_mat(y_train[b],emulators2,X_train[b],j)\n",
    "                # fit to an order-3 polynomial data\n",
    "                y_t=(y_train[b,j]-y_train.mean(axis=0)[j])/y_train.std(axis=0)[j]\n",
    "                model = model.fit(m0.detach().numpy(), y_t.detach().numpy())\n",
    "                a_d[j]=torch.tensor(model.named_steps['lasso'].coef_)\n",
    "\n",
    "\n",
    "            model_dc_lasso=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_lasso.R2_sample(X_test,y_test,1000)\n",
    "            R2[5,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[5,num,:,i]+=model_dc_lasso.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[5,num,i]+=(end-start)/(len(emulators))\n",
    "\n",
    "            start = time.time()\n",
    "            model_dc_lasso_learned=GPE.ensemble(X_train[b,:],y_train[b,:],mean_func=\"discrepancy_cohort\",training_iter=500,ref_emulator=emulators2,a=a_d,a_indicator=True)\n",
    "            end = time.time()\n",
    "            R2temp,R2std=model_dc_lasso_learned.R2_sample(X_test,y_test,1000)\n",
    "            R2[6,num ,:,i]+=R2temp/(len(emulators))\n",
    "            ISE[6,num,:,i]+=model_dc_lasso_learned.ISE(X_test,y_test)/(len(emulators))\n",
    "\n",
    "            Ti[6,num,i]+=(end-start)/(len(emulators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ebdb207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o=2\n",
    "lim=2\n",
    "y_lim=[0.7,1.01]\n",
    "plt.plot(nn[lim:],R2.mean(axis=3)[:,lim:,o].T)\n",
    "#plt.ylim(y_lim)\n",
    "plt.legend(['$f_1$','$f_\\delta$, a=1','$f_\\delta$, regression a','$f_\\delta$, learned a','$f_{\\delta c}$, all','$f_{\\delta c}$, lasso','$f_{\\delta c}$, lasso indicator'])\n",
    "for i in range(7):\n",
    "    plt.fill_between(nn[lim:], R2.mean(axis=3)[i,lim:,o]+R2.std(axis=3)[i,lim:,o], R2.mean(axis=3)[i,lim:,o]-R2.std(axis=3)[i,lim:,o],alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b849cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_save = R2.reshape(7,len(nn)*reps*y_train.shape[1])\n",
    "\n",
    "np.savetxt(\"DiscrepR2TrainNVaryDefinitiveAtria.csv\", R2_save.detach().numpy(), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9d6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
