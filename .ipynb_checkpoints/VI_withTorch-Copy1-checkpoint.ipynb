{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2d8f72-376b-4f7b-b0e0-d1b70bafe8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "from matplotlib import pyplot as plt\n",
    "import GPE_ensemble as GPE\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from  torch.distributions import normal\n",
    "\n",
    "yobs = 8.0\n",
    "sigma2 = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd90672-e817-4cd8-8c99-611507c7f5b4",
   "metadata": {},
   "source": [
    "First we'll learn how to get the variational posterior for $x | y$ for a single value of y. We have\n",
    "$$y= 4x-x^2/2+N(0,\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350d8cd-93ad-464d-aceb-d676326f8bd2",
   "metadata": {},
   "source": [
    "## Variational inference\n",
    "\n",
    "Maximize the ELBO\n",
    "$$ELBO(q) = E[\\log p(y | x)] − KL (q(x)|| p(x)).$$\n",
    "\n",
    "We'll use $q(x) = N(m, s^2)$ as the variational family\n",
    "In this case, the ELBO can be computed exactly, but its a pain to do. So I've approximated the E[log p(y | x)] with a Monte Carlo sum.\n",
    "$\\Phi=(m, \\log s^2)$ are the variational parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e7d49-6e46-4465-8d7f-297c6fd1edae",
   "metadata": {},
   "source": [
    "KL (q(x) || p(x)) = E[log q(x)] − E[log p(x)]\n",
    "where expectations are with respect to q.\n",
    "\n",
    "Note, if $p(x) \\propto 1$, then $E\\log p(x)$ does not depend on $\\phi$ so can be ignored\n",
    "If $q(x) =N(m, \\sigma^2)$, then $E[\\log q(x)] = -0.5 \\log(2 \\pi \\sigma^2) - 1/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525b9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAd1UlEQVR4nO3df5BV9X34/9cFwy6Y3RuBwu4OC2yNqcFNNIBSjUZJI8EyVNOMo0YdSBunOPgDbaZKkxSw4pbEsZ2JCUbbIWQYf8y0g9GJWpk2YBylAkorptEQSXZH2BDEuRfJsNTlfP7wy36zYYFFOPd9l308Zs4fe+7Ze14ez3ifnnvu3UKWZVkAACQwJPUAAMDgJUQAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACCZU1IPcCQHDhyI7du3R11dXRQKhdTjAAD9kGVZ7NmzJ5qammLIkCNf86jqENm+fXs0NzenHgMA+AA6Ojpi3LhxR9ymqkOkrq4uIt7/B6mvr088DQDQH+VyOZqbm3tex4+kqkPk4Nsx9fX1QgQABpj+3FbhZlUAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyVT1F5oBAPnoPpDFS9t2x849+2JMXW2c1zIyhg6p/N91+8BXRJ577rmYPXt2NDU1RaFQiMcff7zX41mWxeLFi6OpqSmGDx8el1xySbz22mvHOy8AcJye2bIjLlz2n3HNQ+vj1kc3xzUPrY8Ll/1nPLNlR8Vn+cAhsnfv3jj77LPj/vvv7/Pxb37zm3HffffF/fffHxs2bIiGhoa49NJLY8+ePR94WADg+DyzZUfcuOrl2FHa12t9Z2lf3Ljq5YrHSCHLsuy4n6RQiNWrV8cVV1wREe9fDWlqaooFCxbEHXfcERERXV1dMXbs2Fi2bFn81V/9Vb+et1wuR7FYjFKp5G/NAMBx6j6QxYXL/vOQCDmoEBENxdp4/o7PHtfbNMfy+p3Lzarbtm2Lzs7OmDFjRs+6mpqauPjii+OFF1447O91dXVFuVzutQAAJ8ZL23YfNkIiIrKI2FHaFy9t212xmXIJkc7OzoiIGDt2bK/1Y8eO7XmsL21tbVEsFnuW5ubmPMYDgEFp557DR8gH2e5EyPXju7//53+zLDvinwReuHBhlEqlnqWjoyPP8QBgUBlTV3tCtzsRcvn4bkNDQ0S8f2WksbGxZ/3OnTsPuUryu2pqaqKmpiaPkQBg0DuvZWQ0Fmujs7Qv+rpB9OA9Iue1jKzYTLlcEWlpaYmGhoZYs2ZNz7r9+/fHunXr4oILLshjlwDAUQwdUohFsydFxPvR8bsO/rxo9qSKfp/IBw6Rd999NzZv3hybN2+OiPdvUN28eXO0t7dHoVCIBQsWxD333BOrV6+OLVu2xNy5c2PEiBHxpS996UTNDgAco5mtjbH8usnRUOz99ktDsTaWXzc5ZrY2HuY38/GBP767du3amD59+iHr58yZE9///vcjy7JYsmRJfO9734t33nknpk2bFt/5zneitbW13/vw8V0AyEee36x6LK/fJ+R7RPIiRABg4En+PSIAAP0hRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGRyDZH33nsvvv71r0dLS0sMHz48/vAP/zDuuuuuOHDgQJ67BQAGiFPyfPJly5bFAw88ECtXroyzzjorNm7cGF/+8pejWCzGrbfemueuAYABINcQefHFF+Pyyy+PWbNmRUTExIkT45FHHomNGzfmuVsAYIDI9a2ZCy+8MP7jP/4j3njjjYiI+O///u94/vnn40//9E/73L6rqyvK5XKvBQA4eeV6ReSOO+6IUqkUZ555ZgwdOjS6u7tj6dKlcc011/S5fVtbWyxZsiTPkQCAKpLrFZHHHnssVq1aFQ8//HC8/PLLsXLlyrj33ntj5cqVfW6/cOHCKJVKPUtHR0ee4wEAiRWyLMvyevLm5ua48847Y/78+T3r7r777li1alX87Gc/O+rvl8vlKBaLUSqVor6+Pq8xAYAT6Fhev3O9IvLb3/42hgzpvYuhQ4f6+C4AEBE53yMye/bsWLp0aYwfPz7OOuuseOWVV+K+++6Lv/iLv8hztwDAAJHrWzN79uyJb3zjG7F69erYuXNnNDU1xTXXXBN/93d/F8OGDTvq73trBgAGnmN5/c41RI6XEAGAgadq7hEBADgSIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACSTe4i89dZbcd1118WoUaNixIgRcc4558SmTZvy3i0AMACckueTv/POO/HpT386pk+fHk8//XSMGTMmfvGLX8RHPvKRPHcLAAwQuYbIsmXLorm5OVasWNGzbuLEiXnuEgAYQHJ9a+aJJ56IqVOnxpVXXhljxoyJT33qU/HQQw8ddvuurq4ol8u9FgDg5JVriLz55puxfPnyOOOMM+Lf//3fY968eXHLLbfED37wgz63b2tri2Kx2LM0NzfnOR4AkFghy7IsrycfNmxYTJ06NV544YWedbfcckts2LAhXnzxxUO27+rqiq6urp6fy+VyNDc3R6lUivr6+rzGBABOoHK5HMVisV+v37leEWlsbIxJkyb1Wvfxj3882tvb+9y+pqYm6uvrey0AwMkr1xD59Kc/Ha+//nqvdW+88UZMmDAhz90CAANEriFy2223xfr16+Oee+6JrVu3xsMPPxwPPvhgzJ8/P8/dAgADRK4hcu6558bq1avjkUceidbW1vj7v//7+Kd/+qe49tpr89wtADBA5Hqz6vE6lptdAIDqUDU3qwIAHIkQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkqlYiLS1tUWhUIgFCxZUapcAQJWrSIhs2LAhHnzwwfjkJz9Zid0BAANE7iHy7rvvxrXXXhsPPfRQnHbaaXnvDgAYQHIPkfnz58esWbPic5/73FG37erqinK53GsBAE5ep+T55I8++mi8/PLLsWHDhn5t39bWFkuWLMlzJACgiuR2RaSjoyNuvfXWWLVqVdTW1vbrdxYuXBilUqln6ejoyGs8AKAKFLIsy/J44scffzy+8IUvxNChQ3vWdXd3R6FQiCFDhkRXV1evx/pSLpejWCxGqVSK+vr6PMYEAE6wY3n9zu2tmT/5kz+JV199tde6L3/5y3HmmWfGHXfccdQIAQBOfrmFSF1dXbS2tvZad+qpp8aoUaMOWQ8ADE6+WRUASCbXT838vrVr11ZydwBAlXNFBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkTkk9ADD4dB/I4qVtu2Pnnn0xpq42zmsZGUOHFFKPBSQgRICKembLjljy5E9jR2lfz7rGYm0smj0pZrY2JpwMSMFbM0DFPLNlR9y46uVeERIR0VnaFzeuejme2bIj0WRAKkIEqIjuA1ksefKnkfXx2MF1S578aXQf6GsL4GQlRICKeGnb7kOuhPyuLCJ2lPbFS9t2V24oIDkhAlTEzj2Hj5APsh1wchAiQEWMqas9odsBJwchAlTEeS0jo7FYG4f7kG4h3v/0zHktIys5FpCYEAEqYuiQQiyaPSki4pAYOfjzotmTfJ8IDDJCBKiYma2Nsfy6ydFQ7P32S0OxNpZfN9n3iMAg5AvNgIqa2doYl05q8M2qQEQIESCBoUMKcf7po1KPAVQBb80AAMnkGiJtbW1x7rnnRl1dXYwZMyauuOKKeP311/PcJQAwgOQaIuvWrYv58+fH+vXrY82aNfHee+/FjBkzYu/evXnuFgAYIApZllXsDzv85je/iTFjxsS6deviM5/5zFG3L5fLUSwWo1QqRX19fQUmBACO17G8flf0ZtVSqRQRESNH9v2FRV1dXdHV1dXzc7lcrshcAEAaFbtZNcuyuP322+PCCy+M1tbWPrdpa2uLYrHYszQ3N1dqPAAggYq9NTN//vz40Y9+FM8//3yMGzeuz236uiLS3NzsrRkAGECq7q2Zm2++OZ544ol47rnnDhshERE1NTVRU1NTiZEAgCqQa4hkWRY333xzrF69OtauXRstLS157g4AGGByDZH58+fHww8/HD/84Q+jrq4uOjs7IyKiWCzG8OHD89w1ADAA5HqPSKHQ99+OWLFiRcydO/eov+/juwAw8FTNPSIV/IoSAGAA8rdmAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZCoSIt/97nejpaUlamtrY8qUKfGTn/ykErsFAKpc7iHy2GOPxYIFC+JrX/tavPLKK3HRRRfFZZddFu3t7XnvGgCocoUsy7I8dzBt2rSYPHlyLF++vGfdxz/+8bjiiiuira3tiL9bLpejWCxGqVSK+vr6PMcEAE6QY3n9zvWKyP79+2PTpk0xY8aMXutnzJgRL7zwwiHbd3V1Rblc7rUAACevXENk165d0d3dHWPHju21fuzYsdHZ2XnI9m1tbVEsFnuW5ubmPMcDABKryM2qhUKh189Zlh2yLiJi4cKFUSqVepaOjo5KjAcAJHJKnk8+evToGDp06CFXP3bu3HnIVZKIiJqamqipqclzJACgiuR6RWTYsGExZcqUWLNmTa/1a9asiQsuuCDPXQMAA0CuV0QiIm6//fa4/vrrY+rUqXH++efHgw8+GO3t7TFv3ry8dw0AVLncQ+Sqq66Kt99+O+66667YsWNHtLa2xlNPPRUTJkzIe9cAQJXL/XtEjofvEQGAgadqvkcEAOBIhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJBMbiHyy1/+Mv7yL/8yWlpaYvjw4XH66afHokWLYv/+/XntEgAYYE7J64l/9rOfxYEDB+J73/tefPSjH40tW7bEDTfcEHv37o177703r90CAANIIcuyrFI7+9a3vhXLly+PN998s1/bl8vlKBaLUSqVor6+PufpAIAT4Vhev3O7ItKXUqkUI0eOPOzjXV1d0dXV1fNzuVyuxFgAQCIVu1n1F7/4RXz729+OefPmHXabtra2KBaLPUtzc3OlxgMAEjjmEFm8eHEUCoUjLhs3buz1O9u3b4+ZM2fGlVdeGV/5ylcO+9wLFy6MUqnUs3R0dBz7PxEAMGAc8z0iu3btil27dh1xm4kTJ0ZtbW1EvB8h06dPj2nTpsX3v//9GDKk/+3jHhEAGHhyvUdk9OjRMXr06H5t+9Zbb8X06dNjypQpsWLFimOKEADg5Jfbzarbt2+PSy65JMaPHx/33ntv/OY3v+l5rKGhIa/dAgADSG4h8uyzz8bWrVtj69atMW7cuF6PVfATwwBAFcvtvZK5c+dGlmV9LgAAEf7WDACQkBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQjBABAJIRIgBAMkIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSqUiIdHV1xTnnnBOFQiE2b95ciV0CAANARULkb/7mb6KpqakSuwIABpDcQ+Tpp5+OZ599Nu699968dwUADDCn5Pnkv/71r+OGG26Ixx9/PEaMGHHU7bu6uqKrq6vn53K5nOd4AEBiuV0RybIs5s6dG/PmzYupU6f263fa2tqiWCz2LM3NzXmNBwBUgWMOkcWLF0ehUDjisnHjxvj2t78d5XI5Fi5c2O/nXrhwYZRKpZ6lo6PjWMcDAAaQQpZl2bH8wq5du2LXrl1H3GbixIlx9dVXx5NPPhmFQqFnfXd3dwwdOjSuvfbaWLly5VH3VS6Xo1gsRqlUivr6+mMZEwBI5Fhev485RPqrvb291z0e27dvj89//vPxr//6rzFt2rQYN27cUZ9DiADAwHMsr9+53aw6fvz4Xj9/+MMfjoiI008/vV8RAgCc/HyzKgCQTK4f3/1dEydOjJzeBQIABihXRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJCBEAIBkhAgAkI0QAgGSECACQTMW+4r2adB/I4qVtu2Pnnn0xpq42zmsZGUOHFFKPBQCDzqALkWe27IglT/40dpT29axrLNbGotmTYmZrY8LJAGDwGVRvzTyzZUfcuOrlXhESEdFZ2hc3rno5ntmyI9FkADA4DZoQ6T6QxZInfxp9/f3fg+uWPPnT6D7gLwQDQKUMmhB5advuQ66E/K4sInaU9sVL23ZXbigAGOQGTYjs3HP4CPkg2wEAx2/QhMiYutoTuh0AcPwGTYic1zIyGou1cbgP6Rbi/U/PnNcyspJjAcCgNmhCZOiQQiyaPSki4pAYOfjzotmTfJ8IAFTQoAmRiIiZrY2x/LrJ0VDs/fZLQ7E2ll832feIAECFDbovNJvZ2hiXTmrwzaoAUAUGXYhEvP82zfmnj0o9BgAMeoPqrRkAoLoIEQAgGSECACQjRACAZIQIAJCMEAEAkhEiAEAyQgQASEaIAADJVPU3q2ZZFhER5XI58SQAQH8dfN0++Dp+JFUdInv27ImIiObm5sSTAADHas+ePVEsFo+4TSHrT64kcuDAgdi+fXvU1dVFoXBi/yhduVyO5ubm6OjoiPr6+hP63Ccbx6r/HKv+c6z6z7E6No5X/+V1rLIsiz179kRTU1MMGXLku0Cq+orIkCFDYty4cbnuo76+3onaT45V/zlW/edY9Z9jdWwcr/7L41gd7UrIQW5WBQCSESIAQDKDNkRqampi0aJFUVNTk3qUqudY9Z9j1X+OVf85VsfG8eq/ajhWVX2zKgBwchu0V0QAgPSECACQjBABAJIRIgBAMoMyRJYuXRoXXHBBjBgxIj7ykY/0uU17e3vMnj07Tj311Bg9enTccsstsX///soOWoUmTpwYhUKh13LnnXemHqtqfPe7342Wlpaora2NKVOmxE9+8pPUI1WdxYsXH3IONTQ0pB6rKjz33HMxe/bsaGpqikKhEI8//nivx7Msi8WLF0dTU1MMHz48LrnkknjttdfSDJvY0Y7V3LlzDznP/viP/zjNsIm1tbXFueeeG3V1dTFmzJi44oor4vXXX++1Tcpza1CGyP79++PKK6+MG2+8sc/Hu7u7Y9asWbF37954/vnn49FHH41/+7d/i7/+67+u8KTV6a677oodO3b0LF//+tdTj1QVHnvssViwYEF87Wtfi1deeSUuuuiiuOyyy6K9vT31aFXnrLPO6nUOvfrqq6lHqgp79+6Ns88+O+6///4+H//mN78Z9913X9x///2xYcOGaGhoiEsvvbTn73INJkc7VhERM2fO7HWePfXUUxWcsHqsW7cu5s+fH+vXr481a9bEe++9FzNmzIi9e/f2bJP03MoGsRUrVmTFYvGQ9U899VQ2ZMiQ7K233upZ98gjj2Q1NTVZqVSq4ITVZ8KECdk//uM/ph6jKp133nnZvHnzeq0788wzszvvvDPRRNVp0aJF2dlnn516jKoXEdnq1at7fj5w4EDW0NCQ/cM//EPPun379mXFYjF74IEHEkxYPX7/WGVZls2ZMye7/PLLk8xT7Xbu3JlFRLZu3bosy9KfW4PyisjRvPjii9Ha2hpNTU096z7/+c9HV1dXbNq0KeFk1WHZsmUxatSoOOecc2Lp0qXesor3r7Jt2rQpZsyY0Wv9jBkz4oUXXkg0VfX6+c9/Hk1NTdHS0hJXX311vPnmm6lHqnrbtm2Lzs7OXudYTU1NXHzxxc6xw1i7dm2MGTMmPvaxj8UNN9wQO3fuTD1SVSiVShERMXLkyIhIf25V9R+9S6WzszPGjh3ba91pp50Ww4YNi87OzkRTVYdbb701Jk+eHKeddlq89NJLsXDhwti2bVv88z//c+rRktq1a1d0d3cfct6MHTt20J8zv2/atGnxgx/8ID72sY/Fr3/967j77rvjggsuiNdeey1GjRqVeryqdfA86usc+9WvfpVipKp22WWXxZVXXhkTJkyIbdu2xTe+8Y347Gc/G5s2bRrU37iaZVncfvvtceGFF0Zra2tEpD+3TporIn3dAPf7y8aNG/v9fIVC4ZB1WZb1uX6gO5Zjd9ttt8XFF18cn/zkJ+MrX/lKPPDAA/Ev//Iv8fbbbyf+p6gOv39+nKznzPG47LLL4otf/GJ84hOfiM997nPxox/9KCIiVq5cmXiygcE51j9XXXVVzJo1K1pbW2P27Nnx9NNPxxtvvNFzvg1WN910U/zP//xPPPLII4c8lurcOmmuiNx0001x9dVXH3GbiRMn9uu5Ghoa4r/+6796rXvnnXfi//7v/w4pxpPB8Ry7g3ehb926dVD/3+zo0aNj6NChh1z92Llz50l5zpxIp556anziE5+In//856lHqWoHP1nU2dkZjY2NPeudY/3T2NgYEyZMGNTn2c033xxPPPFEPPfcczFu3Lie9anPrZMmREaPHh2jR48+Ic91/vnnx9KlS2PHjh09/1KeffbZqKmpiSlTppyQfVST4zl2r7zySkREr5N3MBo2bFhMmTIl1qxZE1/4whd61q9ZsyYuv/zyhJNVv66urvjf//3fuOiii1KPUtVaWlqioaEh1qxZE5/61Kci4v17k9atWxfLli1LPF31e/vtt6Ojo2NQ/rcqy7K4+eabY/Xq1bF27dpoaWnp9Xjqc+ukCZFj0d7eHrt374729vbo7u6OzZs3R0TERz/60fjwhz8cM2bMiEmTJsX1118f3/rWt2L37t3x1a9+NW644Yaor69PO3xCL774Yqxfvz6mT58exWIxNmzYELfddlv82Z/9WYwfPz71eMndfvvtcf3118fUqVPj/PPPjwcffDDa29tj3rx5qUerKl/96ldj9uzZMX78+Ni5c2fcfffdUS6XY86cOalHS+7dd9+NrVu39vy8bdu22Lx5c4wcOTLGjx8fCxYsiHvuuSfOOOOMOOOMM+Kee+6JESNGxJe+9KWEU6dxpGM1cuTIWLx4cXzxi1+MxsbG+OUvfxl/+7d/G6NHj+71PwqDxfz58+Phhx+OH/7wh1FXV9dz5bZYLMbw4cOjUCikPbdy/1xOFZozZ04WEYcsP/7xj3u2+dWvfpXNmjUrGz58eDZy5Mjspptuyvbt25du6CqwadOmbNq0aVmxWMxqa2uzP/qjP8oWLVqU7d27N/VoVeM73/lONmHChGzYsGHZ5MmTez4ex//vqquuyhobG7MPfehDWVNTU/bnf/7n2WuvvZZ6rKrw4x//uM//Ns2ZMyfLsvc/Zrlo0aKsoaEhq6mpyT7zmc9kr776atqhEznSsfrtb3+bzZgxI/uDP/iD7EMf+lA2fvz4bM6cOVl7e3vqsZPo6zhFRLZixYqebVKeW4X/b0gAgIo7aT41AwAMPEIEAEhGiAAAyQgRACAZIQIAJCNEAIBkhAgAkIwQAQCSESIAQDJCBABIRogAAMkIEQAgmf8Hue1WJnkqpYMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p=3\n",
    "\n",
    "rl = -10\n",
    "ru=20\n",
    "\n",
    "obs_error = 0.001\n",
    "\n",
    "x=torch.linspace(rl,ru,p)\n",
    "\n",
    "b=0.5\n",
    "\n",
    "def lin(x):\n",
    "    y = b*x\n",
    "    return y\n",
    "\n",
    "y = lin(x) \n",
    "\n",
    "plt.plot(x[:,None],y[:,None],'o')\n",
    "\n",
    "emulator = GPE.ensemble(x[:,None],y[:,None],mean_func=\"constant\",training_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcf85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4739272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(m,log_s2,x,emulator,y,prior_mean,prior_cov,obs_error):\n",
    "    param=[m,log_s2]\n",
    "    L=torch.zeros((x.shape[0],x.shape[0]))\n",
    "    mu = torch.tensor((param[0:x.shape[0]]))\n",
    "    L=L.diagonal_scatter(torch.exp(torch.tensor(param[x.shape[0]:2*x.shape[0]])),0)\n",
    "    #L[1,0]=param[6]\n",
    "   # L[2,0]=param[7]\n",
    "   # L[2,1] =param[8]\n",
    "    covar = torch.matmul(L,L.T)\n",
    "    z=x*torch.exp(log_s2/2.)+m\n",
    "    \n",
    "    z=z.T\n",
    "    \n",
    "    mc_int = torch.sum(emulator.ensemble_log_likelihood_obs_error(z,y,obs_error)+torch.log(x_prior(z,prior_mean,prior_cov)).squeeze())\n",
    "        #mc_int +=-np.log(np.sum(((emulator.predict(z.iloc[[i]]).detach().numpy()-y.values)**2)))+np.log(x_prior(z.iloc[[i]],prior_mean,prior_cov))\n",
    "        #mc_int += (np.sum(np.log(emulator.ensemble_likelihood(z.iloc[[i]],y)))+np.log(x_prior(z.iloc[[i]],prior_mean,prior_cov)))\n",
    "    \n",
    "    lb = mc_int/x.shape[1] - q_prior(covar)\n",
    "    #print(mc_int/x.shape[1])\n",
    "    #print(-q_prior(covar))\n",
    "    #print(np.mean(z,axis=0))\n",
    "    #print(-lb)\n",
    "    return -lb\n",
    "\n",
    "def x_prior(x,mean,cov):\n",
    "\n",
    "    #var = scipy.stats.multivariate_normal(mean=mean, cov=cov)\n",
    "    #val1 = var.pdf(x)\n",
    "    dist = normal.Normal(loc=mean, scale=torch.sqrt(cov))\n",
    "    val = torch.exp(dist.log_prob(x))\n",
    "    return val\n",
    "\n",
    "def q_prior(covar):\n",
    "    qp = -(covar.shape[0]/2)*(1+torch.log(torch.tensor(2*torch.pi)))-0.5*torch.log(torch.linalg.det(covar))\n",
    "    return qp\n",
    "\n",
    "def f_likelihood(x,y,f,sigma2):\n",
    "    \n",
    "    likelihood_manual=-0.5*((f(x) - y)**2)/(sigma2)- 0.5*torch.log(2*np.pi)-0.5*torch.log(sigma2)\n",
    "    return likelihood_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa68f655-7ebf-4b2f-b77a-cb88572bcecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(log_var):   \n",
    "    return(-0.5*np.log(2.0*math.pi)-0.5*log_var-0.5)\n",
    "\n",
    "def f(x):\n",
    "    return(4.*x-0.5*torch.pow(x,2.))\n",
    "# How do we define functions? x needs declaring?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ZtoX(m, log_s2):\n",
    "    #reparameterization trick\n",
    "    return(Z*torch.exp(log_s2/2.)+m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56c5ab3e-19a1-4afb-bd58-5a6c8ed37629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_dnorm(x, mean, var):\n",
    "    return(-(x-mean).pow(2)/(2.*var)-0.5*np.log(2*math.pi*var))\n",
    "    # checked - could used built-in torch dnorm\n",
    "\n",
    "\n",
    "\n",
    "def Eloglike(m,log_s2):\n",
    "    X= ZtoX(m, log_s2)\n",
    "    \n",
    "    #print(X)\n",
    "    #Rewrite with f\n",
    "    loglikes = log_dnorm(f(X), yobs, sigma2) # observation likelihood\n",
    "    #-(yobs- 4.*X+0.5*X.pow(2)).pow(2)    #f(ZtoX(phi)),2.)\n",
    "    \n",
    "    return(loglikes.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db3cdd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_mean=torch.tensor([0])\n",
    "prior_cov = torch.tensor([5])\n",
    "obs_error = 0.1\n",
    "y_cal = torch.tensor([5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize the variational parameters\n",
    "m = torch.full((), 1.,dtype=dtype, requires_grad=True, device=device)\n",
    "log_s2 = torch.full((),torch.log(torch.tensor(3.)), requires_grad=True, device=device)\n",
    "\n",
    "\n",
    "# Samples fixed here - but try adding them into the loop\n",
    "nsamples = 1000\n",
    "#Z = torch.randn((nsamples), dtype=dtype, requires_grad=False, device=device)\n",
    "\n",
    "\n",
    "learning_rate = 1e-2\n",
    "for t in range(10000):\n",
    "    Z = torch.randn((nsamples), dtype=dtype, requires_grad=False, device=device)\n",
    "    Z=Z[None,:]\n",
    "    #negELBO = -Eloglike(m,log_s2)+KL(log_s2)\n",
    "    \n",
    "    param = [m,log_s2]\n",
    "    \n",
    "    negELBO = ELBO(m,log_s2,Z,emulator,y_cal[:,None],prior_mean,prior_cov,obs_error)\n",
    "    \n",
    "    if t % 100 == 99:\n",
    "        print(t, negELBO.item(), 'm=', m.item(), 's2=', log_s2.exp().item())\n",
    "    \n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    negELBO.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        m -= learning_rate * m.grad\n",
    "        log_s2 -= learning_rate * log_s2.grad\n",
    "        \n",
    "        # Manually zero the gradients after updating weights\n",
    "        m.grad = None\n",
    "        log_s2.grad = None\n",
    "        \n",
    "print(f'Result: p(x|y) = N({m.item()}, {log_s2.exp().item()}) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9484bd82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L=torch.zeros((Z.shape[0],Z.shape[0]))\n",
    "mu = torch.tensor((param[0:Z.shape[0]]))\n",
    "L=L.diagonal_scatter(torch.exp(torch.tensor(param[Z.shape[0]:2*Z.shape[0]])),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e57dfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7770e-02,  9.8429e-01,  7.8432e-01, -1.2257e+00,  3.2777e+00,\n",
       "          8.7271e-01,  6.4811e+00,  2.1063e+00, -2.7562e+00, -5.0316e+00,\n",
       "         -3.9615e+00, -1.2739e+00, -1.3578e-01,  3.8392e+00, -2.8376e+00,\n",
       "         -3.3461e+00,  2.9253e-01, -4.1949e+00,  3.9792e+00, -1.2563e+00,\n",
       "          2.4067e+00,  1.4164e+00,  5.3606e+00,  5.4379e+00,  2.3384e+00,\n",
       "          1.1315e+00, -2.6295e+00,  6.4483e-02,  4.4818e+00, -1.7573e-01,\n",
       "         -9.7180e-01, -2.7055e+00, -5.3464e+00,  3.7005e+00,  1.1657e+00,\n",
       "          2.1279e+00, -5.5671e-01,  2.5462e+00,  3.1479e+00, -3.4215e-01,\n",
       "         -8.3697e+00, -2.1252e+00, -3.5048e+00, -4.9205e-01,  1.6714e+00,\n",
       "         -6.0649e+00, -4.5758e+00, -1.7750e-01,  4.4920e-01,  3.4155e+00,\n",
       "         -6.1457e-01,  1.0687e+00, -2.2057e+00, -7.7398e-01,  3.2858e+00,\n",
       "          1.9600e+00, -2.1092e+00, -4.6666e+00, -3.8906e+00, -2.4324e+00,\n",
       "          1.8219e+00, -3.6936e+00, -2.3147e+00, -2.4183e+00, -1.9653e+00,\n",
       "         -3.2578e+00,  3.4888e+00,  4.3714e+00, -1.8261e+00, -4.3563e+00,\n",
       "          4.9362e+00, -5.5975e+00,  7.4125e-01,  2.1173e+00,  3.5393e+00,\n",
       "          4.0001e+00,  7.1557e+00, -3.5551e+00,  1.8211e+00, -9.7665e-01,\n",
       "          1.2253e+00,  1.8880e-01,  3.1143e+00, -2.5989e+00,  1.8923e+00,\n",
       "          3.1881e+00, -2.6787e+00, -2.7222e+00, -3.6048e+00, -3.9258e-01,\n",
       "         -8.7305e-01,  1.1259e+00, -4.7918e-01,  3.3918e+00,  3.8708e-01,\n",
       "          7.8472e-02,  1.3605e+00,  4.0758e+00, -3.6536e+00,  7.0047e-01,\n",
       "         -1.4536e+00,  3.1379e+00, -2.1750e+00,  2.4271e+00, -3.9501e-01,\n",
       "          3.5234e+00, -1.6116e+00,  3.0906e-01, -7.3619e-01,  1.7999e+00,\n",
       "         -5.7982e-01, -9.7069e-01, -3.8503e+00,  4.7681e+00,  2.5467e+00,\n",
       "          1.4752e+00, -1.1807e-01,  2.2482e+00,  3.1040e+00,  1.6924e+00,\n",
       "         -1.6280e+00,  7.2681e-01, -4.1292e+00,  4.5370e+00, -3.3324e+00,\n",
       "          7.8722e-01, -3.2548e+00,  8.5014e-02, -4.7709e+00, -3.2880e+00,\n",
       "          3.9101e-01,  2.8416e-01, -3.1047e+00,  1.4806e+00, -3.7545e+00,\n",
       "          2.1367e+00, -4.4259e-02,  3.5727e+00, -2.3290e+00,  2.8915e+00,\n",
       "         -3.5624e+00,  3.9342e+00, -1.2326e+00,  2.7186e+00, -4.3953e+00,\n",
       "         -6.2855e-01,  3.1612e+00, -3.1811e+00,  9.0650e+00,  6.7221e+00,\n",
       "         -4.7898e+00, -3.1703e-01,  3.3084e+00, -4.3970e-01,  2.1075e+00,\n",
       "         -1.9294e+00, -1.1570e+00,  9.1808e-02,  3.1723e+00,  4.8143e+00,\n",
       "          3.7229e-01,  2.0401e+00,  2.9103e-01,  1.5663e+00, -3.2935e+00,\n",
       "         -3.5473e+00, -1.5093e+00, -3.7457e-01, -2.3121e+00,  4.9017e+00,\n",
       "          7.2680e-01,  4.9301e-01,  1.7376e+00, -2.2077e+00,  4.8443e-01,\n",
       "         -1.4426e+00,  3.7682e+00, -3.3830e-01, -4.7430e+00,  2.3324e-01,\n",
       "         -5.3457e+00,  5.2737e-02,  6.4294e-01, -4.8037e+00,  1.2207e+00,\n",
       "          5.2380e+00,  4.7943e-01,  2.6498e-01, -2.2052e+00,  5.1786e-01,\n",
       "          4.1492e+00, -2.4064e+00,  5.5800e+00, -2.5358e+00,  6.1714e-02,\n",
       "          3.1682e+00, -8.3710e-01,  4.2375e+00,  2.2808e+00,  2.8497e+00,\n",
       "          3.1208e+00, -1.8582e-01,  2.4888e-01,  1.8536e+00,  4.7437e+00,\n",
       "         -1.5632e+00,  1.1187e+00, -9.5082e-01,  2.6456e+00, -8.3885e+00,\n",
       "          4.0996e-01,  2.1667e+00, -3.8237e+00,  3.0764e+00, -3.7959e-02,\n",
       "          3.8033e+00, -1.5346e+00,  4.1537e+00, -6.0904e-01, -1.5419e+00,\n",
       "          6.3398e+00, -8.9494e+00, -2.7961e-01,  6.1526e-02,  4.9582e+00,\n",
       "         -3.5825e+00,  7.4677e-01, -1.5267e+00,  1.5842e+00, -2.5091e-01,\n",
       "          1.1543e+00,  3.3809e+00, -1.1939e+00, -6.2877e+00,  1.9392e+00,\n",
       "          4.9278e+00,  4.7414e-01,  2.9367e+00, -3.3951e+00,  1.0850e+00,\n",
       "          4.9995e-01,  2.6637e+00, -3.1159e+00,  3.3735e+00,  5.4817e-01,\n",
       "         -3.8119e+00, -9.0264e-01, -9.1467e-01, -1.0525e-01,  3.9995e-01,\n",
       "          2.3055e+00, -4.7966e+00,  3.2771e+00,  1.2911e+00,  6.4578e+00,\n",
       "          3.2950e+00,  4.4238e+00,  1.0651e-01, -9.1854e-03,  3.0142e+00,\n",
       "          7.1981e-01, -4.0944e+00,  2.3189e-01, -1.8532e+00,  1.1951e+00,\n",
       "          3.3163e-01,  2.5650e+00, -2.2378e+00, -7.5679e-01, -2.6145e+00,\n",
       "          2.3989e+00,  3.8299e-01,  2.0464e-01,  1.0127e+00, -1.4484e+00,\n",
       "         -3.6738e+00, -2.0346e+00,  2.3856e+00,  6.3623e-01, -8.8040e+00,\n",
       "          4.2172e+00,  1.5135e+00,  1.0428e+00, -1.3047e+00, -3.0580e+00,\n",
       "         -5.5880e-01, -2.1686e+00,  5.8574e-01,  1.2991e+00, -4.0482e+00,\n",
       "          5.5548e+00,  1.7915e-01,  2.2129e+00,  1.9066e+00, -4.8042e+00,\n",
       "          4.3107e-01,  4.2767e+00, -8.5638e-01, -2.3152e+00,  2.2053e+00,\n",
       "          1.9132e+00,  4.0331e+00, -4.4671e+00, -4.9998e+00, -7.3813e-01,\n",
       "          6.0645e-01,  1.5426e+00,  4.5159e-01,  2.3295e+00, -5.4653e-01,\n",
       "         -2.4321e+00,  2.1846e+00,  1.0188e+00,  8.2165e+00, -5.0296e+00,\n",
       "         -3.6419e+00,  3.1007e+00,  6.3645e+00,  6.7570e+00,  2.0380e+00,\n",
       "          3.6594e+00, -3.5573e+00,  3.4370e+00, -8.4639e-01,  5.3755e+00,\n",
       "         -2.9084e-01, -1.9799e+00, -5.4841e-01,  1.6517e+00,  5.3310e+00,\n",
       "         -5.1312e-01, -2.1550e+00, -3.8714e-01,  7.4792e-02, -8.5438e-01,\n",
       "          2.1475e+00, -1.9769e+00,  3.5414e+00, -1.7619e+00, -9.9500e-01,\n",
       "          9.8931e-01,  6.8336e-02, -9.7013e-01, -2.4131e+00,  4.2566e-01,\n",
       "         -1.0248e+00,  7.0402e+00,  8.3480e-01,  6.1660e-02, -2.6576e+00,\n",
       "          2.9665e+00, -6.3875e+00, -1.6298e+00,  1.8898e+00, -5.0571e+00,\n",
       "          2.2333e+00, -2.8338e+00,  2.3351e+00,  4.7357e+00, -4.3169e+00,\n",
       "         -7.5926e-01, -1.2891e+00,  2.3827e+00, -3.3127e+00,  1.3383e+00,\n",
       "          3.9609e+00, -1.6316e+00, -1.6215e+00, -2.2298e+00,  1.6688e+00,\n",
       "          2.7466e+00,  2.2974e+00,  2.7864e+00,  2.4180e+00,  6.6716e-01,\n",
       "          5.3375e+00, -3.3753e+00,  1.6254e+00, -1.1227e+00, -6.0553e+00,\n",
       "          2.4589e+00, -1.9672e+00,  3.4632e+00,  2.6520e+00,  6.0122e+00,\n",
       "         -3.8229e+00, -3.1470e+00, -1.5181e+00,  2.8155e+00,  2.4517e+00,\n",
       "         -5.2863e+00, -6.8990e-01, -2.1416e+00,  2.9100e+00,  2.2986e+00,\n",
       "         -1.8990e+00, -2.5656e+00, -4.1717e+00, -1.6236e+00,  2.5842e+00,\n",
       "          5.0854e+00, -7.4497e-01,  5.7180e-01,  3.4402e-01,  2.2294e+00,\n",
       "         -2.6990e+00, -4.7058e+00,  3.0701e-02,  6.4679e+00,  4.5206e-01,\n",
       "         -1.8042e+00,  5.4680e+00,  1.9690e+00,  5.2459e+00, -3.4290e+00,\n",
       "          3.2154e+00,  2.9516e+00,  9.7693e-01, -1.7795e-01, -3.9459e+00,\n",
       "          1.1249e+00, -4.4453e-01, -3.3639e+00, -8.6854e-01,  3.2852e+00,\n",
       "         -2.5462e+00, -2.0804e-05, -1.7610e+00, -2.9327e-01, -9.7567e-01,\n",
       "          5.0576e-01,  1.1451e+00, -2.1208e+00,  1.1373e+00, -3.1809e+00,\n",
       "          1.7847e+00,  1.5786e-01, -3.8243e+00, -2.7085e+00, -2.5492e-01,\n",
       "          5.4300e-01,  2.6311e+00,  1.1303e+00,  4.6742e+00, -3.3613e+00,\n",
       "          2.0163e+00, -6.1928e-01, -1.5247e+00,  2.8901e+00,  2.0489e+00,\n",
       "         -2.5511e+00, -4.4904e+00, -4.9113e+00,  8.7256e+00,  3.2058e+00,\n",
       "         -4.2296e+00,  4.2687e+00,  3.1690e+00,  4.6221e+00,  3.0786e+00,\n",
       "          1.9672e+00, -4.6057e+00,  4.5463e+00,  3.9362e+00, -3.6160e+00,\n",
       "         -3.0489e-01,  8.0940e-01, -2.4287e+00, -4.5275e+00, -1.5549e+00,\n",
       "          2.5178e+00,  1.9996e+00,  4.8858e+00, -4.1579e+00,  9.9373e-01,\n",
       "         -3.9260e+00,  2.4305e+00,  1.0990e+00, -2.0975e+00,  7.0932e+00,\n",
       "          8.5631e-01, -1.1347e+00,  5.0483e+00,  5.4351e+00, -1.4487e+00,\n",
       "          1.1505e+00,  1.6415e+00, -2.2593e+00,  3.5606e+00, -4.6147e+00,\n",
       "         -3.4903e+00,  2.5203e+00, -6.3737e-04, -9.8244e+00, -4.0016e-01,\n",
       "         -1.9065e+00,  1.3006e+00, -2.4122e+00, -2.1696e+00,  2.6472e+00,\n",
       "         -1.6369e+00,  6.0617e-01, -3.0595e+00, -5.0064e+00, -2.2753e+00,\n",
       "          3.3280e+00,  2.1190e+00,  6.4464e+00, -5.4922e+00,  7.1298e+00,\n",
       "          4.0151e+00, -5.8237e+00,  3.7913e-01, -2.6684e+00, -5.1000e+00,\n",
       "         -2.3498e+00,  6.6301e+00, -3.0765e-01,  3.1284e+00,  1.5188e-01,\n",
       "         -4.6238e+00,  2.5338e-01, -1.7430e-01,  2.8731e+00, -3.0559e+00,\n",
       "          7.3856e-01, -6.8315e-01, -2.2078e-01,  3.6355e+00, -2.7270e+00,\n",
       "          5.3218e+00, -2.0433e+00,  2.9629e+00,  2.8322e-01, -3.8301e+00,\n",
       "          3.1065e+00,  2.2309e+00, -1.2267e+00,  1.5360e+00,  4.6708e+00,\n",
       "          3.8454e+00,  1.8184e+00,  9.6008e-01,  8.5332e-02, -2.1063e-01,\n",
       "         -1.6440e+00,  2.1814e+00, -3.7502e+00, -3.9661e+00,  2.1359e-01,\n",
       "          2.9793e+00,  9.3494e-01, -2.2921e+00,  2.7636e+00, -7.6360e-01,\n",
       "          2.0764e-01, -2.8650e+00,  2.6402e+00,  2.4274e+00,  1.6268e+00,\n",
       "          2.0576e-01, -8.1471e-01,  1.4967e+00,  3.6707e+00,  2.3545e+00,\n",
       "          5.9756e-01, -1.1652e+00,  1.6500e+00,  2.9891e+00, -6.5652e-01,\n",
       "         -1.7176e+00,  4.2096e-02,  4.7027e+00,  1.9881e+00,  1.3346e+00,\n",
       "         -2.5208e+00,  3.0227e+00, -3.1122e+00,  3.9692e+00, -7.0339e-01,\n",
       "          3.5724e-01,  3.4586e-01, -3.6360e+00,  2.4688e+00, -9.7487e-03,\n",
       "          1.0858e-01, -3.1757e+00, -3.9074e+00,  4.8053e+00,  3.6604e-01,\n",
       "          2.8378e+00, -1.5339e+00,  5.3394e-01, -7.2534e-02, -4.3014e+00,\n",
       "          8.2535e-01, -1.5627e-01,  3.5555e+00, -7.3521e-01, -2.0421e-01,\n",
       "          3.3847e+00, -1.7074e+00, -4.1485e+00,  2.2751e-01,  3.2080e+00,\n",
       "         -8.6427e+00,  9.5846e-01,  3.4566e+00,  3.7240e+00,  4.0975e+00,\n",
       "          1.8588e+00, -1.0373e+00,  1.3107e+00,  4.0319e+00,  7.3839e-01,\n",
       "          2.7588e+00,  3.0660e+00,  1.5204e+00, -5.0123e+00,  2.0871e+00,\n",
       "         -1.7306e+00, -3.4337e+00, -3.4331e-01,  1.7313e-01,  1.1623e+00,\n",
       "          3.6061e+00,  4.9284e+00, -2.8237e+00,  2.9937e+00, -2.1967e+00,\n",
       "          3.8515e+00,  2.4903e+00, -9.8810e-01,  1.4042e+00, -1.2079e+00,\n",
       "          1.1514e+00,  1.8176e+00,  3.0462e+00, -1.0982e+00, -2.9396e+00,\n",
       "          1.4474e+00, -4.9897e-01,  2.7572e+00,  2.8660e+00,  2.0020e+00,\n",
       "         -1.9032e+00, -3.0121e+00, -5.6130e+00,  1.5005e+00, -1.2373e+00,\n",
       "          1.1841e+00,  8.3445e-01, -5.4191e+00, -2.7962e+00, -1.8726e+00,\n",
       "          9.1818e+00, -1.0204e+01,  3.4347e+00, -3.0904e+00, -1.7081e+00,\n",
       "         -1.8695e+00, -2.4331e+00, -6.2396e+00,  2.8604e+00, -1.4581e+00,\n",
       "          2.0190e-02,  2.3687e+00, -4.2595e+00,  2.4758e+00, -1.5399e+00,\n",
       "          1.0206e+00,  3.8260e+00, -1.0645e-02, -1.1838e+00, -3.2069e+00,\n",
       "          7.2318e-01,  2.4849e+00, -1.6985e-01,  5.2580e+00, -3.0634e+00,\n",
       "         -3.6532e+00, -2.0338e+00, -7.9948e-01, -2.5249e-01, -1.5235e-01,\n",
       "         -1.6572e-01,  2.5475e-01,  3.8890e+00, -7.3158e-01,  4.0173e+00,\n",
       "         -4.5159e+00, -1.6678e+00,  1.9498e+00, -1.0151e+00,  2.9587e-01,\n",
       "          4.6597e+00, -2.2458e+00, -9.9624e-01, -3.5075e+00, -7.6732e-02,\n",
       "          3.0403e+00,  4.8705e+00,  1.1468e+00, -7.2164e+00, -5.5208e+00,\n",
       "         -1.2879e+00, -1.9577e+00, -2.7839e+00, -2.1604e+00,  1.8415e+00,\n",
       "         -5.5949e+00, -1.1920e+00, -9.8387e-01,  1.1010e+00, -1.1666e+00,\n",
       "          7.9348e+00, -2.7604e+00, -1.7758e+00, -1.7656e+00, -2.6987e+00,\n",
       "          2.0424e+00,  9.8047e-02, -3.5326e+00,  9.4527e-01,  1.7695e+00,\n",
       "         -1.8759e+00,  2.9655e+00,  4.7367e-01, -8.4560e-01,  1.8647e+00,\n",
       "          4.3047e+00, -7.3313e-01,  2.4497e+00, -3.3058e+00,  3.5485e+00,\n",
       "          2.4244e+00,  7.3668e+00, -1.1429e+00, -4.7246e-01,  6.4280e+00,\n",
       "          3.9830e-01,  2.3726e+00, -1.0680e+00,  4.7739e+00,  1.9633e+00,\n",
       "          1.4927e+00,  6.9411e+00,  5.2422e-01,  8.5033e-01,  4.0186e+00,\n",
       "          1.9898e+00, -2.6156e+00,  2.4903e-01,  7.2774e-01,  1.6012e+00,\n",
       "         -1.4421e+00, -6.3304e-01,  3.9079e+00, -3.8223e+00, -2.4380e-01,\n",
       "         -3.3072e+00, -5.4935e+00,  3.9288e-01,  1.5112e+00,  1.4314e+00,\n",
       "          4.9902e+00,  2.9907e+00, -1.7921e+00,  1.9501e+00, -1.9638e+00,\n",
       "          2.9122e+00,  3.3026e+00, -9.1748e-01, -6.0255e+00, -1.5276e+00,\n",
       "          8.2101e-01, -2.7819e-01, -9.3578e-01, -5.4557e-01, -2.8742e+00,\n",
       "         -5.7210e+00, -2.0713e+00,  7.1104e+00, -1.8821e-01, -3.6920e+00,\n",
       "         -6.4547e+00, -3.9019e+00,  6.5043e+00,  7.4369e-01,  4.7122e+00,\n",
       "         -3.5457e+00, -2.8583e+00,  1.6331e+00,  3.8910e+00, -3.5488e+00,\n",
       "          1.0591e+00,  6.3704e+00,  3.5857e+00, -2.5327e+00, -4.9660e+00,\n",
       "          1.5456e+00, -3.7757e+00,  5.9014e+00, -4.0526e+00, -2.1892e+00,\n",
       "         -6.4832e-01,  1.4330e+00,  8.8292e-01, -1.9120e+00,  4.0366e-01,\n",
       "         -4.5085e+00,  5.9803e-01, -2.4828e+00, -3.7759e+00,  6.0694e+00,\n",
       "          4.0858e+00,  1.4916e+00,  2.7113e+00, -1.0094e+00, -4.3262e+00,\n",
       "          3.3384e+00, -3.6889e+00,  1.3876e-01,  1.8235e+00, -2.2824e+00,\n",
       "          8.9867e+00,  4.0816e+00, -4.9790e-01,  3.4383e+00,  5.8186e+00,\n",
       "          4.0813e+00,  5.0018e+00,  1.2350e+00,  2.2782e+00,  5.4641e+00,\n",
       "          1.2956e+00,  1.7581e-01,  5.1461e+00,  3.7482e+00,  1.1420e+00,\n",
       "          3.6458e-01, -2.4089e+00, -1.3255e+00,  2.0052e+00, -3.2292e+00,\n",
       "          6.2705e+00, -8.1897e+00,  8.6347e-01, -1.8838e+00,  4.5665e+00,\n",
       "         -5.5589e-01, -4.1952e+00, -4.7558e+00, -3.8817e-01,  5.8835e+00,\n",
       "         -7.8830e-01,  2.3882e-01,  1.9468e+00,  1.2443e-01,  1.9636e+00,\n",
       "          6.4687e-01, -3.1945e+00, -4.2309e+00, -3.3961e+00, -4.1045e-01,\n",
       "          3.2881e+00, -1.2430e+00, -1.9764e+00, -4.9505e+00, -2.3382e+00,\n",
       "          1.6500e+00,  6.0443e+00, -1.9353e+00,  9.6910e-02, -2.6410e+00,\n",
       "          6.1543e-01, -6.9976e-01,  4.1020e+00,  9.1979e-01,  4.2583e+00,\n",
       "          6.4119e+00, -2.4249e+00, -2.1623e+00, -1.4308e+00,  1.1853e+00,\n",
       "         -4.1923e-01,  2.6474e+00,  4.2072e+00,  4.6227e+00, -1.2796e+00,\n",
       "          3.0691e-01,  2.5619e+00, -4.0116e+00,  3.3309e+00,  2.1617e+00,\n",
       "         -2.3925e+00, -1.2888e+00,  1.6193e+00, -4.3742e+00,  6.8674e+00,\n",
       "          1.2769e+00,  1.2721e+00, -1.5577e+00,  6.9621e+00, -2.1152e+00,\n",
       "          1.3572e+00,  1.1968e+00,  1.2907e+00, -2.4901e-01,  5.4183e+00,\n",
       "          1.1588e+00, -5.8141e-01,  4.1282e+00, -2.7086e+00, -3.0098e-01,\n",
       "         -1.1121e+01, -1.9609e+00,  2.4579e+00,  4.9503e+00, -7.5168e-01,\n",
       "          1.4530e+00,  3.3139e+00,  8.5753e-01,  6.7767e-01,  1.8631e+00,\n",
       "         -1.9321e-01, -3.7276e+00, -2.4198e+00, -5.3850e+00,  2.2967e+00,\n",
       "         -4.1524e+00, -1.9091e+00, -5.5687e+00, -3.9907e+00, -8.1171e-02,\n",
       "          1.8661e+00,  3.8287e+00,  2.0377e+00, -9.8122e-01, -4.2980e+00,\n",
       "          4.3195e+00, -2.2359e-02, -3.4050e+00, -2.7135e+00,  2.7931e+00,\n",
       "         -2.2162e+00, -1.6408e+00,  3.6129e+00,  4.8946e+00, -4.9444e+00,\n",
       "          2.6764e-01, -1.3238e+00,  2.6901e+00,  8.7363e-01,  1.9826e+00,\n",
       "         -3.2280e+00, -5.3249e+00,  7.3238e+00, -1.8533e+00, -4.0610e+00,\n",
       "          1.3483e+00,  2.1888e+00, -8.1374e-01, -1.5324e+00, -1.6939e+00,\n",
       "          8.5841e-01,  2.6591e+00, -1.6888e-01,  7.6746e+00, -1.5850e+00,\n",
       "         -3.8818e+00, -2.8793e+00,  3.0971e+00,  2.2634e+00,  3.6863e+00,\n",
       "         -1.9553e-01, -8.2330e-01,  1.5698e+00,  7.4427e+00, -1.2265e-01,\n",
       "         -2.1166e+00, -1.7324e+00,  4.1550e+00, -8.6073e-02, -4.5611e+00,\n",
       "          9.5080e-01,  2.3881e+00, -1.1931e+00,  2.6611e+00,  5.6817e+00,\n",
       "         -3.1686e+00, -2.8209e+00,  5.7226e+00, -3.9470e+00, -5.2612e-01,\n",
       "         -2.1441e+00,  4.4185e+00, -2.3447e-01,  2.2018e+00,  5.8503e-01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(L,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac761cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_s2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec3f63-f945-48ee-b751-760320f70606",
   "metadata": {},
   "source": [
    "Next steps\n",
    "\n",
    "- amortized inference\n",
    "- Can we use GPtorch as function?\n",
    "- write as a class with a fwd and backward method\n",
    "- use torch.nn class to define params?\n",
    "- use random Z at each stage? Should the number of samples increase as we converge?\n",
    "- add prior for x\n",
    "- change f to avoid bimodal posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb1605-f104-45fa-8a63-4971a7356851",
   "metadata": {},
   "source": [
    "## Amortized Variational Inference\n",
    "\n",
    "Let's assume $q(x|y)$ can be modelled as $N(m(y), s2(y))$ where $m(y)$ and $s2(y)$ are both modelled as neural networks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ddc48-71b5-4673-ab5e-35d2328c59d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
