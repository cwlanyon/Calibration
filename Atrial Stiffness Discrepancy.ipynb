{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba866e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import GPE_ensemble as GPE\n",
    "\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from GPErks.gp.data.dataset import Dataset\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.means import LinearMean\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from torchmetrics import MeanSquaredError, R2Score\n",
    "#from GPErks.gp.experiment import GPExperiment\n",
    "#from GPErks.train.emulator import GPEmulator\n",
    "#from GPErks.perks.inference import Inference\n",
    "#from GPErks.train.early_stop import NoEarlyStoppingCriterion\n",
    "#from GPErks.train.early_stop import (\n",
    "#    GLEarlyStoppingCriterion,\n",
    "#    PQEarlyStoppingCriterion,\n",
    "#    UPEarlyStoppingCriterion,\n",
    "#)\n",
    "#from GPErks.train.early_stop import PkEarlyStoppingCriterion\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# set logger and enforce reproducibility\n",
    "#from GPErks.log.logger import get_logger\n",
    "#from GPErks.utils.random import set_seed\n",
    "#log = get_logger()\n",
    "seed = 7\n",
    "#set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a64e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/xlabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "y_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/ylabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "meshes=['01','02','03','04','05','06']\n",
    "\n",
    "meshes.copy\n",
    "\n",
    "t_size = 60\n",
    "ts = 9\n",
    "reps = 5\n",
    "MSE_i = np.zeros((len(meshes),7,9))\n",
    "R2_i = np.zeros((len(meshes),7,9))\n",
    "\n",
    "for i in (range(len(meshes))):\n",
    "    val0 = meshes[i]\n",
    "\n",
    "    meshes2 = meshes.copy()\n",
    "    meshes2.remove(meshes[i])\n",
    "\n",
    "    inputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val0+\"/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    outputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val0+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "    X0 = torch.tensor(inputData_0)[0:200]\n",
    "    Y0 = torch.tensor(outputData_0)[0:200]\n",
    "    X0.columns = x_labels\n",
    "    Y0.columns = y_labels\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X0,\n",
    "                Y0,\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )\n",
    "    \n",
    "    for l in range(ts):\n",
    "        t_size = 20*(l+1)\n",
    "\n",
    "\n",
    "        for k in range(reps):\n",
    "            a=np.random.choice(range(X_train.shape[0]),t_size,replace=False)\n",
    "\n",
    "            emulator = GPE.ensemble(X_train[a,:],y_train[a,:],mean_func=\"linear\",training_iter=1000)\n",
    "            MSE_i[i,:,l] += emulator.MSE(X_test,y_test).detach().numpy()/reps\n",
    "            R2_i[i,:,l] += emulator.R2(X_test,y_test).detach().numpy()/reps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fe573c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x2ab724c90>,\n",
       "  <matplotlib.axis.XTick at 0x2ab6db7d0>,\n",
       "  <matplotlib.axis.XTick at 0x2ab72d310>,\n",
       "  <matplotlib.axis.XTick at 0x2ab5aa1d0>,\n",
       "  <matplotlib.axis.XTick at 0x2ab7d0a10>,\n",
       "  <matplotlib.axis.XTick at 0x2ab7012d0>],\n",
       " [Text(0, 0, '01'),\n",
       "  Text(1, 0, '02'),\n",
       "  Text(2, 0, '03'),\n",
       "  Text(3, 0, '04'),\n",
       "  Text(4, 0, '05'),\n",
       "  Text(5, 0, '06')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(R2_i[:,:,8]/reps,'o')\n",
    "plt.xticks(range(len(meshes)),meshes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14327c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '$R^2$')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(20,180,9),R2_i[0,:,:].T/reps)\n",
    "plt.legend(y_labels.values)\n",
    "plt.xlabel('training points')\n",
    "plt.ylabel('$R^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d5b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3130,  0.3869,  0.2734,  0.7547,  0.4779,  0.5911, 38.5422],\n",
       "       dtype=torch.float64, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator.MSE(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f92a183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3495885928.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "x_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/xlabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "y_labels=pd.read_csv(r'/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/ylabels.txt',delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "meshes=['01','02','03','04','05','06']\n",
    "\n",
    "meshes.copy\n",
    "\n",
    "t_size = 60\n",
    "ts = 9\n",
    "reps = 5\n",
    "MSE_disc = np.zeros((len(meshes),len(meshes)-1,7,9))\n",
    "R2_disc = np.zeros((len(meshes),len(meshes)-1,7,9))\n",
    "\n",
    "for i in (range(len(meshes))):\n",
    "    val0 = meshes[i]\n",
    "\n",
    "    meshes2 = meshes.copy()\n",
    "    meshes2.remove(meshes[i])\n",
    "\n",
    "    inputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val0+\"/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "    outputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val0+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "    X0 = torch.tensor(inputData_0)[0:200]\n",
    "    Y0 = torch.tensor(outputData_0)[0:200]\n",
    "    X0.columns = x_labels\n",
    "    Y0.columns = y_labels\n",
    "    emulator_0 = GPE.ensemble(X0,Y0,mean_func=\"linear\",training_iter=500)\n",
    "\n",
    "    for l in range(ts):\n",
    "        t_size = 20*(l+1)\n",
    "\n",
    "        for j in (range(len(meshes)-1)):\n",
    "            val1 = meshes2[j]\n",
    "            inputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val1+\"/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "            outputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case\"+val1+\"/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "            X1 = torch.tensor(inputData_1)[0:200]\n",
    "            Y1 = torch.tensor(outputData_1)[0:200]\n",
    "            X1.columns = x_labels\n",
    "            Y1.columns = y_labels\n",
    "            # split original dataset in training, validation and testing sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X1,\n",
    "                Y1,\n",
    "                test_size=0.1,\n",
    "                random_state=seed\n",
    "            )\n",
    "            for k in range(reps):\n",
    "                a=np.random.choice(range(X_train.shape[0]),t_size,replace=False)\n",
    "                m0 = emulator_0.predict(X_train[a,:])\n",
    "                y_adjust = torch.tensor(y_train[a] - m0)\n",
    "                delta_1 = GPE.ensemble(X_train[a,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "                MSE_disc[i,j,:,l] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
    "                R2_disc[i,j,:,l] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1190145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_anterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_posterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_septum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d_roof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ESV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     d_global\n",
       "1   d_anterior\n",
       "2  d_posterior\n",
       "3     d_septum\n",
       "4    d_lateral\n",
       "5       d_roof\n",
       "6          ESV"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ebaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "533c302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae4ada90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAGwCAYAAAC99fF4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABtgUlEQVR4nO3deVxUVf8H8M+dYd9NlgFkcwc1F3ABo9AMtHJrkRZN3MrsicgypXInzV2z5HFJ0R5/pZX1aBGClT0YKopSLjzKoyCmgwgpgyKLM/f3BzE5zICss8Dn/XrNK++55977ndvAfDnn3HMEURRFEBEREZEGiaEDICIiIjJGTJKIiIiIdGCSRERERKQDkyQiIiIiHZgkEREREenAJImIiIhIByZJRERERDqYGToAU6VSqXD16lXY29tDEARDh0NERET1IIoiSkpK4OHhAYmk7rYiJkmNdPXqVXh5eRk6DCIiImqEy5cvo0OHDnXWYZLUSPb29gCqbrKDg4OBoyEiIqL6UCgU8PLyUn+P14VJUiNVd7E5ODgwSSIiIjIx9Rkqw4HbRERERDowSSIiIiLSgUkSERERkQ5MkoiIiIh0YJJEREREpAOTJCIiIiIdmCQRERER6cAkiYiIiEgHJklEREREOnDGbWqTRJWI8pxiqEoqILG3gKWfIwQJFyomotrx90bbwySJ2pw7pwtxc98FKIsr1GVSRws4jewE657OBoyMiIwVf2+0TexuozblzulCFP0rS+MXHQAoiytQ9K8s3DldaKDIiMhY8fdG28UkidoMUSXi5r4Ldda5ue8iRJWop4iIyNjx90bbxiSJ2ozynGKtvwRrUhaXozynWE8REZGx4++Nto1jkqjNUJXU/YuuofWIqPXj7w3DMJZB8kySqM2Q2Fs0az0iav34e0P/jGmQPLvbqM2w9HOE1LHuX2RSR0tY+jnqKSIiMnb8vaFfxjZInkkStRmCRIDTyE511nEa2ZHznhCRGn9v6I8xDpJnkkRtinVPZ7Qf76/1l6HU0RLtx/tzvhMi0sLfG/phjIPkOSaJ2hzrns6wCmhvFIMCiZqDsQxybc34e6PlGeMgeSZJ1CYJEgFWnZwMHQZRkxnTINfWjr83WpYxDpJndxsRkYkytkGuRE1hjIPkmSQREZkgYxzkStQUxjhInkkSEZEJMsZBrkRNZWyD5DkmiYjIBBnjIFei5mBMg+SZJBERmSBjHORK1FyMZZA8u9uIiEyQMQ5yJWptmCQREZmgvwe5ihBFzcHZVdsiZ4ImaiImSUREJqry6gncSd8IseyGRrl45wbupG9E5dUTBoqMqHXgmCQiIhMkKpW4tmQp7ubn4+7Vk5A6d4Fg6QixvBjKwmxAAK4tuQr7Rx+FIJUaOlwik8QkiYjIBJUez8Dd/Py/tkQoC89rVhCBu/n5KD2eAduBA/QeH1FrwO42IiITdPf69WatR0TaDJ4kbdiwAX5+frCyskJgYCBSU1PrrP/JJ5/A398f1tbW6NatG3bs2KGxPyEhAYIgaL3KysqadF0iImNi5uLSrPWISJtBk6Rdu3YhJiYG7733Hk6ePInQ0FCMGDECeXl5OuvHx8cjNjYWCxYswJkzZ7Bw4UK89tpr2Ldvn0Y9BwcHyOVyjZeVlVWjr0tEZGxsggJhJpMBQi1PrwkCzGQy2AQF6jcwolZEEGs+O6pHAwcORL9+/RAfH68u8/f3x5gxY7B06VKt+iEhIRg8eDBWrFihLouJicHx48dx6NAhAFUtSTExMbh582azXRcAysvLUV5ert5WKBTw8vJCcXExHBwc6v2eiYiaiyI5GVfeiKnauPdX+V+Jk+e6tXAID9d/YERGTKFQwNHRsV7f3wZrSaqoqEBGRgbCa/wAh4eHIy0tTecx5eXlGi1CAGBtbY309HRUVlaqy27dugUfHx906NABTz75JE6ePNmk6wLA0qVL4ejoqH55eXnV+70SEbUEh/BweK5bCzM3N41yMzc3JkhEzcBgT7cVFhZCqVTCrcYPt5ubG/LVT2xoioiIwJYtWzBmzBj069cPGRkZ2Lp1KyorK1FYWAh3d3d0794dCQkJ6NWrFxQKBdatW4fBgwfjt99+Q5cuXRp1XQCIjY3FzJkz1dvVLUlERIbkEB4O+0cfrXra7fp1mLm4wCYokI/9EzUDg08BINToTxdFUaus2ty5c5Gfn49BgwZBFEW4ubkhKioKy5cvh/SvXwiDBg3CoEGD1McMHjwY/fr1w/r16/HRRx816roAYGlpCUtLywa/PyKiliZIpXzMn6gFGKy7zdnZGVKpVKv1pqCgQKuVp5q1tTW2bt2K0tJS5ObmIi8vD76+vrC3t4ezs7POYyQSCfr374/s7OxGX5eIiIjaHoMlSRYWFggMDERKSopGeUpKCkJCQuo81tzcHB06dIBUKsUXX3yBJ598EhKJ7rciiiIyMzPh7u7e5OsSERFR22HQ7raZM2diwoQJCAoKQnBwMDZt2oS8vDxMnz4dQNU4oCtXrqjnQjp//jzS09MxcOBA3LhxA6tXr8bp06exfft29TkXLlyIQYMGoUuXLlAoFPjoo4+QmZmJTz75pN7XJSIiIjJokhQZGYmioiIsWrQIcrkcPXv2RGJiInx8fAAAcrlcY+4ipVKJVatW4dy5czA3N8eQIUOQlpYGX19fdZ2bN2/i5ZdfRn5+PhwdHdG3b1/85z//wYABA+p9XSIiIiKDzpNkyhoyzwIREREZB5OYJ4mIiIjImBl8CgDSJKpElOcUQ1VSAYm9BSz9HCFIap+agMiY8fNMRKaMSZIRuXO6EDf3XYCyuEJdJnW0gNPITrDuqXuKAyJjxc8zEZk6drcZiTunC1H0ryyNLxQAUBZXoOhfWbhzutBAkRE1HD/PRNQaMEkyAqJKxM19F+qsc3PfRYgqjrEn48fPMxG1FkySjEB5TrHWX9w1KYvLUZ5TrKeIiBqPn2ciai2YJBkBVUndXygNrUdkSPw8E1FrwSTJCEjsLZq1HpEh8fNMRK0FkyQjYOnnCKlj3V8YUkdLWPo56ikiosbj55mIWgsmSUZAkAhwGtmpzjpOIztyfhkyCfw8E1FrwSTJSFj3dEb78f5af4FLHS3Rfrw/55Uhk8LPMxG1BpxM0ohY93SGVUB7zlBMrQI/z0Rk6pgkGRlBIsCqk5OhwyBqFvw8E5EpY3cbERERkQ5MkoiIiIh0YJJEREREpAOTJCIiIiIdmCQRERER6cAkiYiIiEgHJklEREREOjBJIiIiItKBSRIRERGRDkySiIiIiHTgsiRERET1ICqVKD2egbvXr8PMxQU2QYEQpFJDh0UtiEkSERHRfSiSk3FtyVLczc9Xl5nJZHB7NxYO4eEGjIxaErvbjIyoVOL20XQUf/c9bh9Nh6hUGjokIqI2TZGcjCtvxGgkSABw99o1XHkjBorkZANFRi2NLUlGhH+pEBEZF1GpxLUlSwFR1LFTBAQB15Yshf2jj7LrrRViS5KR4F8qRETGp/R4htbvZQ2iiLv5+Sg9nqG/oEhvmCQZgfv+pQLg2pKl7HojItKzu9evN2s9Mi1MkowA/1IhIjJOZi4uzVqPTAuTJCPAv1SIiIyTTVAgzGQyQBB0VxAEmMlksAkK1G9gpBdMkowA/1IhIjJOglQKt3dj/9qokSj9te32biwHbbdSTJKMAP9SISIyXg7h4fBctxZmbm4a5WZubvBct5ZPH7dinALACFT/pXLljZiqROneAdz8S4WIyOAcwsNh/+ijnHG7jWGSZCQcwsOBdWu150lyc+M8SURERkCQSmE7cIChwyA9YpJkRPiXChERkfFgkmRk+JcKERG1dcaymDCTJCIiIjIaxrREF59uIyIiIqNgbEt0GTxJ2rBhA/z8/GBlZYXAwECkpqbWWf+TTz6Bv78/rK2t0a1bN+zYsUNj/+bNmxEaGop27dqhXbt2GDZsGNLT0zXqLFiwAIIgaLxkMlmzvzciIiKqH2NcosugSdKuXbsQExOD9957DydPnkRoaChGjBiBvLw8nfXj4+MRGxuLBQsW4MyZM1i4cCFee+017Nu3T13n4MGDeP755/Hzzz/j8OHD8Pb2Rnh4OK5cuaJxrh49ekAul6tfp06datH3SkRERLUzxiW6DDomafXq1ZgyZQqmTp0KAFi7di3279+P+Ph4LF26VKv+Z599hldeeQWRkZEAgI4dO+LIkSNYtmwZRo4cCQDYuXOnxjGbN2/GV199hR9//BEvvfSSutzMzIytR0REREbCGJfoMlhLUkVFBTIyMhBeYxBWeHg40tLSdB5TXl4OKysrjTJra2ukp6ejsrJS5zGlpaWorKzEAw88oFGenZ0NDw8P+Pn54bnnnsPFixfrjLe8vBwKhULjRURERM3DGJfoMliSVFhYCKVSCbca07y7ubkhv5bmtoiICGzZsgUZGRkQRRHHjx/H1q1bUVlZicLCQp3HzJkzB56enhg2bJi6bODAgdixYwf279+PzZs3Iz8/HyEhISgqKqo13qVLl8LR0VH98vLyasS7JiIiIl2McYkugw/cFmrcDFEUtcqqzZ07FyNGjMCgQYNgbm6O0aNHIyoqCgAg1TF/wvLly/H5559jz549Gi1QI0aMwNNPP41evXph2LBh+P777wEA27dvrzXO2NhYFBcXq1+XL19u6FslIiKiWhjjYsIGS5KcnZ0hlUq1Wo0KCgq0WpeqWVtbY+vWrSgtLUVubi7y8vLg6+sLe3t7ODs7a9RduXIllixZguTkZDz44IN1xmJra4tevXohOzu71jqWlpZwcHDQeBEREVHzMbbFhA02cNvCwgKBgYFISUnB2LFj1eUpKSkYPXp0nceam5ujQ4cOAIAvvvgCTz75JCSSv/O9FStWIC4uDvv370dQUNB9YykvL0dWVhZCQ0Mb+W6IiIioORjTEl0Gfbpt5syZmDBhAoKCghAcHIxNmzYhLy8P06dPB1DVxXXlyhX1XEjnz59Heno6Bg4ciBs3bmD16tU4ffq0RjfZ8uXLMXfuXPzf//0ffH191S1VdnZ2sLOzAwC8/fbbGDlyJLy9vVFQUIC4uDgoFApMnDhRz3eAiIiIajKWJboMmiRFRkaiqKgIixYtglwuR8+ePZGYmAgfHx8AgFwu15gzSalUYtWqVTh37hzMzc0xZMgQpKWlwdfXV11nw4YNqKiowDPPPKNxrfnz52PBggUAgD/++APPP/88CgsL4eLigkGDBuHIkSPq6xIREREJoqhraku6H4VCAUdHRxQXF3N8EhERkYloyPe3wZ9uIyIiIjJGBu1uIyIiMhkqJXApDbh1DbBzA3xCAIn+BxOT/jBJIiIiup+ze4Gk2YDi6t9lDh7A8GVAwCjDxUUtit1tREREdTm7F9j9kmaCBAAKeVX52b2GiYtaHJMkIiKi2qiUVS1I0PWM019lSXOq6lGrwySJiIioNpfStFuQNIiA4kpVPWp1mCQRERHV5ta15q1HJoVJEhERUW3sdK8l2uh6ZFKYJBEREdXGJ6TqKTYItVQQAAfPqnrU6jBJIiIiqo1EWvWYPwDtROmv7eEfcr6kVopJEhERUV0CRgHjdgAO7prlDh5V5ZwnqdXiZJJERET3EzAK6P4EZ9xuY5gkERER1YdECviFGjoK0iN2txERERHpwCSJiIiISAcmSUREREQ6MEkiIiIi0oFJEhEREZEOTJKIiIiIdGCSRERERKQDkyQiIiIiHZgkEREREenAJImIiIhIByZJRERERDowSSIiIiLSgUkSERERkQ5MkoiIiIh0YJJEREREpIOZoQMgotZLVCpRejwDd69fh5mLC2yCAiFIpYYOi4ioXpgkEVGLUCQn49qSpbibn68uM5PJ4PZuLBzCww0YGRFR/bC7jYianSI5GVfeiNFIkADg7rVruPJGDBTJyQaKrHVSqkQcvlCEf2deweELRVCqREOHRNQqsCWJiJqVqFTi2pKlgKjji1oUAUHAtSVLYf/oo+x6awZJp+VYuO8s5MVl6jJ3RyvMHxmA4T3dDRgZkeljSxIRNavS4xlaLUgaRBF38/NRejxDf0G1Ukmn5Xj1Xyc0EiQAyC8uw6v/OoGk03IDRdY6scWu7WFLErVNKiVwKQ24dQ2wcwN8QgAJWzWaw93r15u1HummVIlYuO8sdH1NiwAEAAv3ncVjATJIJYKeo2t92GLXNjFJorbn7F4gaTaguPp3mYMHMHwZEDDKcHG1EmYuLs1aj3RLz/lTqwXpXiIAeXEZ0nP+RHCn9voLrBWqbrGrmZBWt9jFj+/HRKmVYncbtS1n9wK7X9JMkABAIa8qP7vXMHG1IjZBgTCTyQChltYLQYCZTAaboED9BtbKFJTUniA1ph7pdr8WO6CqxY5db60TkyRqO1TKqhakun7dJc2pqkeNJkilcHs39q+NGonSX9tu78Zy0HYTudpbNWs90q0hLXbU+jBJorbjUpp2C5IGEVBcqapHTeIQHg7PdWth5uamUW7m5gbPdWs5T1IzGOD3ANwdrVDbaCMBVWNmBvg9oM+wWh222LVtHJNEbceta81bj+rkEB4O+0cf5YzbLUQqETB/ZABe/dcJCNBsH61OnOaPDOCg7SZii13bxiSJ2g67v1s1RBVQet0Cd8ukMLNSwsalAoJEux41jSCVwnbgAEOH0WoN7+mO+PH9tJ66kvGpq2ZT3WKXX1yms6NeQNX9Zotd62Tw7rYNGzbAz88PVlZWCAwMRGpqap31P/nkE/j7+8Pa2hrdunXDjh07tOp8/fXXCAgIgKWlJQICAvDNN980+brUCviEAA4eUFy2xv/2uSHvZ2dcPdwOeT8743/73KC4bA04eFbVIzIRw3u649Dsofh82iCse64PPp82CIdmD2WC1EyqW+wAaHVtssWu9TNokrRr1y7ExMTgvffew8mTJxEaGooRI0YgLy9PZ/34+HjExsZiwYIFOHPmDBYuXIjXXnsN+/btU9c5fPgwIiMjMWHCBPz222+YMGECxo0bh6NHjzb6utRKSKRQOE3AlV+dcPeO5kf/7h0JrvzqBIXTeM6XRCZHKhEQ3Kk9RvfxRHCn9vzCbmbVLXYyR80uNZmjFR//b+UEUdS1doB+DBw4EP369UN8fLy6zN/fH2PGjMHSpUu16oeEhGDw4MFYsWKFuiwmJgbHjx/HoUOHAACRkZFQKBT44Ycf1HWGDx+Odu3a4fPPP2/UdXVRKBRwdHREcXExHBwcGvbGySBEpRL/e3RYnbNBm8lk6PzjAY6bISItSpWI9Jw/UVBSBlf7qi42JqSmpyHf3wZrSaqoqEBGRgbCazzlEh4ejrQ03U8XlZeXw8pKM5O3trZGeno6KisrAVS1JNU8Z0REhPqcjblu9bUVCoXGi0zLfZfLALhcBhHVii12bY/BkqTCwkIolUq41XhE2M3NDfm1fJFFRERgy5YtyMjIgCiKOH78OLZu3YrKykoUFhYCAPLz8+s8Z2OuCwBLly6Fo6Oj+uXl5dXg90yGde8yGCIE3HDqgnzXQNxw6gLxntEGXC6DiIgAI3i6Tagx2Zwoilpl1ebOnYv8/HwMGjQIoijCzc0NUVFRWL58OaT3dI/U55wNuS4AxMbGYubMmepthULBRMnEVC+DUeDcG9mdn0W5VTv1PsuyG+jyvy/hWvgbl8sgIiIABmxJcnZ2hlQq1Wq9KSgo0GrlqWZtbY2tW7eitLQUubm5yMvLg6+vL+zt7eHs7AwAkMlkdZ6zMdcFAEtLSzg4OGi8yLTYBAWiqHMYTveYhnJLJ4195ZZOON1jGoo6h3G5DCIiAmDAJMnCwgKBgYFISUnRKE9JSUFISN2PYJubm6NDhw6QSqX44osv8OSTT0IiqXorwcHBWudMTk5Wn7Mp1yXTJgoSZHd5pmqjluUysrs8A1Ew+MwYRERkBAza3TZz5kxMmDABQUFBCA4OxqZNm5CXl4fp06cDqOriunLlinoupPPnzyM9PR0DBw7EjRs3sHr1apw+fRrbt29Xn/ONN97Aww8/jGXLlmH06NH497//jQMHDqiffqvPdal1kmffROkdQXuyk2qCgNI7VfU8u7WrpRIREbUVBk2SIiMjUVRUhEWLFkEul6Nnz55ITEyEj48PAEAul2vMXaRUKrFq1SqcO3cO5ubmGDJkCNLS0uDr66uuExISgi+++ALvv/8+5s6di06dOmHXrl0YOHBgva9LrdNtRXmz1iMiotbNoPMkmTLOk2R6rpy7gW/XnLxvvTFv9mVLEhFRK2US8yQR6Zt7FyfYOlnWWceunSXcuzjpJyAiIjJqTJKozZBIBIRGdqmzzkPjukDCCeKIiAhMkqiN6dTXFcNf6anVomTXzhLDX+mJTn1dDRQZEREZG4NPJkmkb536usKvtwvk2TdxW1EOW4eqLja2IBERGQeVSjSK39FMkqhNkkgEDs4mIjJCF04WIHVXNm7f/PtJY1snS4RGdtF7az+724yNSgnkpAKnvqr6r0pp6IiIiIj04sLJAiRtPK2RIAHA7ZvlSNp4GhdOFug1HrYkGZOze4Gk2YDi6t9lDh7A8GVAwCjDxUVERNTCVCoRqbuy66xzaHc2/Hq76K3rjS1JxuLsXmD3S5oJEgAo5FXlZ/caJi4iIiI9kGff1GpBqunWjXLIs2/qJyAwSTIOKmVVCxJ0zev5V1nSHHa9ERFRq2WMqyIwSTIGl9K0W5A0iIDiSlU9IiKiVsjWoe7JfhtarzkwSTIGt641bz0iIiITY4yrIjBJMgZ2bs1bj4iIyMQY46oITJKMgNIrGNfQHqpalhpWiUA+2kPpFazfwIiIiPTI2FZF4BQARiD9UjESKiYg3nwtVCJwb5JcnTjNr5iAqEvFCO7U3jBBEhER6YExrYrAliQjUFBShv2qAXi1Mgb5eEBjXz7a49XKGOxXDUBBSZmBIiQiItKf6lURuvaXwbNbO4MtG8WWJCPgam8FANivGoCU8iAMkPwXrriJAjghXdUdqr9y2ep6RERE1PKYJBmBAX4PwN3RCvnFZVBBgiOqAI39AgCZoxUG+D2g+wRERETU7NjdZgSkEgHzR1YlRjUbFKu3548MgJSr1BMREekNkyQjMbynO+LH94PMUbNLTeZohfjx/TC8p7uBIiMiImqb2N1mRIb3dMdjATKk5/yJgpIyuNpXdbGxBYmIiEj/mCQZGalE4GP+RNQwKmXVskW3rlVNOusTAkikho6KyOQxSSIiMmVn91YtkH3v+o8OHsDwZUDAKMPFRdQKcEwSEZGpOrsX2P2S9gLZCnlV+dm9homLqJVgkkREZIpUyqoWJOhaz+ivsqQ5VfWITI1KCeSkAqe+qvqvgT7H7G4jIjJFl9K0W5A0iIDiSlU9v1C9hUXUZEbUhcyWJCIiU3TrWvPWIzIGRtaFzCSJiMgU2bk1bz0iQzPCLmQmSUREpsgnpKoLQmue/moC4OBZVY/IFDSkC1lPmCQREZkiibRqjAaAWhc0Gv4h50si02GEXchMkoiITFXAKGDcDsChxrJFDh5V5ZwniUyJEXYh8+k2IiJTFjAK6P4EZ9wm01fdhayQQ/e4JKFqvx67kJkkERGZOomUj/mT6avuQt79Eqq6jO9NlAzThczuNiIiIjIORtaF3KiWJJVKBYlEO79SqVT4448/4O3t3eTAiIiIqA0yoi7kBrUkKRQKjBs3Dra2tnBzc8P8+fOhVP49X8H169fh5+fX7EESERFRG1Ldhdzrmar/GmiMXYNakubOnYvffvsNn332GW7evIm4uDhkZGRgz549sLCwAACIoq7BVkRERESmpUEtSd9++y02btyIZ555BlOnTkVGRgYKCwsxcuRIlJeXAwAEobaJzYiIiIhMR4OSpMLCQvj4+Ki327dvj5SUFJSUlODxxx9HaWlpswdIREREZAgNSpK8vLyQlZWlUWZvb4/k5GTcuXMHY8eObdbgiIiIiAylQUlSeHg4tm3bplVuZ2eH/fv3w8rKqtkCIyIiIjKkBiVJCxcuxIIFC3Tus7e3x4EDB7Bjx44GBbBhwwb4+fnBysoKgYGBSE1NrbP+zp070bt3b9jY2MDd3R2TJk1CUVGRen9YWBgEQdB6PfHEE+o6CxYs0Novk8kaFDcRERG1bg1Kktq1a4cePXro3Jefn4/Y2FhMnTq13ufbtWsXYmJi8N577+HkyZMIDQ3FiBEjkJeXp7P+oUOH8NJLL2HKlCk4c+YMvvzySxw7dkzjmnv27IFcLle/Tp8+DalUimeffVbjXD169NCod+rUqXrHTURERK1fg5Kkmzdv4sUXX4SLiws8PDzw0UcfQaVSYd68eejYsSOOHDmCrVu31vt8q1evxpQpUzB16lT4+/tj7dq18PLyQnx8vM76R44cga+vL6Kjo+Hn54eHHnoIr7zyCo4fP66u88ADD0Amk6lfKSkpsLGx0UqSzMzMNOq5uLjUGWt5eTkUCoXGi4jIGKhUSlw+8zuyfv0Fl8/8DpVKef+DiOi+GjRP0rvvvov//Oc/mDhxIpKSkvDmm28iKSkJZWVl+OGHH/DII4/U+1wVFRXIyMjAnDlzNMrDw8ORlpam85iQkBC89957SExMxIgRI1BQUICvvvpKoyutpk8//RTPPfccbG1tNcqzs7Ph4eEBS0tLDBw4EEuWLEHHjh1rPc/SpUuxcOHCer8/IiJ9yD6ahp8SNuHWn4XqMrsHnDE06mV0Gai/hUCJWqMGtSR9//332LZtG1auXIm9e/dCFEV07doVP/30U4MSJKBqOgGlUgk3NzeNcjc3N+Tn5+s8JiQkBDt37kRkZCQsLCwgk8ng5OSE9evX66yfnp6O06dPa3UBDhw4EDt27MD+/fuxefNm5OfnIyQkRGNsU02xsbEoLi5Wvy5fvtyg90tE1Nyyj6Zh7+olGgkSANz6sxB7Vy9B9lHdf3ASUf00KEm6evUqAgICAAAdO3aElZVVg8Yg6VJz8klRFGudkPLs2bOIjo7GvHnzkJGRgaSkJOTk5GD69Ok663/66afo2bMnBgwYoFE+YsQIPP300+jVqxeGDRuG77//HgCwffv2WuO0tLSEg4ODxouIyFBUKiV+SthUZ52ft29i1xtREzSou02lUsHc3Fy9LZVKtbqx6svZ2RlSqVSr1aigoECrdana0qVLMXjwYMyaNQsA8OCDD8LW1hahoaGIi4uDu/vfqwaXlpbiiy++wKJFi+4bi62tLXr16oXs7OxGvRciIn27knVGqwWpppKiQlzJOgOvHg/qKSqi1qVBSZIoioiKioKlpSUAoKysDNOnT9dKlPbs2XPfc1lYWCAwMBApKSkak1CmpKRg9OjROo8pLS2FmZlmyFKpVB3bvXbv3o3y8nKMHz/+vrGUl5cjKysLoaGh961LRGQMbt280az1iEhbg5KkiRMnamzXJwGpy8yZMzFhwgQEBQUhODgYmzZtQl5enrr7LDY2FleuXFHPvTRy5EhMmzYN8fHxiIiIgFwuR0xMDAYMGAAPDw+Nc3/66acYM2YM2rdvr3Xdt99+GyNHjoS3tzcKCgoQFxcHhUKh9f6IiIyVnVO7Zq1HZExUKmVVa+nNG7BzagdP/x6QSKR6j6NBSZKu2babIjIyEkVFRVi0aBHkcjl69uyJxMRE9fpwcrlcY86kqKgolJSU4OOPP8Zbb70FJycnDB06FMuWLdM47/nz53Ho0CEkJyfrvO4ff/yB559/HoWFhXBxccGgQYNw5MgRjXXpiIiMmad/D9g94Fxnl5t9e2d4+uue247IWBnTE5uCWLOfiupFoVDA0dERxcXFHMRNRAZR/XRbbUbNfJfTAJBJ0cdnuiHf3w16uo2IiIxHl4EhGDXzXdg94KxRbt/emQkSmRxjfGKzQd1tRERkXLoMDEGn/gONYvwGUVMY4xObTJKIiEycRCLlY/5k8ozxiU0mSdQmKVUi0nP+REFJGVztrTDA7wFIJbonMSUiopZn7Vi/JzHrW685MEmiNifptBwL9p3G9cosCGYlEO/aw8XcHwtG9sTwnu73PwERETW7q5buKJHawk55G7r+ZBUB3JLa4aqlO3z1FBOTJGpTkk7L8Y9/74Cl2z7YmBery0sqHfGPf4/Ex3iJiRIRkQFcv12B1PYPYUTBfoiARqJU/Rh+avvB6Hu7Qm8x8ek2ajOUKhFzUz6Hlee/IJgVa+wTzIph5fkvzE35HEoVZ8UgItI3V3srXLDtiB9cI3BLqrmSxy2pHX5wjcAF245wtbfSW0xsSaI248jF6yi13wMBQM01lAUBEEWg1H4Pjlwcj8GdXQ0SIxFRWzXA7wG4O1rhIjrioo0vPMrksFGWolRqg6tW7oAggbtj1RhSfWFLErUZ6fnHITEv1kqQqgkCIDEvRnr+cf0GRkREkEoEzB8ZULUhSHDF2hPZdl1wxdoTEKrSlfkjA/T6kA2TJGozJGa3mrUeERE1r+E93RE/vh9kjppdajJHK8SP76f3MaPsbqM2Y6C3L7acq189IiIyjOE93fFYgMwopmlhkkRtRn9ZIBzNnXGzolBnl5soAu0sXNBfFqj/4Fqpyrsq/Jx6GUWFpWjvbIMhoV4wN2MDNhHVTSoRENypvaHDYJLU0pRKJSorKw0dBv1l0cC5+DD9w1r3zxkwB5UVlaiE4f+fmZubQyo13aUlvvr3OVxM/gO2yqqM9E8AmV/9Dx3DO+CZ0d0MGxwRUT0IoijyeedGuN8qwqIoIj8/Hzdv3tR/cFSnsrtlKC4vhlL8e5FEqSCFo6UjrMz092hpfTg5OUEmk0GobbS5kfrq3+eQ/8MfAADhntlOxL9mO5GNYKJERIZxv+/ve7ElqYVUJ0iurq6wsbExuS+51k4URdy5ewdKUQmpIIW1mbVR/T8SRRGlpaUoKCgAALi7m84El5V3VbiY/AdsoJkg4a9tESIuJv+Byie6sOuNiIwak6QWoFQq1QlS+/aG71Ml3axhbegQ6mRtXRVfQUEBXF1dTabr7efUy+ouNl0ECLBVVtULH+Kjx8iIiBqGf8a1gOoxSDY2NgaOhExd9WfIlMa1FRWWNms9IiJDYZLUgoyp+4ZMkyl+hto71++Pg/rWIyIyFCZJRNSshoR64bZUVA/SrkmEiNtSEUNCvfQcGRFRwzBJIqJmZW4mQcfwDgCglShVb3cM78BB20Rk9PhbysgpVSIOXyjCvzOv4PCFohZfoT4sLAyCIEAQBGRmZtbrmISEBDg5OTVbDFFRURgzZky96x88eBCCIDR5uoWwsDDExMTUut/X11d9bzi1Q92eGd0NshEdUFpjrHmplI//E5Hp4NNtRizptBwL952FvLhMXebuaIX5IwNadP2aadOmYdGiRXB2dkZubi78/PzQFqfTCgsLQ1RUFKKiogAAx44dQ2pqKp5++mnDBmYinulyDsr/zUF+oRNuq9rBVnIDMuebkHb5EACTJCIyfmxJMlJJp+V49V8nNBIkAMgvLsOr/zqBpNPyFru2jY0NZDIZzMyYQ9/LxcUFDzzwgKHDMA1n9wK7X4K05Ao8Lc+gq/UheFqegbTkKrD7par9RERGjkmSEVKqRCzcd1bnsNfqsoX7zrZ411ttEhIS4O3tDRsbG4wdOxZFRUUNOj4uLg6urq6wt7fH1KlTMWfOHPTp06fW+uXl5YiOjoarqyusrKzw0EMP4dixY1r1fv31V/Tu3RtWVlYYOHAgTp06pd5XVFSE559/Hh06dICNjQ169eqFzz//vEFxUz2plEDSbKCuT3DSnKp6RERGjEmSEUrP+VOrBeleIgB5cRnSc/7UX1B/OXr0KCZPnowZM2YgMzMTQ4YMQVxcXL2P37lzJz744AMsW7YMGRkZ8Pb2Rnx8fJ3HvPPOO/j666+xfft2nDhxAp07d0ZERAT+/FPz/c+aNQsrV67EsWPH4OrqilGjRqnnFyorK0NgYCC+++47nD59Gi+//DImTJiAo0ePNvwmUN0upQGKq3VUEAHFlap6RERGjP0pRqigpPYEqTH1msLX11djPNK6desQERGBOXPmAAC6du2KtLQ0JCUl1et869evx5QpUzBp0iQAwLx585CcnIxbt27prH/79m3Ex8cjISEBI0aMAABs3rwZKSkp+PTTTzFr1ix13fnz5+Oxxx4DAGzfvh0dOnTAN998g3HjxsHT0xNvv/22uu7rr7+OpKQkfPnllxg4cKDOax88eLBe74lquHWteesRERkIW5KMkKt9/RZZrW+95pSVlYXg4GCNsprbdTl37hwGDBigUVZz+14XLlxAZWUlBg8erC4zNzfHgAEDkJWVVWscDzzwALp166auo1Qq8cEHH+DBBx9E+/btYWdnh+TkZOTl5dU7dqonO7fmrUdEZCBMkozQAL8H4O5ohdrmWhZQ9ZTbAD/9DyJujqfcas4iXdc5q/fpOqY+s1FX11m1ahXWrFmDd955Bz/99BMyMzMRERGBioqKhoZP9+MTAjh4AHV9gh08q+oRERkxJklGSCoRMH9kAADtr5nq7fkjAyCV6H/JioCAABw5ckSjrOZ2Xbp164b09HSNsuPHj9dav3PnzrCwsMChQ4fUZZWVlTh+/Dj8/f1rjePGjRs4f/48unfvDgBITU3F6NGjMX78ePTu3RsdO3ZEdnZ2veOmBpBIgeHL/tqo5RM8/MOqekRERoxJkpEa3tMd8eP7Qeao2aUmc7RC/Ph+LTpPUl2io6ORlJSE5cuX4/z58/j444/rPR4JqBoL9Omnn2L79u3Izs5GXFwcfv/991pbhWxtbfHqq69i1qxZSEpKwtmzZzFt2jSUlpZiypQpGnUXLVqEH3/8EadPn0ZUVBScnZ3Vk1J27twZKSkpSEtLQ1ZWFl555RXk5+c3+j7QfQSMAsbtABxqfE4dPKrKA0YZJi4iogbgwG0jNrynOx4LkCE9508UlJTB1b6qi80QLUjVBg0ahC1btmD+/PlYsGABhg0bhvfffx+LFy+u1/EvvvgiLl68iLfffhtlZWUYN24coqKitFqX7vXhhx9CpVJhwoQJKCkpQVBQEPbv34927dpp1XvjjTeQnZ2N3r17Y+/evbCwsAAAzJ07Fzk5OYiIiICNjQ1efvlljBkzBsXFxY2/GVS3gFFA9yeqnmK7da1qDJJPCFuQiMhkCGJbnEq5GSgUCjg6OqK4uBgODg4a+8rKypCTkwM/Pz9YWel/cHVThIWFoU+fPli7dq3ervnYY49BJpPhs88+09s1G+vgwYMYMmQIbty40axLsdTGlD9LRETGqK7v75rY3UZaNmzYADs7O43JGJtLaWkpVq9ejTNnzuC///0v5s+fjwMHDmDixInNfq3m1qNHD/U0BERE1Pqxu4007Ny5E3fu3AEAeHt7N/j4Hj164NKlSzr3bdy4EU899RQSExMRFxeH8vJydOvWDV9//TWGDRvWpLj1ITExUT055f3++iAiItPHJIk0eHp6Nun4exOJmtzc3GBtbY0DBw406RrNQRRFVJbdgVKphFQqhbmV9X2nFPDx8dFTdEREZAyYJFGzMoVEouzWLZQUXYfy7l11mdTMDPbtXWBlZ2fAyIiIyJhwTBK1KWW3buHmNblGggQAyrt3cfOaHGW1LI9CRERtD5MkajNEUURJ0fU665QUXW+WWcWJiMj0MUmiNqOy7I5WC1JNyrt3UVl2R08RERGRMWOSRG2GUqls1npERNS6GTxJ2rBhg3qivMDAQKSmptZZf+fOnejduzdsbGzg7u6OSZMmoaioSL0/ISEBgiBovcrKypp0XTJ9Umn9Znqubz0ialuUKiWO5R9D4sVEHMs/BqWKf1C1dgZNknbt2oWYmBi89957OHnyJEJDQzFixAjk5eXprH/o0CG89NJLmDJlCs6cOYMvv/wSx44dw9SpUzXqOTg4QC6Xa7zuna24odc1KJUSyEkFTn1V9d8W/qEMCwtTJ5aZmZn1OiYhIUEvs083lbmVNaRm2g907vp6D7r1DQRQ9ZSbuZV1s1zv4MGD6ntZvYYcEZmmA5cOIOLrCEzePxmzU2dj8v7JiPg6AgcuGX5KE2o5Bk2SVq9ejSlTpmDq1Knw9/fH2rVr4eXlhfj4eJ31jxw5Al9fX0RHR8PPzw8PPfQQXnnlFa1V5AVBgEwm03g15boAUF5eDoVCofFqcWf3Amt7AtufBL6eUvXftT2rylvQtGnTIJfL0bNnT+Tm5t53/iB9q46pvklcNUEQYN/eRat81BOP49cDyQAA+/YujX6/Ne9VSEgI5HI5xo0b16jzEZFxOHDpAGYenIlrpdc0ygtKCzDz4EwmSq2YwZKkiooKZGRkIDw8XKM8PDwcaWlpOo8JCQnBH3/8gcTERIiiiGvXruGrr77CE088oVHv1q1b8PHxQYcOHfDkk0/i5MmTTbouACxduhSOjo7ql5eXV0PfcsOc3QvsfglQXNUsV8irylswUbKxsYFMJoOZjlYXU2dlZwcnN3d1i1JlZSWsrazg5uYGJzf3Rs+TpGsCTQsLC8hkMlhbN0/LFBHpn1KlxIfpH0KE9lOv1WXL0pex662VMliSVFhYCKVSCTc3N41yNzc35Ofn6zwmJCQEO3fuRGRkpPoLyMnJCevXr1fX6d69OxISErB37158/vnnsLKywuDBg5Gdnd3o6wJAbGwsiouL1a/Lly839q3XSRRFVJSWQ0ycrfOHEtVlSXNavOutNgkJCfD29oaNjQ3Gjh2rMSbsfi5cuIDRo0fDzc0NdnZ26N+/v9YM3L6+vliyZAkmT54Me3t7eHt7Y9OmTer9fn5+AIC+fftCEASEhYWp923btg3+/v6wsrJC9+7dsWHDBvW+6paevYmJeHbiJPj26IXEn3/Bdz/+hC69+2okSPHx8ejUqRMsLCzQrVs3rcV3BUHAP//5T4wePRq2traIi4ur9z0gItNxouCEVgvSvUSIyC/Nx4mCE3qMivTF4AO3a3ZtiKJYa3fH2bNnER0djXnz5iEjIwNJSUnIycnB9OnT1XUGDRqE8ePHo3fv3ggNDcXu3bvRtWtXjUSqodcFAEtLSzg4OGi8mltZaSWKrtzG7d8PQrh1FbVHIwKKK8Cl2lu+WsrRo0cxefJkzJgxA5mZmRgyZEiDEoRbt27h8ccfx4EDB3Dy5ElERERg5MiRWuPBVq1ahaCgIJw8eRIzZszAq6++iv/+978AgPT0dADAgQMHIJfLsWfPHgDA5s2b8d577+GDDz5AVlYWlixZgrlz52L79u0a5549ezaio6ORlZWFkaNHw8zCUmP/N998gzfeeANvvfUWTp8+jVdeeQWTJk3Czz//rFFv/vz5GD16NE6dOoXJkyfX+x4Qkem4Xlr33GoNrUemxWD9Kc7OzpBKpVqtNwUFBVqtPNWWLl2KwYMHY9asWQCABx98ELa2tggNDUVcXBzc3d21jpFIJOjfv7+6Jakx19WHstJKKK5Xzc9jfqf2v1o03KpnvSbw9fXVmFxx3bp1iIiIwJw5cwAAXbt2RVpaGpKSkup1vt69e6N3797q7bi4OHzzzTfYu3cv/vGPf6jLH3/8ccyYMQNAVVKzZs0aHDx4EN27d4eLS9W4ovbt22uMN1u8eDFWrVqFp556CkBVi9PZs2exceNGTJw4UV0vJiZGXUeXlStXIioqSn39mTNn4siRI1i5ciWGDBmirvfCCy9oJUeciJKodXGx0R7H2JR6ZFoM1pJkYWGBwMBApKSkaJSnpKQgJCRE5zGlpaWQSDRDrn5cu7YvJ1EUkZmZqU6gGnPdliaKIm79Wa7eVlnXM1mz039Sl5WVheDgYI2ymtt1uX37Nt555x0EBATAyckJdnZ2+O9//6vVkvTggw+q/109EL+goKDW816/fh2XL1/GlClTYGdnp37FxcXhwoULGnWDgoLqjDErKwuDBw/WKBs8eDCysrIadB4iMn39XPvBzcYNQi1t+wIEyGxk6OfaT8+RkT4YdGTuzJkzMWHCBAQFBSE4OBibNm1CXl6euvssNjYWV65cwY4dOwAAI0eOxLRp0xAfH4+IiAjI5XLExMRgwIAB8PDwAAAsXLgQgwYNQpcuXaBQKPDRRx8hMzMTn3zySb2vq2+V5UqolKq/t90GQGnjDklpPgSd45IEwMED8NF/UtfUlpJZs2Zh//79WLlyJTp37gxra2s888wzqKio0Khnbm6usS0IAlQqFWpTvW/z5s0YOHCgxr6a8x7Z2treN876dMfW5zxEZNqkEinmDJiDmQdnQoCgMVa0OnGaPWA2pBLOr9YaGTRJioyMRFFRERYtWqR+5DwxMVG9krxcLtdoYYiKikJJSQk+/vhjvPXWW3BycsLQoUOxbNkydZ2bN2/i5ZdfRn5+PhwdHdG3b1/85z//wYABA+p9XX1TKWskHhIpbg1cCIefX4H414/l3/76oh7+IWCAH8qAgAAcOXJEo6zmdl1SU1MRFRWFsWPHAqgao5Sbm9ugGCwsLABozozt5uYGT09PXLx4ES+++GKDzleTv7+/ek6uamlpafD392/SeYnINA3zGYbVYavxYfqHGoO43WzcMHvAbAzzGWbA6KglGfwZ7xkzZqjHftSUkJCgVfb666/j9ddfr/V8a9aswZo1a5p0XX2TSLWbcct9R0AxZCPsjs6HtFT+9w4Hj6oEKWCUHiP8W3R0NEJCQrB8+XKMGTMGycnJ9R6PBACdO3fGnj17MHLkSAiCgLlz59bZQqSLq6srrK2tkZSUhA4dOsDKygqOjo5YsGABoqOj4eDggBEjRqC8vBzHjx/HjRs3MHPmzHqff9asWRg3bhz69euHRx99FPv27cOePXu0nsIjorZjmM8wDPEaghMFJ3C99DpcbFzQz7UfW5BaOYM/3UaAuaUUEqn2/4py3xEoevYwbgzfDcWQTyBO3AfEnDJYggRUPT24ZcsWrF+/Hn369EFycjLef//9eh+/Zs0atGvXDiEhIRg5ciQiIiLQr1/D+vLNzMzw0UcfYePGjfDw8MDo0aMBAFOnTsWWLVuQkJCAXr164ZFHHkFCQoJ6yoD6GjNmDNatW4cVK1agR48e2LhxI7Zt26Yx1QARtT1SiRT9Zf3xeMfH0V/WnwlSGyCIfBynURQKBRwdHVFcXKw1HUBZWRlycnLUa8PVx71Pt+ni4GINKxvzWvc3l7CwMPTp0wdr165t8Wu1FVFRUbh58ya+/fbbBh/bmM8SERHVrq7v75rYkmQkrGzM4eBirdWiJJFK9JYgVduwYQPs7Oxw6tQpvV2zNUpNTYWdnR127txp6FCIiKgRDD4mif5mZWMOS2uzv552EyGRCjC3lOp17bSdO3fizp2qFi1vb+8GH9+jRw9cunRJ576NGzc2eVC1KQkKClKvL2fXyOVOiIjIcJgkGRlBEGBhZbj/LZ6enk06PjExUec6ZgAMOlmnIVhbW6Nz586GDoOIiBqJSRI1K0NNo0BERNTcOCaJiIiISAcmSUREREQ6MEkiIiIi0oFJEhEREZEOHLhNRGTilColl8sgagFsSTJySpUSx/KPIfFiIo7lH4NSpbz/QU0QFhYGQRAgCIJ6jp/7SUhIgJOTU4vGZSgHDx6EIAi4efNms543NzdXfZ/79OnTrOemtuXApQOI+Go43t+9BJu/2YX3dy9BxFfDceAS1xokaiq2JBmxA5cO6Fx1es6AOS266vS0adOwaNEiODs7Izc3F35+fjCl1WsEQcA333yDMWPGNPlcISEhkMvlcHR0bJa4cnJy4OvrCy8vL8jlcqxcuZIL51KjHbh0AOu/TsBjudNhV9FOXX7rfzew/o8E4GlwhXqiJmBLkpE6cOkAZh6cqZEgAUBBaQFmHpzZon8l2tjYQCaTwcysbefQlZWVsLCwgEwma9Ks5xUVFVplUqkUMpms1c/ErVIpcfnM78j69RdcPvM7VC3cEtqWKFVK7PjuGzx2fhJsK5w09tlWOOGx85Ow47tvWrz1mag1Y5JkhJQqJT5M/xAitFtvqsuWpS8z2C+/hIQEeHt7w8bGBmPHjkVRUVG9j12wYAH69OmDjRs3wsvLCzY2Nnj22Wc1urNUKhUWLVqEDh06wNLSEn369EFSUpJ6f0VFBf7xj3/A3d0dVlZW8PX1xdKlSwEAvr6+AICxY8dCEAT1NgDs27cPgYGBsLKyQseOHbFw4ULcvXtXvV8QBPzzn//E6NGjYWtri7i4OJ3dbV9//TV69OgBS0tL+Pr6YtWqVRrv0dfXF3FxcYiKioKjoyOmTZtW7/vTmmQfTcPm16Zg96J3kfjRCuxe9C42vzYF2UfTDB1aq5CRn4Ee54YCAARoJvHV2wHnhiIjP0PvsRE1lb6HmtSGSZIROlFwQqsF6V4iROSX5uNEwQk9RlXl6NGjmDx5MmbMmIHMzEwMGTIEcXFxDTrH//73P+zevRv79u1DUlISMjMz8dprr6n3r1u3DqtWrcLKlSvx+++/IyIiAqNGjUJ2djYA4KOPPsLevXuxe/dunDt3Dv/617/UydCxY8cAANu2bYNcLldv79+/H+PHj0d0dDTOnj2LjRs3IiEhAR988IFGbPPnz8fo0aNx6tQpTJ48WSv2jIwMjBs3Ds899xxOnTqFBQsWYO7cuUhISNCot2LFCvTs2RMZGRmYO3dug+5Pa5B9NA17Vy/BrT8LNcpv/VmIvauXMFFqBpfP/wm7inZaCVI1AQLsK9rh8vk/9RwZUdMcuHQAEV9HYPL+yZidOhuT909GxNcRBhln17b7U4zU9dLrzVqvKXx9fTXGI61btw4RERGYM2cOAKBr165IS0vTaOm5n7KyMmzfvh0dOnQAAKxfvx5PPPEEVq1aBZlMhpUrV2L27Nl47rnnAADLli3Dzz//jLVr1+KTTz5BXl4eunTpgoceegiCIGgsheLi4gIAcHJygkwmU5d/8MEHmDNnDiZOnAgA6NixIxYvXox33nkH8+fPV9d74YUXNJKjnJwcjdhXr16NRx99VJ34dO3aFWfPnsWKFSsQFRWlrjd06FC8/fbbGsea0riuplCplPgpYVOddX7evgmd+g+EhE9gNZptpQOAsnrWIzIN1UNNavakVA81WR22Wq/j7NiSZIRcbFyatV5zysrKQnBwsEZZze378fb2VidI1cerVCqcO3cOCoUCV69exeDBgzWOGTx4MLKysgAAUVFRyMzMRLdu3RAdHY3k5OT7XjMjIwOLFi2CnZ2d+jVt2jTI5XKUlpaq6wUFBdV5nqysLJ2xZWdnQ6n8uzn4fudpza5kndFqQaqppKgQV7LO6Cmi1inAq1uz1iMyNGMcasKWJCPUz7Uf3GzcUFBaoPPDIkCAm40b+rn203tsLdEaUj0o+t7B0TUHSouiqC7r168fcnJy8MMPP+DAgQMYN24chg0bhq+++qrWa6hUKixcuBBPPfWU1j4rKyv1v21tbeuM9d447i2r6X7nac1u3bzRrPVItw5dH4CZvYjKEu0xSUDVl4q5fVU9IlPQkKEm/WX99RITW5KMkFQixZwBVd1ZtQ3InD1gtkEmiwsICMCRI0c0ympu309eXh6uXr2q3j58+DAkEgm6du0KBwcHeHh44NChQxrHpKWlwd/fX73t4OCAyMhIbN68Gbt27cLXX3+NP/+sGnthbm6u0aoDVCVW586dQ+fOnbVeEkn9fwwCAgJ0xta1a1dIpew6AgA7p3b3r9SAeqSbRCJg2Au9IABaf0yJECEAGPZCL0gkjX8yk0ifjGmoSTW2JBkZURRRWXYHg9sPxPKQpViZuUZrnqTZA2YbbO6T6OhohISEYPny5RgzZgySk5MbNB4JqGq5mThxIlauXAmFQoHo6GiMGzdOPYZo1qxZmD9/Pjp16oQ+ffpg27ZtyMzMxM6dOwEAa9asgbu7O/r06QOJRIIvv/wSMplMPaGlr68vfvzxRwwePBiWlpZo164d5s2bhyeffBJeXl549tlnIZFI8Pvvv+PUqVMNGnj+1ltvoX///li8eDEiIyNx+PBhfPzxx9iwYUOD7kFr5unfA3YPONfZ5Wbf3hme/j30GFXr1KmvK4a/0gupu87j9s2/p5qwa2eF0HFd0KmvqwGjI2oYYxxqwiTJiJTduoWSoutQ/vVYeh9JV/yr/z9xQbyKYvGWUSw3MGjQIGzZsgXz58/HggULMGzYMLz//vtYvHhxvc/RuXNnPPXUU3j88cfx559/4vHHH9dIMqKjo6FQKPDWW2+hoKAAAQEB2Lt3L7p06QIAsLOzw7Jly5CdnQ2pVIr+/fsjMTFR3SK0atUqzJw5E5s3b4anpydyc3MRERGB7777DosWLcLy5cthbm6O7t27Y+rUqQ16//369cPu3bsxb948LF68GO7u7li0aJHGoO22TiKRYmjUy9i7ekmtdYZMfJmDtptJp76u8OvtAnn2TdxWlMPWwRLuXZzYgkQmxxiHmghiW3nkppkpFAo4OjqiuLgYDg6aT4+UlZUhJycHfn5+GuNd6lJ26xZuXpPXut/JzR1Weph4MCwsDH369MHatWtb5PwLFizAt99+W+8lT1q7+92PxnyWjEX20TT8lLBJo0XJvr0zhkx8GV0GhhgwMiIyVtVPtwGa3cjVQ02a4+m2ur6/a2JLkhEQRRElRXX3sZYUXYelrW2TZn6urw0bNmDLli04fPgwevXq1eLXa4vy8vIQEBCAiooKBAQEGDqcFtFlYAg69R9Y9bTbzRuwc2oHT/8ebEEioloN8xmG1WGrdS7JZYihJkySjEBl2R11F1ttlHfvorLsDiysbVo0lp07d+LOnTsAqh7Vb6gePXrg0qVLOvdt3LixSbG1Jh4eHurWI0tLS8MG04IkEim8ejxo6DCIyIQM8xmGIV5DcKLgBK6XXjfoUBMmSUag5pNYTa3XFJ6enk06PjExEZWVlTr3ubm5wd7eHgsWLGjSNVoDMzMzdO7c2dBhEBEZJalEqrfH/OvCJMkI1PfRcVN4xPze2a+JiIhMGedJMgLmVtaQmtWdr0rNzGBuZa2niIiIiIhJkhEQBAH27eue98G+vYteBm0TERFRFSZJRsLKzg5Obu5aLUpSMzO9Pf5PREREf+OYJCNiZWcHS1vbqqfdlEpIpVKYW1mzBYmIiMgAmCQZGUEQWvwxfyIiIro/drcZOVGpxO2j6Sj+7nvcPpoOsYWnAQgLC4MgCBAEod6zYickJKjXTWvrDh48qL5/Y8aMMXQ4RETUBEySjJgiORn/e3QY8iZOxNW330bexIn436PDoEhObtHrTps2DXK5HD179kRubq7JdfcJgoBvv/1WL9eqeX9CQkIgl8sxbtw4vVyfiIhaDpMkI6VITsaVN2JwNz9fo/zutWu48kZMiyZKNjY2kMlkMLvPtASkzcLCAjKZDNbWnK6BiMjUMUkyQqJSiWtLlgK61h7+q+zakqUt3vVWm4SEBHh7e8PGxgZjx45FUVFRvY/97bffMGTIENjb28PBwQGBgYE4fvy4en9aWhoefvhhWFtbw8vLC9HR0bh9+7Z6v6+vLxYvXowXXngBdnZ28PDwwPr16zX2A8DYsWMhCIJ6OyoqSqv7KyYmBmFhYertsLAwvP7664iJiUG7du3g5uaGTZs24fbt25g0aRLs7e3RqVMn/PDDD/W/WUREZLKYJBmh0uMZWi1IGkQRd/PzUXo8Q39B/eXo0aOYPHkyZsyYgczMTAwZMgRxcXH1Pv7FF19Ehw4dcOzYMWRkZGDOnDkwNzcHAJw6dQoRERF46qmn8Pvvv2PXrl04dOgQ/vGPf2icY8WKFXjwwQdx4sQJxMbG4s0330RKSgoA4NixYwCAbdu2QS6Xq7fra/v27XB2dkZ6ejpef/11vPrqq3j22WcREhKCEydOICIiAhMmTEBpaWmDzktERKaH/SlG6O71681aryl8fX0h3tOitW7dOkRERGDOnDkAgK5duyItLQ1JSUn1Ol9eXh5mzZqF7t27AwC6dOmi3rdixQq88MILiImJUe/76KOP8MgjjyA+Ph5WVlYAgMGDB2tc/9dff8WaNWvw2GOPwcWlalJOJycnyGSyBr/f3r174/333wcAxMbG4sMPP4SzszOmTZsGAJg3bx7i4+Px+++/Y9CgQVr3h4iIWg+2JBkhM5e6Z99uaL3mlJWVheDgYI2ymtt1mTlzJqZOnYphw4bhww8/xIULF9T7MjIykJCQADs7O/UrIiICKpUKOTk5tV4vODgYWVlZjXxHmh588O8V66VSKdq3b49evXqpy9zc3AAABQUFzXI9IiIyXgZPkjZs2AA/Pz9YWVkhMDAQqampddbfuXMnevfuDRsbG7i7u2PSpEkaY2I2b96M0NBQtGvXDu3atcOwYcOQnp6ucY4FCxaoH9OufjWm1aGl2AQFwkwmA2p7qkwQYCaTwSYoUL+BAU1uNVmwYAHOnDmDJ554Aj/99BMCAgLwzTffAABUKhVeeeUVZGZmql+//fYbsrOz0alTpzrPe78n8CQSiVbslZWVWvWqu/7uPe+9ZdXXUalUdV6PiIhMn0GTpF27diEmJgbvvfceTp48idDQUIwYMQJ5eXk66x86dAgvvfQSpkyZgjNnzuDLL7/EsWPHMHXqVHWdgwcP4vnnn8fPP/+Mw4cPw9vbG+Hh4bhy5YrGuXr06AG5XK5+nTp1qkXfa0MIUinc3o39a6PGl/9f227vxkKQSvUcGRAQEIAjR45olNXcvp+uXbvizTffRHJyMp566ils27YNANCvXz+cOXMGnTt31npZWFjUer0jR46ou++AqkRHWWNQu4uLC+RyuUZZfeeBIiKitsmgSdLq1asxZcoUTJ06Ff7+/li7di28vLwQHx+vs/6RI0fg6+uL6Oho+Pn54aGHHsIrr7yi8XTUzp07MWPGDPTp0wfdu3fH5s2boVKp8OOPP2qcy8zMDDKZTP1yMUDXVV0cwsPhuW4tzP7q3qlm5uYGz3Vr4RAebpC4oqOjkZSUhOXLl+P8+fP4+OOP6z0e6c6dO/jHP/6BgwcP4tKlS/j1119x7Ngx+Pv7AwBmz56Nw4cP47XXXkNmZiays7Oxd+9evP766xrn+fXXX9XX/+STT/Dll1/ijTfeUO/39fXFjz/+iPz8fNy4cQMAMHToUBw/fhw7duxAdnY25s+fj9OnTzfTXSEiotbIYElSRUUFMjIyEF7jyz48PBxpaWk6jwkJCcEff/yBxMREiKKIa9eu4auvvsITTzxR63VKS0tRWVmJBx54QKM8OzsbHh4e8PPzw3PPPYeLFy/WGW95eTkUCoXGq6U5hIej848H4L19OzxWroT39u3o/OMBgyVIADBo0CBs2bIF69evR58+fZCcnKwe6Hw/UqkURUVFeOmll9C1a1eMGzcOI0aMwMKFCwFUjQf65ZdfkJ2djdDQUPTt2xdz586Fu7u7xnneeustZGRkoG/fvli8eDFWrVqFiIgI9f5Vq1YhJSUFXl5e6Nu3LwAgIiICc+fOxTvvvIP+/fujpKQEL730UjPdFSIiapVEA7ly5YoIQPz11181yj/44AOxa9eutR735ZdfinZ2dqKZmZkIQBw1apRYUVFRa/0ZM2aInTp1Eu/cuaMuS0xMFL/66ivx999/F1NSUsRHHnlEdHNzEwsLC2s9z/z580UAWq/i4mKtunfu3BHPnj2rcU1T8cgjj4hvvPGGocOolY+Pj7hmzRpDh3FfEydOFEePHt3k85jyZ4mIyBgVFxfX+v1dk8EHbtcccCuKYq2DcM+ePYvo6GjMmzcPGRkZSEpKQk5ODqZPn66z/vLly/H5559jz5496sfHAWDEiBF4+umn0atXLwwbNgzff/89gKo5cmoTGxuL4uJi9evy5csNfasmY8OGDbCzszOqcVqmIjU1FXZ2dti5c6ehQyEioiYy2DxJzs7OkEqlyK8xaWJBQYH6Meuali5disGDB2PWrFkAqrpnbG1tERoairi4OI1umZUrV2LJkiU4cOCAxmPdutja2qJXr17Izs6utY6lpSUsLS3r+/ZM1s6dO3Hnzh0AgLe3d4OP79GjBy5duqRz38aNG/Hiiy82KT5jFxQUpB4QbmdnZ9hgiIioSQyWJFlYWCAwMBApKSkYO3asujwlJQWjR4/WeUxpaanWemLSv57wEu95vHvFihWIi4vD/v37ERQUdN9YysvLkZWVhdDQ0Ma8lVbF09OzSccnJibqfLQeQK3Jb0Pk5uY2+RwtydraGp07dzZ0GERE1AwMOuP2zJkzMWHCBAQFBSE4OBibNm1CXl6euvssNjYWV65cwY4dOwAAI0eOxLRp0xAfH4+IiAjI5XLExMRgwIAB8PDwAFDVxTZ37lz83//9H3x9fdUtVdWTEwLA22+/jZEjR8Lb2xsFBQWIi4uDQqHAxIkTDXAXWhcfHx9Dh0BERNQsDJokRUZGoqioCIsWLYJcLkfPnj2RmJio/qKVy+UacyZFRUWhpKQEH3/8Md566y04OTlh6NChWLZsmbrOhg0bUFFRgWeeeUbjWvPnz8eCBQsAAH/88Qeef/55FBYWwsXFBYMGDcKRI0f4BU9ERERqgihy4anGUCgUcHR0RHFxMRwcHDT2lZWVIScnRz2TOFFj8bNERNS86vr+rsngT7cRERERGSODdreRNlEUUXq3FHdVd2EmMYONmc191yUjIiKi5sckyYgoyhWQ35bjruquusxMYgZ3W3c4WNbdJEhERETNi91tRkJRrsDlkssaCRIAVN6txO+/XcBvaTm4cu4GVKqWHUIWFhYGQRAgCEK9F4BNSEiAk5NTveouWLAAffr0aXR8+hAVFYUxY8bUur8x94iIiEwPkyQjIIoi5LflWuXXz5ThyMpC/Lb1Bg7tyMG3a05ix7tpuHCyoEXjmTZtmvppw9zcXIN39wmCgG+//dZg14+KilI/GQkAe/bsQXp6usHiISIi/WCSZASqxyDd6/qZMpz5vBjlCpVG+e2b5UjaeLpFEyUbGxvIZDKtiTtNXW2TXDbUAw88ABcXl2Y5FxERGS8mSUagZoIkqkT87/uSOo85tDu7xbveapOQkABvb2/Y2Nhg7NixKCoqavS5jh07hsceewzOzs5wdHTEI488ghMnTqj3+/r6AgDGjh0LQRDU2wCwb98+BAYGwsrKCh07dsTChQtx9+7f91IQBPzzn//E6NGjYWtri7i4OCiVSkyZMgV+fn6wtrZGt27dsG7dukbHT0RErReTJCNgJtFssbmZW6nVglTTrRvlkGffbMGodDt69CgmT56MGTNmIDMzE0OGDEFcXFyjz1dSUoKJEyciNTUVR44cQZcuXfD444+jpKQqSTx27BgAYNu2bZDL5ert/fv3Y/z48YiOjsbZs2exceNGJCQk4IMPPtA4//z58zF69GicOnUKkydPhkqlQocOHbB7926cPXsW8+bNw7vvvovdu3c3+j0QEVHr1Lr6U0yUjZkNzCRm6halihJlvY67rShvybAAVLXk3Dvf6Lp16xAREYE5c+YAALp27Yq0tDQkJSU16vxDhw7V2N64cSPatWuHX375BU8++aS6W8vJyQkymUxd74MPPsCcOXPUS8l07NgRixcvxjvvvIP58+er673wwguYPHmyxjUWLlyo/refnx/S0tKwe/dujBs3TmeMCQkJjXpvRERk2tiSZAQEQYC7rbt628JeWq/jbB0sWyqkWmVlZSE4OFijrOZ2QxQUFGD69Ono2rUrHB0d4ejoiFu3bmksR6NLRkYGFi1apF6Tz87OTj3gvLS0VF1P1wLH//znPxEUFAQXFxfY2dlh8+bN970eERG1PWxJMhIOlg7wghfkt+Vw8hVh6SCps8vNrp0l3Ls46S/AvzT3KjZRUVG4fv061q5dCx8fH1haWiI4OBgVFRV1HqdSqbBw4UI89dRTWvvuXb7D1tZWY9/u3bvx5ptvYtWqVQgODoa9vT1WrFiBo0ePNs8bIiKiVoNJkhFxsHSAvYU9Su+WQnzGDv/ZerHWug+N6wKJRP+P5gcEBODIkSMaZTW3GyI1NRUbNmzA448/DgC4fPkyCgsLNeqYm5tDqdTsguzXrx/OnTuHzp07N/h6ISEhmDFjhrrswoULjYyeiIhaMyZJRkYQBNia26LXAFvYmNsgdVc2bt/8e+yRXTtLPDSuCzr1dTVIfNHR0QgJCcHy5csxZswYJCcnN3o8EgB07twZn332GYKCgqBQKDBr1ixYW1tr1PH19cWPP/6IwYMHw9LSEu3atcO8efPw5JNPwsvLC88++ywkEgl+//13nDp1qs6B5J07d8aOHTuwf/9++Pn54bPPPsOxY8fg5+fX6PdAREStE8ckGbFOfV3x0pIQjHmzLx6bEoAxb/bFhA9CDJYgAcCgQYOwZcsWrF+/Hn369EFycjLef//9Rp9v69atuHHjBvr27YsJEyYgOjoarq6a72/VqlVISUmBl5cX+vbtCwCIiIjAd999h5SUFPTv3x+DBg3C6tWr4ePjU+f1pk+fjqeeegqRkZEYOHAgioqKNFqViIiIqglicw8yaSMUCgUcHR1RXFwMBwfNddXKysqQk5MDPz8/jfExpiAsLAx9+vTB2rVrDR2KUcvNzYWfnx9OnjzZosusmPJniYjIGNX1/V0TW5JIy4YNG2BnZ4dTp04ZOhSjNGLECPTo0cPQYRARUQvjmCTSsHPnTty5cwcA4O3t3eDje/TogUuXLunct3HjRrz44otNis8YbNmypUn3iIiITAOTJNLg6enZpOMTExNrXSPNzc2tSec2Fk29R0REZBqYJFGzut/AaSIiIlPBMUlEREREOjBJIiIiItKBSRIRERGRDkySiIiIiHTgwG0iIqJ6UKmUuJJ1Brdu3oCdUzt4+veARCI1dFjUgpgkGTl9/1CGhYXhl19+AYB6zyadkJCAmJgY3Lx5s8Xiqo/8/HxMmDABaWlpMDc31xmPIFQtCuzo6GjweInIdGQfTcNPCZtw68+/F+C2e8AZQ6NeRpeBIQaMjFoSu9uMWPbRNGx+bQp2L3oXiR+twO5F72Lza1OQfTStRa87bdo0yOVy9OzZE7m5uerEwtitWbMGcrkcmZmZOH/+PICqxXEPHjyoriOXy7nkChE1SPbRNOxdvUQjQQKAW38WYu/qJS3+O5kMh0mSkTLkD6WNjQ1kMhnMzFq+obG2iScb48KFCwgMDESXLl20FsmtJpPJ4Ojo2GzXJKLWTaVS4qeETXXW+Xn7JqhUSj1FRPrEJMkIGfsPZUJCAry9vWFjY4OxY8eiqKio3scuWLAAffr0wdatW9GxY0dYWlpCFEXk5eVh9OjRsLOzg4ODA8aNG4dr165pHBsfH49OnTrBwsIC3bp1w2effabe5+vri6+//ho7duyAIAiIiopqrrdLRG3YlawzWn+s1lRSVIgrWWf0FBHpE5MkI2TMP5RHjx7F5MmTMWPGDGRmZmLIkCGIi4tr0Dn+97//Yffu3fj666+RmZkJABgzZgz+/PNP/PLLL0hJScGFCxcQGRmpPuabb77BG2+8gbfeegunT5/GK6+8gkmTJuHnn38GABw7dgzDhw/HuHHjIJfLsW7dumZ7z0TUdt26eaNZ65Fp4cBtI2RMP5S+vr4QRVG9vW7dOkRERGDOnDkAgK5duyItLQ1JSUn1PmdFRQU+++wzuLi4AABSUlLw+++/IycnB15eXgCAzz77DD169MCxY8fQv39/rFy5ElFRUZgxYwYAYObMmThy5AhWrlyJIUOGwMXFBZaWlrC2toZMJlNfKzc3t6m3gIjaMDunds1aj0wLW5KMkDH/UGZlZSE4OFijrOb2/fj4+KgTpOpzenl5qRMkAAgICICTkxOysrLUdQYPHqxxnsGDB6v3ExG1BE//HrB7wLnOOvbtneHp30NPEZE+MUkyQsb8Q3lvq1Jj2draap1T1xN0Nctr1qntOCKi5iKRSDE06uU66wyZ+DLnS2qlmCQZIWP+oQwICMCRI0c0ympuN+aceXl5uHz5srrs7NmzKC4uhr+/PwDA398fhw4d0jguLS1NvZ+IqKV0GRiCUTPf1frj1b69M0bNfJfzJLViHJNkpKp/KGtOXmbf3hlDJhpu8rLo6GiEhIRg+fLlGDNmDJKTkxs0HkmXYcOG4cEHH8SLL76ItWvX4u7du5gxYwYeeeQRBAUFAQBmzZqFcePGoV+/fnj00Uexb98+7NmzBwcOHGiOt0VEVKcuA0PQqf9AzrjdxjBJMmLG+EM5aNAgbNmyBfPnz8eCBQswbNgwvP/++1i8eHGjzykIAr799lu8/vrrePjhhyGRSDB8+HCsX79eXWfMmDFYt24dVqxYgejoaPj5+WHbtm0ICwtrhndFRHR/EokUXj0eNHQYpEeC2ByDTNoghUIBR0dHFBcXw8HBQWNfWVkZcnJy4OfnBysrKwNF2DhhYWHo06dPq56V2liWUakPU/4sEREZo7q+v2vimCTSsmHDBtjZ2eHUqVOGDqXZ2dnZYfr06YYOg4iITAC720jDzp07cefOHQCAt7d3g4/v0aMHLl26pHPfxo0b8eKLLzYpvqaqnrxSKuU4AiIiqhuTJNLg6enZpOMTExNrXY/Nzc2tSeduDp07dzZ0CEREZCKYJFGz8vHxMXQIREREzcLgY5I2bNigHpQaGBiI1NTUOuvv3LkTvXv3ho2NDdzd3TFp0iStBVa//vprBAQEwNLSEgEBAfjmm2+afF0iIiJqWwyaJO3atQsxMTF47733cPLkSYSGhmLEiBHIy8vTWf/QoUN46aWXMGXKFJw5cwZffvkljh07hqlTp6rrHD58GJGRkZgwYQJ+++03TJgwAePGjcPRo0cbfV0iIiJqeww6BcDAgQPRr18/xMfHq8v8/f0xZswYLF26VKv+ypUrER8fjwsXLqjL1q9fj+XLl6tna46MjIRCocAPP/ygrjN8+HC0a9cOn3/+eaOuq0trnQKAjAs/S0REzcskpgCoqKhARkYGwsPDNcrDw8ORlpam85iQkBD88ccfSExMhCiKuHbtGr766is88cQT6jqHDx/WOmdERIT6nI25LgCUl5dDoVBovIiIiKj1MliSVFhYCKVSqfXEk5ubG/Lz83UeExISgp07dyIyMhIWFhaQyWRwcnLSmJk5Pz+/znM25roAsHTpUjg6Oqpf965YT0RERK2PwQduN2Rl97NnzyI6Ohrz5s1DRkYGkpKSkJOTozU5YH3O2dAV5WNjY1FcXKx+3bsYa0sSVSLKLtxEaWYByi7chKhq2d7RsLAwCIIAQRDUcwoZi4SEBHVsMTExhg6HiIhaOYMlSc7OzpBKpVqtNwUFBbXOp7N06VIMHjwYs2bNwoMPPoiIiAhs2LABW7duhVwuBwDIZLI6z9mY6wKApaUlHBwcNF4t7c7pQuQvS0fh5lP484tzKNx8CvnL0nHndOH9D26CadOmQS6Xo2fPnsjNzdVIHg8ePKhOVGq+qu/p7du3MXv2bHTs2BFWVlZwcXFBWFgYvvvuOwBAr169NAbb3+vzzz+Hubk5rl27hoMHD8LX11e9LzIyEnK5HMHBwS335qlZKVVKHMs/hsSLiTiWfwxKldLQIRER1ZvBkiQLCwsEBgYiJSVFozwlJQUhIbpXuC8tLYVEohly9czJ1ePPg4ODtc6ZnJysPmdjrmsId04XouhfWVAWV2iUK4srUPSvrBZNlGxsbCCTyWBmVvs0WufOnYNcLtd4ubq6AgCmT5+Ob7/9Fh9//DH++9//IikpCU8//bR6qoYpU6Zg9+7dKC0t1Trv1q1b8eSTT+pMWK2trSGTyWBhYdFM75Ra0oFLBxDxdQQm75+M2amzMXn/ZER8HYEDlw4YOjQionox6GSSM2fOxIQJExAUFITg4GBs2rQJeXl56u6z2NhYXLlyBTt27AAAjBw5EtOmTUN8fDwiIiIgl8sRExODAQMGwMPDAwDwxhtv4OGHH8ayZcswevRo/Pvf/8aBAwdw6NChel/X0ESViJv7LtRZ5+a+i7AKaA9BUnsXYUtydXWFk5OTzn379u3DunXr8PjjjwMAfH19ERgYqN4/YcIEzJ49G19++SUmTpyoLs/Ly8NPP/2Ef//73y0aO7W8A5cOYObBmRCh2T1cUFqAmQdnYnXYagzzGWag6IiI6segSVJkZCSKioqwaNEidfdOYmKietZmuVyuMXdRVFQUSkpK8PHHH+Ott96Ck5MThg4dimXLlqnrhISE4IsvvsD777+PuXPnolOnTti1axcGDhxY7+saWnlOsVYLUk3K4nKU5xTDqpOTfoJqAJlMhsTERDz11FOwt7fX2t++fXuMHj0a27Zt00iStm3bBjc3N4wYMUKf4VIzU6qU+DD9Q60ECQBEiBAgYFn6MgzxGgKphGvokelQqUTIs2/itqIctg6WcO/iBImB/lAl/TD4siQzZszAjBkzdO5LSEjQKnv99dfx+uuv13nOZ555Bs8880yjr2toqpK6E6SG1msKX19f6JpKq0OHDhrbnp6eOHfuHABg06ZNePHFF9G+fXv07t0bDz30EJ555hkMHjxYXX/y5Ml4/PHHcfHiRXTs2BGiKCIhIQFRUVHqLtSwsDDk5ua23JujFnGi4ASulV6rdb8IEfml+ThRcAL9Zf31GBlR4104WYDUXdm4fbNcXWbrZInQyC7o1NfVgJFRSzL4022kTWJfvzE39a3XElJTU5GZmal+7d+/X73v4YcfxsWLF/Hjjz/i6aefxpkzZxAaGorFixer64SHh6NDhw7Ytm0bAOCnn35Cbm4uJk2apPf3Qs3reun1Zq1HZGgXThYgaeNpjQQJAG7fLEfSxtO4cLLAQJFRS2OSZIQs/Rwhdaw7AZI6WsLSz1FPEWnz8/ND586d1a97n0IDAHNzc4SGhmLOnDlITk7GokWLsHjxYlRUVLV+SSQSREVFYfv27VCpVNi2bRsefvhhdOnSxQDvhpqTi41Ls9YjMiSVSkTqruw66xzanQ1VC0/PQobBJMkICRIBTiM71VnHaWRHgw3aboyAgADcvXsXZWVl6rJJkybhjz/+wJ49e7Bnzx5MmTLFgBFSc+nn2g9uNm4QoPvzKUCAzEaGfq799BwZUcPJs29qtSDVdOtGOeTZN/UTEOkVkyQjZd3TGe3H+2u1KEkdLdF+vD+sezobKLIqBQUFyM/P13hVVlYCqBpLtHHjRmRkZCA3NxeJiYl49913MWTIEI35pfz8/DB06FC8/PLLMDc3v+84MjINUokUcwbMAQCtRKl6e/aA2Ry0TSbhtqLuBKmh9ci0GHzgNtXOuqczrALaozynGKqSCkjsLWDp52gULUjdunXTKjt8+DAGDRqEiIgIbN++He+++y5KS0vh4eGBJ598EvPmzdM6ZsqUKfjxxx/x8ssvw8bGRh+hkx4M8xmG1WGr8WH6hxqDuN1s3DB7wGw+/k8mw9bBslnrkWlhkmTkBIlgVI/5h4WF6Xza7V6xsbGIjY2t1/mef/55PP/8880RGhmZYT7DMMRrCE4UnMD10utwsXFBP9d+bEEik+LexQm2TpZ1drnZtauaDoBaH3a3kZYNGzbAzs4Op06dMnQoGnbu3Ak7OzukpqYaOhSqJ6lEiv6y/ni84+PoL+vPBIlMjkQiIDSy7gdKHhrXhfMltVJsSSINO3fuxJ07dwAA3t7eBo5G06hRo9STgtY22zcRUXPr1NcVw1/pqTVPkl07Szw0jvMktWZMkkiDp6enoUOolb29vc4ZvImIWlqnvq7w6+3CGbfbGCZJRERE9SCRCPDs1s7QYZAecUxSC7rfAGei++FniIjIcJgktQBzc3MAQGlpqYEjIVNX/Rmq/kwREZH+sLutBUilUjg5OaGgoGo9HxsbGwgC+62p/kRRRGlpKQoKCuDk5KRe9JeIiPSHSVILkclkAKBOlIgaw8nJSf1ZIiIi/WKS1EIEQYC7uztcXV3Vy3UQNYS5uTlbkIiIDIhJUguTSqX8oiMiIjJBHLhNREREpAOTJCIiIiIdmCQRERER6cAxSY1UPcmfQqEwcCRERERUX9Xf2/WZrJdJUiOVlJQAALy8vAwcCRERETVUSUkJHB0d66wjiFz3oFFUKhWuXr0Ke3v7Zp8oUqFQwMvLC5cvX4aDg0Oznpv+xvusH7zP+sH7rB+8z/rTUvdaFEWUlJTAw8MDEkndo47YktRIEokEHTp0aNFrODg48IdQD3if9YP3WT94n/WD91l/WuJe368FqRoHbhMRERHpwCSJiIiISAcmSUbI0tIS8+fPh6WlpaFDadV4n/WD91k/eJ/1g/dZf4zhXnPgNhEREZEObEkiIiIi0oFJEhEREZEOTJKIiIiIdGCSRERERKQDkyQD27BhA/z8/GBlZYXAwECkpqaq9+3ZswcRERFwdnaGIAjIzMw0XKAmrrb7XFlZidmzZ6NXr16wtbWFh4cHXnrpJVy9etXAEZumuj7PCxYsQPfu3WFra4t27dph2LBhOHr0qAGjNV113ed7vfLKKxAEAWvXrtVvgK1EXfc5KioKgiBovAYNGmTAaE3b/T7TWVlZGDVqFBwdHWFvb49BgwYhLy+vxeNikmRAu3btQkxMDN577z2cPHkSoaGhGDFihPp//O3btzF48GB8+OGHBo7UtNV1n0tLS3HixAnMnTsXJ06cwJ49e3D+/HmMGjXK0GGbnPt9nrt27YqPP/4Yp06dwqFDh+Dr64vw8HBcv37dwJGblvvd52rffvstjh49Cg8PDwNFatrqc5+HDx8OuVyufiUmJhowYtN1v3t94cIFPPTQQ+jevTsOHjyI3377DXPnzoWVlVXLByeSwQwYMECcPn26Rln37t3FOXPmaJTl5OSIAMSTJ0/qMbrWo773uVp6eroIQLx06ZI+wms1Gnqfi4uLRQDigQMH9BFeq1Gf+/zHH3+Inp6e4unTp0UfHx9xzZo1eo7S9N3vPk+cOFEcPXq0ASJrfe53ryMjI8Xx48cbIjSRLUkGUlFRgYyMDISHh2uUh4eHIy0tzUBRtT6Nuc/FxcUQBAFOTk56iLB1aOh9rqiowKZNm+Do6IjevXvrK0yTV5/7rFKpMGHCBMyaNQs9evQwRJgmr76f54MHD8LV1RVdu3bFtGnTUFBQoO9QTd797rVKpcL333+Prl27IiIiAq6urhg4cCC+/fZbvcTHJMlACgsLoVQq4ebmplHu5uaG/Px8A0XV+jT0PpeVlWHOnDl44YUXuHhlA9T3Pn/33Xews7ODlZUV1qxZg5SUFDg7O+s7XJNVn/u8bNkymJmZITo62hAhtgr1uc8jRozAzp078dNPP2HVqlU4duwYhg4divLyckOEbLLud68LCgpw69YtfPjhhxg+fDiSk5MxduxYPPXUU/jll19aPD6zFr8C1UkQBI1tURS1yqjp6nOfKysr8dxzz0GlUmHDhg36DK/VuN99HjJkCDIzM1FYWIjNmzdj3LhxOHr0KFxdXfUdqkmr7T5nZGRg3bp1OHHiBH+PNIO6Ps+RkZHq8p49eyIoKAg+Pj74/vvv8dRTT+k1ztagtnutUqkAAKNHj8abb74JAOjTpw/S0tLwz3/+E4888kiLxsWWJANxdnaGVCrVas0oKCjQyqip8ep7nysrKzFu3Djk5OQgJSWFrUgNVN/7bGtri86dO2PQoEH49NNPYWZmhk8//VTf4Zqs+93n1NRUFBQUwNvbG2ZmZjAzM8OlS5fw1ltvwdfX1zBBm6DG/H52d3eHj48PsrOz9RFiq3G/e+3s7AwzMzMEBARo7Pf39+fTba2ZhYUFAgMDkZKSolGekpKCkJAQA0XV+tTnPlcnSNnZ2Thw4ADat29viFBNWmM/z6IosnuiAe53nydMmIDff/8dmZmZ6peHhwdmzZqF/fv3Gyhq09OYz3NRUREuX74Md3d3fYTYatzvXltYWKB///44d+6cxv7z58/Dx8en5QM0yHBxEkVRFL/44gvR3Nxc/PTTT8WzZ8+KMTExoq2trZibmyuKoigWFRWJJ0+eFL///nsRgPjFF1+IJ0+eFOVyuYEjNy113efKykpx1KhRYocOHcTMzExRLperX+Xl5YYO3aTUdZ9v3bolxsbGiocPHxZzc3PFjIwMccqUKaKlpaV4+vRpQ4duUu73e6MmPt3WOHXd55KSEvGtt94S09LSxJycHPHnn38Wg4ODRU9PT1GhUBg6dJNzv8/0nj17RHNzc3HTpk1idna2uH79elEqlYqpqaktHhuTJAP75JNPRB8fH9HCwkLs16+f+Msvv6j3bdu2TQSg9Zo/f77hAjZRtd3n6ukVdL1+/vlnwwZtgmq7z3fu3BHHjh0renh4iBYWFqK7u7s4atQoMT093cARm6a6fm/UxCSp8Wq7z6WlpWJ4eLjo4uIimpubi97e3uLEiRPFvLw8A0dsuu73mf7000/Fzp07i1ZWVmLv3r3Fb7/9Vi9xCaIoii3fXkVERERkWjgmiYiIiEgHJklEREREOjBJIiIiItKBSRIRERGRDkySiIiIiHRgkkRERESkA5MkIiIiIh2YJBERERHpwCSJiKiRcnNzIQgCMjMzDR0KEbUAJklE1OpERUVBEARMnz5da9+MGTMgCAKioqL0HxgRmRQmSUTUKnl5eeGLL77AnTt31GVlZWX4/PPP4e3tbcDIiMhUMEkiolapX79+8Pb2xp49e9Rle/bsgZeXF/r27asuE0URy5cvR8eOHWFtbY3evXvjq6++Uu+/ceMGXnzxRbi4uMDa2hpdunTBtm3bNK518eJFDBkyBDY2NujduzcOHz7c8m+QiFockyQiarUmTZqkkdBs3boVkydP1qjz/vvvY9u2bYiPj8eZM2fw5ptvYvz48fjll18AAHPnzsXZs2fxww8/ICsrC/Hx8XB2dtY4x3vvvYe3334bmZmZ6Nq1K55//nncvXu35d8gEbUoQRRF0dBBEBE1p6ioKNy8eRNbtmxBhw4d8N///heCIKB79+64fPkypk6dCicnJ3zyySdwdnbGTz/9hODgYPXxU6dORWlpKf7v//4Po0aNgrOzM7Zu3ap1ndzcXPj5+WHLli2YMmUKAODs2bPo0aMHsrKy0L17d729ZyJqfmaGDoCIqKU4OzvjiSeewPbt2yGKIp544gmNVqCzZ8+irKwMjz32mMZxFRUV6i65V199FU8//TROnDiB8PBwjBkzBiEhIRr1H3zwQfW/3d3dAQAFBQVMkohMHJMkImrVJk+ejH/84x8AgE8++URjn0qlAgB8//338PT01NhnaWkJABgxYgQuXbqE77//HgcOHMCjjz6K1157DStXrlTXNTc3V/9bEASNcxOR6WKSRESt2vDhw1FRUQEAiIiI0NgXEBAAS0tL5OXl4ZFHHqn1HC4uLoiKikJUVBRCQ0Mxa9YsjSSJiFonJklE1KpJpVJkZWWp/30ve3t7vP3223jzzTehUqnw0EMPQaFQIC0tDXZ2dpg4cSLmzZuHwMBA9OjRA+Xl5fjuu+/g7+9viLdCRHrGJImIWj0HB4da9y1evBiurq5YunQpLl68CCcnJ/Tr1w/vvvsuAMDCwgKxsbHIzc2FtbU1QkND8cUXX+grdCIyID7dRkRERKQD50kiIiIi0oFJEhEREZEOTJKIiIiIdGCSRERERKQDkyQiIiIiHZgkEREREenAJImIiIhIByZJRERERDowSSIiIiLSgUkSERERkQ5MkoiIiIh0+H9S55y0ODEs5wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(R2_disc[:,:,:,8].mean(axis=1),'o')\n",
    "plt.xticks(range(len(meshes)),meshes)\n",
    "plt.ylabel('R2')\n",
    "plt.xlabel('Mesh')\n",
    "plt.legend(y_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e5361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.,  40.,  60.,  80., 100., 120., 140., 160., 180.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(20,180,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f4bea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_disc[:,:,0,:].mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74bfb2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ae54d110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(R2_disc[:,:,3,:].mean(axis=1),'o')\n",
    "plt.xticks(range(len(meshes)),meshes)\n",
    "plt.ylabel('R2')\n",
    "plt.xlabel('Mesh')\n",
    "plt.legend(np.linspace(20,180,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ce606a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aeb87a10>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9c610>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9c910>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9ccd0>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9cfd0>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9d350>,\n",
       " <matplotlib.lines.Line2D at 0x2aeb9d8d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(R2_disc[0,:,:,:].mean(axis=0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5e7dc72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      " value = ('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([0.], requires_grad=True))\n",
      " value = ('mean_module.raw_constant', Parameter containing:\n",
      "tensor(0., requires_grad=True))\n",
      " value = ('covar_module.raw_outputscale', Parameter containing:\n",
      "tensor(0., requires_grad=True))\n",
      " value = ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True))\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      " value = ('likelihood.noise_covar.raw_noise', Parameter containing:\n",
      "tensor([-1.8245], requires_grad=True))\n",
      " value = ('mean_module.weights', Parameter containing:\n",
      "tensor([[-0.6323],\n",
      "        [ 0.0180],\n",
      "        [-0.0515],\n",
      "        [ 0.0835],\n",
      "        [-0.1273],\n",
      "        [-0.7567],\n",
      "        [ 0.4297],\n",
      "        [-0.0470],\n",
      "        [-0.0719]], requires_grad=True))\n",
      " value = ('mean_module.bias', Parameter containing:\n",
      "tensor([1.2614], requires_grad=True))\n",
      " value = ('covar_module.raw_outputscale', Parameter containing:\n",
      "tensor(-0.1065, requires_grad=True))\n",
      " value = ('covar_module.base_kernel.raw_lengthscale', Parameter containing:\n",
      "tensor([[ 1.5176,  8.7925,  7.5821,  7.2340,  2.9469,  2.0707,  3.7983,  7.0737,\n",
      "         11.8984]], requires_grad=True))\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3438816790.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3438816790.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3438816790.py:64: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[a] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3438816790.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE[i,j] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pmzcwl/Documents/GitHub/Calibration/GPE_ensemble.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_score=1-self.MSE(inputVals,outputVals)/torch.tensor(torch.var(outputVals,axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "inputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_0 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case01/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "inputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case02/X.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "outputData_1 = pd.read_csv(\"/Users/pmzcwl/Library/CloudStorage/OneDrive-TheUniversityofNottingham/shared_simulations/LA_data/case02/Y.txt\",index_col=None,delim_whitespace=True,header=None).values\n",
    "\n",
    "X0 = torch.tensor(inputData_0)[0:200]\n",
    "Y0 = torch.tensor(outputData_0)[0:200]\n",
    "\n",
    "X1 = torch.tensor(inputData_1)[0:200]\n",
    "Y1 = torch.tensor(outputData_1)[0:200]\n",
    "\n",
    "\n",
    "\n",
    "emulator_0 = GPE.ensemble(X0,Y0,mean_func=\"constant\",training_iter=0)\n",
    "\n",
    "for param in emulator_0.models[0].named_parameters():\n",
    "    print(f' value = {param}')\n",
    "\n",
    "emulator_0 = GPE.ensemble(X0,Y0,mean_func=\"linear\",training_iter=500)\n",
    "\n",
    "for param in emulator_0.models[0].named_parameters():\n",
    "    print(f' value = {param}')\n",
    "\n",
    "# split original dataset in training, validation and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X1,\n",
    "    Y1,\n",
    "    test_size=0.1,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "X_test.shape[1]\n",
    "\n",
    "a=np.random.choice(range(X_train.shape[0]),18,replace=False)\n",
    "\n",
    "X_train\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "m0 = emulator_0.predict(X_train[a])\n",
    "\n",
    "y_adjust = torch.tensor(y_train[a] - m0)\n",
    "\n",
    "delta_1 = GPE.ensemble(X_train[a],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "\n",
    "np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())\n",
    "\n",
    "1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-y_test)**2).mean(axis=0)/y_test.var(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "p = int(X1.shape[0]*0.05)\n",
    "n = int(X_train.shape[0]/p)\n",
    "reps = 5\n",
    "MSE = np.zeros((n,reps,7))\n",
    "R2 = np.zeros((n,reps,7))\n",
    "MSE_p = np.zeros((n,reps,7))\n",
    "R2_p = np.zeros((n,reps,7))\n",
    "for i in range(n):\n",
    "    for j in range(reps):\n",
    "        a=np.random.choice(range(X_train.shape[0]),(i+1)*p,replace=False)\n",
    "        m0 = emulator_0.predict(X_train[a,:])\n",
    "        y_adjust = torch.tensor(y_train[a] - m0)\n",
    "        delta_1 = GPE.ensemble(X_train[a,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "        MSE[i,j] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())\n",
    "        R2[i,j] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-y_test)**2).mean(axis=0)/y_test.var(axis=0)).detach().numpy()\n",
    "        \n",
    "        delta_1p = GPE.ensemble(X_train[a,:],y_train[a],mean_func=\"linear\",training_iter=500)\n",
    "        MSE_p[i,j] += delta_1p.MSE(X_test,y_test).detach().numpy()\n",
    "        R2_p[i,j] += delta_1p.R2(X_test,y_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b934d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0afddc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77a81e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab6ee303",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(20,180,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e28de7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20.        ,  29.41176471,  38.82352941,  48.23529412,\n",
       "        57.64705882,  67.05882353,  76.47058824,  85.88235294,\n",
       "        95.29411765, 104.70588235, 114.11764706, 123.52941176,\n",
       "       132.94117647, 142.35294118, 151.76470588, 161.17647059,\n",
       "       170.58823529, 180.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9480fad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$m$')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,MSE.mean(axis=1))\n",
    "plt.fill_between(x, MSE.mean(axis=1)[:,0]+MSE.std(axis=1)[:,0], y2=MSE.mean(axis=1)[:,0]-MSE.std(axis=1)[:,0],alpha=0.4)\n",
    "plt.fill_between(x, MSE.mean(axis=1)[:,1]+MSE.std(axis=1)[:,1], y2=MSE.mean(axis=1)[:,1]-MSE.std(axis=1)[:,1],alpha=0.4)\n",
    "plt.legend(y_labels.values)\n",
    "\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "#plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "772d5e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[0,7]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,0]+MSE.std(axis=1)[1:,0], y2=MSE.mean(axis=1)[1:,0]-MSE.std(axis=1)[1:,0],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,0]+MSE_p.std(axis=1)[1:,0], y2=MSE_p.mean(axis=1)[1:,0]-MSE_p.std(axis=1)[1:,0],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "960e8a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAGwCAYAAABxbMuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABnlElEQVR4nO3dd5Qc1Z0v8G917p5Ok7OyUERCCIFJBoEBYUB++DgsfgSHfbus7cXAO6zt592D12efs7HXJvjB2mZZ1gvrPcBiG5DBJhqMsKSRUI6jGU2OHadj1fvjTo8mT4eqrg7fzzmD1N01VbdGw/R3bvhdSVEUBURERESkOoPeDSAiIiIqVQxaRERERBph0CIiIiLSCIMWERERkUYYtIiIiIg0wqBFREREpBEGLSIiIiKNmPRuQDmTZRnd3d1wuVyQJEnv5hAREVEaFEVBIBBAU1MTDIb5+6wYtHTU3d2N1tZWvZtBREREWejs7ERLS8u8xzBo6cjlcgEQ/1But1vn1hAREVE6/H4/WltbJ97H58OgpaPUcKHb7WbQIiIiKjLpTPvhZHgiIiIijTBoEREREWmEQYuIiIhII5yjRURERLNKJpOIx+N6NyPvzGYzjEajKudi0CIiIqIpFEVBb28vRkdH9W6KbrxeLxoaGnKuc8mgRURERFOkQlZdXR0cDkdZFdVWFAXhcBj9/f0AgMbGxpzOx6BFREREE5LJ5ETIqq6u1rs5urDb7QCA/v5+1NXV5TSMyMnwRERENCE1J8vhcOjcEn2l7j/XOWoMWkRERDRDOQ0Xzkat+2fQIiIiItIIgxYRERGRRhi0iIiIiDTCoEVERESaSMoK3jkxhP9u68I7J4aQlJW8XLe3txef+tSn0NDQAIvFgqamJnz/+9/Py7WnY3kHIiIiUt1L+3vwj78+iB5fZOK5Ro8N99+0FtvW51abaiF//dd/jWg0ildeeQWVlZXo6+vTrfgqe7RKle8MEOzXuxVERFSGXtrfg795cveUkAUAvb4I/ubJ3Xhpf4+m149Go2hvb8c777yDWCyG888/H1dddZWm15wLg1apkhPA8VeAsVG9W0JERGUkKSv4x18fxGyDhKnn/vHXBzUbRkwkEti2bRuefvppbNu2DQ899BBuvPFGBAIBTa63EAatUpaIAsdeBmJhvVtCRERlYuep4Rk9WZMpAHp8Eew8NazJ9b/0pS+hpaUFGzduRGtrK77//e/jwIEDePjhhwEAN998MyorK/Gxj31Mk+tPx6BV6mJB0bOVLL/d14mIKP/6A3OHrGyOy8SePXvw5JNP4iMf+ciU5z0eD7q7uwEAd911F5544gnVrz0XBq1yEB4CTrwKyLLeLSlu/PoRES2ozmVT9bhMPPPMMzjnnHNgNpsnnguHwzhy5AjWrl0LANi6dStcLpfq154Lg1a58HcBp/+odyuK19goMHxS71YQERW8C5dWodFjw1wb2EgQqw8vXFql+rVHRkYQCoWmPPfYY49BUZS8DRVOx6BVToaOA1279G5FceraBQS0XSVDRFQKjAYJ998keo+mh63U4/tvWgujQf29FC+66CIcOnQIP/zhD3Hs2DE8+OCD+MpXvoKf/OQnqK6uVv166WAdrXLTsw+wOIHaVXq3pHgE+4HRDsCav65mIqJitm19Ix659fwZdbQaNK6jdeutt6KjowM//vGPcf/992P9+vX41a9+hRtvvFGT66WDQascdbwDmO2Ad5HeLSkOZ/4s/owGxApOi0Pf9hARFYFt6xtxzdoG7Dw1jP5ABHUuMVyoRU9WiiRJ+NrXvoavfe1rml0jUwxa5UhRgJOvA+dsA5y1eremsI12AsG+s4+DfUDVUv3aQ0RURIwGCRcv12fIbi7XXXcddu/ejVAohJaWFjz77LPYsmWLZtdj0CpXqYKmqz8M2Dx6t6YwKQrQ9eepzzFoEREVtR07duT1epwMX84SEVHQND6md0sK09CJmZX1J/duERERLYBBq9xFAyJssaDpVMkE0L175vPhYSARy397iIioKDFokShoevI1FuScbOAwEAvN/lqIm3UTEVF6GLRI8J0BOt7WuxWFIREFevfN/XqAw4dERJQeBi06a/AY0L1H71bor3e/CFtz4TwtIiJKE4MWTdXdBgwc1bsV+omFgP4D8x8TGgDkZH7aQ0RERY1Bi2bqeFvUjypH3W0LhyhFBkKDeWkOEREVNwYtmklRxOT4cgsTYyPA0LH0juXwIRERpYFBi2YnJ0TZh4hf75bkT9duETLTwaBFRERpYNCiuSUiwLHfAfHIwscWu0Cf2Dg6XcH+9EMZERGVLQYtml80ILbqSSb0bom2unZldnwyJoYaiYioID300ENYsmQJTCYT7rvvPt3awb0OaWGhATFna/lVgKEEs/loR3ZDgcE+wFGlfnuIiEqFnAROvy1+XjrrgcWXAAaj5pfdv38/7r77bjz33HM4//zz4fHot6cvg1YpkpPAmfdEL43VDVQvB6QcA5KvE+j8k/ifpJTIcua9WSmBXqBujbrtISIqFQefB176MuDvPvucuwnY9h1g7XZNL/38889j8+bNuOGGGzS9TjoYtErNbN/YNi+w7magcWNu5x44ApgdQNN5uZ2nkAzPsnF0uoLcioeIaFYHnwf+83YA0+ay+nvE8594QrOwtXz5cpw8eRIAIEkSbr31Vvzbv/2bJtdKRwmOA5Wx1Df25JAFAJFRYNcvgJ69uV+jew8weDz38xSCZCK3SvjxcHmtyiQiSoecFL/wTw9ZwNnnXvqKZoWf33nnHSxbtgzf+9730NPTg4cffliT66SLQatUzPuNPe7As6LYZq5OvyX2Rix2A4fm3jg6XezVIiKa6vTbM3/hn0IB/F3iOA04nU60t7fjsssuQ0NDA26//XZUVlbiYx/7mCbXWwiDVqlY8Bsbomdr6ETu11IU4MSrQGgo93PpJREFeubZODpdrKdFRDRVuj8XNfr5uW+f+Nl+7rnnAgDuuusuPPHEE5pcKx0MWqUi3W/YqEpDXXICOP6yKP9QjHrfFyUacsWgRUQ0lbNe3eMy1NbWhhUrVqCiogIAsHXrVrhcLk2ulQ4GrVKR7jes1a3eNeNjxVnQNBoE+g+qc66IT3wdiIhIWHyJWF0IaY4DJMDdrNkq9ra2NmzcmOPiLxUxaJWKBb+xIVYfVi9X97oRP3Di98VV0LSnTd1JmOzVIiI6y2AUJRwAzHxPGn+87dua1dNqa2vDeeedp8m5s8GgVSrm/cYet+7m3OtpzSbYD5x6XdSkKnThYWBI5VWTnBBPRDTV2u2ihIO7cerz7iZNSzvIsoz333+/oHq0WEerlKS+sbWqozWf0Q6xVc/yrYDRrN11ctWdwcbR6WKPFhHRTGu3A6tvyGtleIPBgFAox9XkKmPQKjWpb+wDzwAnX1evMnw6/F3A0ZeAFR8CzHbtr5epQB8w2qn+ecNDQDJe2AGTiEgPBiOw9HJdm3Dddddh9+7dCIVCaGlpwbPPPostW7bk7foMWqXIYARatohJ3/kWGgQO/xZYeS1gU3HivRq6/qzNeRVFDB96mrU5PxERZW3Hjh26Xp9ztEh90QBw5AUxH6pQjJzWdi4Vhw+JiGgWDFqkjfiYCFv+Hr1bktvG0enihHgiIpoFgxZpJxkXdbaGT+nbjqHjot6VlkIDxbHqkoiI8opBi7SlyMDJ14A+lQqEZirXjaPTJSfEpHgiIqJJGLQoPzrfBc5oPHw3m/6DQDycn2txnhYRlRBF7VI4RUat+2fQovzp3Qe0v5W/IbZ4ROxpmC/B3vxdi4hII2azKFUTDufpl9QClbr/1NcjWyzvQPk1eEwEoGVXAkaNv/3U2jg6XcF+UepBmmcbJCKiAmc0GuH1etHfLxb5OBwOSGX0c01RFITDYfT398Pr9cJozK3AKoMW5Z+vc1JhU5s211Bz4+h0JaJAZBSwV+b3ukREKmtoaACAibBVjrxe78TXIRcMWqSP0IAo/7DyWsDqVP/83XvERPx8C/YzaBFR0ZMkCY2Njairq0M8Hte7OXlnNptz7slKYdAi/UR841XkrwEcVeqdV4uNo9MV6AVqV+lzbSIilRmNRtUCR7niZHjSVzwMHHlRBBS1dO1W71yZYuFSIiKahEGL9JeMicKmI6dzP1egV8wB00ssqM8ek0REVJAYtKgwyEng5KtA/+HcznNGo42jM8F6WkRENI5BiwqHogAd72RfyX2kXUyy1xuHD4mIaByDFhWe7jbg9NsieKUrHxtHp4uFS4mIaByDFhWmgSPAiT+IvQrTMXQMiPi1bVO6xkZFUVYiIip7DFpUuEY7xCT5RHT+45IJ0QtWSEIcPiQiIgYtKnTBPlHYNBaa+5h8bhydLs7TIiIiMGhRMRgbBQ6/IP6cLt8bR6dLzbpgRERUtBi0qDjEgqJna3pPUb43jk5XeCj9+WVERFSyGLSoeCSiwNEdYu4WoM/G0elS5MIoNUFERLpi0KLiIifEasTBY/ptHJ0uFi4lIip73FSaio+iAO1v6d2KhXFCPBFR2WOPVqkyWvVuAYX6RSFVIiIqWwxapcrVAFhdereivCXjwNiI3q0gIiIdMWiVKkkC6tfp3QridjxERGWNQauUVa8AjBa9W1HeOCGeiKisMWiVMqMZqF2ldyvKW4BBi4ionDFolbra1WIYkfSRiAARn96tICIinTBolTqrE/Au1rsV5Y29WkREZYtBqxzUr9e7BeWN87SIiMoWg1Y5cNYCFbV6t6J8MWgREZUtBq1ywVIP+okGgFhY71YQEZEOGLTKhXcxYHFqc25FFnsPdu0Sfxby/oN6Ya8WEVFZ4l6H5cJgAOrWAGfeU/e8PXuBA88CkdGzz9m8wLqbgcaN6l6rmAX7gKqlereCiIjyjD1a5aTmHMCgYrbu2Qvs+sXUkAWIx7t+IV4ngT1aRERliUGrnJgsQM1Kdc6lyKInaz4HnuUwYkp4GEjE9G4FERHlGYNWualbq855hk7M7MmaLjIqjiMh1K93C4iIKM8YtMqNzQ14W3M/T9Sv7nHlgIVLiYjKDoNWOapTodSD1a3uceWA87SIiMoOg1Y5cjcCjqrczlG9XKwunI/NK44jITwIyEm9W0FERHnEoFWucu3VkgyihMN81t0sjiNBTgKhQb1bQUREecR3wXJVtRQw23M7R+NGYPNnZvZs2bziedbRmonDh0REZYUFS8uVwQjUrga69+R2nsaNQMO5YnVh1C/mZFUvZ0/WXIJceUhEVE4YtMpZ7Wqgd1/u84Ykg3r1uUpdsA9QFECS9G4JERHlAbsdypnZBlRxsnpeJWPA2IjerSAiojxh0Cp39SoVMKX0cZ4WEVHZYNAqd/ZKwN2sdyvKC4MWEVHZYNAi9mrlGyvEExGVDQYtEj1aNo/erSgf8TAQ4dZERETlgEGLxAq4ehW25aH0scwDEVFZYNAioWo5YLLq3YrywXlaRERlgUGLBKMJqF2ldyvKB4MWEVFZYNCis2rXsKJ7vkR8QHxM71YQEZHG+K5KZ1kcQOUSvVtRPtirRURU8hi0aKr69Xq3oHxwQjwRUclj0KKpKqoBZ73erSgP7NEiIip5DFo0E0s95Ed4CEjG9W4FERFpiEGLZvIuAqwuvVtR+hSFw4dERCWOQYtmkiSgjtvyTFBkYPAY0LVL/KnI6p2bw4dERCXNpHcDqEDVrAS69wDJmN4t0VfPXuDAs0Bk9OxzNi+w7magcWPu52ePFhFRSWOPFs3OaBZhq5z17AV2/WJqyALE412/EK/nKjQAyCr2kBERUUFh0KK51a0Rw4jlSJFFT9Z8Djyb+zCinBCT4omIqCQxaNHcrC4xMb4cDZ2Y2ZM1XWRUHJcrztMiIipZDFo0v7oyLfUQ9at73HyCvbmfg4iIChKDFs3PVQ9U1OjdivyzutU9bj7BflHqgYiISg6DFi2sHEs9VC8XqwvnY/OK43KViC48TElEREWJQYsWVrkUsFTo3Yr8kgyihMN81t0sjlMDyzwQEZUkBi1amMEA1K7WuxX517gR2PyZmT1bNq94Xo06WikBztMiIipFLFhK6aldJepGyQm9W5JfjRuBhnPF6sKoX8zJql6uXk9WCnu0iIhKEoMWpcdkBapXAAOH9W5J/kkG7Yu3xoJANAhYndpeh4iI8opDh5S+ujV6t6C0sZ4WEVHJYdCi9Nm9gKdV71aULg4fEhGVHAYtykx9GZZ6yBcWLiUiKjkMWpQZdxNgr9S7FaVpbFTU1CIiopLBoEWZqy/TbXnygfO0iIhKCoMWZa5qGWC2692K0sR5WkREJYVBizJnMIq6WqQ+Fi4lIiopDFqUndrV6hftJCA8BCTLrChsvvDrSkQ64DslZcdsV2dDZZpKkYHQgN6tKE2DR4FoQO9WEFGZYdCi7NWx1IMmOCFefYoC9B8EQoN6t4SIygyDFmXPUQW4GvVuRenhhHj1jZ4WvVkMWkSUZwxalBuWelBfqB+QZb1bUVr6Dog/wwxaRJRfDFqUG08LYHPr3YrSkowDYyN6t6J0BAfO9hKGh8QwIhFRnjBoUW4kCahjr5bquB2Pevr2n/17Mg5EfPq1hYjKDoMW5a56BWC06N2K0sIJ8eqIBsT8rMk4T4uI8ohBi3JnNLGAqdo4IV4d/YdnDhVynhYR5RGDFqmj5hy9W1Ba4mMc4spVIgYMHpn5PHu0iCiPGLRIHTY3YLLp3YrSMtKudwuK29AxMSdrurFhruokorxh0CL1OKr1bkFp6doNdLzLUJANWQb6Ds7xWpKrOokobxi0SD0MWurrPwgcfQmIhfVuSXEZPQ3EgnO/znlaRJQnDFqkHkeV3i0oTcE+4NCvOUE+E6kCpXPhPC0iyhMGLVJPRY3eLShd8TBw5EWg/5DeLSl8wf6FN+ZmjxYR5QmDFqnH6gJMVr1bUboUGej4E3DqDSCZ0Ls1hWtygdK5jI3wa0hEecGgReriPC3tDZ0ADv8GiPj1bknhifiB0Y6Fj1MUsfqQiEhjDFqkLgat/BgbEfO2Rjv1bklh6T+U/l6GnKdFRHnAoEXqYtDKn2QMOP4K0L2HGyUDokDp0LH0j19oHhcRkQoYtEhdDFr5190GHP89kIjq3RJ9DR6ZvUDpXMJD2rWFiGgcgxapy+bmBtN68HWKocRwmc47kuXMV2RGfKIXjIhIQwxapD72aukjGgAO/1ZMli83I6eAWCjzz2OvFhFpjEGL1MegpR85Ico/dPypvLbu6Z9ju52FcJ4WEWmMQStHv/nNb7Bq1SqsXLkS//Iv/6J3cwpDBYOW7voPAUdfLI+tewJ92a8gZOFSItKYSe8GFLNEIoF7770Xr776KtxuN84//3x89KMfRVVVmW9Fo3WPliKL4bGoH7C6gerlgMTfGWYI9ot5W8uuBFz1erdGO+kUKJ1LiEOHRKQtBq0c7Ny5E+vWrUNzczMA4MMf/jB27NiBW265ReeW6czqBozmzFaApatnL3DgWSAyevY5mxdYdzPQuFH96xW7eFhsSt2yBahfq3dr1JdugdK5xIJAfAww29VrExHRJGXdDfDGG2/gpptuQlNTEyRJwnPPPTfjmIcffhhLly6FzWbD5s2b8eabb0681t3dPRGyAKClpQVdXV35aHphkyRterV69gK7fjE1ZAHi8a5fiNdpJkUGOt8FTr5eetvOZDs3azIWLiUiDZV10AqFQti4cSMefPDBWV9/+umncffdd+NrX/sa9uzZg8svvxzXX389OjrEb9DKLEUiJUnStM1Fw6HyBtOKLHqy5nPgWXEczW74ZGlt3ZOIAoMZFCidC+dpEZGGyjpoXX/99finf/onfPSjH5319QceeACf+9zn8Jd/+ZdYs2YNfvSjH6G1tRWPPPIIAKC5uXlKD9aZM2fQ2Ng45/Wi0Sj8fv+Uj5LlUHme2tCJmT1Z00VGy7O0QSYmtu7JYbitUAwcEassc8V5WkSkobIOWvOJxWLYtWsXrr322inPX3vttXj77bcBABdeeCH279+Prq4uBAIBvPDCC7juuuvmPOe3vvUteDyeiY/W1lZN70FXag8dRtMMpekeV86SMVFJvmt38W7dk02B0rmwR4uINMSgNYfBwUEkk0nU109drVVfX4/e3l4AgMlkwg9+8ANs3boVmzZtwn333Yfq6rkDxle/+lX4fL6Jj87OEt4Q2OYRE+LVYnWrexyJOW3HXynOrXtGTomJ/mqIjwHRoDrnIiKahqsOFzB9zpWiKFOe2759O7Zv357WuaxWK6xWq6rtK1iSBNirgGCfOuerXi5WF843fGjziuMofb4z4yUgthZX/bO+A+qeLzwIWJ3qnpOICOzRmlNNTQ2MRuNE71VKf3//jF4umkOFihPiJYMo4TCfdTeznlY2ogHgSBFt3ePvUX/rHM7TIiKN8F1pDhaLBZs3b8bLL7885fmXX34Zl1xyiU6tKjJqz9Nq3Ahs/ozouZrM5hXPs45W9uSk2LpnpF3vlixM7d4sgPO0iEgzZT10GAwGcfz48YnHp06dQltbG6qqqrBo0SLce++9uO2223DBBRfg4osvxqOPPoqOjg7ceeedOra6iKi98hAQYarhXFaG18rJ14FzbICrQe+WzG5sFPBpMLcxNCgWBrA8CxGprKyD1p///Gds3bp14vG9994LALjjjjvw+OOP45Of/CSGhobwjW98Az09PVi/fj1eeOEFLF68WK8mFxebFzCY1FmCP5lkAGpWqntOEhRZrEhcdb02QTlXaq00nC4ZE8Hd5tHm/ERUtiRltqqblBd+vx8ejwc+nw9ud4muljv8gnoT4il/zA5g9YcBq0vvlpwVjwDv/0r94J6y9INcTEFEacnk/ZvjLaQtrTeYJm3Ew8Cx34lwUygGVSpQOhduxUNEGmDQIm0xaBWviB84/rI2m4NnSk4C/Ye1vQYnxBORBhi0SFuFOM+H0hcaBE68Kiqx62lYxQKlcwkP63+fRFRyGLRIW6kJ8VS8/F3A6bf03a6nb7/215ATC++nSUSUIQatEtU1OoYzIxr3AKTDYGCvVikYOgGc+bM+1/Z3i82w84HztIhIZQxaJUqWFbx5bBCnh0J6N4XztEpF336gNw89SzOuq0GB0rlwnhYRqYxBq4QpCvDH40M43q/zhrkMWqXjzHv53apnbETsx5gv7NEiIpUxaJWBnaeGcbjXr18DGLRKS/tb+Qs/fQfzc52UsRGxwpGISCUZBa3vfve7GBsbm3j8xhtvIBqNTjwOBAL4/Oc/r17rSDW7T49if5dPn4vbvIDBqM+1SX2KLFYiBge0vU48AgzneaNrRRarD4mIVJJR0PrqV7+KQCAw8fjGG29EV1fXxONwOIz/9//+n3qtI1XtO+PDno48TSqezGAA7JwQX1LkBHD8FbH3oFYGDuvTu8R5WkSkooyC1vTderh7T/E51BPAe+3D+f+34/Bh6UlEgGMvAzENVrfKSRG09MB5WkSkIs7RKkPH+oL408lhyHIewxaDVmmKBcVWPYmYuucdOgHExxY+Tgvs0SIiFTFolalTgyH88cRg/sJWRU1+rlMKFBkYPAZ07RJ/KgVerXxsBDjxe3WH+frzWNJhurHRwth2iIhKQsYlu//lX/4FTqcTAJBIJPD444+jpka8iU6ev0WFr3N4DK/LA7h8RQ1MRo0zd2pCPFd0za9nL3Dg2akVym1eYN3NQONGvVq1sEAvcOp1YNlWQJJyO5evS9u5X+kIDwGuBn3bQEQlQVIymKyzZMkSSGn8ED116lROjSoXfr8fHo8HPp8Pbrdb1XN3Dofx5rH0hkDqXFZcsaoWZq3D1qFfc/7LfHr2Art+Mffrmz9T2GELAGpXAYsvye0cR38ntv3RU8sWoGG9vm0gooKVyft3Rj1a7e3tubSLClR/IIo/HO7HlatqYTVpWIbBUc2gNRdFFj1Z8znwLNBwLiAV8Ij/wBHAbAeaNmX3+eFh/UMWwHlaRKSaAv6JTfk0FIzh94f6EYlrOLTn4DytOQ2dWHhD48hofquyZ6u7TQSubPTnuUDpXPgLARGpJKOg9e677+LFF1+c8twTTzyBpUuXoq6uDn/1V381pYAp6SMpK9jTMYK9naM4ORCEnObo8Gg4jpcP9iEUTWjTMK48nFs0zcr96R6nt453gJHTmX1OfKxwgmQ0IAqmEhHlKKOhw69//eu48sorcf311wMA3n//fXzuc5/Dpz/9aaxZswbf+9730NTUhK9//etatJXS8NL+Hvzjrw+ix3f2TcJtM+PGDY1Y3+xZ8PMDkQReOdSHq1bXwWUzq9s4e6UY9ir0VXR6sKY5Ry/d4/SmKGJyvOna9CeV9x8qrO+N8BDgada7FURU5DLq0Wpra8PVV1898fipp57CRRddhMceewz33nsvfvzjH+M///M/VW8kpeel/T34myd3TwlZAOCPxPHLnR1pb8ETiibxyqE++MIqL3E3GETYopmql4vVhfOxecVxxUJOAsd/n96WNslE9sONWglpvMUQEZWFjILWyMgI6uvrJx6//vrr2LZt28TjLVu2oLOzU73WUdqSsoJ//PVBzDdI+Nv3e9IeRhyLyXjlUB+GQyoXouTw4ewkgyjhMJ91Nxf2RPjZJGOienx0gdIvwydEpflCwgnxRKSCjH5q19fXT5RuiMVi2L17Ny6++OKJ1wOBAMxmlYebKC07Tw3P6MmazjcWR/tgKO1zRhMyfn+oD/0BFd8AWbh0bo0bRQmH6T1bNm9xlHaYSzwsqsfPNedJUYA+HQuUziU0pHcLiKgEZDRHa9u2bfjKV76C73znO3juuefgcDhw+eWXT7y+b98+LF9eREMbOnnooYfw0EMPIZlUb4VfumEoEMlsons8qeC1wwP44Dm1aPDYsmnaVOzRml/jRlHCYeiEmPhudYvhwmLryZou4hebUJ+zDTBO+7HjOwNE0hvWzqt4WOzjaHHo3RIiKmIZ/fT+p3/6JxiNRlxxxRV47LHH8Oijj8JisUy8/vOf/xzXXnut6o0sNV/4whdw8OBBvPfee6qds86VXghy2TLeDAAJWcFrR/pxZkSFzYNTE+JpbpIBqFkJNG8Wf5bK1ys0AJx8FZCnTXgvlJIOs+E8LSLKUUbvurW1tXjzzTfh8/ngdDphNE4tbvmrX/0KLpdL1QZSei5cWoVGjw29vsic87Q8djOW1FRkdX5ZAd48NoiLl1VnfQ4AYhseuze9CdJUenxngNNvAUsuF1v1hIcBf7ferZpbeBCoXKx3K4ioiGUUtD772c+mddzPf/7zrBpD2TMaJNx/01r8zZO7IQGzhq0bzm2EIYd96BQFePvEEBKyghV1zqzPA0cNg1Y5GzoBmB1AywWFOTdrMs7TIqIcZRS0Hn/8cSxevBibNm1CBlskUp5sW9+IR249f0YdLY/djBvOTa+OVjp2nhpGQpaxuiHLmk6cp0W97wOQgOGTerdkflx5SEQ5yiho3XnnnXjqqadw8uRJfPazn8Wtt96KqqoqrdpGWdi2vhHXrG3Ab/d144/Hh+CymbCkpiKnnqzZ7D49ikRSyS68ZRC0koqCaEJGNCEjlkgiGpcnHiuKApNRgslggNkowWQc/9Nw9s/U6wZ1b5/U0LtP7xYsLBEVE/ltRVIologKjqRk2DUVjUbxzDPP4Oc//znefvtt3HDDDfjc5z6Ha6+9FpLKb+alLpPdvzPVORzGm8e0/218TaMLmxZlWIQ0mQDangQUBbICRJMiQMUSSUQTCqKJpAhT8STiSXV6To0GCWajCF5mowEmw9k/ZzxnlGDk9zKlLLsCqFqmdyuIqIBk8v6d8RI0q9WKW265BbfccgtOnz6Nxx9/HJ///OcRj8dx8OBBOJ05zN2honOoJ4CErOCCxZWzBm1ZVhCKJRCKJhGMJhAa/6gYBOTwCGKJ/AxBJ2UFSTkJpFns3jgewEyGsz1kHrsFNU7Lwp9MpSU0xKBFRFnLfK3/JJIkQZIkKIoCefqSbSobx/qCiCdkNHhs42FKhKpwLIFwLInZ+kzrki64EoU70VgEMwVii3RR72wwGIM/YsXiagd7vMoJ52kRUQ4yLtATjUbxH//xH7jmmmuwatUqvP/++3jwwQfR0dHB3qwy1j4Uxp9ODmN/lx+nBkMYCEQRis4esgAgainOPQ8HAlEc6vYjklCv2GxBUGRg8BjQtUv8WUibO+stNIg5v5GJiBaQUY/W5z//eTz11FNYtGgRPvOZz+Cpp55CdTVXkFHmohav3k3IWiiWxP4uP5bVVqDKUQJDiT17gQPPApHRs8/ZvGJvxWLd9kdNckJ8bbghOhFlIaPJ8AaDAYsWLcKmTZvmnfj+zDPPqNK4UlcKk+GzJckJLOt6ruh7Cho8NrRWOop3VWPPXmDXL+Z+vZj3WFTTksuBmhV6t4KICoRmk+Fvv/12riwkVSgGE2ImNyzxAtzjLgO9vgiC0QRW1DphNRXZVjmKLHqy5nPgWbH3YqlsA5St0ACDFhFlJeOCpURqiVoqiz5oAUAwksCBbh+W1TrhtZv1bk76hk5MHS6cTWRUHFezMh8tKlzhwl24QUSFrcx/TSU9ZTtPS1aAAwEH/jjswoGAA3IBjD7GkwqO9AZwZnRszr0mC07Ur+5xpSw8NHMzbCKiNORU3oEoF9msPHx3xInHO+sxHD/bc1RljuPTrX24qDKoZvOy0jUyhmAkjuW1TpiNBf57jDXNeYHpHlfKFBkYGwEquPiHiDJT4O8EVAxkRcHJgSD2do7i5EAQcpoT3KNmL5DBnL93R5x44GQzhuNTfz8YjpvwwMlmvDtSGOVFfGMJ7O/2wR9NszqqXqqXi9WF87F5xXEa8EfiBdEbmbbQgN4tIKIixB4tysn+Lh9+s68H/sjZUOG2mXHjhoU3sRYT4l2wxBcempIV4PHO+vFH08OZBEDBv3bWY4s3WBArAGMJBYd7AmitdKDRY9O7ObOTDKKEw3yrDtfdrMlE+L5ABKeHwmj22tHstat+fk2wcCkRZYE9WpS1/V0+/HJnx5SQBYieil/u7MD+roUnuqc7fHgo6BgfLpwrRUkYiptxKOhI63z5oChAx3AYR/uDSBRq103jRlHCYXrPls2rWWmHM6NjaB8MQ1GA7tExhGJFUvw1xKBFRJljjxZlRVYU/GZfz7zH/Pb9HqxtcsMwz/Bg1OKFK3R6weuNxo1ptSvd4/JpJBTD/lgCK+tcqLAUXvvQuFGUcBg6ISa+W91iuFDlnixZAdqHxK4Bk587MRDEuiZ34W9rFBkVG6Ib+WOTiNLHHq0S1VJpx6UrquG2a/Om0D4YmtGTNZ1vLI72wdC8x0QtVWldz2tOr9cj3ePyLRqXcbDbh75ARO+mzE4yiBIOzZvFnyqHrKSi4Fh/YErIShmLJXFmJKzq9TShKCzzQEQZY9AqUZIkYXF1BW44txEXL6+G06Zu4ApEEqocFzXPP48rZY0zjCpzHJizeIKCanMca5yF+4YtK0D7YBgnBoJIFHlF/EzEkzIO9wYwGp47mPf6ovCNFfjiAYDztIgoYwxaJU6SJCytqcCN5zbiA8uqVAtcrjTPs9BxisGMuNm14HkMEvDp1r7UZ00/CwDgjta+gpgIv5DBYAwHu/0IF8vcpBxEEjIO9gQQTCOYnxwMIa5VrSq1Ns3mPC0iyhAnG5QJg0HCslonllRX4ORgCAe6fQhFs3+jX1JTAbfNPO/wocduxpKaigXPFbVUwhwPLHjcRZVB3Lusa0YdrWpzAncUSB2tdI3FkjjY48eS6grUOEtgY+pZhGJJHO3zI5ZIr/culpDRMRTG8lqVy3SouWk2e7SIKEMMWmXGYJCwos6JZTUVODkYxIFuf1aByyBJuHFDI365s2POY244t3HeifApUbMXTsx9nskuqgxiizeIQ0EHRuNGeM1JrHGGi6Ina7qkrODEQBDBqBWLqiqK8h7m4huL41h/EMkMV1sOBmPwOmKorlApfM61aXZkVDyf6crKiB9IxABTaYZjIlIfhw7LlAhcLty4oQlbllTCkcVquPXNHnzqwkVw26bu7+exm/GpCxctWEcrJZLmhPgUgwSsc4VxaVUA61zFGbIm6/NHcbDHh0iiNIYSB4MxHO0LZByyUtqHQogmVRhCTHfT7EyHEdmrRUQZYI9WmTMaJKysd2FZrRPH+4M42OPDWCz9N571zR6sbXKjfTCEQCQBl82EJTUVafVkpcSy3POwlISiSezv8mNZbQWqHMXbW9Lji6BjOLcFCYmkglMDIaxuWHju3ry02jQ7NAi4m3JpGRGVEQYtAiAC16oGF5bXVuD4QBAHu/2IxNMLXAZJzP/Kljw+IT6deVqlLCkrONYXRIPHhtZKR1H11CkQxVl7feqUr/CNxdEXiKDelUNVfa02zWaPFhFlgEOHNIXJaMDqBje2b2zCpkVeWE35+RaJmr15uU4x6PVFcLjXr87wWR6kio6qFbJSOofHMJbLcKpWm2aHWEuLiNLHoEWzMhkNWNPoxvbzmrCx1QOLxoEr3a14ykUgksC+M6NoHwrlFjY0lpAVHOnzYygYU/3cSVnByYFQ9htPa7VpdiwIxMeybBQRlRsGLZqX2WjAuiYPtm9swoYWD8xGbcazGLRmkmUxUX5fpw9H+4PwRwuroGcsKeNwjx/+sfSK12YjGEmgx5dlqEltmj2fbDfNZj0tIkoTgxalxWIyYH2zBx85r1mTwMWgNb+RUAyHugM40OPHcDg2Z338fAnHRR2wfGwI3TU6hmA0yzCn1abZoYHsPo+Iyg4nw1NGUoFrZb0TR3oDONwbQCKZ+9u+bDAjYXLClCieoqN6CEYSOBYJwmY2osFjRY3TmvfNmAPRBI72qfPvng5FEVXjs954WotNs7nnIRGliUFLBw899BAeeughJJOFO/dmIVaTERtavDin3oUjvQEc6Q0gkfVkGiFi8cLJoJWWSDyJ9sEwzoyMod5tQ73LCrNR+w7qkXAMJwZCWdfIylZq4+nFVQvvNDCr1KbZauHQIRGlSVKUMtrdtsD4/X54PB74fD643RmufCowkXgSofHhHWlar0Pq0eSnpdSzk54z9u+HsWcXZvtsaeZTONkfhD/Nza1LncEAVFdY0eCxwWHOvPhsOvoDUbQPhaDnT4xVDS547eaFD8yHcz8OWFXeLoiIikIm79/s0SJV2MxG2HJ9g6+sBwbSP0dLlQMHuzOsgVSiZBkYCEQxEIiissKCBrd1RsX+XJwZHUPXiP4r7U4NhrC+2Q2zoQCml4YGGLSIaEEF8NOKaJyjOqPDXVYTqtTaE6+EjIRiONQTwP5uP4ZCsezLI0DUyDo5GCqIkAWc3Xi6IHCeFhGlgUGLCofJClgz23alpcqOPM8FLxqhaALH+4PY1zWKXn8EiQzH/JKKguMDQQwEohq1MDuDwRiGQurX7coY52kRURoYtKiwZNirZTcZUeeyatSY0hCNyzg9FEZbxyg6R8YQS6PifDwp43BvACOFEGhmcWpQpY2ncxEegq4T1oioKDBoUWHJMGgBQJPXDqOGGwPKCnAg4MAfh104EHDkNBSn5/WSsoLu0THs7RzFycEQwnPUwIokZBzqDSBYwAsNkrLYeFrXmJOMARGfni0goiLAyfBUWLIIWhajAQ0emybziN4dceLxznoMx89OLK8yx/Hp1j5cVKl+KYp8XE9Wzk6c9zrMaPTYJibOh2JJHO3zI5Yo/J4a31gc/bluPJ2r8BBg9+p3fSIqeOzRosKSRdACgAa3TfVq9e+OOPHAyWYMx6f+PjIcN+GBk814d0TdFWf5vh4AjIbj4xPnfej2RXCopzhCVkrn8BjCcR3r0XGeFhEtgEGLCovZBlgyDxQmg4Qmr121ZsgK8Hhn/fij6QFOPP7XznrVhvXyfb3pQtEkOofDeS9EmqucN57OVZhBi4jmx6BFhaciu16tOpct91pe4w4FHePDd3P1kkkYiptxKOgoyuuVklA0ge5sN57OVXhIFDEjIpoDgxYVniyHDw0S0FKpTq/WaDy9wJbucYV2vVLTPTqGQLYbT+dCTgKR0fxfl4iKBoMWFR5HTdafWlVhQYU19zDiNac37yfd4wrteqVGUYCTAyEk9Si3wHlaRDQPBi0qPFn2aAFi4K21MvfhtTXOMKrMcWDOAgIKqs1xrHGqU6U839fTmxYlLCJxMc8s70ID+b8mERUNlnegwpOaEB/LrpyBx26Gx26GbyyedRMMEvDp1j48cLIZIvxMnjslUsEdrX1Qq3zX/NeD6tfTk5YlLPr8UXgdlvxuPM2teIhoHuzRosLkqMrp01urcu/VuqgyiHuXdaHKPHXuT7U5gXuXdaleR+uiqjD+coMVbtvU/Rs9djM+deEiLFu+CkmjjjWjVJCPEhanBoOI53OC+tiImKtFRDQL9mhRYXJUA6MdWX96hcWIGqcFg8HctpC5qDKILd4gDgUdGI0b4TUnscYZVr1nKWm0obfmYiyz1uDvliloHwwhEEnAZTNhSU0FDJIEP7wIOFpRGTgKr/8oJKVwK7fPZuESFgr+tbMeW7zBnL6+sYSC00NhrKhVv+7YrBQZCA8Dztr8XI+IigqDFhWmHOZppTRXOjAciuU8/8cgAetc2s39iVir0VtzMZJG+/j1JCybIyQoBjOGPevgq1iKat8BuELtmrVLbWdLWMzlbAmLXL/eQ8EYvPYYapyWhQ9WQ2iAQYuIZsWgRYWpIvuVhyk2kwF1bit6fVEVGqQNn2sFBr0bASmzUfykyYH+6i0Yda1Ezeg+2CN9GrVQPZNLUxgg40LDYdRhFP3wYqe8GvL4TAa1Sli0D4XgsptgNeZhhgQLlxLRHBi0qDCZ7YClAoiFcjpNk8eOgUCs4CqeK5IRA1XnI1CxJKfzxCxedNd9EI6xXlSP7oUl7lengRpIlaa4zrAT95ufQJM0PPFat1KFf4zfjh3yhaqVsBAbTwexqsE9ZxlY1bDEAxHNgZPhqXDlOCEeAMxGAxo9hTWBPGFyoKt+a84ha7KwvQGdDddgoGpzwU6YX+MM42Pmd/CI+UdowPCU1xowjEfMP8LHzO+oWsLCN5ZAnz+i2vnmFPEBidzmAxJRaWLQosKVQ+HSyRo8NlhMhVEXYcxWj876DyFqqVT/5JIBfucynG7chmHPWihSYXVYGyDjfvMT4u/T/jlSj+83PwED1F0x2DkSzs/G0yzzQESzYNCiwqXChHgAMEoSmlXccDpbo+7V6K69HLLRqul1FIMZI551ON14naq9ZrlyhTvgkn1zrig0SIBL9sEVzn616WxkGTg5ENR+42nO0yKiWTBoUeFSKWgBQI1TvQ2nM6VIJvTWXIwh77mAlL+etdSE+c6GazFmq1/4EzRmSaRXdyzd4zIRiia133ia87SIaBaFNbZANJnFAZgdQDz3OTsGCWitsuNYn/pv4vOJm13oqbkYcbMnr9edLGbxoLvug7CP9aJmdB8scZ8+7TClV9cq3eMy1T06hmAkDqfNDJfVhAqbCSY1gy+HDoloFgxaVNgc1YBPncnRVQ4LnDYTgpH8FPoM25vQV30hZEMet4OZx5i9AZ22erhDp1DlOwBj8uwkcVmB5kVZA45FiJrcsCT8s64CVADETG4EHIvUvXDq/IqYHO8bE//+kgQ4LEa4bCY4rWa4bCZYcikFEQ0A8YjYQioPZFnB6Fgcw6HYxIeiKNjQ6i2IoXIiEhi0qLA5qgBfp2qna62041BPQLXzzWXYsw4j7jV5HSpMiyTB71yGgKMV3sBRVPqPYuewTbO9B6de24DTjddhZeev5tg9EjjdeF3GNcWypShiSDEUTQIQtdasZgNcVtNE+LJbjJmVhggPAp4W1dsqywp8Y3EMhWIYCccwFIzBNxZDcpZ1A68fGUCjx4ZNi7zwOvJUsJWI5iQpilJYBYbKiN/vh8fjgc/ng9vt1rs5hWm0Azj+e1VPeaQvgNFw9htOz0c2mNFX/QGE7Q05ncdoABZVVeDUYG51xBZyqHMA//bnnvFHM6OPFns6VvoPYXHPDlgTZ2t+RU1unG68ToTTAmI0SHDZxoOXzQSnxTx/T1/TJqDpvJyumQpVw+GzPVWj4dlD1XwkCVhWU4ENLV7YLfrMTyQqVZm8f7NHiwqbihPiU1orHRgNqz9PKWb2oKfmEiTMuc0xMhklXHFOLerdNjR4bHj35JAmK+ZkRcF/7x/CzH0HATX3HpxuxL0GI65VcIU7YEkEETM5xXBhnnqyMpGUFYyG4xPB3CABDqsJLqsIXi6rCebJw40ZrjyUZQX+iOipyiVUzUZRgBMDIZweDmNtoxurG1ww5aNKPhFNwaBFhc1SIarEx9VbMeawGFHjtGIwqN7WPMGKReiv3AzFkNv/UlaTAVtX16GqQgz5LK2pgN1sxBvHBpBIqpu22gdD8Efm69lTb+/Bmac2FFTpiXTJChCMJMQ8v/GsbrcY4UwFL/RhrtlRk0PVSCiGIRVD1XwSSQX7zvhwYiCIjS1eLK52QCq0IW2iEsagRYXPUQ34zqh6ypZKO4bDUci5vslJEga9G+BznZNzmyqsRmxdXQe3berk+QaPDdesqcdrR/sxFlPvXTmQ5qIAtfYeLFVjsSTGYkkMBKLAQAi98lFUeitR67LCYjJMhCpfOI6EjltBhaJJvH1iCEf6Ati0yIs6V2HuIEBUahi0qPBpELSsJgPqXTb0+LLfniVptKG3+gOI2Gpzbo/HbsbW1bVwWGb/X7KywoJr1zbg1SP98I+ps2rSZUvvf3+19h4sG6EhnFFsODOicd2uLA0FY3jlYD8WVTmwsdUDl60wVsUSlSoO2FPh02CeFgA0em0wZjn5KGqtQmf91aqErBqnBR9aWzdnyEqpsJpwzdp61LrUqSy/pKZiRu/ZVAqqzXFV9x7Ui6wABwIO/HHYhQMBh6ZV4m2x4YUPKgAdw2H8dl8P9nSMIJbQePySqIyxR4sKn0ZBy2wwoMlrR+dwZkHC71yGwcrzoEi5D6k1em24fEVN2pOUrSYjrlpdh3dODKEjw3ZPZ5Ak3LihEb/cOduWNyKJ3NHap3o9rXx7d8SZn/IV46yxEdXPqRVZAQ71BHByIIQNLR4sr3XCUOz/4EQFhj1aVPisTsCkzXySereYR5MWyYCBqs0YqNqsSshaUu3AFStrM14JZjRIuHRFNVY15F5BfX2zB5+6cNGMnq1Kq6RJaYd8e3fEiQdONmM4PvV3yuG4CQ+cbMa7I+pXobfq0KMlKwpODgSxt3N0fF/HzLrsogkZ77WP4IX9PegaLcwhT6JixR4tKg6OasDfpfppjZKE5ko7Tg3MX68qabShp+YSRK3q9K6tanDi/EWVWa/+kiQJmxdXwWExYU/HaE5tWd/swdomN9oHQwhEEnDZTFhWZcHSnhNAEY8oyQrweGdqj8fpX2ftylcY5DgMsQCO+6SJr+eSmgoYNFrpt7/Lh9/s65mygtRtM+PGDY1Y35zZ1k/+sQQLnhKpjEGLikOFNkELAGqdVvT6IhiLzT7pO2b2oKf2MiRMDlWut6HFk/Eb4FzWNLrhsBjxzoncam0ZJAnLaqf27oy6VqHKtz/HFurnUNAxZbhwJm3KV7w74sTP95/GaPTsP0i2wWch+7t8sw79+iNx/HJnBz514aKsrtnji6B3fy8LnhKpgEOHVBw0mqcFiL6N1srZqx+F7Q3oqt+qWsjasqRS9TfbxdUV2Lq6Dmajuj0mo64VkA3F26ORblkKNctXpIYqR6NTuwJTwWd/l3qFcmVFwW/29cx7zG/f78l4GDElVfD01/u6caDbh4TWBb+IShSDFhUHR42mp690WGaUO/A7l6On5lJVNoU2SMBlK2qwst6V87lmU++24dq1DXCo2POgGMwYca9S7Xz5lm5ZCrXKV8w/VCnkEnymW7jgLOAbi6M9x22cEkkFezt9+O37PWgfDIG7thFlhkFLBw899BDWrl2LLVu26N2U4mF1AiZ1yhrMpbXqbK/VYOVGDFSdr8q2MCaDhCtW1WJRtTq9YnPxOMy4dl09vA716iL5nMshG7X9umtljTOMKnMcZ7esnk7d8hVnhyrn7llUI/ikpFtwNt3jFpIqePq7g33oD2Rff46o3DBo6eALX/gCDh48iPfee0/vphQXjXu1XFYTvE47emovVaXSOyAKo161pg6Nnrk2ZlGXw2LCh9bUo96tTjhSDGaMuIqzV8sgAZ9u7Rt/ND1sqV++It0hSLWCT7oFZ9M9Ll2pgqdvHRuEbyzOHi6iBXAyPBUPjVYeTjA70Hjh9dh9IjZ3J0gGHBaxpY7Hnt/K2xaTAVtX1eFPJ4fQPpR7b43PuRzewFEYk8XXi3FRZRD3LuuaUUer2pzAHSrX0Up3CFKt4JMqODvf8KHHbsaSmgpVrjddx3AYHcNhGA2imK4z9WEzocJigstmQsX0TbeJyhCDFhUPR5W2517xIbgtFVjuH8bx/tzegN12E7auqkOFVZ//xQwGCRcvr4bdYsShnkBO51IMJoy4V6NmpE2dxuXZRZVBbPEGcSjowGjcCK85iTXOsOqFWFNDlaJm1+wnVzP4zF9wVrjh3EbNykqkJGVRFmKuraFsZgMqrCa4rCJ4OW1nQ5nDYtRtg+tYQkYkkUQknkQ0LiMST2IsnkRk/O+ReBKRhIwqhwVLahxo8thZzJWywqBFxaNCo6FDTyuw7ArAKHo8zm32oH0wlPUGwFUVFly5qhY2s75L4iVJwqZFlaiwmvDn9tyqlfudy1DpP1yUvVqAGEZUs4TDXNf4dGsfHjjZDNElOvNNWe3gkyo4O72Olsduxg3nql9OIhsiuMQwFIzNeM0gTeoNm9YT5rSa0i8mDEBRFEQTsghN4wFqcmhKhajo+GvpLqIMRhLoGA7DajJgUbUDS6orVNsGi8qDpHCAXTd+vx8ejwc+nw9ut1vv5hSHtl8Ciah656tbC7ReCEx789vbOYoD3f6MT9fgseLylbUFN1zSORzG2ycG035zmY07cAK1I7vVa1SJmm3LH62Dj6woUwrOalkgNZ8sJsO0IUkjErJyNkQlkoiOh6hoXNZ0D8vJnDYTllQ70tgvlEpVJu/fDFo6YtDKwtEdgL879/NIEtB6EVC3ZtaXYwkZv97bjWgGm+0uqnLg4uXVWW9UrbX+QARvHB3MegNhSUliUc9LMCWKf5NprcmKWIXYY2gAqpdjca2nJIIPzVRVYcHSmgosrnbo3otN+ZPJ+3dh/dpNtBA1CpcazcDyq+cMWYD4TXpdc/rhd0WdE5euKNyQBQB1LhuuWVuPCmt2bwaKZMSIe+6vGZ2VGqr8UMVJbI2/BWekb+FPoqI0HIph1+kRPLunC68d6RfTDljclSbhHC0qLrkGLUsFsOJDaU2sX1nnwpHeAELR+VeTrW92Y0OLN7d25YnHbsa1axvw+tF+DIfmL3Y5G3/FElT6D8OUUKcWVDkwJsfQOPAmAhVLMFh5nioFcPWmx1BloQ+PKgrQPRpB92gEJqOE1koHltQ40OC26TbhnwoDgxYVl1yClqNahCxLeoVDjQYJG1u8ePvE0JzHbF5ciVUN2lR714rdYsTVa+rx1rFB9PgynNwuGTDsXoO64T9r07gS5gq1wxHpQ3/VBQjbG/RuTtbU3MS6kK+Zi0RSwanBEE4NhmC3GLC4ugJLqitQVVG8W1pR9jhHS0eco5WlPf8OJGeuYJqXdxGw9ArAmNnvFoqi4KX9vRgJT+39MUjAB5ZVa1ajKB9kWcG7p4ZxKtNK5YqMxT07YEqoV4NKa2ajBLfdDIvRMF4iTUHqJ19qArV4rEx9DuJ7IPWSIv4jnp/8OTOeE8cmkgqSs8zQLtberbk2sU7JdhPrQrsmoE0PmijvIVYu5qv0SyIpIxRLYiyWRDiWQDiWRDiWRCiWwFgsCVlRUF1hRY3TgqoKCyodFpaxSEMm79/s0aLi46gGAvNvpjtF/Xqg5YIZKwvTIUkSzlvkxauHByaeMxkkXLqyBs3e/FR710qq1laF1Yj9XRmssJQMGPasRd3QTu0alyOjQYLLZoLbbobHZlZ1D8hMRZMyxsbf6MbGV8gZx04XXe9WuptYr21yqzakp8c1Ae160Hxjcezt9GFvpw91LiuW1FSgtcoOqym778+5QtTkv6ez+MU/lpj4hctoEHu/VjutqK6woNppgYsrK3PCoEXFJ92gJUnAoouB2ty2kGn02NHgsaLXF4XZKPYtrHPZcjpnIdnQ4oXDYsR77SNIt3874FiESv8hmOO5FUNVi0ESS+7dNjPcdjMqLCbVC5Jmy2o0wGo3wDtthwARwNrgMy9Gn2sDRmIS/GNxxJOFOciQySbWy2qdRXvNuXrQ/JE4frmzQ7UetP5AFP2BKP7cDjRX2tFa6UDX6BgGg1HUuWw4f5EX0aSMcDS3EJWppAwMBmMYnFT3zGoyoNppQY3Tiurxnq9sw2E5YtCi4pNOhXijBVh2JeBpVuWSG1u88I0NYOuqOngdpTfPYkWdC267Gb2+CPxjCfjG4ghE4nPXJZIkDLvXoX7oT3lt52QVVhM8djNcNlHk0lhkE44nApjcjcVjPmDxpYCnFeGY+Pr7xuLwheMYHYsXRADL9ybWelxTn1474MX3ewt6Dlo0IU9M9E9x2UxnwxeHHOfFoEXFZ6EK8RYnsOJqVbfsqXZa8eFzG0v6t7g6l21KT50sKwhEE/CPv+n7I+IN3z+WQEJWEHS0oNLvhiWeeWHXbNgtRrjHhwNdNhPMhhKqThMLAcd+B9ScA0fLFjg89hkbkesdwPTYxDrf1yzlHjS1BSIJBCIJtA+KunpGA+B1WFDjtKC6wsohx0kYtKj4WN2iFlZylh+IFbUiZJnVnz9VyiFrNgaDBI/dDI/djNZJzyuKglAsCf9YHOHKD8Bw6nUx9yiWnHXid7YsJsP4UKAIV9YCq7avicGjYuP0xZfO6I11WExwWEzzBrChYAxdo2NIaBC+9NjEOt/XLIcetMnXVnOyf1IGhoKprZbEQhmryYAqpwU148Gr2lmeQ44MWlR8JGl8nlbv1OcrlwBLLs94ZSFlRpKkiW1R4FkPJE8C4WEAQCx5dnPe1OTvSDyJWGLhN37jeLBz201w2cxwlGuV7Um9W2jZApjmH6qeHsASSRk9vghOD4XRNRrOadulyfTYxDrf1yyHHjQgf+UyogkZPaMR9IxGJoJdQpaxvNaJD62tL5saY3xHouLkqJkatBo2AM3nZ7WykHIgSUDjecCJPwAALEYDLEbDjP3f4rKMSFyesvIuGpdhNRlEj5XNjAqraZZtmMvYPL1b8zEZDWitcqC1yoF4UkbXyBhOD4fRMzqW816Aemxinc9rlnoPGqDPUOVswe57O47i5k1NuP7cRrRU2tHgtsFUor3WDFpUnFLzryTD+MrCc/RtTzmrXCx6GMNzF3Y1GwwwWw1w5al2UMnIsHdrOrPRgCU1FVhSU4FYQsaZkTBOD4XR64+kvcJ0uvXNHqxtcue1Snu+rlnqPWh6DFXOF+z+9Z3TiCcVrG/2wGSQUO+xoaXSjmavvaT2jeRPPSpOjmqxsnD5VsDdpHdrqGkTcPwVvVtRurLs3ZrMYjJgWa0Ty2qdiMSTE6Grzx/N+FwGSVJ1KKuQrlnKPWj5HqrMJNglZKBrZAxdI2MAgFqXFc1eO1qq7DN6yIsNgxYVJ5sHWH0DYPfq3RICAG+rWIgQGlj4WMpOjr1bk9nMRqyoc2FFnQtjsSQ6hsM4PRSaUjupnJVqD1q+hypzCXYDgSgGAlG0dY7CbTeJ0FXpQI3TUnTzuhi0qDhJEkNWoWnaJIIAaUuF3q3J7BYjVjW4sKrBhVA0MRG6stl0XE0Wk0HUSLOKxREumwkOqxHhaBLD4RiGgzEMh2OarLAEtO1B8zrMqHVZUeO04qaNjfjgOTX4x18fnLL3aIPbis9ethSLqhyq/Vvke6hSrWDnH0vAPxbAoZ4AbGYDmr12NBfRvC4GLSJSh6cZcNYDwT69W1L6VOzdmqzCasKaRjfWNLoRiMRxeiiMjuEwRsPahK7ZwpRzvADtnGUAXMASiKE0RRG13lKhayQUw3Aopntx18lMBgnVTstEsKpxWmExTQ0H29Y34pq1Ddh5ahj9gQjqXDZcuLQKxvECoIFIHB3DYXQOh3MKXfkeqtQi2EXiMk4MhHBiIASTQUKDx4bmOeZ1JWVlzq9pPnFTaR1xU2kqOf4e4OhLereivFgqVOvdmosvHMfp4RBOD4UzHlbKKkzlIBW+RkIxDIXyH74cFiNqnNbxYKV+xfRcQ1c+N+mWFQXffenIgsHuvutW5Tw8KklAjdMqJtNX2vH28cEZvYSNHhvuv2kttq1vzOlaQGbv3wxaOmLQopJ05MWZNc7KjSIDQyeAqF8U2K1eLlbIaknl3q25DIdiE8OLoWgSQP7DVKYURUEwmsDweOgaVil8SRLgtZtR47KidjxcVeRxZW0qdHUMhTGSQa/jbOUWtCrRkc9gt9A1U1HukVvPzzlsMWgVCQYtKkmBXhG2ylXPXuDAs0Bk9OxzNi+w7magcaO21zZZgbo1QN1a8XeN+cbisJkNBRGmshGIxDESimMoFMVIWFQ1ny98mQwSalyWiR6r6oqZw4B68Ufi6BgSPV3phC61K8PPxmQURYiP9AbwxDvtUxZb1Lqs+NylS7Gh1YPQpI2zc00kC/WiSQAaPDa89eWrchpGZNAqEgxaVLKO7gD83Xq3Iv969gK7fjH365s/o33YAsQWVbWrgfp1mmxHVcpS4Ss158tiMkzMr/LazUWxcXKmoStXVpNhfFcH88TuDh67GQ7L2d69dOZLybKCsXgSoVgC4WgSwagIX6FYAqGoeC6xQNXdkwNB/MtbpxZs83/8rw/g4uXV2d0wMnv/5mR4IlJf06byC1qKLHqy5nPgWaDhXO2HEZNxoPd9oP+gGFKsXw9Y81v3qliJoU8zFlU79G5K1tw2M9Y3e7C+2aNq6HJYjBMhymM3j+9Fak6ruKjRIC0YbAwGCRVWkxh+dc1+TCSeFOFrPISJMJZAKCqeS3cOYX8gsvBBKmHQIiL1OesATwvgO6N3S/Jn6MTU4cLZREbFcTUr89EiQE4C/YeAgSNinljDuaIGHZWNbEKX02aC22aa2ktlMxfEMKnNbITNbERVxexzEevdVjz9584Fz1PnsqndtDkxaBGRNhrPK6+gFfWre5yaFBkYPAYMHRebrzdsOLuNFZWN2ULXaDgO16RQ5baZiqI21VwuXl6DRo8Nvb4IZhtkTM3RunBp/r7/GbSISBvOWsDTCvgW/u2yJFjTnGeZ7nFaUBRg+JT48LYCDRvFvxOVnVToKjVGg4T7b1qLv3lyNyRgSthKzQi7/6a1ea2nVbyxlYgKX9MmvVuQP9XLxerC+di84rhCMNoJHP7N+MKF+fejIyom29Y34pFbz0eDZ+rwYIPHpkpph0yxR4uItFNRDXgXAaNz19EpGZJBlHCYb9Xhupu1nwifKX+3+HDWiSFFb6veLSLK2ULV9vOJ5R10xPIOVBbCw8DB/9a7FfmjZx0tNTiqxaT5yiWiIicRzcDyDkRUOBxV4k17pF3vluRH40YRVPJdGV4t4SHg5GtidWLDBqBqGWAokrYTFSAGLSLSXtN55RO0ABGq8lXCQSsRH9D+JtDTJoJj9QrAUJwV4In0xF9TiEh79krRM0LFJxoATr8NvP9fQN8BIJnZptJE5Y5Bi4jyo3Ej5/wUs3gY6NwJvP8rMQ8tEVv4c4iIQ4dquvnmm/Haa6/h6quvxn/913/p3RyiwmL3AlXLRdFMUpci529OWCICdO0GeveL65jtgMEEGMxiaNFgEnstznhsEh8M21RmGLRUdNddd+Gzn/0s/vVf/1XvphAVpsaNwPAJUTiT1KHXKsdkTGzvk6lU4DKYAKNpUkgziWA2EdImP04dbwHcTZwrRkWFQUtFW7duxWuvvaZ3M4gKl80tJlUPHtO7JaWhZ+/sdbsio+L5zZ8pvJISckJ8ZMvsAOrXic2yTbPvd0dUSApijlZXVxduvfVWVFdXw+Fw4LzzzsOuXbtUO/8bb7yBm266CU1NTZAkCc8999ysxz388MNYunQpbDYbNm/ejDfffFO1NhDRuMaNxVPqoJApsujJms+BZ8VxpSQeBs68J+aKndkFxMf0bhHRvHT/aTcyMoJLL70UZrMZL774Ig4ePIgf/OAH8Hq9sx7/xz/+EfH4zF3HDx8+jN7e3lk/JxQKYePGjXjwwQfnbMfTTz+Nu+++G1/72tewZ88eXH755bj++uvR0XG2ovXmzZuxfv36GR/d3d2Z3TRRObO6ir/0QSEYOjF1uHA2kVFxXClKxoDefSJwnX4HiOiwWTdRGnQfOvzOd76D1tZW/OIXZ7u/lyxZMuuxsizjC1/4AlauXImnnnoKRqMYpz969Ci2bt2Ke+65B3/3d3834/Ouv/56XH/99fO244EHHsDnPvc5/OVf/iUA4Ec/+hF27NiBRx55BN/61rcAQNVeNqKy1rBBDB+WWm9LPkXTDBbpHles5CQwcBgYPCIK49afK7Z+IioQuvdoPf/887jgggvw8Y9/HHV1ddi0aRMee+yxWY81GAx44YUXsGfPHtx+++2QZRknTpzAVVddhe3bt88astIRi8Wwa9cuXHvttVOev/baa/H2229ndc75PPTQQ1i7di22bNmi+rmJioLVCdSu0rsVxc2a5rZd6R5X7BQFGD4FHHoeOPo7bpRNBUP3oHXy5Ek88sgjWLlyJXbs2IE777wTd911F5544olZj29qasIf/vAH/PGPf8SnPvUpXHXVVbj66qvx05/+NOs2DA4OIplMor6+fsrz9fX1cw5Hzua6667Dxz/+cbzwwgtoaWnBe++9N+txX/jCF3Dw4ME5XycqC43niWFEyk71crG6cD42rziu3Pi7gKMvAYd+LcIXV7mSjnQfOpRlGRdccAG++c1vAgA2bdqEAwcO4JFHHsHtt98+6+csWrQITzzxBK644gosW7YMP/vZzyCpUJtl+jkURcnovDt27Mi5DURlw2wDVl4DHH5B1GaizEgGUcJhtlWHKetuLu+FB6HB8X0b3WJIsXo5S0NQ3un+f2BjYyPWrl075bk1a9ZMmYQ+XV9fH/7qr/4KN910E8LhMO65556c2lBTUwOj0Tij96q/v39GLxcRqcjmAVZ8SNRIosw1bhQlHKb3bNm8hVnaQS8RP3D6j2Ibod73WdWe8kr3n26XXnopjhw5MuW5o0ePYvHixbMePzg4iKuvvhpr1qzBr371Kxw7dgxXXnklrFYrvv/972fVBovFgs2bN+Pll1/GzTffPPH8yy+/jI985CNZnZOI0uSsBZZdCZz4PYd4stG4UWz6nK/K8MUsHgbO/Bno2QfUrgbq1gAWh96tohKne9C65557cMkll+Cb3/wmPvGJT2Dnzp149NFH8eijj844VpZlbNu2DYsXL8bTTz8Nk8mENWvW4JVXXsHWrVvR3Nw8a+9WMBjE8eNnt/04deoU2traUFVVhUWLFgEA7r33Xtx222244IILcPHFF+PRRx9FR0cH7rzzTu1unogEbyuw6BLR60CZkwwsmZGJVGmI/gOigG79ejG8SKQBSVH0/xXyN7/5Db761a/i2LFjWLp0Ke699178r//1v2Y99uWXX8bll18Om8025fm2tjZUV1ejtbV1xue89tpr2Lp164zn77jjDjz++OMTjx9++GF897vfRU9PD9avX48f/vCH+OAHP5jbzc3D7/fD4/HA5/PB7eb/5ETo2i2qnRPlkyQB3sWi7AhLQ1AaMnn/LoigVa4YtIhm0f4Wt+gh/bibxFCsu0nvllABy+T9W/ehQyKiKRZdAsQjgK9T75ZQOfJ3iw9HtQhcnhaxsTVRlhi0iKiwGAzAsitEHaTQoN6toXIVHhKlIQCxOtZRPemjCjBZdW0eFQ8GLSIqPEazKPtw+LdANKB3a7LjbQWqV4rimaOdYsVbqVDk8lrlGPGJj+GTZ5+zukTgmhzAzHb92kgFi0GLiAqT2Q6svFaErWIraNp0nqh8L0lA5WJgMYDQkBgO9XUWd09dz17gwLNTN7S2eUVx1HKq2xUNiI+R02efs1TMDF+WCv3aSAWBk+F1xMnwRGkIDohhRDmhd0sWZjQDSy4X4Wo+sTDgOwP4OsSefMVwb4AIWfNVomeR1JlMtqlDjo5qlpIoAZwMT0Slo1gKmlpdwIqrAXvlwsdaHEDtOeIjmQACPePBqxOIhbRvazYUWfRkzefAs2ICeSkPI2YqERHDx/6us88ZLbOEL4/oAaWSw6BFRIWv0AuaelqApVcAJkvmn2s0ifvztgK4GAgPA6MdIniFBlRvataGTkwdLpxNZFQcp0Xx1FKaF5aMiXAd6Dn7nMEkApenWcztY8X6ksGgRUTFofYcIB4Cutv0bslUDRuA5vPV641wVImPpvPEEKO/SwQvf7e+Q4xRv7rHZaIc5oXJCSDYJz662wDvIqB2FeBqZE9XkWPQIqLi0bRJhI/Bo3q3RPRALLkMqFqq3TUsDtE7VLMSkJOiB2S0U/R2xYLaXXc21jTnFaV7XLrmmhcWGRXPl+K8MEUGRtrFh9UlAlf1Cq5qLFIMWkRUXBZdDMTH9C1oanUBy68SPU/5YjCKIUpPi3gcHhZfg9HO/AwxVi8XvUjzDR/avOI4tXBemFjZeObPYnuqysVAzSrA3ah3qygDDFpEVFwMBjE5/uiL+pRJcDeJ+Vhm28LHaik1xNi4cTx4domevmCfNteTDGKobr5Vh+tuVjfw6DkvrNDmhCkyMHxKfNjcInBVr9D/+5AWxKBFRMXHaNKnoGn9eqB5swh7hcRsB2pWiDDQfxDo2iWGGtXWuFEM1eVrvpRe88IKfU5YxA+ceQ/o3i02w65dDbjq9W4VzYFBi4iKUz4LmhqMwOJL1R0W04IkAfXrxATq9jfF8KLaGjeKobp89PboMS+smOaEyUlRrX74pCgPUbta/Ftwe6CCUmC/lhERZcDmFj1bBg1/Z7Q4gVU3FH7ImsxRBay+SayI1GLFmmQQQ3XNm8WfWg2ppeaFzUfNeWHpzglTZHWuN/3ag8dEb+TgscyvEfEBne8C+54GTr0JBPvVbyNlhT1aRFTctCxo6moQ5y7G1V4GA9CyWUyeb3+zOPeMzPe8ML3mhKk5VCkngaHj4sNeKVYsVi3PrsYbqYI9WkRU/FIFTdVUtwZYeV1xhqzJXPXA2o8ANefo3ZLspOaFTe/ZsnnVH8bTY05YaqhyesBLDVX27M3+3GMjQMefRC9X+1tiOyvKO/ZoEVFpUKugqWQQJSRqizSYzMZoBpZcKgLp6bfFKsVikq95YfmeE5av8hVyQgxHDh4Tw8o1q8TXz2jO7nzJhKhuL8eBZOojJv6UU38fP2b680Yr0Hphfkuj6IxBi4hKR64FTc0OUR/LWatuuwqFdxFQUSe2Mhrt0Ls1mUnNC9NSvmuF6TFUGR4GOt4RqxarlolyJXJy9lA0OSzJibOv5zpH7dDzQP25IkAbSz+GlP4dElF5ybagqbMOWLa19PeYM9vE5teDx8Tk6WRc7xYVjnzPCdNzWyM5IX4h0WOXBUUBevcBI6fE/6+e5vy3IY84R4uISkuqoGlFTfqfU3MOcM620g9Zk9WsFHO3nKy/NEU+54Tpta1RoYgGgGO/A069AcQ1LtGiI/ZoEVHpSbegqWQAWi8C6lbnr22FxOoCVl0P9O0XW7xoUbagGOVrTpge2xoVoqETYmeDli2i8G6JYY8WEZWmVEFT0xxblJjtoherXENWiiSJULHmJlEOgIR81ApLDVXOR+1tjQpVIiLKkBzdISrfl5Ay+NcjorJlcwMrr5lZ0LSiBlh9I7ctmcxRJcJWw7l6t6S85HOocrJcC6RqdT1/N3DwOaBnHyCXRg+rpChqV/ijdPn9fng8Hvh8PrjdJToGT1QIRjvPFjStXiEm4JbBaqesBXpFdfFYUO+WlI98bmKd770cs72evVJsfVWAq4Azef9m0NIRgxZRHg0eEyvs6tfq3ZLikIiJVYlDx/VuCalprr0cU9TuRVPjenVrgebzs6/7pYFM3r85dEhE5aFmJUNWJkwWYOnloq7YXPPcqLjkey9Hta7Xf1AcV2y138YxaBER0dwqF4syEJ5WvVtCucqkQGqhXS8WAo7/HjjxqihKXEQYtIiIaH4WB7DyQ8DiS2YuLKDike8CqVpcb6Rd9G4NHFF/E3mNMGgREVF6aleNFzmt07sllI18F0jV6nrJmNiz88iLYuPsAsegRURE6bO5gXOuF5OTS72+k90LuBqAilrAUS0eW12AxSnqsBktoodPkvRuaXpSBVLno2aBVK2vF+wDDj4viu3KyezOkQfsAyYioswYDGKlWOVSwN8lykEEekXRyWJmdohNlt1NgKsxsy2ZFEW82StJMbl7yt9l8Xd5/PGUv8tTn48GRYDQoqcm33s55uN6iixWNo60i6FtV0P259IIyzvoiOUdiKhkKIoIB8E+INADBPoKP3gZzeKN2TUeruxevVt0ViImvpbBfvFnaEC91YDFUkcrGzXnAC0XACaruuedhnW0igSDFhGVrFTwCvQCwVSPV1TfNkkGMQyY6rVy1IjeuWIgJ4HQ4NTwlYxlf758FkjN9/XMdrGHqXeRmMsV7BObpy++BDAYVbkEg1aRYNAiorIxOXgFesSbXz6Cl73y7FCgq6Ggil7mZKIHcTx0BftECQQSevYCh54HwkNnn3M3Adu+A6zdnvPpGbSKBIMWEZUtrYKXpUKEqmzmWRW71Pyu1MfYqN4t0sec1ejHFy184omcw1Ym79+cDE9ERPknSWIja0eVqNg/Ebx6zk6uT2dozGgRPVWpYFVI86zyzeoUH6lVfInotHleg9pvHq23eavRKwAk4KWvAKtvUG0YcSEMWkREpL8pwWvdtOA1Prk+GRPzepx1471WzaLsQrHMs8o3k1XMU/IuEo+TCSA8Ps8r0AeE+sX+n6VkwWr0ilgpe/ptscVUHjBoERFR4ZkteEVGRQ2rUplnlW9G0/gqywagEeJrGg0AckIELjkByHERyOT4+HOpx7O9Nu3zCmEmUrpV5oN92rZjEgYtIiIqfJIkJraTeiRJFKBVy5RANj2Ijf89GZv0/Phxc/09m2HOdKvMO+szP3eWGLSIiIgod0aT+IBNnfPJSRHMJkJbbOGA5moC9v4HMDY8x0klMZ9v8SXqtDENDFpERERUeAxGwGAXdbEycdM/A/95+/iDycOZ46sOt307bxPhAe51SERERKVk7XZRwsHdOPV5d5MqpR0yxR4tIiIiKi1rt4sSDhpVhs8EgxYRERGVHoMxbyUc5m2G3g0oRw899BDWrl2LLVu26N0UIiIi0hC34NERt+AhIiIqPpm8f7NHi4iIiEgjDFpEREREGmHQIiIiItIIgxYRERGRRhi0iIiIiDTCoEVERESkEQYtIiIiIo0waBERERFphEGLiIiISCMMWkREREQa4abSOkrtfuT3+3VuCREREaUr9b6dzi6GDFo6CgQCAIDW1ladW0JERESZCgQC8Hg88x7DTaV1JMsyuru74XK5IEmS3s1Rjd/vR2trKzo7O8tis2zeb2nj/ZY23m9p0+p+FUVBIBBAU1MTDIb5Z2GxR0tHBoMBLS0tejdDM263uyz+R07h/ZY23m9p4/2WNi3ud6GerBROhiciIiLSCIMWERERkUYYtEh1VqsV999/P6xWq95NyQveb2nj/ZY23m9pK4T75WR4IiIiIo2wR4uIiIhIIwxaRERERBph0CIiIiLSCIMWERERkUYYtEgV3/rWtyBJEu6+++6J5xRFwde//nU0NTXBbrfjyiuvxIEDB/RrZI66urpw6623orq6Gg6HA+eddx527do18Xop3W8ikcDf//3fY+nSpbDb7Vi2bBm+8Y1vQJbliWOK+X7feOMN3HTTTWhqaoIkSXjuueemvJ7OvUWjUfzt3/4tampqUFFRge3bt+PMmTN5vIv0zXe/8XgcX/7yl3HuueeioqICTU1NuP3229Hd3T3lHKVyv9P99V//NSRJwo9+9KMpz5fa/R46dAjbt2+Hx+OBy+XCBz7wAXR0dEy8Xkr3GwwG8cUvfhEtLS2w2+1Ys2YNHnnkkSnH5PN+GbQoZ++99x4effRRbNiwYcrz3/3ud/HAAw/gwQcfxHvvvYeGhgZcc801E3s8FpORkRFceumlMJvNePHFF3Hw4EH84Ac/gNfrnTimlO73O9/5Dn7605/iwQcfxKFDh/Dd734X3/ve9/CTn/xk4phivt9QKISNGzfiwQcfnPX1dO7t7rvvxrPPPounnnoKb731FoLBIG688UYkk8l83Uba5rvfcDiM3bt34x/+4R+we/duPPPMMzh69Ci2b98+5bhSud/JnnvuObz77rtoamqa8Vop3e+JEydw2WWXYfXq1Xjttdewd+9e/MM//ANsNtvEMaV0v/fccw9eeuklPPnkkzh06BDuuece/O3f/i3++7//e+KYvN6vQpSDQCCgrFy5Unn55ZeVK664QvnSl76kKIqiyLKsNDQ0KN/+9rcnjo1EIorH41F++tOf6tTa7H35y19WLrvssjlfL7X7veGGG5TPfvazU5776Ec/qtx6662KopTW/QJQnn322YnH6dzb6OioYjablaeeemrimK6uLsVgMCgvvfRS3tqejen3O5udO3cqAJTTp08rilKa93vmzBmlublZ2b9/v7J48WLlhz/84cRrpXa/n/zkJyf+351Nqd3vunXrlG984xtTnjv//POVv//7v1cUJf/3yx4tyskXvvAF3HDDDfjQhz405flTp06ht7cX11577cRzVqsVV1xxBd5+++18NzNnzz//PC644AJ8/OMfR11dHTZt2oTHHnts4vVSu9/LLrsMv//973H06FEAwN69e/HWW2/hwx/+MIDSu9/J0rm3Xbt2IR6PTzmmqakJ69evL/r7BwCfzwdJkiZ6bEvtfmVZxm233Yb77rsP69atm/F6Kd2vLMv47W9/i3POOQfXXXcd6urqcNFFF00Zbiul+wXEz6/nn38eXV1dUBQFr776Ko4ePYrrrrsOQP7vl0GLsvbUU09h9+7d+Na3vjXjtd7eXgBAfX39lOfr6+snXismJ0+exCOPPIKVK1dix44duPPOO3HXXXfhiSeeAFB69/vlL38Zt9xyC1avXg2z2YxNmzbh7rvvxi233AKg9O53snTurbe3FxaLBZWVlXMeU6wikQi+8pWv4FOf+tTEJryldr/f+c53YDKZcNddd836eindb39/P4LBIL797W9j27Zt+N3vfoebb74ZH/3oR/H6668DKK37BYAf//jHWLt2LVpaWmCxWLBt2zY8/PDDuOyyywDk/35Nqp+RykJnZye+9KUv4Xe/+92Ucf7pJEma8lhRlBnPFQNZlnHBBRfgm9/8JgBg06ZNOHDgAB555BHcfvvtE8eVyv0+/fTTePLJJ/HLX/4S69atQ1tbG+6++240NTXhjjvumDiuVO53NtncW7Hffzwex1/8xV9AlmU8/PDDCx5fjPe7a9cu/PM//zN2796dcduL8X5TC1g+8pGP4J577gEAnHfeeXj77bfx05/+FFdcccWcn1uM9wuIoPWnP/0Jzz//PBYvXow33ngDn//859HY2Dhj9GUyre6XPVqUlV27dqG/vx+bN2+GyWSCyWTC66+/jh//+McwmUwTvQHTfzvo7++f0VNQDBobG7F27dopz61Zs2Zi1U5DQwOA0rnf++67D1/5ylfwF3/xFzj33HNx22234Z577pnovSy1+50snXtraGhALBbDyMjInMcUm3g8jk984hM4deoUXn755YneLKC07vfNN99Ef38/Fi1aNPGz6/Tp0/jf//t/Y8mSJQBK635rampgMpkW/PlVKvc7NjaG//N//g8eeOAB3HTTTdiwYQO++MUv4pOf/CS+//3vA8j//TJoUVauvvpqvP/++2hra5v4uOCCC/A//+f/RFtbG5YtW4aGhga8/PLLE58Ti8Xw+uuv45JLLtGx5dm59NJLceTIkSnPHT16FIsXLwYALF26tKTuNxwOw2CY+uPBaDRO/HZcavc7WTr3tnnzZpjN5inH9PT0YP/+/UV5/6mQdezYMbzyyiuorq6e8nop3e9tt92Gffv2TfnZ1dTUhPvuuw87duwAUFr3a7FYsGXLlnl/fpXS/cbjccTj8Xl/fuX9flWfXk9la/KqQ0VRlG9/+9uKx+NRnnnmGeX9999XbrnlFqWxsVHx+/36NTJLO3fuVEwmk/J//+//VY4dO6b8+7//u+JwOJQnn3xy4phSut877rhDaW5uVn7zm98op06dUp555hmlpqZG+bu/+7uJY4r5fgOBgLJnzx5lz549CgDlgQceUPbs2TOxyi6de7vzzjuVlpYW5ZVXXlF2796tXHXVVcrGjRuVRCKh123Nab77jcfjyvbt25WWlhalra1N6enpmfiIRqMT5yiV+53N9FWHilJa9/vMM88oZrNZefTRR5Vjx44pP/nJTxSj0ai8+eabE+copfu94oorlHXr1imvvvqqcvLkSeUXv/iFYrPZlIcffnjiHPm8XwYtUs30oCXLsnL//fcrDQ0NitVqVT74wQ8q77//vn4NzNGvf/1rZf369YrValVWr16tPProo1NeL6X79fv9ype+9CVl0aJFis1mU5YtW6Z87Wtfm/LGW8z3++qrryoAZnzccccdiqKkd29jY2PKF7/4RaWqqkqx2+3KjTfeqHR0dOhwNwub735PnTo162sAlFdffXXiHKVyv7OZLWiV2v3+7Gc/U1asWKHYbDZl48aNynPPPTflHKV0vz09PcqnP/1ppampSbHZbMqqVauUH/zgB4osyxPnyOf9SoqiKOr3kxERERER52gRERERaYRBi4iIiEgjDFpEREREGmHQIiIiItIIgxYRERGRRhi0iIiIiDTCoEVERESkEQYtIiIiIo0waBERERFphEGLiIiISCMMWkREREQaYdAiIlJBe3s7JEnCM888gw9+8IOw2+3YvHkz2tvb8dprr+HCCy+Ew+HA1q1bMTw8rHdziShPTHo3gIioFLS1tQEAHn74YXzzm9+E0+nE//gf/wO33XYbnE4nHnroISiKgg9/+MP42c9+hvvuu0/fBhNRXjBoERGpYO/evaisrMRTTz2FmpoaAMDWrVvxhz/8AQcPHkRFRQUAYMuWLejt7dWzqUSURxw6JCJSQVtbG7Zv3z4RsgCgo6MDt9xyy0TISj23dOlSPZpIRDpg0CIiUsHevXvxgQ98YMpzbW1tuOiiiyYeRyIRHD16FOedd16eW0dEemHQIiLKkd/vR3t7OzZt2jTx3OnTpzE8PDzluQMHDiCZTGLjxo16NJOIdMCgRUSUo71798JgMGDDhg0Tz7W1tcHr9WLJkiVTjlu2bBlcLpcOrSQiPTBoERHlaO/evVi9ejXsdvvEc3v27JnRc7V3714OGxKVGUlRFEXvRhARERGVIvZoEREREWmEQYuIiIhIIwxaRERERBph0CIiIiLSCIMWERERkUYYtIiIiIg0wqBFREREpBEGLSIiIiKNMGgRERERaYRBi4iIiEgjDFpEREREGvn/w1n1rk65100AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[1,8]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,1]+MSE.std(axis=1)[1:,1], y2=MSE.mean(axis=1)[1:,1]-MSE.std(axis=1)[1:,1],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,1]+MSE_p.std(axis=1)[1:,1], y2=MSE_p.mean(axis=1)[1:,1]-MSE_p.std(axis=1)[1:,1],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b12c339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[2,9]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,2]+MSE.std(axis=1)[1:,2], y2=MSE.mean(axis=1)[1:,2]-MSE.std(axis=1)[1:,2],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,2]+MSE_p.std(axis=1)[1:,2], y2=MSE_p.mean(axis=1)[1:,2]-MSE_p.std(axis=1)[1:,2],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a971a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[3,10]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,3]+MSE.std(axis=1)[1:,3], y2=MSE.mean(axis=1)[1:,3]-MSE.std(axis=1)[1:,3],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,3]+MSE_p.std(axis=1)[1:,3], y2=MSE_p.mean(axis=1)[1:,3]-MSE_p.std(axis=1)[1:,3],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de12223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[4,11]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,4]+MSE.std(axis=1)[1:,4], y2=MSE.mean(axis=1)[1:,4]-MSE.std(axis=1)[1:,4],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,4]+MSE_p.std(axis=1)[1:,4], y2=MSE_p.mean(axis=1)[1:,4]-MSE_p.std(axis=1)[1:,4],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42ce1a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[5,12]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,5]+MSE.std(axis=1)[1:,5], y2=MSE.mean(axis=1)[1:,5]-MSE.std(axis=1)[1:,5],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,5]+MSE_p.std(axis=1)[1:,5], y2=MSE_p.mean(axis=1)[1:,5]-MSE_p.std(axis=1)[1:,5],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c2bd766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[1:],np.hstack((MSE.mean(axis=1),MSE_p.mean(axis=1)))[1:,[6,13]],'o') \n",
    "plt.fill_between(x[1:], MSE.mean(axis=1)[1:,6]+MSE.std(axis=1)[1:,6], y2=MSE.mean(axis=1)[1:,6]-MSE.std(axis=1)[1:,6],alpha=0.4)\n",
    "plt.fill_between(x[1:], MSE_p.mean(axis=1)[1:,6]+MSE_p.std(axis=1)[1:,6], y2=MSE_p.mean(axis=1)[1:,6]-MSE_p.std(axis=1)[1:,6],alpha=0.4)\n",
    "plt.legend(['$\\delta_1$','$f_1$'])\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('$m$')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b4b84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/1110072799.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[b] - m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/1110072799.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_mn[i,k] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/1110072799.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_mn[i,k] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#b=np.random.choice(range(X_train.shape[0]),18,replace=False)\n",
    "p = int(X0.shape[0]*0.05)\n",
    "n = int(X0.shape[0]/p)\n",
    "m = 18\n",
    "MSE_mn = np.zeros((n,m,7))\n",
    "R2_mn = np.zeros((n,m,7))\n",
    "reps = 5\n",
    "for i in range(n):\n",
    "    for k in range(m):\n",
    "        for j in range(reps):\n",
    "            b=np.random.choice(range(X_train.shape[0]),(k+1)*p,replace=False)\n",
    "            a=np.random.choice(range(X0.shape[0]),(i+1)*p,replace=False)\n",
    "            emulator_0 = GPE.ensemble(X0[a,:],Y0[a,:],mean_func=\"linear\",training_iter=500)\n",
    "            m0 = emulator_0.predict(X_train[b,:])\n",
    "            y_adjust = torch.tensor(y_train[b] - m0)\n",
    "            delta_1 = GPE.ensemble(X_train[b,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "            MSE_mn[i,k] += np.sqrt(((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
    "            R2_mn[i,k] += (1-((emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef2ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "307addd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2ae437c90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAG2CAYAAABcYt1RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACC2ElEQVR4nO2de3wU5b3/P3vJbkJINgKSi4arCJRwO0kP5VLFoqGo0OqvBaVFpdCKKBJQWmjggBwh1V8bsXKCpUURkAOv3xGsp6VqpIJQ7FEC1BuFUjgSaNJUSzYXQja7O78/4i6zuzO7c59nZr/v12tfktmZ3ZlNzLzz+X6f53FwHMeBIAiCIAiCYZxmnwBBEARBEEQqSFgIgiAIgmAeEhaCIAiCIJiHhIUgCIIgCOYhYSEIgiAIgnlIWAiCIAiCYB4SFoIgCIIgmIeEhSAIgiAI5iFhIQiCIAiCeUhYCIIgCIJgHlOF5Z133sH06dNRVFQEh8OBV199Neb5trY2PPLII7j++uuRlZWF4cOHY9OmTTH7dHZ2YtGiRejTpw+ys7MxY8YMXLhwwcCrIAiCIAhCb0wVlvb2dowePRobN24UfH7JkiV4/fXXsWPHDpw8eRJLlizBokWL8Otf/zq6T0VFBfbu3Ytdu3bh8OHDaGtrw5133olQKGTUZRAEQRAEoTMOVhY/dDgc2Lt3L775zW9Gt5WUlGDWrFlYtWpVdFtpaSluv/12/Pu//zv8fj+uvfZabN++HbNmzQIA/O1vf0NxcTH27duHqVOnGn0ZBEEQBEHogNvsE0jGpEmT8Nprr+F73/seioqKcODAAZw+fRrPPvssAKCurg5dXV0oLy+PHlNUVISSkhIcOXJEVFg6OzvR2dkZ/TocDuOf//wnevfuDYfDoe9FEQRBEJaG4zi0traiqKgITqd+hYorV64gEAiofh2Px4PMzEwNzshcmBaWn//85/j+97+P66+/Hm63G06nE7/61a8wadIkAEBjYyM8Hg+uueaamOPy8/PR2Ngo+rpVVVV44okndD13giAIwt7U19fj+uuv1+W1r1y5goH9e6KxSX17Q0FBAc6dO2d5aWFeWP74xz/itddeQ//+/fHOO+9g4cKFKCwsxK233ip6HMdxSZOSFStWYOnSpdGv/X4/+vXrhxm/vhcZ2R4AQA9Xaqvt6e5M+rzP3ZHyNeSQ67qi8etd1vT1tMbnlH5+PZ3SPxufhp9jnlP9Xz/pQnPYk3If+jy1x+ek1FgLchze6L9b28IYXFqPnJwc3d4vEAigsSmEM0eLkZujPMVpaQ3jhrJ6BAIBEha96OjowI9//GPs3bsXd9xxBwBg1KhROHHiBH7605/i1ltvRUFBAQKBAC5duhSTsjQ1NWHChAmir+31euH1ehO2Z2R7osLSBQ+y3cl/eXrdYdHnumUlI+nxqfC54oVHu2+Xz3VZ09fTgx4ul+R9s53S9+3p0i7CDaL7F4BeN9pUN3kr3eB7Ipj0erqvhWZa0Br+3+d5JC8q6AIA5PLExYgWgtwcpyphsRPMfgpdXV3o6upKqA+6XC6Ew92iUFpaioyMDNTW1kafb2howEcffZRUWFjE5+pIeOj3XsqTlTxXu4ZnYv77aEVz2CMpQRA7Tuwh5XgrkecMWEqy7EZzmENzmIlxFpalhetEK5c8XSf0wdQ/sdva2nDmzJno1+fOncOJEyfQq1cv9OvXDzfffDOWLVuGrKws9O/fHwcPHsS2bdtQXV0NAPD5fJg3bx4ee+wx9O7dG7169cLjjz+OkSNHJi0ZsYCeQpL8fdXLSuS/zaFsTc7JTkQEgn9TtppUGEGeMxDzuZDEGEtEWihxIayEqcJy9OhR3HLLLdGvI30l999/P7Zu3Ypdu3ZhxYoV+M53voN//vOf6N+/P9atW4cFCxZEj3nmmWfgdrsxc+ZMdHR0YMqUKdi6dStcMsoJRmCWoMSeg7bJCn+bmfKSI6N/xSiMlJTmsMeSN3wrnrPd4KctJC8E6zAzD4uZtLS0wOfz4f+8dX+0hyWCWB9Ljlv8JinUbGu2sBhVBtJKXOS8p1xhyWNAHvWABIDQAhKX1LS2hjF4WCP8fj9yc3N1eY/IfanpVH/VTbd9h36q67kaBbM9LHbCyrIilzxXu+X6T+wClZ4ILaAeF4JV2B4mQqhGrawolQ9WykUEQciHelwIFiFh0Rit515Rg1myIvY6UsVFz4TGruWgCFbtZyHYpDnMkbSYTCvXCXDKiyGtnPj0G1aDSkI82roS52ZpD6qL2a04GgjQRxqoXGQMVBoitISGQhOsQAkLkYDeUkHlIv2hpIXQGioTEWZDCUscQimL1TCyyVYtalMXFoc0E4SdobSFMAtKWDQkvn/FjHIQi6UgOe9rl8SlOZRlyPsk68mhlMVe5DkdzMgCpS2EGZCwGIQVUg8W+ktYOAelGCUp8e9J0mJv+FLAkrQAJC6EsVBJSID4spDaxlsrYGVRMJvmUJYpsiIVasK1LlYRAZYkirAvlLDoBL8cxHq6QrIiH5YEJVXKohT+zZJuSMaSTFT0SlmE1sGSdzylLYS+kLBoBEvzrxD6wZKo8NG7NMRaKcLOmHHD56dwJC5s4Q9zCKn4f6/NRv/fUkmIR3tXRvTfakYLmT0VvxzSKV1RmkJESj6sykqEVOentjSU53TQTUhnpH6+Wn4fxH4umsMeVT8zJLiE1lDCIpH2oEd0IcRksFwOsrqs6DmkmXU5UYrUpMWMkkQ6Y3aqkmo/SlsIFqCEJQl2mJNFDKvLil5YIUlJhmHDqekGpBlKP0s13wO5yQmlLQQLkLCkISQriVhdVOSgxaghugFZGyWJidoeKIJQCwmLQlqDmZL284d66Hwm0qG1fOyP1D6dVNIiJCSRNWVIVrRF6eep9vuQ5wxILA9K20/4WOp7IrSDhEUj/MGrf537GfxLnUTF/shtKpYiLSQp9kdMRkhUCNYgYZGB0gnkzExZ7Jqq0BpC2kCTyrGB2ULIlxMSFYJVaJSQClqDmchxC984/aEs04c321FU1KDXBGssoOa6aPp+NmgOc6bf7NWICqEPzWEPgmHl2UJbOKzh2ZgLCYuG+INZTEwgR6JCEPbG7ESGD8kKYRQkLAbhD/UwZE4WkpX0Q4vUyMiURagMRQlPNyykLFKxynkS9oF6WDQmWfOt3r0s6SIr1L9yFS1LXHr1s0Tm8Eg2lwf10lgH6lMhzIKERSVShzdH0Eta0kVWCH3RZo6W1IJCiMNSuYcPiQphNiQsMpE7UkhoiDNLc7MQ1kWvBmIlkqGFoJDcXIUlaSFRSU9qamowcOBAZGZmorS0FIcOHUq6/8svv4zRo0ejR48eKCwsxNy5c/H5559Hn9+zZw/KysqQl5eH7OxsjBkzBtu3b5d1TiQsOsAvCxkBpSvph96jnVLP0aJPikLSkhqjZIZEJX3ZvXs3KioqUFlZiePHj+OrX/0qpk2bhvPnzwvuf/jwYdx3332YN28ePv74Y/y///f/8P7772P+/PnRfXr16oXKykq8++67+OCDDzB37lzMnTsXb7zxhuTzImHhkZ3Rpei4VGUhSlkIrchzdRg2NJsvD0aWeUhaujErZSFRIaqrqzFv3jzMnz8fw4cPx4YNG1BcXIxNmzYJ7v/HP/4RAwYMwKOPPoqBAwdi0qRJePDBB3H06NHoPpMnT8Zdd92F4cOHY/DgwVi8eDFGjRqFw4cPSz4vEhadkJKykLTIJ50bbs2YQ8asPhSSFuMhUbE3LS0tMY/Ozk7B/QKBAOrq6lBeXh6zvby8HEeOHBE8ZsKECbhw4QL27dsHjuPw97//Hf/1X/+FO+64Q3B/juOwf/9+nDp1CjfddJPka6BhzSajdrgzlYPsj10nu0sFTWin/zBnEhT28YcyEQy5FB/fHgoBAIqLi2O2r169GmvWrEnY/7PPPkMoFEJ+fn7M9vz8fDQ2Ngq+x4QJE/Dyyy9j1qxZuHLlCoLBIGbMmIHnnnsu9lr8flx33XXo7OyEy+VCTU0NbrvtNsnXQsJiEMlmvjVqjhbCWqSrqBCxaC0tJCnpSX19PXJzc6Nfe73epPs7HLE/JxzHJWyL8Mknn+DRRx/Fv/3bv2Hq1KloaGjAsmXLsGDBAmzZsiW6X05ODk6cOIG2tjbs378fS5cuxaBBgzB58mRJ10DCohFC0/THz3yrtbRQumJPSFSuQilLLEr7WkhSiNzc3BhhEaNPnz5wuVwJaUpTU1NC6hKhqqoKEydOxLJlywAAo0aNQnZ2Nr761a/iySefRGFhIQDA6XTihhtuAACMGTMGJ0+eRFVVlWRhoR4WBShdBBFgcyVnq6BX/0ozQ98TkpVEqJ9FmahEelJIVgg5eDwelJaWora2NmZ7bW0tJkyYIHjM5cuX4XTG6oTL1V3G4jjxn12O40R7aYSghEVnhNYXEkta5KQslK7YCxKV5FDSklpaSEwIrVi6dCnmzJmDsrIyjB8/Hps3b8b58+exYMECAMCKFStw8eJFbNu2DQAwffp0fP/738emTZuiJaGKigr867/+K4qKigB0pzBlZWUYPHgwAoEA9u3bh23btomOPBKChMUktJAWwvqQqEiHpCURkhRCD2bNmoXPP/8ca9euRUNDA0pKSrBv3z70798fANDQ0BAzJ8sDDzyA1tZWbNy4EY899hjy8vLwta99DU899VR0n/b2dixcuBAXLlxAVlYWhg0bhh07dmDWrFmSz8vBJctr0oSWlhb4fD5M/d0PkJEdGz/3zBCOq7Ldwr844/tYAIiu4CzWz9L9nLi0pGu6olVJKF4SzCoJkawoI92lhSTFfFpbwxg8rBF+v19SX4gSIvelvX8aguwcFaOEWkO4a/RfdD1Xo6AeFgMQm5MlWT8LzdFiX4yc/I2wFyQrRDpjqrC88847mD59OoqKiuBwOPDqq68m7HPy5EnMmDEDPp8POTk5+MpXvhITRXV2dmLRokXo06cPsrOzMWPGDFy4cEGT8xNLVwDxxluxWW+1lJbmULboMXamNSxvoUkxmkNZMQ+jIFHRBmrCJdKJtnAmWlU82jT6vckCpgpLe3s7Ro8ejY0bNwo+/9e//hWTJk3CsGHDcODAAfzpT3/CqlWrkJl59RtQUVGBvXv3YteuXTh8+DDa2tpw5513IvTFZDm6nr/chRCTSIuYuCSTlnQUF62kxWhIVAiCINRhatPttGnTMG3aNNHnKysrcfvtt+Ppp5+Obhs0aFD0336/H1u2bMH27dtx6623AgB27NiB4uJivPXWW5g6daric0uWrqRCaE6WCBFpEeprSdaICwj3tTSHstOup6U1nGmZKfpJVAiCILSB2R6WcDiM3/72t7jxxhsxdepU9O3bF+PGjYspG9XV1aGrqytmzYOioiKUlJSIrnkAdJeR4tdVUIrc0lAErdOWdIP1pIXKP4TWUP8Kke4wKyxNTU1oa2vDT37yE3z961/Hm2++ibvuugt33303Dh48CABobGyEx+PBNddcE3NssjUPgO7x4D6fL/qIX2NBbrqitbQA4r0tVCK6CuvSQhAEQWgHs8ISDocBAN/4xjewZMkSjBkzBsuXL8edd96J559/PumxydY8ALonvfH7/dFHfX199Dk1pSAl+INZshty/aEelLZ8AYvSQskKQRCE9jArLH369IHb7caXvvSlmO3Dhw+PjhIqKChAIBDApUuXYvZJtuYB0L3oU2RdBanrK6RCacoSgUpEymFJWoyQlTxnIOZBEASRDjArLB6PB1/+8pdx6tSpmO2nT5+OzrZXWlqKjIyMmDUPGhoa8NFHH4mueZAMtemKFtKiVdpC0mI8esuKmKCQtBAEkQ6YOkqora0NZ86ciX597tw5nDhxAr169UK/fv2wbNkyzJo1CzfddBNuueUWvP766/jv//5vHDhwAADg8/kwb948PPbYY+jduzd69eqFxx9/HCNHjoyOGjKa9qBHdBZcqQitPwRclRapU/qn2wgiM0cP6SkrUoQksg/NUWJPqOGWIEwWlqNHj+KWW26Jfr106VIAwP3334+tW7firrvuwvPPP4+qqio8+uijGDp0KF555RVMmjQpeswzzzwDt9uNmTNnoqOjA1OmTMHWrVujK0WyQiRlERvuHI+YtADy1iGKJC3pIi5WGvKcCiXJSZ4zQNJCEDbCH+6BQEj5rbojHNTwbMyF1hLC1TUb/s9b9yesJaSUVCmLVHEB5K9FJLYOUbpIC6DdukNS0Dpd0arEY2dxSbcyGCUsbGHkWkIb68Yhq6cKYWkL4pHS/6G1hAhxUs2CK7WvBZDfkEvNuMb1tGgpK1o30dr5pm5nGSMIQhgSFhNpDWbq1pBLzbj6S4tWsqLnaB8aSUQQhF0gYdERqWsNaZW2CG8nadEDtbJi9LBkkhZ9ocSHIPSHhEVn5EiLXnO2kLRoKy1qZMXMxIOkRXuaw56orFhdWprDHJrDad/SSDAMCQtj6FkiiiedpvM3e54WVkozrJyHlYlIipCg6CEtejbcRiSFLyokLQSrkLAYgNSUJYJWaUvitvRuxtVCWuSmK6wKAovnxDpikiK0H8sISYrYPgTBEqbOw5JORKRFzqRyUuduiUhL/PBnoflaItKSrpPMqZmnRY6sWEEIaLI5aSj5fJrDHqZ+BpTKR3OYoyHVJtMSUjcPy5WQfeZhoYTFYOSmLYC69Yi0bsbNcV6x/MRsSpIWu8kKH6udr1FITVSSHW8mUpIUOa9DEGZDwsKjhyuAbPfVh160Bz26lYn0lBa+qNhBXIirkLRcRa2oxL+WkWglKWKvTRBmQiWhJMiRFqkCokSE5MyKK4bYdP5CyCkPxUuL2c2thDLMTgNYQY/PgbXyEEFYFRIWjdAjkdFCVCJIlRW1kMBYB6tLilVEQM05yu0fyXM6KAkhbAsJC2OolRSxdYfkoGXzLV9grCwvzaEsyX0sLN9IrS4pemOHxSP1khZqviXMhoSFAbRMUoSQu0iiXqRT+sK/6bEgL1a/CRPyiMgFpS2EnSBhMQk9JEWLdMVI9BQYlhqCk8mCnjJDkmJttEg0tEpbKF0hWICExUD0TlKEMKp3RQtYkgwh5JSFJL+mxjKjtaTYoUQiF7tds1ppIVkxl5ZQJjpDGYqP7wx1aXg25kLCYhBay4raNEWsHJQOk8dZBbGbZrzI6HVzZaGURWgDNeMSdoCERWe0EBWrlXrsjB4pi+xzMPivf5YTB5YbnAG2pE+JtFC6QrAECYuOKJEVLeWElWZbwnqwdKM1A7MlTS9RkNOMS7JCsAYJi05IkRVKTgiCMAMqERFWhKbm15gc9xVRWfG5O2IeeqJ1sy3rDbFG0iyy1IFdEEpX0j1xsSPJEhRKV4iamhoMHDgQmZmZKC0txaFDh0T3feCBB+BwOBIeI0aMiNlvw4YNGDp0KLKyslBcXIwlS5bgyhXp9xYSFg1JJSoskKwcRA23hBmwKoBmSZqRskBiQgixe/duVFRUoLKyEsePH8dXv/pVTJs2DefPnxfc/9lnn0VDQ0P0UV9fj169euHb3/52dJ+XX34Zy5cvx+rVq3Hy5Els2bIFu3fvxooVKySfFwmLRiSTFaOx0lBmIr1hVVa0wCqpVJ7TESMuJDFEdXU15s2bh/nz52P48OHYsGEDiouLsWnTJsH9fT4fCgoKoo+jR4/i0qVLmDt3bnSfd999FxMnTsTs2bMxYMAAlJeX495778XRo0clnxcJiwawJCuEMdj1RpvsJqv1DZj/Gar5PPVsjrWKdGhBvLgQ9qKlpSXm0dnZKbhfIBBAXV0dysvLY7aXl5fjyJEjkt5ry5YtuPXWW9G/f//otkmTJqGurg7vvfceAODs2bPYt28f7rjjDsnXQE23KmBRVJKlKzQ6iGAFuwofQWiNP5gFb1DFxHHB7tt8cXFxzPbVq1djzZo1Cft/9tlnCIVCyM/Pj9men5+PxsbGlO/X0NCA3/3ud9i5c2fM9nvuuQf/+Mc/MGnSJHAch2AwiIceegjLly+XfC0kLAqRKyvxIuGnX9iWh4U5WbTE7DTBbp+nEijhIPSivr4eubm50a+9Xm/S/R2O2J9FjuMStgmxdetW5OXl4Zvf/GbM9gMHDmDdunWoqanBuHHjcObMGSxevBiFhYVYtWqVpGsgYVGAWlkR2yaGVLlR07tCDbeEFLSYnyRZusKitJg9JwtBaEFubm6MsIjRp08fuFyuhDSlqakpIXWJh+M4vPDCC5gzZw48ntj/Z1atWoU5c+Zg/vz5AICRI0eivb0dP/jBD1BZWQmnM3WHCgmLDLQQFSVo8TpWKAfF36iobGAcRqUr6fI9NTutIgileDwelJaWora2FnfddVd0e21tLb7xjW8kPfbgwYM4c+YM5s2bl/Dc5cuXE6TE5XKB4zhwnLQ5gUhYJGKWrKQDYn9R87ezeqNjMRGwOko+U9an6JcClYMIVli6dCnmzJmDsrIyjB8/Hps3b8b58+exYMECAMCKFStw8eJFbNu2Lea4LVu2YNy4cSgpKUl4zenTp6O6uhpjx46NloRWrVqFGTNmwOVySTovEhYJkKxoj9wbUmR/VsXFSPifgRmypLREIud7x5oIUllIHfxZdfUWs1xHbG9GCyc8GoYQZ9asWfj888+xdu1aNDQ0oKSkBPv27YuO+mloaEiYk8Xv9+OVV17Bs88+K/iaK1euhMPhwMqVK3Hx4kVce+21mD59OtatWyf5vByc1CzGxrS0tMDn82HO2/fC0zP2l5IdZEVKOShVD4vWM92quRmxKC1a31zlXKPa91aSTMi9eSv5nsmWWgMSFqnXreRc7JSwpJr2X69rjZeVCFpLS2trGIOHNcLv90vqC1FC5L700KG74e2pYpRQWxc2fXWPrudqFDQPi0L8QeFfwKyN/mG1d6U5lCX7JqbkGKNQNY/IF9fFfxiJbPlQkDTonZYYVQ6S8j5WL01pgVlzusSLSQvXSQmLjaCSUBJSLWDoD2YJJi3+UBYTSYscWWkOZSdNWVrDmbqsJxS5OYvd0FgVFCGkljG0viYtyid26AExCr3KQ81hzlYpCyC8OrRR12gXUWkLehEIKv95CwTtk0uQsNgUJcmKWdLS/d7WEZNkCAmYXa4N0HdWWT4s9a8IISYtJH3CCImLXthFVIhE7KNeJsFiaUhNGag5lJ30+dZwJlrDmYpfP10wq7yjBr1lRC8JMW+RwkDSr4lE7JYgEcZiqrC88847mD59OoqKiuBwOPDqq6+K7vvggw/C4XBgw4YNMds7OzuxaNEi9OnTB9nZ2ZgxYwYuXLig+txSlYNYxaielYi4kLzYi2TSQqNkEslzBjQVFSMSCIKwKqYKS3t7O0aPHo2NGzcm3e/VV1/F//zP/6CoqCjhuYqKCuzduxe7du3C4cOH0dbWhjvvvBOhUEiv006AlZRFK1lJlbLEQ/JCaAnr5SAhKF0hCP0xtYdl2rRpmDZtWtJ9Ll68iEceeQRvvPFGwqqOfr8fW7Zswfbt23HrrbcCAHbs2IHi4mK89dZbmDp1qqLzUpKumN2Aq3WykqqfRYyItOjV60IIo+W8JUINuFqlK3muDk3LZCQKBJE+MN3DEg6HMWfOHCxbtgwjRoxIeL6urg5dXV0xy2AXFRWhpKQk6TLYnZ2dCUttWxm9ykBykxY+LKcuLJ4Ta1D5xzyoLEQQwjAtLE899RTcbjceffRRwecbGxvh8XhwzTXXxGxPtQx2VVUVfD5f9BG/7LZSWCkNsYaZ4sIXJ/55kLRIx0h5sWI5iCAIY2BWWOrq6vDss89i69atkpa05pNqGewVK1bA7/dHH/X19dHn1DbbGi0tejfZqklZ4tE7dRGTk1T7E8I0hz26yIpWUkLlIIJIL5idh+XQoUNoampCv379ottCoRAee+wxbNiwAf/7v/+LgoICBAIBXLp0KSZlaWpqwoQJE0Rf2+v1wusVnsLZShg1IkhpP0sy+KKgpN9FS9HQc34ZglCCHSeRI5RxOeRBl4qJ47qMG3+iO8wmLHPmzMEHH3yAEydORB9FRUVYtmwZ3njjDQBAaWkpMjIyUFtbGz2uoaEBH330UVJhEaOnW5sJh4xIWYyecl/LpCWeZEmHUGqiRypih7TFSnO+CEHlIIIgkmFqwtLW1oYzZ85Evz537hxOnDiBXr16oV+/fujdu3fM/hkZGSgoKMDQoUMBAD6fD/PmzcNjjz2G3r17o1evXnj88ccxcuTI6Kgh1tBi1JBZ6wPpkbTwYUEYKG0xBrWjhagcRBDph6nCcvToUdxyyy3Rr5cuXQoAuP/++7F161ZJr/HMM8/A7XZj5syZ6OjowJQpU7B161a4XC49TlkyYsOc9STP1a5rEgJcTVr0FBezoaHZ9sLIaeG1hMpCBBGLqcIyefJkcJz0XyL/+7//m7AtMzMTzz33HJ577jkNz0wb9JibRSxdiQhE5L8kLuqhtMU4jCgH5TkdlpMWgiCuwmwPi91R0s+SSlbitxkhE82h7OjDjtiht4VVlEqKnHJQfEKR53RYKrUgwSKIq5Cw6IxYA65clPatGCUugL3lxSrSYvXGW6OwkrQQBNENCYsB6DlqSKqMRMSF5EU5VpEWq2HW6CCSFoKwFszOw5IuSOlnkVMKkoJRfS4R+O9j9Z4XasjVFrmyoqYcJLYP62UXar5Nb9q6vMjoUjEPS5d9fnYoYTEIpaUhrWVF69eQi11SF0pb7APJAEFYAxIWA9GyNGT1m74dxIWkhTAK1lMggjACEhZGEJMWf6iHLu/HijCwcA5KobKQ8chZ2yjVTb45zEUfVsAq50kQekHCYjBKSkNi0qL0Zm9lSWAFkhXzUCMtVpOUeKx63gShBSQsDKF3aYiVVMXqsC4r6TC0Wa60WFlSCILohoTFBLRMWaTAuqiwfG7xsC4rhP0h8SLSFRIWHm1BL1qDmTEPvTCiAZd1USEINchJWewGSQuRjtA8LCmIl5Yct/5/YYvNzeIP9ZA84y2JivZQusIezWFP2q7cTPOzpAftXRlwq5iHJdhlH7klYZGJUOqiVGKUrOgsJi0kKPpCssIuJC0kLUR6QCUhDdCjjKTFtP1WgmXhIllhHyoPEYT9IWHRgXiBSSYxyRpwjZ6bhUiEZIUgCIINSFgMQqm0iB5D0kIQMVDKQhD2hoSFcdKtNMQSStOVPFdH9EEYC0kLQWhDTU0NBg4ciMzMTJSWluLQoUOi+z7wwANwOBwJjxEjRkT32bNnD8rKypCXl4fs7GyMGTMG27dvl3VOJCwGQilLcljqY1EjK/FfW1lcrNjMStJCEOrYvXs3KioqUFlZiePHj+OrX/0qpk2bhvPnzwvu/+yzz6KhoSH6qK+vR69evfDtb387uk+vXr1QWVmJd999Fx988AHmzp2LuXPn4o033pB8XiQsBqOkKTdZymI3aWEBrWRF6nOsEpEVK0pLOkPSQqiluroa8+bNw/z58zF8+HBs2LABxcXF2LRpk+D+Pp8PBQUF0cfRo0dx6dIlzJ07N7rP5MmTcdddd2H48OEYPHgwFi9ejFGjRuHw4cOSz4uEhSGUNOAS2qKHrPD3saK4ANaTlnROWQCSFiKRlpaWmEdnZ6fgfoFAAHV1dSgvL4/ZXl5ejiNHjkh6ry1btuDWW29F//79BZ/nOA779+/HqVOncNNNN0m+BpqHxQRag5mic7doOTcLYQxyJSTP1aH7ej/NoSxVciQkKHnOgKVEIJ3nZyHsQ0eXR5OJ44qLi2O2r169GmvWrEnY/7PPPkMoFEJ+fn7M9vz8fDQ2NqZ8v4aGBvzud7/Dzp07E57z+/247rrr0NnZCZfLhZqaGtx2222Sr4WExUKIzYBrJ5pD2chztZvy3krSFaVSEDkuHRYqNJN0lhaaVI7gU19fj9zc3OjXXq836f4OR+zPDsdxCduE2Lp1K/Ly8vDNb34z4bmcnBycOHECbW1t2L9/P5YuXYpBgwZh8uTJkq6BhMUkKGVhC7PmWzEibZFLshu81VIWgKSFpIUAgNzc3BhhEaNPnz5wuVwJaUpTU1NC6hIPx3F44YUXMGfOHHg8ib8nnE4nbrjhBgDAmDFjcPLkSVRVVUkWFuphMRE9GnAjD0I6evatSH0dK/W2WPHm3xz2RB/pBvWzEHLweDwoLS1FbW1tzPba2lpMmDAh6bEHDx7EmTNnMG/ePEnvxXGcaC+NEJSwMEqylEVKaSgiLVZMXYwsC5ktK/GvaXbaIlVGrJi0ROCftxXlSwmUtBByWLp0KebMmYOysjKMHz8emzdvxvnz57FgwQIAwIoVK3Dx4kVs27Yt5rgtW7Zg3LhxKCkpSXjNqqoqlJWVYfDgwQgEAti3bx+2bdsmOvJICBIWm8NPW6woLyxipTSESE46yQtJCyGVWbNm4fPPP8fatWvR0NCAkpIS7Nu3Lzrqp6GhIWFOFr/fj1deeQXPPvus4Gu2t7dj4cKFuHDhArKysjBs2DDs2LEDs2bNknxeDo7j0j4vbGlpgc/nw5y374Wnp3F/NYr1sEjtX1HSgGsVaTEiYVHTt6KHtGidrihuCJZ447ZqwpIMO0sLyYp2tLaGMXhYI/x+v6S+ECVE7kulryyBOzt5g2wygu2dqPs/z+h6rkZBCYsJiIkKIF1W7I6Zo4WkEJELteJidglIKXaUFSC9G3QJgnVIWAxGbarCx+7DnFmXFkC5uLAsKqlu2naVFYJgkStBN1xdym/VoWBIw7MxFxolZBA57iuayopSaARRN1oPY5YqIM2hLENkRa8+G5IVa0LlIMIOUMJiAHqKCqUs7CCWtrCcpoghlLKQrBAEYSYkLDrDQqpidbSWFr0nibOioKQinWTFbn0sLKUrkTlhWDonwjpQSUhHhGTF5+7QXFZoYURCDyKSkk6yQugHTWBHqIWERSfEZMXqmFWeaQ5lm/K+6Q7JCqEF8bJC8kIogYRFB8yQFTkpi9LGW7N7SUhaCKOwi6ixUHoRkxMrSkuuw4tchxc5DuXzohDKMVVY3nnnHUyfPh1FRUVwOBx49dVXo891dXXhRz/6EUaOHIns7GwUFRXhvvvuw9/+9reY1+js7MSiRYvQp08fZGdnY8aMGbhw4YLBV3IVuyYrfMwWFzWYtcghQRDWJSIqhLmYKizt7e0YPXo0Nm7cmPDc5cuXcezYMaxatQrHjh3Dnj17cPr0acyYMSNmv4qKCuzduxe7du3C4cOH0dbWhjvvvBOhkPFjz82WFTv0sqRKfyhlIQjrkCpFYTlliUgKiQo7mDpKaNq0aZg2bZrgcz6fL2G1yOeeew7/+q//ivPnz6Nfv37w+/3YsmULtm/fjltvvRUAsGPHDhQXF+Ott97C1KlTZZ3P5ZAHSoNgs2Ulgl7DnONTlTxXu+byEJEVf6hH0iUErDTUmbAuVh8tZHY5iGUZSQZrgtIZcMPlzlB8fChAE8eZgt/vh8PhQF5eHgCgrq4OXV1dKC8vj+5TVFSEkpISHDlyRPR1Ojs70dLSEvNQAyuyIgfWJ5Bj/fwI62DHYeasI0dWWBAbSlOsgWWE5cqVK1i+fDlmz54dXcCpsbERHo8H11xzTcy++fn5aGxsFH2tqqoq+Hy+6KO4uFjxeUmRFZ+rI+ahN0aVhrRMOYQEJZm0UGlIHFpN+ioRWSFpIYQgSbEWlhCWrq4u3HPPPQiHw6ipqUm5P8dxcDjE49AVK1bA7/dHH/X19YrOS6qsJOxjoLxogd7lF6VpilxpMarhtjWcGX0Q5hEvKUqkxaqjhcwsBylJTIxMWShNsS7MC0tXVxdmzpyJc+fOoba2NmZ57IKCAgQCAVy6dCnmmKamJuTn54u+ptfrRW5ubsxDLkplJeEYncTFKg24qWTFSqUhIUkhcTEHSlTMgYXyjhgkKdaHaWGJyMpf/vIXvPXWW+jdu3fM86WlpcjIyIhpzm1oaMBHH32ECRMmKHrP9mDqv6i0kpX4/Y1OXLSQATXpi9T3Z7k0JDVNIXExhlSLS6aDyJiVrqiVFb1kh0TFPpg6SqitrQ1nzpyJfn3u3DmcOHECvXr1QlFREb71rW/h2LFj+M1vfoNQKBTtS+nVqxc8Hg98Ph/mzZuHxx57DL1790avXr3w+OOPY+TIkdFRQ1qjvAzUPeol1U06cqwWCYkWI4b0KgdZKTkRQql8tIYzaS4YnZCzYracPh+rjxYyAq1koznMaSJcJCj2xFRhOXr0KG655Zbo10uXLgUA3H///VizZg1ee+01AMCYMWNijnv77bcxefJkAMAzzzwDt9uNmTNnoqOjA1OmTMHWrVvhcrk0P1+1ssL/t1Rx6d6X7b8K5Q5xViIryYY6SxnmrIUkaJWQRF6HxEU70iE5IaRBsmJfTBWWyZMng+PEzTzZcxEyMzPx3HPP4bnnntPy1BLQQlaEtku5eatJXfSal0UpapIVtdKiFL1KOSQu2qComVZmymIVzCgHaV3K0SplsQuhoBNcUHn3RljFsaxhnythAD2TEDNSFjkCYMeJ3IzqO9HqPfJcHba8CafCiGu2wmghuskTdoeEJY5sd2KtWihdAQB/MFEi4sVCbH6RyCMV/lCWKllJlq4km01WL9S8Z6pjk5Wl5EiB0Q2yWiQs6SgqfORev50+rzynw3ayoia1aeE60cJ1ang2BCuYWhKyAmKyEsEfzEooDcWXYZT1bKhPVFiTFSNIVhpK1fBqxVE8drrxqiXyWaQqESn9zFhrvrWbpGgNX1qor8UeUMLCo4dL2S8jKUmLpNf5Ik1hoclWSYlH6jFKZElPwTJzyLGadIVkRZhkn4vaz4yV0hBLsqLXuWjZGxNJXSh5sTYkLElIla7wUSMtekgK6+mKnucgtTRk5blRSFaSI/T52OEzs2P5x2hIXqwLCYuGyJEWPdMUM+de0aP5VoncpJIWFkSF9dFBec4AUyUQufCbkLWUFbNSlnQUFb1nziV5sRYkLCLISVf4pJIWs0s+LKQrEfQ+F7NnwdULI5ICvqhYWVoA+yQrLKPn+Rk13T/JC/tQ060OiDXiGgELpSA5E8n5XJeTNiWzJFhawnK6IiQoec4AM/0bLMBaAy6hLSw17Ia6XOACyidCDXdpP4mqWVDCIoDSdIWPUNKiN1pMEGe3+VTslrLonRYkuwnTDToWowSO9XTFCMxcVJGSF3YgYdERM6RFDJaTilSzAauFNWlhMV2xer+KXbGSrFjpXJUSEZdWkhdTIGGJQ4t0hY9R0sJCKYiP3ZIaFtArXZEjKiQ1sVCZzDjMTFkINiBhMQCWkpZkmCkZ8VKltWSxkrIoTVdYkBU1x9gZvaTFiomFFc+ZsA4kLDx6uvWL+fzBLN3EhbV0JYJcAaJRQ8ahtgRE0kKYAaUsxlFTU4OBAwciMzMTpaWlOHToUNL9Ozs7UVlZif79+8Pr9WLw4MF44YUXYvbZsGEDhg4diqysLBQXF2PJkiW4ckX6H3E0SshghEYQ6QXLfSvJsOp5p4KVdEUr2aCRQ1fRetQQJRWEmezevRsVFRWoqanBxIkT8Ytf/ALTpk3DJ598gn79+gkeM3PmTPz973/Hli1bcMMNN6CpqQnBYDD6/Msvv4zly5fjhRdewIQJE3D69Gk88MADAIBnnnlG0nmRsJiAltKixcgggJ2eEyNSFlau1Qy0TkZIWq6ilbRYXVbynA5dk5DmMGf5z4h1qqurMW/ePMyfPx9AdzLyxhtvYNOmTaiqqkrY//XXX8fBgwdx9uxZ9OrVCwAwYMCAmH3effddTJw4EbNnz44+f++99+K9996TfF5UEjIJPUtEADspBYtyYEZpyOx0hUYBEUR609LSEvPo7BRugQgEAqirq0N5eXnM9vLychw5ckTwmNdeew1lZWV4+umncd111+HGG2/E448/jo6Oq7+/Jk2ahLq6uqignD17Fvv27cMdd9wh+RooYTGA1mD3NPBCI5DUpC1i6QorssIyEWlhUai0Rm9RoZTlKmpTFrOSA/7kaFaYbySdUhauywXOrXzyN+6LieOKi4tjtq9evRpr1qxJ2P+zzz5DKBRCfn5+zPb8/Hw0NjYKvsfZs2dx+PBhZGZmYu/evfjss8+wcOFC/POf/4z2sdxzzz34xz/+gUmTJoHjOASDQTz00ENYvny55GshYdGJiKTEbxOTFgCyxEWrUhCg/01bzsy3RmNEicjMdEWLm6eUeF+NtDSHsmwxfb7VEJvBNdfhVS0tepeFgPSSFi2or69Hbm5u9GuvN/kMvg5H7GfLcVzCtgjhcBgOhwMvv/wyfD4fgO6y0re+9S38x3/8B7KysnDgwAGsW7cONTU1GDduHM6cOYPFixejsLAQq1atknQNJCwaISQoyfbTOm2JQOmKfOyYtqhNVfg3Aqk3HyXS0vzFkhV2khalKYtRN1+zp5onzCE3NzdGWMTo06cPXC5XQprS1NSUkLpEKCwsxHXXXReVFQAYPnw4OI7DhQsXMGTIEKxatQpz5syJ9sWMHDkS7e3t+MEPfoDKyko4nak7VKiHRQWtwczoQ8mxQkjpa9EyXTEKK8hAcyhb8yTIjHRFS1lJtk3r927WYb2tSO8O/2EEcsVNb1nJdXijD6n7WwEa5qw9Ho8HpaWlqK2tjdleW1uLCRMmCB4zceJE/O1vf0NbW1t02+nTp+F0OnH99dcDAC5fvpwgJS6XCxzHgeOkfR9JWGTAFxQlkiL2evEobchVkq5YQSSMhtXylRT0kBW9EBIULaVF7LMwWl7MxiryQbDD0qVL8atf/QovvPACTp48iSVLluD8+fNYsGABAGDFihW47777ovvPnj0bvXv3xty5c/HJJ5/gnXfewbJly/C9730PWVnd/09Pnz4dmzZtwq5du3Du3DnU1tZi1apVmDFjBlwuaT06VBKSQaSMo4WsxL+mHPyhLMGUxR/qIVtajBrma2UJUIoZawapbfoU6wvQ4y/ZPFdHgqAYXRaKfFZmNw3r2Y8h1o+STGTU9rAYlXxQD4s+zJo1C59//jnWrl2LhoYGlJSUYN++fejfvz8AoKGhAefPn4/u37NnT9TW1mLRokUoKytD7969MXPmTDz55JPRfVauXAmHw4GVK1fi4sWLuPbaazF9+nSsW7dO8nk5OKlZjI1paWmBz+fDQ4fuhrdnhqRjtJAWKbIi1tOSqizEStpiRVHR6nNQKyxqb95api1Sb0BKe1ii76llM7nC69dCXpS+tx1uwEaWacz6vFpbwxg8rBF+v19SX4gSIvel4v94As4s5febcMcV1D+8WtdzNQoqCSkkx31F84UShRArDflTROf+UA/Z76WlXOjRD2IErMiKFqi98TaHuejDiPfTErXLDpi1bIGVezLk/KxogR3kjpAHlYRUkuO+oihtMUR2vpAWOWmL2hEzVpQUVtFi5ExEIvTu12BJVrSC/5kZeX1WG65rhmRZ6fNRTcAJuFRkCwH75BL2uRIT0TttUZqyXN1P/7TFqokKHzulK/HoecPV6rVZHtYstVFXKzG0StJilfMk7AEJi4ZIlRZFjbYaSItccZEiIXYQFYDd0VJajprRQ1pYTFaMmNlX6D20fl+WZcDo8g+ftEpXiBhIWDQmVdpiRCkoGVqlLXYRFUBbWdEjXdFaWrSSDBZlxUiMGB7NorSYeU4kK+kNCYtO6CEmalOWq/srT1vsJCoA+7KiF+obctNbVuJJB2kxM1UhCICERVfi0xYtJEYraek+Rn7aQpiDHrPAKk1btJSVSN+KlqtS2xH+iC2jpYEVUaF0haBRQgZgVBlIbEK55MfIH0lkF9I1XYlHzmRzlKywQSqB0OrmzoKoACQrRDckLBYk2SKJSqSl+zj5s+RaGSvKip4LBEoZ/kyyYh3UCg0rokIQfEhYLEoqaQHkL5KYDmkLq6OBWEEsbbGCrNi1HKQHVhISSleICCQsNsauaQtL0mF0KUjPlCX6HgZNNheB5flXCEKIHAMXlHQEHHC4lEubI2Af4SNhsTDJUpboPhZLW1iSkVRYuW9FClZIVQh7w2K6kuvwogVhs08jLTF1lNA777yD6dOno6ioCA6HA6+++mrM8xzHYc2aNSgqKkJWVhYmT56Mjz/+OGafzs5OLFq0CH369EF2djZmzJiBCxcuGHgV5iI2aihhP4WjTGgkEXvoMWLI6lA5yH6wJiu5Dm/SFa4J/TFVWNrb2zF69Ghs3LhR8Pmnn34a1dXV2LhxI95//30UFBTgtttuQ2tra3SfiooK7N27F7t27cLhw4fR1taGO++8E6FQyKjLsAz+UJbi4c9GiAulK9IhaSEI4yBRYQNTS0LTpk3DtGnTBJ/jOA4bNmxAZWUl7r77bgDASy+9hPz8fOzcuRMPPvgg/H4/tmzZgu3bt+PWW28FAOzYsQPFxcV46623MHXqVMOuxUyklIZi9ldRJtKrRGQlWSEIQl9YSldIVtiB2Ynjzp07h8bGRpSXl0e3eb1e3HzzzThy5AgAoK6uDl1dXTH7FBUVoaSkJLqPEJ2dnWhpaYl5pCMspy0sY3a6EqE5lEVJC6gcZDdIVggxmBWWxsZGAEB+fn7M9vz8/OhzjY2N8Hg8uOaaa0T3EaKqqgo+ny/6KC4u1vjsjUdqL0vCcQyUiayUrrAiK3xIXOxPZFZi/oPQF5IV9lBcEtq/fz/279+PpqYmhMOxHdMvvPCC6hOL4HDE2jbHcQnb4km1z4oVK7B06dLo1y0tLbaSFjnloeixJg2BtpKssE5EWmiYsH1IJibJnrNq6sRKukKywiaKhOWJJ57A2rVrUVZWhsLCwpQCoYSCggIA3SlKYWFhdHtTU1M0dSkoKEAgEMClS5diUpampiZMmDBB9LW9Xi+8Xnv+QCqRFVXvp1BWrCgqLKYrQpC4EHKWWyDYxhFywBFUMQ9LiA0J1AJFwvL8889j69atmDNnjtbnE2XgwIEoKChAbW0txo4dCwAIBAI4ePAgnnrqKQBAaWkpMjIyUFtbi5kzZwIAGhoa8NFHH+Hpp5/W7dxYRamsKElW0klUrIpQmciOEmPnm3PkuuyYpsTDSroCAC1cJwBKWlhDkbAEAoGkCYZU2tracObMmejX586dw4kTJ9CrVy/069cPFRUVWL9+PYYMGYIhQ4Zg/fr16NGjB2bPng0A8Pl8mDdvHh577DH07t0bvXr1wuOPP46RI0dGRw3JOp+gF16LTgikRFZIVNKPeImxi8DYWVoA+0iJ1WjhOklaGEKRsMyfPx87d+7EqlWrVL350aNHccstt0S/jvSV3H///di6dSt++MMfoqOjAwsXLsSlS5cwbtw4vPnmm8jJyYke88wzz8DtdmPmzJno6OjAlClTsHXrVrhcLkXn1BrMlLSfUSsw6wGJChHBTimM3aWFMAdKW9jBwXGc7FWwFi9ejG3btmHUqFEYNWoUMjIyYp6vrq7W7ASNoKWlBT6fD3Pevheentp23xslNlITFiNkxa6SYpUeFi2xoryQtFgTlkpCych1eNHSGkbfoZ/C7/cjNzdXl/eJ3Jf6r18HZ6a0P6SFCF+5gk9/XKnruRqFooTlgw8+wJgxYwAAH330UcxzejTgWhl+YqOXvEiRFRIVQglWbOClpMV6WEVWgO7EpZWzZuuA1VEkLG+//bbW55EWtAYzDS8lkagQWmDEKtFaQtJCEPaDVmvmcTnkQVcwtiSU7Wb7l55YuqJEVLqPky4rJCrpBUkLQRBmQsKSgvag9J4WKXKjd8qit6ikq6SkY/+KEFYrEZG0EFbHGXDAqaZkFrBOuS0VJCwakkpuIkKjlbTEpyt6l3/SVVaIRKyUtpC0sI2V+lcIc2F2LSG7I3X4tJ7ISVVIVoh4rLR+Ea29QxDWhxIWA2kPemLKRlqWh+SkK1T+IbTCSiWiiLRQ2kIQ1oSEhUdblxcZXan/EuuZ0an4PbSSFmUz21L5h9AHKhERBKE3VBJSQFuXV/aDj5xGXilISVeo/EPoTXMoyzJlIioRsQH1r7BLTU0NBg4ciMzMTJSWluLQoUNJ9+/s7ERlZSX69+8Pr9eLwYMH44UXXog+v2fPHpSVlSEvLw/Z2dkYM2YMtm/fLuucKGExiLYub0wyw09a5KYsctIVK6YqzaFsZs6FkI9V0hYqERGEMLt370ZFRQVqamowceJE/OIXv8C0adPwySefoF+/foLHzJw5E3//+9+xZcsW3HDDDWhqakIwGIw+36tXL1RWVmLYsGHweDz4zW9+g7lz56Jv376YOnWqpPMiYTGQeGnho7g0JHJj0ENU+EN7W8P6Ng2TtJhP5HusZEi3VaQFYL9EJJRCNIdlr6hCEJKprq7GvHnzMH/+fADAhg0b8MYbb2DTpk2oqqpK2P/111/HwYMHcfbsWfTq1QsAMGDAgJh9Jk+eHPP14sWL8dJLL+Hw4cOShYVKQjzauzLQJqGHRQ388lB8aUjKyKFU6YrPdVnz8k+O80rCTUtomxY0h7IF/20m6TYHS2s4M0ZIlcoplYjUked0iJZMqJRCyKWlpSXm0dkp/MdzIBBAXV0dysvLY7aXl5fjyJEjgse89tprKCsrw9NPP43rrrsON954Ix5//HF0dAjfrziOw/79+3Hq1CncdNNNkq+BEhYB1EhLzwx5f6mpacKNT1f0TlWSPa9X4kJJi7GIfR/TIW1hpUQkVUYi+1k1bSHpkoYzALjURAtf/DgXFxfHbF69ejXWrFmTsPtnn32GUCiE/Pz8mO35+flobGwUfIuzZ8/i8OHDyMzMxN69e/HZZ59h4cKF+Oc//xnTx+L3+3Hdddehs7MTLpcLNTU1uO222yRfCgmLxiSTnYjMJOtnSYaSkUHxaCUqYvvrIS4kLfoj9fvWGs60tbQA5pWIlN7ArS4uhDHU19fHrNbs9XqT7J24kDHHcaKLG4fDYTgcDrz88svw+XwAustK3/rWt/Af//EfyMrqTlpzcnJw4sQJtLW1Yf/+/Vi6dCkGDRqUUC4Sg4TFQNq6PJKkRUk/i5R0RS9ZETpW7x4XQhuUfJ/USAtgnTlbjJIWrZIGEhciGbm5uTHCIkafPn3gcrkS0pSmpqaE1CVCYWEhrrvuuqisAMDw4cPBcRwuXLiAIUOGAACcTiduuOEGAMCYMWNw8uRJVFVVSRYW6mExkfjhznzi+1nUTsNvhKyofZ1kPSus9LPYCTVSqeZYK/W16N3bokdZxAqlFiucY7ri8XhQWlqK2tramO21tbWYMGGC4DETJ07E3/72N7S1tUW3nT59Gk6nE9dff73oe3EcJ9pLIwQJi4HE97fwE5b4khA/YUklK1LSFak3fC2SkfimTSlIOT+zpMWuaZHSxmktGq6tIi2Avg25eqQhrCcsJCvss3TpUvzqV7/CCy+8gJMnT2LJkiU4f/48FixYAABYsWIF7rvvvuj+s2fPRu/evTF37lx88skneOedd7Bs2TJ873vfi5aDqqqqUFtbi7Nnz+LPf/4zqqursW3bNnz3u9+VfF5UEjIIM2UlQuSGnyptUdpgqeTGbpXkRE3TKetIHa5ux2uXip4louYwp9lNnGSF0IJZs2bh888/x9q1a9HQ0ICSkhLs27cP/fv3BwA0NDTg/Pnz0f179uyJ2tpaLFq0CGVlZejduzdmzpyJJ598MrpPe3s7Fi5ciAsXLiArKwvDhg3Djh07MGvWLMnn5eA4ju2fcANoaWmBz+fDpNcehjs7eSOSEliQlXi0LBHpkaYkg4UG3HS4eRshaVboZ+GjZ1+LFjdzloXFTrLS2hrG4GGN8Pv9kvpClBC5Lw3+8Xq4MpWnvKErV/DX9T/W9VyNghIWHUkmKoA6WVGLFmmL0aLCEnZOXCLY+dqUwnLSQrJC2B0SFp3QW1bUpCt85IqLmvfQCpaGOaeDuOiJlYY7R2BRWliWFUIdziDg7FJ+PBdMvY9VIGHRATmyEj982UhZ4SNVXJS8ZjpA4pJesDLJHMC+rFC6QmgFjRLSGL1lRW+aQ9mqRCNyvN6ywqoMKRkhle5YacRQPHqMIJIjICQrRDpBCYtGCE3Jr1RWkomKHumKEHLLLqwKhFlQ4pI+6FEiklIaIlkh0g1KWDRAKFWxsqxEkJKUGJGmWBlKW9IDs5MWgkgHSFhUIqUEZEVZ4SMkJSyIitnvLxWSltRYuSwUwUhpYV1mKF0h9IBKQipQMxIIkC4rrGAVQWARK5aI+KN37CAURmBEeYhkhUhXKGFRQM+MgKGyYma6wjpWkygrpC15ro6EocZGDD22ixTpmbSQrKSmOcwx/zkRyiBhkYncfhWAZIWIheWRRMnEREhkCGHSsaeFFVnh/5v1z4yQB5WEZCA3VQGsXwayAixNJCeH1nAmMyUiOSIS2dcqiUieM6D7qstC6DnBHBFLMjHRcq0mM3AGADWnz9noR5CERSJqS0CAfFmhdMX+mN3boiYx0UNc9Jr5NiIOZohLOmCmEEhJUSL7WFlcCCoJpUSrfhWSFX2xWi9LPGaUiLQSA5ZLRfEJh9GJRzoIEuuyomZ/gi0oYUlCKlEB5PWrANYuA/lDPWK+JqnSFqPSFr3kQqvERauURUxOjC4R2bk0ZCVZ4R9HSYs1IWERQet+FUC6rLAkAvGSIvYcS+dsdfTqbZErAfybrJwbvBV6XIwuEdlRWqwoK/HHk7hYC6ZLQsFgECtXrsTAgQORlZWFQYMGYe3atQiHw9F9OI7DmjVrUFRUhKysLEyePBkff/yxqvdVUgJiQVa0bDz1h3oklRWx/eUcozUslYXUnouWJSK5JZs8Z0CTUoqaUpFa2ZF6vkZKRDqUh/RG65E/VCKyFkwnLE899RSef/55vPTSSxgxYgSOHj2KuXPnwufzYfHixQCAp59+GtXV1di6dStuvPFGPPnkk7jttttw6tQp5OTkyHq/7IwuZGTEGreaIcvRbQbKSp6rXdXNUgvhSLfSkdjnrXb0khYlIjWpithzcm+8RicuciXEyBKRXZIWM5IJveSC0hbrwLSwvPvuu/jGN76BO+64AwAwYMAA/Od//ieOHj0KoDtd2bBhAyorK3H33XcDAF566SXk5+dj586dePDBB007dyuhdypiZOnIjCHOaiVRL1hthGURpeUvwhiMSEKot4V9mC4JTZo0Cfv378fp06cBAH/6059w+PBh3H777QCAc+fOobGxEeXl5dFjvF4vbr75Zhw5ckT0dTs7O9HS0hLzAID2rgzV5+wPKv8rUk1JJbK2j9wbp9ElHCPezwx5yHO1Cz7UkOO8Yvhw51Q3a6U3c1bTFbHX0CMF0et1CXvjDKh/2AWmE5Yf/ehH8Pv9GDZsGFwuF0KhENatW4d7770XANDY2AgAyM/PjzkuPz8fn376qejrVlVV4YknnlB0Tu1BT0xZqDWYKTjnihoiN3U90wgze02MuD6rTiYXQa2oqElXxMoWrMuK1mjVmEuSop48p4NSFoLthGX37t3YsWMHdu7ciWPHjuGll17CT3/6U7z00ksx+zkcsT9gHMclbOOzYsUK+P3+6KO+vj76XFtX7C+nti6vBleiDD2aWM1ujOWj93mwWKZJhRmpihDxN2mjZYWlclYkGVHUeEyyQhCawXTCsmzZMixfvhz33HMPAGDkyJH49NNPUVVVhfvvvx8FBQUAupOWwsLC6HFNTU0JqQsfr9cLr9c8EZGLVokEK6LCR++0xUpJi1aiotXNPpK0WCVZMUIOpKYudhcVSiIIM2A6Ybl8+TKczthTdLlc0WHNAwcOREFBAWpra6PPBwIBHDx4EBMmTFD8vqlSlvZg7POtwdghqPF9LH6NfnErTUdYSlXEYP389ISVVEUIq8iK0YglLtSnoh8kSATTCcv06dOxbt069OvXDyNGjMDx48dRXV2N733vewC6S0EVFRVYv349hgwZgiFDhmD9+vXo0aMHZs+ebfLZ64fUVMJqEqBX2sJyysKqqChFC1FRkhCZJQkkJwRhHEwLy3PPPYdVq1Zh4cKFaGpqQlFRER588EH827/9W3SfH/7wh+jo6MDChQtx6dIljBs3Dm+++absOVisiNgN3mqiEo8/1MP20qKXqJjZ+2H3VIUgCHNxcByX9lP9tbS0wOfzYdJrD8OdfbX8I2fGWykTyAHWXkvIaPToa2FBWvRMVcwSFi1lRcvJ7gj9sNPkcfGkurbW1jAGD2uE3+9Hbm6uLucQuS8NX7geLq/yma9DnVdwsubHup6rUTCdsBhNR5cHSnMZqcOb+f0sJC/JsVvSYtVFDVNByUp6YkbjrVHDm1nCGQKcQeXHcyHtzsVsmG66NRs1Q5ylTCDnD2VFH4QwepS3zBjubLdelQhaywpLw5kJgmALEpY4Orqkj4qIHy2kBpIXcazck2PUCCAzbvQsJCtUDiKI9IGEJQXxKUsy4oc3K4UvLyQw3VhRWuyaqgBsyApBEOkFCYsAyVIWM2a+JXnpRktp0bMsZPS8KkanK6zICqUr5mNGPwnNx5K+kLBIIFnKkqwspGYhRNHXTHN5YT1psXOqAugrK9S/QrBCujX2ClFTU4OBAwciMzMTpaWlOHTokOi+Bw4cgMPhSHj8+c9/jtlvw4YNGDp0KLKyslBcXIwlS5bgyhXpvzNplBCPK0E3en7x744uD7Iy2P4LLl1HHOkxekgLSFaMQ066IvYXudVuSvGzDlPCROjF7t27UVFRgZqaGkycOBG/+MUvMG3aNHzyySfo16+f6HGnTp2KGTp97bXXRv/98ssvY/ny5XjhhRcwYcIEnD59Gg888AAA4JlnnpF0XiQsCmjr8ibMyRJBj9WbpZBu8qKFtGg5xNksWTEqlWBJVrQiVWmBJaERWiKBvy3d5CUdhzcbSXV1NebNm4f58+cD6E5G3njjDWzatAlVVVWix/Xt2xd5eXmCz7377ruYOHFidBb6AQMG4N5778V7770n+byoJJQEfi+L0rKQGaRL2YiVNZLsmqw0h7KiD5bQIl2RemyyB0s0hz0xD4KIp6WlJebR2Sn8R3cgEEBdXR3Ky8tjtpeXl+PIkSNJ32Ps2LEoLCzElClT8Pbbb8c8N2nSJNTV1UUF5ezZs9i3bx/uuOMOyddACUscHV1uZGWknqUnWcrCxx/MEp311gjSIXlRk7aoTVnMlBXNVmVmQEis2L8iJC16/NWvRECMLB/Rys364goALjUv8MW3vri4OGbz6tWrsWbNmoTdP/vsM4RCIeTn58dsz8/PR2Njo+BbFBYWYvPmzSgtLUVnZye2b9+OKVOm4MCBA7jpppsAAPfccw/+8Y9/YNKkSeA4DsFgEA899BCWL18u+VJIWFLA72Vp6/IkTNcvhFlloVSwLi+R81Nybmb0tVixDMSCnBiFGTdRrUsVWqUl6Vw+Irqpr6+P6S/xepOPeHU4Yv//4TguYVuEoUOHYujQodGvx48fj/r6evz0pz+NCsuBAwewbt061NTUYNy4cThz5gwWL16MwsJCrFq1StI1kLAIIDVl4dMe9MSsLcQ6rMiLUNnKH8piXlpYlxW7iokVbrZaSYtepR1q3k1PcnNzJa0l1KdPH7hcroQ0pampKSF1ScZXvvIV7NixI/r1qlWrMGfOnGhfzMiRI9He3o4f/OAHqKyshNOZukOFelhE6Ohy8/4t3MsidU4WPYY3a4nde12SIbccZPQcK/EI9ZTwe01Y7DnREjk3cWrKTI1WsmL0Z03fW/3weDwoLS1FbW1tzPba2lpMmDBB8uscP34chYWF0a8vX76cICUulwscx0HqGsyUsPDoDLjRQ0IPJ780xO9l4acs8WWheGkxs6+FJSJJihbSJCddUdK3wlJzrZ2lJBXNYY/kG60Z/RVa3UzznAHdUhY9UhWjPmsjZCXde3KWLl2KOXPmoKysDOPHj8fmzZtx/vx5LFiwAACwYsUKXLx4Edu2bQPQPYpowIABGDFiBAKBAHbs2IFXXnkFr7zySvQ1p0+fjurqaowdOzZaElq1ahVmzJgBl0talw4JSxydgQx4PV0AYktDyeZlkSotfPRIXawsQT5Xh6oelnSSFbuhpCcnciOXcuOVc4NTe6Ni/S9/vcs/ekqLUZ9tussKAMyaNQuff/451q5di4aGBpSUlGDfvn3o378/AKChoQHnz5+P7h8IBPD444/j4sWLyMrKwogRI/Db3/4Wt99+e3SflStXwuFwYOXKlbh48SKuvfZaTJ8+HevWrZN8Xg5OahZjY1paWuDz+TDwxUp4crt/EUakBUBMPwtfWnrG/Dt2xBC/n8XIBlyl0sJKE67S/hU9hYVkRV/UjhCyew+GFimL0Z+Rljd9oyVQyrm3toYxeFgj/H6/pL4QJUTuS6PmrofLo3ydulDgCj548ce6nqtRUA9LHMFg90fSGciIblPbz6LVoojpAEuyYna/CiENmndEnDxnwBSh06bpmGNSVgjzIGHhEerqrqNpIS3xk8kZJS2sN/iaiVxZIayDnSdMUyIcZokKH6WyYYaoAOzKiivAqX7YBRKWOEIBadLCR460xD+shM91OfpgBannQrKSHthVWqTCgqjwkSMeZokKwK6sELGQsPDgvkhYpEhLR5Kp+vmkmrZfD4kxImVhSVq0hGTF+thRWlJJCGuiwieViJgpKoS1IGGJQ4q0RFA7P4sYQhIjV2TSQVq0TFeoX8Ve2LlExIdlUYknXkpYERVKV6wDCQufQPfHES8tESLSorafRSlmlpTE5MCsEpHWskLYE7tKi5VEhU9EUlgQFYBkxWqQsMQjIC2RlAVQJy2Rh5YkkxcjG3DNTluEIFkhAPukLRFJsaKoEIQWkLDwcAS+sO04aQGQUlrEECoP6SkvZmKUtGj1PiQr6YVdxIXQBkpXrAcJSxxC0hLfz8JHqAm3TWJDLqCfvETQImWRIwisJC3J0hXqV2EHtZPGKYHEhSBZsSYkLDwcoe4f4nhpAeSPHFLShKuFvJidsgD69rVIeV0lU+8T6QeJS3pCsmJdaC2hOBxBBzg3B0fAAc7DAQEnOACOjBBCARdcnhCCQSfc7rDgukP8NYfiF0mMED+NvxB8aeFP8y8FoYUXlU/Zr1w8fK7L8IckrCapIalkhZIVIh6+tFB/CMEazi5A2tKAwnBdqfexCpSw8HB+kaw4golJixbDna9u88oa+qxF8mLWDLhaJi2pXotkxVqYUQ5KBaUu9obSFWtDwhKHqLQg9RwtUppw+UTERQ95YaE0FEELaVH7GiQrhBxIXOwHyYr1IWHhEUmDBaVFZI4WMWmR24QrV1wA+cmL3JRFSBKU9ofoPV8LS30rea4OJtMDQj4kLgTBDiQscbhEpAWAammRIy5K5CUerVOWiBTkudpViYvWx7BUCuKLCkmLOHp9Ns2hLNGHqtclcbE0lK7YA2q65eEMdv/XFQBCnm5pCXu4qLREmnDhCYPrciVtxBVqwgVi05aeGckb/JQ06qZq0JXagCt1NE5zKDvlfkKvrVUzLquyYgSt4VghTZeyl1L54B+n9HsVkRZqzrUOJCv2gYRFBvyRQ3KkRYyIvKQSl+59vZKkhbA/8aIitJ1VeZEqCmoTEamvT+JiX0hU7AcJSxLCnu71Ljj3F//94mt4wgC6hzoDgMvT/V+3u3t7ZKhzMlmJIEVWpBKfrvCHNkcQS1f8oSz4eL+8/aEeCSlLcyg7mmgoSVYir6sl/HMi2IRKY4SRkKjYFxIWHmF393j3EIOl6lTpihpZiSBVWuRi9FwsfFrDmcymDXZGjaTona7EvxcJlX2wo6y4Ojm4VCwWyXWxsdCkFjDfdHvx4kV897vfRe/evdGjRw+MGTMGdXV10ec5jsOaNWtQVFSErKwsTJ48GR9//LHi94vIitJ0RQ5S0xUjZEUMNbLhD/XQRFbMFB4rYpagRUZHkQAQZmBHWSFiYVpYLl26hIkTJyIjIwO/+93v8Mknn+BnP/sZ8vLyovs8/fTTqK6uxsaNG/H++++joKAAt912G1pbW005Z6nlIL1kRQg5suIX+OtWjjBEJMVIyUiV+oj1fBDqsYOkGJnoEPpAspIeMF0Seuqpp1BcXIwXX3wxum3AgAHRf3Mchw0bNqCyshJ33303AOCll15Cfn4+du7ciQcffFDW+4U93QYnN11JRpaAmOgpK/HpipJkJb40JO0YSkGMgBX50nNYMkHIgWQlfWA6YXnttddQVlaGb3/72+jbty/Gjh2LX/7yl9Hnz507h8bGRpSXl0e3eb1e3HzzzThy5Ijo63Z2dqKlpSXmEY+YrAihpBykFr1kJUJ80iIkJEamKaneQ2kTsJbY/WZrhzRFDLt/7+wKyUp6wbSwnD17Fps2bcKQIUPwxhtvYMGCBXj00Uexbds2AEBjYyMAID8/P+a4/Pz86HNCVFVVwefzRR/FxcXR5yLpihiRdEWISDkoGVqkK3rLihh8QbFaosJKMmE17CwphLUhWUk/mBaWcDiMf/mXf8H69esxduxYPPjgg/j+97+PTZs2xezncMT+4HIcl7CNz4oVK+D3+6OP+vr67vdLUQrik6wcJNa/YjVZEepnMROrSZLVMVpS9Eo5pMqqkven2W/NgWQlPWFaWAoLC/GlL30pZtvw4cNx/vx5AEBBQQEAJKQpTU1NCakLH6/Xi9zc3JiHFITSlWTlIKH+lVSwIisRWJOWZNi9+dbI87dLohL5zKz+vSeuQrKSvjAtLBMnTsSpU6ditp0+fRr9+/cHAAwcOBAFBQWora2NPh8IBHDw4EFMmDBB0XsqTVdSlYPUThBnVhkIsJa0pDtaDGm2m6zIgXpZ2CXP6UhLWXF2hVU/7ALTwrJkyRL88Y9/xPr163HmzBns3LkTmzdvxsMPPwyguxRUUVGB9evXY+/evfjoo4/wwAMPoEePHpg9e7bi9+UE+likpitSZrcVQyxdMVNWIrAiLVQW0hc7ywqlLNYlHUWFSITpYc1f/vKXsXfvXqxYsQJr167FwIEDsWHDBnznO9+J7vPDH/4QHR0dWLhwIS5duoRx48bhzTffRE5Ojuz341wcYv63kNm7ogaWZUUJagRH7pBqPqmm6td75luaOVUZWiYbycREyvefvodsQbJCRGBaWADgzjvvxJ133in6vMPhwJo1a7BmzRpN3k9qusJHyuigZFhFVlhJWQh9sMNN2q4pSroutkiyQvBhuiRkKinSlVRzr/AbbpP1r1hFVowklRhZYU4WrdH7RpxOsmI1qeGPREqnUUkkK0Q8JCw8hBptU6UrfNT0r/BJZ1kxAqvdsPTGbFnRohwk93uaan8Wmm+bwx5BQUkHaSFZMZ+amhoMHDgQmZmZKC0txaFDh0T3PXDgABwOR8Ljz3/+c3SfPXv2oKysDHl5ecjOzsaYMWOwfft2WefEfEmIRfjpippykFC6olRW4vs+qHyTHCNWcWbhppcKs2VFC+wooOkgJWKQrJjP7t27UVFRgZqaGkycOBG/+MUvMG3aNHzyySfo16+f6HGnTp2KmSbk2muvjf67V69eqKysxLBhw+DxePCb3/wGc+fORd++fTF16lRJ50UJSzwi6YrWzbZKZUUIoSZVn6tDVfOq2RhRFtLrRmeWqMgVsHSXFVZTFimyYlehIVlhg+rqasybNw/z58/H8OHDsWHDBhQXFydM2hpP3759UVBQEH24XK7oc5MnT8Zdd92F4cOHY/DgwVi8eDFGjRqFw4cPSz4vEhYTUCMr8elKKimxurjojRX+OtfjHNNdVrR8Da0QKwEl299OkKzoS/z6eZ2dwv2TgUAAdXV1MWv0AUB5eXnSNfoAYOzYsSgsLMSUKVPw9ttvi+7HcRz279+PU6dO4aabbpJ8DSQsfCSkK2LlIH7/SrKGWyNlJX5fteLiD2bFPOwCSzct1mB1VIqc75maJmyjUhal8mEHaUnXCeGk4gpwcHWqeAS6ezOLi4tj1tCrqqoSfL/PPvsMoVBI1hp9hYWF2Lx5M1555RXs2bMHQ4cOxZQpU/DOO+/E7Of3+9GzZ094PB7ccccdeO6553DbbbdJ/iyoh8VAtJQVpUSkRU6Pi5icCG1nqRk41ZwsfIzoaWEFqelKRFbynAGmboxKZCXZz4LZ33uWPlujIVExjvr6+pj+Eq/Xm3R/OWv0DR06FEOHDo1+PX78eNTX1+OnP/1pTIKSk5ODEydOoK2tDfv378fSpUsxaNAgTJ48WdI1kLAYhJY9K2qxQkNu6lLXZc3fM3Ij1OLmZdbIFynnLnVitOawhzlZAa5+f6R8PlKENdlnlupz0iKBYvEzJuyH1HXz+vTpA5fLJXuNvni+8pWvYMeOHTHbnE4nbrjhBgDAmDFjcPLkSVRVVUkWFioJ8Qlc/Ti4LleSHdUjV1aE0gwl4qHkGCmpic/doUm6kqp05XNdliUrSsoBreHMmIeRqH1frVcmNuJGmufqUNRTo4VYqpEVLVEqPqyW7KRA6QqbeDwelJaWxqzRBwC1tbWy1ug7fvw4CgsLk+7DcZxoL40QlLBIIBRwRftYgkFnyknjUqE0WfEHsxRLgdpUxefu0L0ElEpUlCKnNCREvARoWT7QQ4i0TlqMInIuctIpOWmL2LHJzsVIIvIhVRJJVgi9WLp0KebMmYOysjKMHz8emzdvxvnz57FgwQIAwIoVK3Dx4kVs27YNALBhwwYMGDAAI0aMQCAQwI4dO/DKK6/glVdeib5mVVUVysrKMHjwYAQCAezbtw/btm1LOfKIDwlLPAGn4Cy3ShCa4TZeVtSWgPyhrJTlE61KQHxpMUpUup9XX/5RKy181AiMUYmNVaUF6JYFuSU1ueKihazoJQxSSkQkK4SezJo1C59//jnWrl2LhoYGlJSUYN++fejfvz8AoKGhAefPn4/uHwgE8Pjjj+PixYvIysrCiBEj8Nvf/ha33357dJ/29nYsXLgQFy5cQFZWFoYNG4YdO3Zg1qxZks/LwXFc4uI5aUZLSwt8Ph+Kn/l3OLMyBUcLpRopJDRKqGf0v92Rl1ayImXiOMD6vSp69KloJS3J4N8MzR6BJFWmWJOWCEp6gVJ95lolK0ZIg5i4WFVY7CIrra1hDB7WCL/fL6kvRAmR+9LEW5+A263890gweAV/eGu1rudqFJSw8HAEHEAWBFMWfllICVomK6lKQyQq4miZtIihp6TE9+SkuhapjcQRMWBNXLQuE1lJViLvEy8tVpUVglALCQsPR8gBR8ARs2Iz1+WStZ6QFPQYCWQFSQHMGf0Tj1gjrhHpixykNAxLFTArl4gA5eLClxbWelakwpcWK8uKXdIVo3F1huAKKb8HcUFt719mQsIiRpJeFjWNt1rJipoGXLMwK1WRipkio25ys/SQFkC+uEi5XlavlY+VRYUgtIKEhYcz4ACC3X8F8FOWCFLKQlkCM9tGykFaJytWkRYWUhU1JJMJJTKjRk6SvWa6SAugrDFX7HVkH0PyIBtKVwgtIGFJxhcpi5KyUPwIISMmhGMRq8tKKpKlMnqIiZRzkdLXIlVaul+PTXFRUiYSOp7QF5IVQito4jgezkB3yuIIdveyWAFW1/TRegI4q2G0rMh9bzmT05m1arFUlEw8p1RWKF0hCPMgYUnFF7PfRma+DQW6/xsMsvPRsSYtalKVPFd79EEoR6owyZEWu4gLJSvGQekKoSXs3HUZwBkEXDJTls5Ahuhzkf6VdCkHqUlVhCSFpEUdWktL92taW1xIVgjCulAPSxIckQZcKO9lMQqzG3DVpirJnjOzvGIk/lAP2cekKqtp3Yx79XXZbsoFEntc1J4vlYPkQekKoTUkLDycAcDRFfnKgbDASCFA2SRyfJnQq4Sjx7T5qUglKt37iKcqUojsp6W4KJEDFvGHekiSFkC7Ztyrr8t2U24E1s+PIAhpkLDwcAYAR8wfUQ5EZluJpCxidHS5o9PzC60hxEdveTFKXPRKVZIdo4W02EVWIkiRFkBa2iJ1ZtzY12U/bVELpSvyoHRFO5ydIThVTBzntNHEcdTDIpNI8y2QvPE2sn5QKnzuDt3EQq8kJ1WvSvc+8mUlx3kl5iF2rJreFrvJSgR/qIeka9Ojr6X7ddnvbSGMgWSF0AsSFh7OUGRoM+DsEmjADVz9uCKjhZIRabiVIiR6iYs/mKWpuEgRFTmNtRGEBCX5VOrypcWussLHTGnpfm0SF4Ig9IGERQH8lEUqUlIJ4Kq4aC0vWkiLnqmKGKnSFqmkg6xE0FpalIqLXaBykHQoXSH0hHpYeLgCAARXc0/ey9IZyIDX05V4mAD8m36qBQsj0qJVQqKmt0WprCSTCjl9EvEL2cW/vtkjieQuPilFXtWgZTMuIL8ht/v1rdGUSxCENSBhsRGtwUxJc75o3ZTL+oy1atIVvVbBVvO6WsqOnJRKSUMuYF1xoWRFHpSuEHpDwsIj5AEcbiDs+eKR0b0t7OHAubnuBRE9YTgyQnB5QrJXbJZzk5KaqrQG5cf1WhMRAiFxSfZXvJy/2sXKEsmSFS3KQBE50Etc5J6HtH1TCyRNyicMSYpymsPd00CQuBB6QcLCI+wCHBJkJRVtXYJ1paRYSVDEUCIuqf5qT9Y/ISYrevSrmCEucpMUqUmXWllRUh4C2B7+TKKiHc1hjqSF0AUSFgWIpSsdXd0fZ1aKeVgAawmK3BtnKnERS1uAq+KiRFT4760XeouLknKPUaJiN0hS9IOkRTucgRCcoaDy41XM4cIaJCw8wp4vEhaNS0GAtQRFK8QaP1OVicQwU1Ti0VJclPakmCkqVk5ZSFSMgaSF0BoSFh5hD+BQKSuRlCUesWZYrQVFauOtUSjtbxHaL9nrm4VScVHbOEt9KvIgSTEH6mshtISEhUfYDUBAVqQgdWiznRIUOSgpE0WeS/Z6rCBFXLQY3cOSqFglZSFZMR8rpS0RyUpGm4R9CO2x1MRxVVVVcDgcqKioiG7jOA5r1qxBUVERsrKyMHnyZHz88ceavq+SUlBHlwdtXR60dXnRHvSgNZiZtrLCR2wK+eZQdoycxH8d/xqsEj9BYORrI2RF7bIFdoRkhR2kiIAe7yn3QbCLZRKW999/H5s3b8aoUaNitj/99NOorq7G1q1bceONN+LJJ5/EbbfdhlOnTiEnJ0fWe4Q9ADToW+EvhEgIk6q/RewYq6D1xHBaLySpFVZJWQg2ICEg1GCJhKWtrQ3f+c538Mtf/hLXXHNNdDvHcdiwYQMqKytx9913o6SkBC+99BIuX76MnTt3yn4fLZts42kPyh/qzAJ6zsgqdcE+qfvZEaVrMxGUrhCE3bCEsDz88MO44447cOutt8ZsP3fuHBobG1FeXh7d5vV6cfPNN+PIkSOy34dzfSErGtDR5Y4pCwHd0mJVcdETMSFJZ1EB2E1V4lGy1hBgr/WGCILQH+ZLQrt27cKxY8fw/vvvJzzX2NgIAMjPz4/Znp+fj08//VT0NTs7O9HZ2Rn9uqWlJXYHjdOVeCLSku3W5y9A1kYKSYXfmJvOogIoW5uJuAqlK4RdcHR2weFSni04QtLWubMCTCcs9fX1WLx4MXbs2IHMTPG/4hyO2O5zjuMStvGpqqqCz+eLPoqLi7uPU1kK6gxkxHwdn7JEkpYIlLgIk86ykqoExCrpnrI0h+n/Y4LQG6aFpa6uDk1NTSgtLYXb7Ybb7cbBgwfx85//HG63O5qsRJKWCE1NTQmpC58VK1bA7/dHH/X19d1P6JysABAVF4KwSgmIdShdIQh7wrSwTJkyBR9++CFOnDgRfZSVleE73/kOTpw4gUGDBqGgoAC1tbXRYwKBAA4ePIgJEyaIvq7X60Vubm7MQ2/i1xeKFxdKW9IbJY21Skbn6InSlMXqRNIVSlkIQl+Y7mHJyclBSUlJzLbs7Gz07t07ur2iogLr16/HkCFDMGTIEKxfvx49evTA7NmzZb9fd7ri1DRd4a8vFJGWnry1htq6vOiZcbWfRu/+FjnoOUKI6EZpqhKRFSlrL7GOlkOcKV0hCPvCdMIihR/+8IeoqKjAwoULUVZWhosXL+LNN9+UPQcLALgy9CsF8Wn7oq/l6tfU3+IPZQk+7IzSVEUoWYlsNzt1sbI4KYFSFcKu1NTUYODAgcjMzERpaSkOHTok6bg//OEPcLvdGDNmTMJzGzZswNChQ5GVlYXi4mIsWbIEV65I/53FdMIixIEDB2K+djgcWLNmDdasWaP6tV06yQp/faGsmHTFk5C2AGA2cdEaKULC38cuiY/aVCUVVkxdtEhZWEhXmsMeJs6DINSwe/duVFRUoKamBhMnTsQvfvELTJs2DZ988gn69esnepzf78d9992HKVOm4O9//3vMcy+//DKWL1+OF154ARMmTMDp06fxwAMPAACeeeYZSedl+YSFNeJHCsXT0eVBR0y64knZ3wLIT1xYXQZATXpih/RFiawoTU5YSFwIgrAe1dXVmDdvHubPn4/hw4djw4YNKC4uxqZNm5Ie9+CDD2L27NkYP358wnPvvvsuJk6ciNmzZ2PAgAEoLy/Hvffei6NHj0o+LxIWg4hfxbkjQVL0ERcW0EsyrCYvWjfWSk0kjBYXM4Y4m5FqUDmIsBItLS0xD/5cZHwCgQDq6upiJmQFgPLy8qQTsr744ov461//itWrVws+P2nSJNTV1eG9994DAJw9exb79u3DHXfcIfkaLFcSsjJXG3CDX3zt+eLr2DIRkNiY273NOqUiuRLhDyZZ5did+sbMeulIydwqUmQl8l8pN3srloqsCJWFCC1xdAbhcLmUHx/qvt9E5huLsHr1asFWis8++wyhUEhwQtb4KUQi/OUvf8Hy5ctx6NAhuN3CWnHPPffgH//4ByZNmgSO4xAMBvHQQw9h+fLlkq+FhIUBOro8MdICJPa3WAUW0g5/KItJadGTPFeH5IQix3mFpEUFqZIVkpXkRD4/+pyMpb6+PmYKD6/Xm2Rv6ROyhkIhzJ49G0888QRuvPFG0dc7cOAA1q1bh5qaGowbNw5nzpzB4sWLUVhYiFWrVkm6BhIWBoiXFQCqZUXK1Pz+YFbS9ELujV+NrPjcHYIpi5R0JWb/NBAVLYYA6yktSstPaq5L71RDavmHbsLSoM/JeKTOOdanTx+4XC7JE7K2trbi6NGjOH78OB555BEAQDgcBsdxcLvdePPNN/G1r30Nq1atwpw5czB//nwAwMiRI9He3o4f/OAHqKyshNOZukOFhIVHKOiE8uBNGpFyECtoIS1apSp8aZErKoB0WYmUZ+y2BICclEUvzGzy1fIvd+pPIdIVj8eD0tJS1NbW4q677opur62txTe+8Y2E/XNzc/Hhhx/GbKupqcHvf/97/Nd//RcGDhwIALh8+XKClLhcLnAcB46TtugwCUscwaC2E8elQmq6wu9fiaBV/0oqaUl6rMY3SKXnIVdWIv+2m7TIQeuURY2saDVxHKA8bVErKZQaSIM+J/ZZunQp5syZg7KyMowfPx6bN2/G+fPnsWDBAgDdy9tcvHgR27Ztg9PpTJjgtW/fvsjMzIzZPn36dFRXV2Ps2LHRktCqVaswY8YMuCT26JCw8Ah1uXQdNmVUuqJkpeZk0iKWsrDQryKnBCTU+Go3aZGbsmglLawNn5YiLVqmKHQTJuzErFmz8Pnnn2Pt2rVoaGhASUkJ9u3bh/79+wMAGhoacP78eVmvuXLlSjgcDqxcuRIXL17Etddei+nTp2PdunWSX8PBSc1ibExLSwt8Ph/6bf43OLMyVS9+6PUkLuctJCtq0hVAPGFRIixA6nSDLwdWkpVkc59E0Fta5I4SUjOcWW5ZSK2wqJUVLdMVwdfnyYRepR4SlvSirTWMf/nS3+H3+3Vbiy5yX7p10GK4XckbZJMRDHXirbPP6nquRkEJCw+uywVkAaFAdzxlZGlILlrLCiCtn4UF1KYqYvtZIWmRcnM3MmVhLVkRQu9+FJIVgjAGEpY4uC4XHBkh3aVFj5FBWqCmn8UI9JAV/v5WkBYpmFUakove6QpBWJ7OTnVTvIaFE3orQjPd8gl0fxxcV7eshAIuBIPmfkRi5SA9STaJm5nIKQGlmgJfrBQjV3LSGdZLQQRB2AsSFh6OgMMQaVGbruhRDoqHJWnxuTo061fhi0oyabGDuMgVAjkCYoVSkBFQOYggjIOEJQ4haQEgS1riF0BUOjrIjHSFDwvSomUJSEhQkk2NbwdpkYsUEdFCVihdIQhCLiQsPByh7mmH46Ul0s+iRdLCau8Ki2glK8lKQJHnlbyuFdBaDEhWCIIwCxKWOBxB3loJGkuLkKzIxYhyEB8zUha5JaBUsiIFK0iLUTd6MSkhWYnFbuWg5rCHZvhNQZ7TgTynAz5n4po6hP6QsPBwBr5IWIKO7pQF0C1piSCWrphdDuJjpLToXQJSur+R0qJ1f4gSSYg/B+pZsS/xohL5muTlKhFRIcyFhCUOvaRFi3TFTIyQFqNKQDnOK6I3YFakRWvUJBtayQqlK2whRUrSXVxIVNiChIVH5HdQMmkBIEtakjXcyk1XjC4HxaOntBhVAuLffNNNWuSiZapiJ1mxOkokJN1SFxIVNqGJ43g4g4AjAIQ83dIS9nDRnhbOwwEBJzggOrGcyxMyfLFEs9FjYjk9hiwLIXQDFpswLfJazaFswfOw4gRzSlZztkPfSnMoy/RzYAGtZIP/OnZImvgwKSmdAZUTx9nne0TCEofzi2WA9JYWK/SuiKGVtBjVr5Lqpptsltc8V7uotAD6r0F09TzohiuHeDGLfK3F52ilm7TeiUjk9a30mQjBpKgQCVBJiEe0JNQFuOLKQwBiykP8ieUAbRtxhRArB5mF2vKQkf0qUki+2KB9SkRGi4/R79ccykqaIslNmKyK0eUbq5aMqPRjLUhY4hCTlkjKkkxaxIhvuNVy3hWj+leEUCotZvSrSMFoaZE7islqGCUrEUmRKiN2lhYWpIGFc0gFiYo1oZIQD2cAgLf7v5H/31z8nhYAnJuDI+AQLA8BbK/wrAcRaWFtwUQahkukEywKAqu9LiQq1oUSljj4/19F+llcvG0xE8t9Qaop/Du6Yn+ZtHVp98ulNWj8CrtCyElb/BL/wk3VHyLUWxLByJWHpfSxCO3THMoWvAahc9ciFZCTQmiBUe+X5+qIeUjZVw0sygHLsCQrANAc5tAc5sw+DUIBJCw8nCHev3mloavbBPpZRIhfT0gqbV1ewe3tQfN+SbYGM2MeYviDWZLFxR/KkiQuappa5UpLsv3F5EjO+flDPUTFRcq5yL3580slZpZBjH5/IYHRQlT4kLRYH5IW60HCEoczyJ+P5ep20ZRFYH4WKbCassTLidBrp3o/uWlLKnFJJgXJUhZAurQokZVkJLsutdKSqqnUbEERw6zz0quXhqVeDdZSjAisnlcESlusBfWw8HAFAHzx+4ffx+LsAsIZke3dQ50BXO1lQXdZyJERQjwdXW7RyePaujyCDbhtXV7B4c3tQY9mo4XUSk7keLGmX7m9Lf5QVtJmXH+oh2hza3MoO2kDa2s4M2lPi1JZERMpvqiIXZfQ9QhdR+Tc4s8/MrcIi2KSCi2HGLOAXYb2ao2VPo+ItLDY38JduQLOobw3kuOs831IBSUsAjh5fiGWsiRDSh+L1ogJiFBiolRW2oOehNKUlLRFqzKRHkmLnrKSbJvYaxjd12ImrCZBSmElbSGUQ2kL25Cw8HAFuBgpEWrAjSClLBTfxyIkLWKlISW9LFqJidB78t83/msp76VVU64R5aFUryVHVvjPCcuMur4Wgi1IWrqxUroSD5WJ2IWEhUf33Cvd0pIsZZHTfCsFLftZtCaZIOmdtog/p420KBEAtTPb6tHXYnXslLIA5kmLlSWBRUhc2IOEhYerM/aHk9+AC6RIWSA+vLmjy837t/RfZmaOGBIq/7R1eaMPsXORmrZIERc9pUXrEUFSh2on21eOtNhRXOxEOictdhMnkhZ2IGGJwxUQLg0lS1kAxJSFUqFFaUgvkolK/LZkx0gpR5kpLVoeJ0dW+MeIlYiEzsnuaYueKUueM2DKTZSlUUSEOihtYQMSFh7OrjBcnVyMtDiD8fvEfu0IOhLKQnKGN/ORUxrSOmURkg4gVkzaujwx5xgvMUqlJZW4GCUtWvatqEmR5Pa12EVc9JAWvqiY9Ze/kdJidrph9vvrDUmLuZCw8HAFODi7hIePxacs3dsSUxZ+WQgQn0BOi9KQVoiJSrysCP9bfYkISH2D11tatJYVoX+Lv766EhFgr7RFK4RunukgLYS+NIc5+ElcTIFpYamqqsKXv/xl5OTkoG/fvvjmN7+JU6dOxezDcRzWrFmDoqIiZGVlYfLkyfj4449VvW+ylMUZiF0YMYJQ861YH8vVbdJLQ0KoTVmklH/iUxWx7VqUiIDkN3i9pEUvWeFvU5oiyZUWq4uLIVP5k7Togt3TFbMId1xBuKNDxcM+66oxLSwHDx7Eww8/jD/+8Y+ora1FMBhEeXk52tuvTq719NNPo7q6Ghs3bsT777+PgoIC3HbbbWhtbZX9fq7OEFydnGhpSOj/R/5KznyEykJqpEXLlEVK+UfoPDq6PNGH0D5api2izym8oYnd5PWWFVnPa9DXAlDaAqS+eWp9c5U6p4xdpYVkhTACpoXl9ddfxwMPPIARI0Zg9OjRePHFF3H+/HnU1dUB6E5XNmzYgMrKStx9990oKSnBSy+9hMuXL2Pnzp2y38/ZGYpKS9L9RFIWAIJlIT5C0qIGuSmL1PIPX0TiJSWyjb9//Oslez+9pEXNYolSX0uprMjZT21fC2DttEVtyiL15qnVTZZ/vlKlRU9xIXkg7ArTwhKP3+8HAPTq1QsAcO7cOTQ2NqK8vDy6j9frxc0334wjR46Ivk5nZydaWlpiHvEoSVnE5mRJtRCiESmLmlQl9mvhIdpKSkRqJpvTQlq0WNBQCXqUiKyatoidn1JpkXuz1uPmLvXc7ZK2kCARRmEZYeE4DkuXLsWkSZNQUlICAGhsbAQA5Ofnx+ybn58ffU6Iqqoq+Hy+6KO4uBgA4AyEYlKWZNKSNGXhITxNv7TSkBBC0pJqcjctUpWOLnf0vOOlRWmJCFC3kKIaadFy+LKcWXzlHCenRARYL22JnJNW5yZ248xzOpKuEaPmhismJ+kmLQRhBJYRlkceeQQffPAB/vM//zPhOYcjbgI3jkvYxmfFihXw+/3RR319fffrdHbB2RmMSotcoinLF2WhZMObpZSG1MyAKyYq3a+rPFUR26a2RJRMXPSQFvHX06YUpEW/TrL3TlYiYj1tkSpQclKWZLIi9G+pxycj1fmZ2ddiVOpB6Yp9qampwcCBA5GZmYnS0lIcOnRI0nF/+MMf4Ha7MWbMmJjte/bsQVlZGfLy8pCdnY0xY8Zg+/btss7JEsKyaNEivPbaa3j77bdx/fXXR7cXFBQAQEKa0tTUlJC68PF6vcjNzY15CCEnZUkY4hxHqrIQoK40FL/WjxBqUhWg+xr41xH/vJoSEZA8bTFCWrSUFf6/tVhnSe41JptszixxSfbeas5Jiqwk25bqdYSQI1Pp3IxLWJPdu3ejoqIClZWVOH78OL761a9i2rRpOH/+fNLj/H4/7rvvPkyZMiXhuV69eqGyshLvvvsuPvjgA8ydOxdz587FG2+8Ifm8mBYWjuPwyCOPYM+ePfj973+PgQMHxjw/cOBAFBQUoLa2NrotEAjg4MGDmDBhguz3c3QGE1IWIWnRCjWlISH0TFX4oiIkLvzX0atEpKe06CErUrbzX09NXwvrZSKl75XqZi9HVqQ9l1palPTXsNCMqzWUrtiX6upqzJs3D/Pnz8fw4cOxYcMGFBcXY9OmTUmPe/DBBzF79myMHz8+4bnJkyfjrrvuwvDhwzF48GAsXrwYo0aNwuHDhyWfl7ZDVjTm4Ycfxs6dO/HrX/8aOTk50STF5/MhKysLDocDFRUVWL9+PYYMGYIhQ4Zg/fr16NGjB2bPni35fTiuW0KCHd1DobmQG1woA+GgC1zQhaDTjTCcCDkdCANAmwOcB+A60f1fD7o/SQ/AeThwLg6chwM8YYQzQghnhOByh3H5MuD1xE6d2wYg0x27LZgR+4ugGUB2RuwUu5fgQM+MzpTXdlUQul+zvSsiGt3HXpWL7q+vBCM/Et0lsc5A7Nd8+NcTfx2tALK+uI748+efezOAHnGNQJ/DiZ5u4Wtrghs+d4foc7muxDkHrsCDXNdlwWMAoCXUA0BQYHsmgK6E7d1ikbi9LehF5HMWItl1RUh2fZHnAci6zg50/wz4nInPXUYGejr1m6ehLSoqqUusYufSDg98AtcLAG5n4kSPPqcDrUj+h4ULEJ38y40rScWhPSS/XAwkvw4+bXBrIgNtYeFJMLVC6LNPF9rauq89cu/QkyC6kOLHOfXxQMLgEq/XC683Ma0PBAKoq6vD8uXLY7aXl5cnHczy4osv4q9//St27NiBJ598Muk5cRyH3//+9zh16hSeeuopqZcCcAyD7m9TwuPFF1+M7hMOh7nVq1dzBQUFnNfr5W666Sbuww8/lPU+9fX1ou9FD3rQgx70oIfQ469//avGd72rdHR0cAUFBZqcZ8+ePRO2rV69WvB9L168yAHg/vCHP8RsX7duHXfjjTcKHnP69Gmub9++3KlTpziO47jVq1dzo0ePTtivubmZy87O5txuN+f1erktW7bI+kyYTlg4CfbqcDiwZs0arFmzRvH7FBUVob6+Hjk5OUmbdbWipaUFxcXFqK+vF+2fsRp2uya7XQ9A12QF7HY9gD2vye/3o1+/ftEpNvQgMzMT586dQyCgPm3jBAaiCKUrfKQOZgmFQpg9ezaeeOIJ3HjjjUlfMycnBydOnEBbWxv279+PpUuXYtCgQZg8ebKk62BaWIzC6XTGNPMaRbKGX6tit2uy2/UAdE1WwG7XA9jzmpxOfdtAMzMzkZlpbJN8nz594HK5JA9maW1txdGjR3H8+HE88sgjAIBwOAyO4+B2u/Hmm2/ia1/7GoDuz+uGG24AAIwZMwYnT55EVVWVZGFhuumWIAiCIAjj8Hg8KC0tjRnMAgC1tbWCg1lyc3Px4Ycf4sSJE9HHggULMHToUJw4cQLjxo0TfS+O49DZmboXMwIlLARBEARBRFm6dCnmzJmDsrIyjB8/Hps3b8b58+exYMECAN1zmV28eBHbtm2D0+mMTuYaoW/fvsjMzIzZXlVVhbKyMgwePBiBQAD79u3Dtm3bUo484kPCYgJerxerV69OWUO0Ena7JrtdD0DXZAXsdj0AXZMVmTVrFj7//HOsXbsWDQ0NKCkpwb59+9C/f38AQENDQ8o5WeJpb2/HwoULceHCBWRlZWHYsGHYsWMHZs2aJfk1HJyUzlaCIAiCIAgToR4WgiAIgiCYh4SFIAiCIAjmIWEhCIIgCIJ5SFgIgiAIgmAeEhaDqKqqiq59FIHjOKxZswZFRUXIysrC5MmT8fHHH5t3khK4ePEivvvd76J3797o0aMHxowZg7q6uujzVrqmYDCIlStXYuDAgcjKysKgQYOwdu1ahHlrsLB+Pe+88w6mT5+OoqIiOBwOvPrqqzHPSzn/zs5OLFq0CH369EF2djZmzJiBCxcuGHgVsSS7pq6uLvzoRz/CyJEjkZ2djaKiItx3333429/+FvMaVrqmeB588EE4HA5s2LAhZjtL1yTlek6ePIkZM2bA5/MhJycHX/nKV2JGlrB0PUDqa2pra8MjjzyC66+/HllZWRg+fHjCkFzWrslukLAYwPvvv4/Nmzdj1KhRMduffvppVFdXY+PGjXj//fdRUFCA2267Da2trSadaXIuXbqEiRMnIiMjA7/73e/wySef4Gc/+xny8vKi+1jpmp566ik8//zz2LhxI06ePImnn34a//f//l8899xz0X1Yv5729naMHj0aGzduFHxeyvlXVFRg79692LVrFw4fPoy2tjbceeedCClc5E8tya7p8uXLOHbsGFatWoVjx45hz549OH36NGbMmBGzn5Wuic+rr76K//mf/0FRUVHCcyxdU6rr+etf/4pJkyZh2LBhOHDgAP70pz9h1apVMbO2snQ9QOprWrJkCV5//XXs2LEDJ0+exJIlS7Bo0SL8+te/ju7D2jXZDlkrDxGyaW1t5YYMGcLV1tZyN998M7d48WKO47oXbSwoKOB+8pOfRPe9cuUK5/P5uOeff96ks03Oj370I27SpEmiz1vtmu644w7ue9/7Xsy2u+++m/vud7/LcZz1rgcAt3fv3ujXUs6/ubmZy8jI4Hbt2hXd5+LFi5zT6eRef/11w85djPhrEuK9997jAHCffvopx3HWvaYLFy5w1113HffRRx9x/fv355555pnocyxfk9D1zJo1K/r/kRAsXw/HCV/TiBEjuLVr18Zs+5d/+Rdu5cqVHMexf012gBIWnXn44Ydxxx134NZbb43Zfu7cOTQ2NqK8vDy6zev14uabb066hLeZvPbaaygrK8O3v/1t9O3bF2PHjsUvf/nL6PNWu6ZJkyZh//79OH36NADgT3/6Ew4fPozbb78dgPWuJx4p519XV4eurq6YfYqKilBSUmKJawS6F6JzOBzRpM+K1xQOhzFnzhwsW7YMI0aMSHjeStcUDofx29/+FjfeeCOmTp2Kvn37Yty4cTElFitdT4RJkybhtddew8WLF8FxHN5++22cPn0aU6dOBWDNa7IaJCw6smvXLhw7dgxVVVUJz0UWlopfTCo/Pz9h0SlWOHv2LDZt2oQhQ4bgjTfewIIFC/Doo49i27ZtAKx3TT/60Y9w7733YtiwYcjIyMDYsWNRUVGBe++9F4D1riceKeff2NgIj8eDa665RnQflrly5QqWL1+O2bNnRxfWs+I1PfXUU3C73Xj00UcFn7fSNTU1NaGtrQ0/+clP8PWvfx1vvvkm7rrrLtx99904ePAgAGtdT4Sf//zn+NKXvoTrr78eHo8HX//611FTU4NJkyYBsOY1WQ2aml8n6uvrsXjxYrz55ptJV9uUuoQ3C4TDYZSVlWH9+vUAgLFjx+Ljjz/Gpk2bcN9990X3s8o17d69Gzt27MDOnTsxYsQInDhxAhUVFSgqKsL9998f3c8q1yOGkvO3wjV2dXXhnnvuQTgcRk1NTcr9Wb2muro6PPvsszh27Jjs82PxmiJN69/4xjewZMkSAN0r8x45cgTPP/88br75ZtFjWbyeCD//+c/xxz/+Ea+99hr69++Pd955BwsXLkRhYWFCgs6H5WuyGpSw6ERdXR2amppQWloKt9sNt9uNgwcP4uc//zncbnf0r16pS3izQGFhIb70pS/FbBs+fHi087+goACAda5p2bJlWL58Oe655x6MHDkSc+bMwZIlS6KJmNWuJx4p519QUIBAIIBLly6J7sMiXV1dmDlzJs6dO4fa2tpougJY75oOHTqEpqYm9OvXL/q74tNPP8Vjjz2GAQMGALDWNfXp0wdutzvl7wqrXA8AdHR04Mc//jGqq6sxffp0jBo1Co888ghmzZqFn/70pwCsd01WhIRFJ6ZMmZKw5HZZWRm+853v4MSJExg0aBAKCgpilvAOBAI4ePCg4BLeLDBx4kScOnUqZtvp06ejC2INHDjQUtd0+fJlOJ2x/wu4XK7oX4hWu554pJx/aWkpMjIyYvZpaGjARx99xOw1RmTlL3/5C9566y307t075nmrXdOcOXPwwQcfxPyuKCoqwrJly/DGG28AsNY1eTwefPnLX076u8JK1wN0/8x1dXUl/X1htWuyJGZ1+6Yj/FFCHMdxP/nJTzifz8ft2bOH+/DDD7l7772XKyws5FpaWsw7ySS89957nNvt5tatW8f95S9/4V5++WWuR48e3I4dO6L7WOma7r//fu66667jfvOb33Dnzp3j9uzZw/Xp04f74Q9/GN2H9etpbW3ljh8/zh0/fpwDwFVXV3PHjx+PjpiRcv4LFizgrr/+eu6tt97ijh07xn3ta1/jRo8ezQWDQeauqauri5sxYwZ3/fXXcydOnOAaGhqij87OTktekxDxo4Q4jq1rSnU9e/bs4TIyMrjNmzdzf/nLX7jnnnuOc7lc3KFDh5i8HinXdPPNN3MjRozg3n77be7s2bPciy++yGVmZnI1NTXMXpPdIGExkHhhCYfD3OrVq7mCggLO6/VyN910E/fhhx+ad4IS+O///m+upKSE83q93LBhw7jNmzfHPG+la2ppaeEWL17M9evXj8vMzOQGDRrEVVZWxtz4WL+et99+mwOQ8Lj//vs5jpN2/h0dHdwjjzzC9erVi8vKyuLuvPNO7vz58yZcTTfJruncuXOCzwHg3n77bUtekxBCwsLSNUm5ni1btnA33HADl5mZyY0ePZp79dVXY16DpevhuNTX1NDQwD3wwANcUVERl5mZyQ0dOpT72c9+xoXD4ehrsHZNdsPBcRynb4ZDEARBEAShDuphIQiCIAiCeUhYCIIgCIJgHhIWgiAIgiCYh4SFIAiCIAjmIWEhCIIgCIJ5SFgIgiAIgmAeEhaCIAiCIJiHhIUgCIIgCOYhYSEIgiAIgnlIWAiCIAiCYB4SFoIgAACTJ0/GokWLUFFRgWuuuQb5+fnYvHkz2tvbMXfuXOTk5GDw4MH43e9+Z/apEgSRhpCwEAQR5aWXXkKfPn3w3nvvYdGiRXjooYfw7W9/GxMmTMCxY8cwdepUzJkzB5cvXzb7VAmCSDNo8UOCIAB0JyyhUAiHDh0CAIRCIfh8Ptx9993Ytm0bAKCxsRGFhYV499138ZWvfMXM0yUIIs2ghIUgiCijRo2K/tvlcqF3794YOXJkdFt+fj4AoKmpyfBzIwgivSFhIQgiSkZGRszXDocjZpvD4QAAhMNhQ8+LIAiChIUgCIIgCOYhYSEIgiAIgnlIWAiCIAiCYB4aJUQQBEEQBPNQwkIQBEEQBPOQsBAEQRAEwTwkLARBEARBMA8JC0EQBEEQzEPCQhAEQRAE85CwEARBEATBPCQsBEEQBEEwDwkLQRAEQRDMQ8JCEARBEATzkLAQBEEQBME8JCwEQRAEQTAPCQtBEARBEMzz/wEr65k+92cCEAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x\n",
    "\n",
    "y = np.linspace(9,180,20)\n",
    "\n",
    "y\n",
    "\n",
    "xx,yy=np.meshgrid(x,y)\n",
    "\n",
    "xx[1:,1:].shape\n",
    "\n",
    "level = 1\n",
    "\n",
    "plt.contourf(xx[level:,level:],yy[level:,level:],R2_mn[level:,level:,0],origin='lower',levels=50)\n",
    "plt.ylabel('n')\n",
    "plt.xlabel('m')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a5a43e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "267f7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy(a,y_train,m0,output):\n",
    "    a=torch.tensor(a)\n",
    "    res = ((a*m0-y_train)**2).mean(axis=1).detach().numpy()\n",
    "    return res[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2ec3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94849362]\n",
      "[1.86849791]\n",
      "[2.06302633]\n",
      "[2.01391448]\n",
      "[1.951214]\n",
      "[2.03817778]\n",
      "[1.98946034]\n",
      "tensor([1.9485, 1.8685, 2.0630, 2.0139, 1.9512, 2.0382, 1.9895],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3734071795.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_adjust = torch.tensor(y_train[b] - a_d*m0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3734071795.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  MSE_a[i,k] += np.sqrt(((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
      "/var/folders/_j/ptyc01811q5b1dg30hshtfzh0000gr/T/ipykernel_80698/3734071795.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  R2_a[i,k] += (1-((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.6333407]\n",
      "[1.95161565]\n",
      "[1.85690151]\n",
      "[1.80652923]\n",
      "[2.11987943]\n",
      "[2.11527699]\n",
      "[1.87578329]\n",
      "tensor([1.6333, 1.9516, 1.8569, 1.8065, 2.1199, 2.1153, 1.8758],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71109401]\n",
      "[1.65325838]\n",
      "[1.48367007]\n",
      "[2.15585139]\n",
      "[1.67386339]\n",
      "[1.85033513]\n",
      "[1.89120167]\n",
      "tensor([1.7111, 1.6533, 1.4837, 2.1559, 1.6739, 1.8503, 1.8912],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9278205]\n",
      "[1.63857024]\n",
      "[2.03488785]\n",
      "[1.82290457]\n",
      "[1.76075296]\n",
      "[1.69335959]\n",
      "[1.87813713]\n",
      "tensor([1.9278, 1.6386, 2.0349, 1.8229, 1.7608, 1.6934, 1.8781],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76872913]\n",
      "[1.82964626]\n",
      "[1.90278219]\n",
      "[1.82648107]\n",
      "[1.92118367]\n",
      "[1.82942708]\n",
      "[1.7664799]\n",
      "tensor([1.7687, 1.8296, 1.9028, 1.8265, 1.9212, 1.8294, 1.7665],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79817707]\n",
      "[2.48228205]\n",
      "[0.95495942]\n",
      "[-0.75051075]\n",
      "[2.23370592]\n",
      "[1.28216465]\n",
      "[2.27724737]\n",
      "tensor([ 1.7982,  2.4823,  0.9550, -0.7505,  2.2337,  1.2822,  2.2772],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86616467]\n",
      "[1.69768259]\n",
      "[2.06396706]\n",
      "[1.86356948]\n",
      "[1.92470058]\n",
      "[1.77085824]\n",
      "[1.77510514]\n",
      "tensor([1.8662, 1.6977, 2.0640, 1.8636, 1.9247, 1.7709, 1.7751],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69816156]\n",
      "[2.22080516]\n",
      "[2.41855445]\n",
      "[1.78638059]\n",
      "[2.15240182]\n",
      "[1.83270878]\n",
      "[1.92040817]\n",
      "tensor([1.6982, 2.2208, 2.4186, 1.7864, 2.1524, 1.8327, 1.9204],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.64104487]\n",
      "[1.8515663]\n",
      "[1.69005744]\n",
      "[1.69879224]\n",
      "[1.85552996]\n",
      "[1.93107488]\n",
      "[1.81768828]\n",
      "tensor([1.6410, 1.8516, 1.6901, 1.6988, 1.8555, 1.9311, 1.8177],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.30406218]\n",
      "[1.99297353]\n",
      "[2.02885379]\n",
      "[1.82180501]\n",
      "[2.06349497]\n",
      "[1.92998428]\n",
      "[1.77102605]\n",
      "tensor([2.3041, 1.9930, 2.0289, 1.8218, 2.0635, 1.9300, 1.7710],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.32895479]\n",
      "[1.83880465]\n",
      "[1.93002169]\n",
      "[1.66847754]\n",
      "[1.66639679]\n",
      "[1.43254988]\n",
      "[1.78266346]\n",
      "tensor([1.3290, 1.8388, 1.9300, 1.6685, 1.6664, 1.4325, 1.7827],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89998777]\n",
      "[1.56554899]\n",
      "[2.04338893]\n",
      "[1.65122224]\n",
      "[1.75665725]\n",
      "[1.60795731]\n",
      "[1.86426189]\n",
      "tensor([1.9000, 1.5655, 2.0434, 1.6512, 1.7567, 1.6080, 1.8643],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75839512]\n",
      "[1.95353191]\n",
      "[1.58372525]\n",
      "[1.83823854]\n",
      "[1.98185621]\n",
      "[1.9272911]\n",
      "[1.77550122]\n",
      "tensor([1.7584, 1.9535, 1.5837, 1.8382, 1.9819, 1.9273, 1.7755],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75988122]\n",
      "[1.92788299]\n",
      "[1.74144226]\n",
      "[1.97390344]\n",
      "[1.87432945]\n",
      "[1.5822912]\n",
      "[1.75982595]\n",
      "tensor([1.7599, 1.9279, 1.7414, 1.9739, 1.8743, 1.5823, 1.7598],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81878576]\n",
      "[1.68938339]\n",
      "[1.95646061]\n",
      "[2.09697843]\n",
      "[1.98283048]\n",
      "[1.79141968]\n",
      "[2.08932557]\n",
      "tensor([1.8188, 1.6894, 1.9565, 2.0970, 1.9828, 1.7914, 2.0893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96811563]\n",
      "[1.64813688]\n",
      "[2.5323149]\n",
      "[1.5420198]\n",
      "[2.36272649]\n",
      "[2.32745973]\n",
      "[1.59479606]\n",
      "tensor([1.9681, 1.6481, 2.5323, 1.5420, 2.3627, 2.3275, 1.5948],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.44665595]\n",
      "[1.70758114]\n",
      "[1.60443051]\n",
      "[1.57101559]\n",
      "[1.9805041]\n",
      "[1.3863031]\n",
      "[1.57088885]\n",
      "tensor([1.4467, 1.7076, 1.6044, 1.5710, 1.9805, 1.3863, 1.5709],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8519244]\n",
      "[1.74613848]\n",
      "[2.12009813]\n",
      "[2.05913942]\n",
      "[2.38651872]\n",
      "[2.11484703]\n",
      "[1.8699885]\n",
      "tensor([1.8519, 1.7461, 2.1201, 2.0591, 2.3865, 2.1148, 1.8700],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.18545099]\n",
      "[1.37509942]\n",
      "[1.59438887]\n",
      "[0.97510462]\n",
      "[2.14531193]\n",
      "[1.42776012]\n",
      "[1.26154968]\n",
      "tensor([1.1855, 1.3751, 1.5944, 0.9751, 2.1453, 1.4278, 1.2615],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.10241085]\n",
      "[1.84258909]\n",
      "[1.66389344]\n",
      "[1.88202334]\n",
      "[1.8646015]\n",
      "[1.90238786]\n",
      "[1.97277713]\n",
      "tensor([2.1024, 1.8426, 1.6639, 1.8820, 1.8646, 1.9024, 1.9728],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94937187]\n",
      "[1.80647796]\n",
      "[1.70768919]\n",
      "[1.95229043]\n",
      "[1.6856563]\n",
      "[2.09928887]\n",
      "[1.83018066]\n",
      "tensor([1.9494, 1.8065, 1.7077, 1.9523, 1.6857, 2.0993, 1.8302],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94039275]\n",
      "[2.0694544]\n",
      "[1.806371]\n",
      "[1.96999565]\n",
      "[1.73928792]\n",
      "[1.83982063]\n",
      "[1.75124062]\n",
      "tensor([1.9404, 2.0695, 1.8064, 1.9700, 1.7393, 1.8398, 1.7512],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72916706]\n",
      "[1.56571808]\n",
      "[2.31060625]\n",
      "[2.66894137]\n",
      "[2.61906214]\n",
      "[1.93520098]\n",
      "[2.62923694]\n",
      "tensor([1.7292, 1.5657, 2.3106, 2.6689, 2.6191, 1.9352, 2.6292],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7389247]\n",
      "[2.34177389]\n",
      "[2.12706642]\n",
      "[1.76390185]\n",
      "[1.57736709]\n",
      "[1.67459572]\n",
      "[1.50900429]\n",
      "tensor([1.7389, 2.3418, 2.1271, 1.7639, 1.5774, 1.6746, 1.5090],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.35146877]\n",
      "[2.03539087]\n",
      "[1.84967049]\n",
      "[1.95406612]\n",
      "[1.78060425]\n",
      "[2.94864517]\n",
      "[2.01791084]\n",
      "tensor([2.3515, 2.0354, 1.8497, 1.9541, 1.7806, 2.9486, 2.0179],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93430403]\n",
      "[1.99843726]\n",
      "[2.19544224]\n",
      "[1.73377259]\n",
      "[1.56978017]\n",
      "[1.62286499]\n",
      "[1.65595742]\n",
      "tensor([1.9343, 1.9984, 2.1954, 1.7338, 1.5698, 1.6229, 1.6560],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.51488575]\n",
      "[3.08788174]\n",
      "[2.67337923]\n",
      "[1.95443225]\n",
      "[1.48922948]\n",
      "[4.71035738]\n",
      "[2.06446998]\n",
      "tensor([1.5149, 3.0879, 2.6734, 1.9544, 1.4892, 4.7104, 2.0645],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.07126683]\n",
      "[1.88997959]\n",
      "[2.35788502]\n",
      "[1.74409148]\n",
      "[2.15636879]\n",
      "[1.77656389]\n",
      "[1.72575428]\n",
      "tensor([2.0713, 1.8900, 2.3579, 1.7441, 2.1564, 1.7766, 1.7258],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.98422467]\n",
      "[-0.91783066]\n",
      "[-1.07779179]\n",
      "[1.86992472]\n",
      "[2.41024052]\n",
      "[3.18251905]\n",
      "[2.17957187]\n",
      "tensor([ 2.9842, -0.9178, -1.0778,  1.8699,  2.4102,  3.1825,  2.1796],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.18754198]\n",
      "[1.79348202]\n",
      "[2.48329609]\n",
      "[1.84569259]\n",
      "[1.66838439]\n",
      "[1.66399543]\n",
      "[2.2547267]\n",
      "tensor([2.1875, 1.7935, 2.4833, 1.8457, 1.6684, 1.6640, 2.2547],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.09393725]\n",
      "[1.97726227]\n",
      "[1.68785485]\n",
      "[1.99713041]\n",
      "[2.16326681]\n",
      "[1.73945501]\n",
      "[1.71761712]\n",
      "tensor([2.0939, 1.9773, 1.6879, 1.9971, 2.1633, 1.7395, 1.7176],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[4.03959868]\n",
      "[2.12092423]\n",
      "[2.24633642]\n",
      "[2.29176605]\n",
      "[1.84170702]\n",
      "[2.08823744]\n",
      "[2.47755977]\n",
      "tensor([4.0396, 2.1209, 2.2463, 2.2918, 1.8417, 2.0882, 2.4776],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.64812956]\n",
      "[2.15059765]\n",
      "[1.83914434]\n",
      "[2.12449397]\n",
      "[1.50400866]\n",
      "[2.50757041]\n",
      "[1.60460333]\n",
      "tensor([1.6481, 2.1506, 1.8391, 2.1245, 1.5040, 2.5076, 1.6046],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[4.59331877]\n",
      "[1.62323549]\n",
      "[2.26373087]\n",
      "[1.75223681]\n",
      "[-1.82803164]\n",
      "[2.48552815]\n",
      "[3.45044825]\n",
      "tensor([ 4.5933,  1.6232,  2.2637,  1.7522, -1.8280,  2.4855,  3.4504],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.55498039]\n",
      "[1.49735066]\n",
      "[1.50503505]\n",
      "[1.52205155]\n",
      "[1.3300857]\n",
      "[1.52449222]\n",
      "[2.06134239]\n",
      "tensor([2.5550, 1.4974, 1.5050, 1.5221, 1.3301, 1.5245, 2.0613],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76002226]\n",
      "[2.04144311]\n",
      "[1.77525803]\n",
      "[1.68897895]\n",
      "[1.81507773]\n",
      "[1.94592693]\n",
      "[1.73488367]\n",
      "tensor([1.7600, 2.0414, 1.7753, 1.6890, 1.8151, 1.9459, 1.7349],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89890124]\n",
      "[1.84674399]\n",
      "[1.86604777]\n",
      "[1.66747225]\n",
      "[1.78832229]\n",
      "[1.68666469]\n",
      "[1.83061703]\n",
      "tensor([1.8989, 1.8467, 1.8660, 1.6675, 1.7883, 1.6867, 1.8306],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69484073]\n",
      "[1.6892022]\n",
      "[1.63364771]\n",
      "[1.78627025]\n",
      "[1.96901172]\n",
      "[1.81932849]\n",
      "[1.98934644]\n",
      "tensor([1.6948, 1.6892, 1.6336, 1.7863, 1.9690, 1.8193, 1.9893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.20278498]\n",
      "[1.85776166]\n",
      "[1.75037392]\n",
      "[1.7434516]\n",
      "[2.07693985]\n",
      "[1.76190236]\n",
      "[1.53590738]\n",
      "tensor([2.2028, 1.8578, 1.7504, 1.7435, 2.0769, 1.7619, 1.5359],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86339598]\n",
      "[1.86696739]\n",
      "[1.97659915]\n",
      "[1.72238167]\n",
      "[1.85524685]\n",
      "[1.9120975]\n",
      "[1.78420237]\n",
      "tensor([1.8634, 1.8670, 1.9766, 1.7224, 1.8552, 1.9121, 1.7842],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.24406877]\n",
      "[1.90602301]\n",
      "[3.11334953]\n",
      "[2.74972851]\n",
      "[2.24406705]\n",
      "[3.1079719]\n",
      "[2.24763439]\n",
      "tensor([2.2441, 1.9060, 3.1133, 2.7497, 2.2441, 3.1080, 2.2476],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.06689711]\n",
      "[1.90882535]\n",
      "[1.72883484]\n",
      "[2.02393171]\n",
      "[1.74600008]\n",
      "[1.82606517]\n",
      "[1.80759048]\n",
      "tensor([2.0669, 1.9088, 1.7288, 2.0239, 1.7460, 1.8261, 1.8076],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89896133]\n",
      "[2.02208695]\n",
      "[1.88543708]\n",
      "[1.9203021]\n",
      "[2.01186383]\n",
      "[2.05320069]\n",
      "[1.72755156]\n",
      "tensor([1.8990, 2.0221, 1.8854, 1.9203, 2.0119, 2.0532, 1.7276],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81500362]\n",
      "[1.59777787]\n",
      "[1.81582255]\n",
      "[1.83411427]\n",
      "[1.85914131]\n",
      "[1.64363222]\n",
      "[1.71469231]\n",
      "tensor([1.8150, 1.5978, 1.8158, 1.8341, 1.8591, 1.6436, 1.7147],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.67772429]\n",
      "[1.97879149]\n",
      "[3.41951436]\n",
      "[2.9373727]\n",
      "[2.24102548]\n",
      "[1.49552132]\n",
      "[1.85173925]\n",
      "tensor([2.6777, 1.9788, 3.4195, 2.9374, 2.2410, 1.4955, 1.8517],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[3.1618324]\n",
      "[1.73183672]\n",
      "[1.4608695]\n",
      "[4.15564418]\n",
      "[1.69286503]\n",
      "[3.99135141]\n",
      "[2.17799461]\n",
      "tensor([3.1618, 1.7318, 1.4609, 4.1556, 1.6929, 3.9914, 2.1780],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.57824242]\n",
      "[1.69992527]\n",
      "[1.59725275]\n",
      "[1.71575339]\n",
      "[1.75486388]\n",
      "[1.84694394]\n",
      "[1.76925296]\n",
      "tensor([1.5782, 1.6999, 1.5973, 1.7158, 1.7549, 1.8469, 1.7693],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.55299448]\n",
      "[1.88331755]\n",
      "[1.82114507]\n",
      "[1.5998369]\n",
      "[1.88662023]\n",
      "[2.26375608]\n",
      "[2.4202013]\n",
      "tensor([1.5530, 1.8833, 1.8211, 1.5998, 1.8866, 2.2638, 2.4202],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86916058]\n",
      "[1.95194026]\n",
      "[1.83554063]\n",
      "[1.86277404]\n",
      "[1.6741429]\n",
      "[1.71358299]\n",
      "[1.59134103]\n",
      "tensor([1.8692, 1.9519, 1.8355, 1.8628, 1.6741, 1.7136, 1.5913],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80650504]\n",
      "[1.93305259]\n",
      "[2.25277157]\n",
      "[1.80886756]\n",
      "[1.82310258]\n",
      "[1.91084626]\n",
      "[1.71142194]\n",
      "tensor([1.8065, 1.9331, 2.2528, 1.8089, 1.8231, 1.9108, 1.7114],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.04589751]\n",
      "[2.10833704]\n",
      "[1.74494238]\n",
      "[1.9292906]\n",
      "[1.96499708]\n",
      "[1.68571037]\n",
      "[1.70177544]\n",
      "tensor([2.0459, 2.1083, 1.7449, 1.9293, 1.9650, 1.6857, 1.7018],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.09105931]\n",
      "[1.7990678]\n",
      "[2.06362231]\n",
      "[3.31180153]\n",
      "[1.89623384]\n",
      "[2.40832741]\n",
      "[2.32128806]\n",
      "tensor([2.0911, 1.7991, 2.0636, 3.3118, 1.8962, 2.4083, 2.3213],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.62975019]\n",
      "[1.97799328]\n",
      "[1.74916465]\n",
      "[1.60620356]\n",
      "[1.49292632]\n",
      "[1.50393015]\n",
      "[1.47092656]\n",
      "tensor([1.6298, 1.9780, 1.7492, 1.6062, 1.4929, 1.5039, 1.4709],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71277802]\n",
      "[2.13201507]\n",
      "[1.93278961]\n",
      "[1.81138776]\n",
      "[2.10836841]\n",
      "[2.03952511]\n",
      "[1.76320377]\n",
      "tensor([1.7128, 2.1320, 1.9328, 1.8114, 2.1084, 2.0395, 1.7632],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.60838922]\n",
      "[1.43499729]\n",
      "[5.94871488]\n",
      "[2.58182093]\n",
      "[3.39490902]\n",
      "[2.27317989]\n",
      "[1.27943199]\n",
      "tensor([1.6084, 1.4350, 5.9487, 2.5818, 3.3949, 2.2732, 1.2794],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.39935571]\n",
      "[1.49749313]\n",
      "[1.66379421]\n",
      "[1.38488235]\n",
      "[2.39794109]\n",
      "[1.67252164]\n",
      "[0.99278991]\n",
      "tensor([1.3994, 1.4975, 1.6638, 1.3849, 2.3979, 1.6725, 0.9928],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91992196]\n",
      "[2.11280366]\n",
      "[1.57883751]\n",
      "[2.66498369]\n",
      "[1.87743484]\n",
      "[1.59156476]\n",
      "[1.52007213]\n",
      "tensor([1.9199, 2.1128, 1.5788, 2.6650, 1.8774, 1.5916, 1.5201],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86535744]\n",
      "[1.75567538]\n",
      "[1.85496337]\n",
      "[2.33352426]\n",
      "[1.92880931]\n",
      "[2.04841057]\n",
      "[2.31691718]\n",
      "tensor([1.8654, 1.7557, 1.8550, 2.3335, 1.9288, 2.0484, 2.3169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72430664]\n",
      "[1.76506448]\n",
      "[1.94960765]\n",
      "[1.66856763]\n",
      "[1.89605722]\n",
      "[1.96524058]\n",
      "[1.50254504]\n",
      "tensor([1.7243, 1.7651, 1.9496, 1.6686, 1.8961, 1.9652, 1.5025],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82437357]\n",
      "[2.23325819]\n",
      "[1.93722711]\n",
      "[2.100542]\n",
      "[1.68326206]\n",
      "[1.98903334]\n",
      "[1.7805487]\n",
      "tensor([1.8244, 2.2333, 1.9372, 2.1005, 1.6833, 1.9890, 1.7805],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.6564063]\n",
      "[1.75520971]\n",
      "[1.6718326]\n",
      "[1.53656019]\n",
      "[1.74916347]\n",
      "[1.91856267]\n",
      "[1.91926787]\n",
      "tensor([1.6564, 1.7552, 1.6718, 1.5366, 1.7492, 1.9186, 1.9193],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77891462]\n",
      "[2.98358449]\n",
      "[1.86749971]\n",
      "[2.15592481]\n",
      "[1.70507799]\n",
      "[2.24359179]\n",
      "[2.31384964]\n",
      "tensor([1.7789, 2.9836, 1.8675, 2.1559, 1.7051, 2.2436, 2.3138],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71499863]\n",
      "[2.24571326]\n",
      "[1.79744651]\n",
      "[1.82880177]\n",
      "[1.89210764]\n",
      "[1.78979305]\n",
      "[2.02716565]\n",
      "tensor([1.7150, 2.2457, 1.7974, 1.8288, 1.8921, 1.7898, 2.0272],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74267671]\n",
      "[2.00353386]\n",
      "[1.85514135]\n",
      "[1.80732384]\n",
      "[1.81321291]\n",
      "[2.10461272]\n",
      "[1.74145387]\n",
      "tensor([1.7427, 2.0035, 1.8551, 1.8073, 1.8132, 2.1046, 1.7415],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.50416755]\n",
      "[1.6538963]\n",
      "[1.84526745]\n",
      "[1.74265739]\n",
      "[1.60381616]\n",
      "[2.09994812]\n",
      "[1.78088613]\n",
      "tensor([1.5042, 1.6539, 1.8453, 1.7427, 1.6038, 2.0999, 1.7809],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88666121]\n",
      "[1.86695361]\n",
      "[2.06848782]\n",
      "[1.87388819]\n",
      "[1.79998201]\n",
      "[2.01656146]\n",
      "[1.74862028]\n",
      "tensor([1.8867, 1.8670, 2.0685, 1.8739, 1.8000, 2.0166, 1.7486],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.68591001]\n",
      "[2.00173618]\n",
      "[1.97166349]\n",
      "[1.98115348]\n",
      "[2.09846563]\n",
      "[2.02438676]\n",
      "[1.84676376]\n",
      "tensor([1.6859, 2.0017, 1.9717, 1.9812, 2.0985, 2.0244, 1.8468],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.58912612]\n",
      "[1.67767437]\n",
      "[1.93532947]\n",
      "[1.48439211]\n",
      "[1.87740494]\n",
      "[1.76292997]\n",
      "[1.87244478]\n",
      "tensor([1.5891, 1.6777, 1.9353, 1.4844, 1.8774, 1.7629, 1.8724],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71963692]\n",
      "[1.79230283]\n",
      "[2.00054198]\n",
      "[1.88045683]\n",
      "[1.88301902]\n",
      "[1.84466376]\n",
      "[1.96658995]\n",
      "tensor([1.7196, 1.7923, 2.0005, 1.8805, 1.8830, 1.8447, 1.9666],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9321874]\n",
      "[1.7540661]\n",
      "[1.80717519]\n",
      "[1.81112357]\n",
      "[1.77187877]\n",
      "[1.96932002]\n",
      "[1.97332452]\n",
      "tensor([1.9322, 1.7541, 1.8072, 1.8111, 1.7719, 1.9693, 1.9733],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.40080408]\n",
      "[1.83528123]\n",
      "[1.79554631]\n",
      "[1.97674811]\n",
      "[2.12842935]\n",
      "[1.13422784]\n",
      "[1.70323997]\n",
      "tensor([2.4008, 1.8353, 1.7955, 1.9767, 2.1284, 1.1342, 1.7032],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.10320638]\n",
      "[2.22977625]\n",
      "[2.54517218]\n",
      "[2.35846069]\n",
      "[2.05680838]\n",
      "[1.71544666]\n",
      "[2.43651206]\n",
      "tensor([2.1032, 2.2298, 2.5452, 2.3585, 2.0568, 1.7154, 2.4365],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83188421]\n",
      "[1.88608631]\n",
      "[1.94036522]\n",
      "[1.71751693]\n",
      "[1.86776648]\n",
      "[1.55684605]\n",
      "[1.79605325]\n",
      "tensor([1.8319, 1.8861, 1.9404, 1.7175, 1.8678, 1.5568, 1.7961],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.3175734]\n",
      "[2.43765837]\n",
      "[1.51293989]\n",
      "[1.11090748]\n",
      "[1.24386953]\n",
      "[1.88917309]\n",
      "[2.19380264]\n",
      "tensor([1.3176, 2.4377, 1.5129, 1.1109, 1.2439, 1.8892, 2.1938],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.01674684]\n",
      "[1.33565513]\n",
      "[1.48000067]\n",
      "[2.39524517]\n",
      "[1.2670491]\n",
      "[1.24262392]\n",
      "[1.43695787]\n",
      "tensor([2.0167, 1.3357, 1.4800, 2.3952, 1.2670, 1.2426, 1.4370],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.12471679]\n",
      "[2.00332627]\n",
      "[1.26531458]\n",
      "[1.50915885]\n",
      "[1.98158401]\n",
      "[2.22444315]\n",
      "[1.16168491]\n",
      "tensor([2.1247, 2.0033, 1.2653, 1.5092, 1.9816, 2.2244, 1.1617],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83258322]\n",
      "[1.71545561]\n",
      "[1.8361668]\n",
      "[1.68039305]\n",
      "[1.55671119]\n",
      "[1.66559423]\n",
      "[1.66968953]\n",
      "tensor([1.8326, 1.7155, 1.8362, 1.6804, 1.5567, 1.6656, 1.6697],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.44419153]\n",
      "[1.47967693]\n",
      "[2.19439512]\n",
      "[1.85190696]\n",
      "[1.88765328]\n",
      "[2.54940329]\n",
      "[2.1371319]\n",
      "tensor([1.4442, 1.4797, 2.1944, 1.8519, 1.8877, 2.5494, 2.1371],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.47607781]\n",
      "[1.80985805]\n",
      "[2.04236724]\n",
      "[1.79333427]\n",
      "[1.83759646]\n",
      "[2.29258966]\n",
      "[1.9024846]\n",
      "tensor([1.4761, 1.8099, 2.0424, 1.7933, 1.8376, 2.2926, 1.9025],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.68945468]\n",
      "[2.06362156]\n",
      "[2.00928198]\n",
      "[1.56115112]\n",
      "[1.81646019]\n",
      "[1.66704395]\n",
      "[1.52750958]\n",
      "tensor([1.6895, 2.0636, 2.0093, 1.5612, 1.8165, 1.6670, 1.5275],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82539444]\n",
      "[1.88731472]\n",
      "[1.77762802]\n",
      "[1.92777153]\n",
      "[1.87379789]\n",
      "[1.76488193]\n",
      "[1.7902706]\n",
      "tensor([1.8254, 1.8873, 1.7776, 1.9278, 1.8738, 1.7649, 1.7903],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.40812141]\n",
      "[1.77294042]\n",
      "[1.23377412]\n",
      "[1.37601544]\n",
      "[1.51182231]\n",
      "[3.00211371]\n",
      "[1.34403441]\n",
      "tensor([1.4081, 1.7729, 1.2338, 1.3760, 1.5118, 3.0021, 1.3440],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.56713682]\n",
      "[1.620003]\n",
      "[1.8025138]\n",
      "[1.53091483]\n",
      "[1.9450743]\n",
      "[1.63107999]\n",
      "[1.71737266]\n",
      "tensor([1.5671, 1.6200, 1.8025, 1.5309, 1.9451, 1.6311, 1.7174],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.34818993]\n",
      "[4.10635804]\n",
      "[1.75037987]\n",
      "[2.0391709]\n",
      "[1.3612556]\n",
      "[1.28605136]\n",
      "[1.61689658]\n",
      "tensor([1.3482, 4.1064, 1.7504, 2.0392, 1.3613, 1.2861, 1.6169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.06727983]\n",
      "[1.9264791]\n",
      "[1.92576783]\n",
      "[1.90174935]\n",
      "[1.78033817]\n",
      "[1.87651549]\n",
      "[1.76085483]\n",
      "tensor([2.0673, 1.9265, 1.9258, 1.9017, 1.7803, 1.8765, 1.7609],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70987056]\n",
      "[1.87691893]\n",
      "[1.98629409]\n",
      "[1.91012859]\n",
      "[1.41483488]\n",
      "[1.60343771]\n",
      "[1.54524015]\n",
      "tensor([1.7099, 1.8769, 1.9863, 1.9101, 1.4148, 1.6034, 1.5452],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9204902]\n",
      "[1.82981225]\n",
      "[1.68609655]\n",
      "[1.89385495]\n",
      "[1.85755363]\n",
      "[1.75036516]\n",
      "[1.97141739]\n",
      "tensor([1.9205, 1.8298, 1.6861, 1.8939, 1.8576, 1.7504, 1.9714],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9211843]\n",
      "[1.86602238]\n",
      "[1.81035054]\n",
      "[1.80194617]\n",
      "[1.92645927]\n",
      "[1.74032711]\n",
      "[1.81808146]\n",
      "tensor([1.9212, 1.8660, 1.8104, 1.8019, 1.9265, 1.7403, 1.8181],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91245912]\n",
      "[1.75788349]\n",
      "[1.88138155]\n",
      "[1.79008303]\n",
      "[1.78543414]\n",
      "[2.02308713]\n",
      "[2.33299198]\n",
      "tensor([1.9125, 1.7579, 1.8814, 1.7901, 1.7854, 2.0231, 2.3330],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.13054094]\n",
      "[2.09269972]\n",
      "[1.79967147]\n",
      "[1.48074191]\n",
      "[1.81356676]\n",
      "[1.87096536]\n",
      "[1.80109618]\n",
      "tensor([2.1305, 2.0927, 1.7997, 1.4807, 1.8136, 1.8710, 1.8011],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74693407]\n",
      "[1.78325763]\n",
      "[1.72326721]\n",
      "[1.7702392]\n",
      "[1.7077069]\n",
      "[2.0383655]\n",
      "[1.7114558]\n",
      "tensor([1.7469, 1.7833, 1.7233, 1.7702, 1.7077, 2.0384, 1.7115],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75194874]\n",
      "[1.79885584]\n",
      "[1.84288485]\n",
      "[1.61026472]\n",
      "[1.88333442]\n",
      "[1.85140889]\n",
      "[1.78854823]\n",
      "tensor([1.7519, 1.7989, 1.8429, 1.6103, 1.8833, 1.8514, 1.7885],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69956785]\n",
      "[1.90745112]\n",
      "[1.84194087]\n",
      "[1.73064325]\n",
      "[1.77974759]\n",
      "[1.67132888]\n",
      "[1.81856587]\n",
      "tensor([1.6996, 1.9075, 1.8419, 1.7306, 1.7797, 1.6713, 1.8186],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81804945]\n",
      "[1.92440091]\n",
      "[1.75955157]\n",
      "[1.7432493]\n",
      "[1.74780974]\n",
      "[1.92221466]\n",
      "[1.7495215]\n",
      "tensor([1.8180, 1.9244, 1.7596, 1.7432, 1.7478, 1.9222, 1.7495],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77890581]\n",
      "[1.8963432]\n",
      "[2.02605548]\n",
      "[1.84079492]\n",
      "[2.0032365]\n",
      "[1.86292646]\n",
      "[1.79388925]\n",
      "tensor([1.7789, 1.8963, 2.0261, 1.8408, 2.0032, 1.8629, 1.7939],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82535338]\n",
      "[1.8951137]\n",
      "[1.97644688]\n",
      "[1.74778985]\n",
      "[1.81667258]\n",
      "[1.90996509]\n",
      "[1.86969749]\n",
      "tensor([1.8254, 1.8951, 1.9764, 1.7478, 1.8167, 1.9100, 1.8697],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.6944235]\n",
      "[2.12940438]\n",
      "[1.67563694]\n",
      "[1.89511964]\n",
      "[1.71908798]\n",
      "[1.56350481]\n",
      "[1.91399563]\n",
      "tensor([1.6944, 2.1294, 1.6756, 1.8951, 1.7191, 1.5635, 1.9140],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69735119]\n",
      "[1.78088045]\n",
      "[2.41238]\n",
      "[2.03828278]\n",
      "[1.82810205]\n",
      "[1.84106489]\n",
      "[2.11571727]\n",
      "tensor([1.6974, 1.7809, 2.4124, 2.0383, 1.8281, 1.8411, 2.1157],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80946174]\n",
      "[1.87642418]\n",
      "[1.75027203]\n",
      "[1.74024515]\n",
      "[1.76671666]\n",
      "[1.74435096]\n",
      "[1.75617733]\n",
      "tensor([1.8095, 1.8764, 1.7503, 1.7402, 1.7667, 1.7444, 1.7562],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77649388]\n",
      "[1.88028787]\n",
      "[2.1880753]\n",
      "[1.73206886]\n",
      "[1.86408385]\n",
      "[2.06914625]\n",
      "[1.86353527]\n",
      "tensor([1.7765, 1.8803, 2.1881, 1.7321, 1.8641, 2.0691, 1.8635],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90943035]\n",
      "[1.7708256]\n",
      "[1.77740338]\n",
      "[1.81198577]\n",
      "[1.92430443]\n",
      "[1.79565296]\n",
      "[1.86144578]\n",
      "tensor([1.9094, 1.7708, 1.7774, 1.8120, 1.9243, 1.7957, 1.8614],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.02677768]\n",
      "[1.86891031]\n",
      "[1.78171557]\n",
      "[1.9049551]\n",
      "[1.83090697]\n",
      "[1.85999695]\n",
      "[1.89443691]\n",
      "tensor([2.0268, 1.8689, 1.7817, 1.9050, 1.8309, 1.8600, 1.8944],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88611919]\n",
      "[1.79710083]\n",
      "[1.86604509]\n",
      "[1.95187588]\n",
      "[1.95829165]\n",
      "[1.75911642]\n",
      "[1.7949897]\n",
      "tensor([1.8861, 1.7971, 1.8660, 1.9519, 1.9583, 1.7591, 1.7950],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71402218]\n",
      "[1.70966604]\n",
      "[1.63609027]\n",
      "[1.94960103]\n",
      "[1.89196535]\n",
      "[1.78254537]\n",
      "[1.90196467]\n",
      "tensor([1.7140, 1.7097, 1.6361, 1.9496, 1.8920, 1.7825, 1.9020],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87911038]\n",
      "[1.87555481]\n",
      "[1.90494305]\n",
      "[1.82857184]\n",
      "[2.01017947]\n",
      "[1.9619537]\n",
      "[1.77571018]\n",
      "tensor([1.8791, 1.8756, 1.9049, 1.8286, 2.0102, 1.9620, 1.7757],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82722278]\n",
      "[1.78158314]\n",
      "[1.76041836]\n",
      "[1.87896089]\n",
      "[1.7398858]\n",
      "[1.86069056]\n",
      "[1.96000221]\n",
      "tensor([1.8272, 1.7816, 1.7604, 1.8790, 1.7399, 1.8607, 1.9600],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78412489]\n",
      "[1.86795767]\n",
      "[1.88721094]\n",
      "[1.81385162]\n",
      "[1.84308915]\n",
      "[1.85879984]\n",
      "[1.91859224]\n",
      "tensor([1.7841, 1.8680, 1.8872, 1.8139, 1.8431, 1.8588, 1.9186],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88244887]\n",
      "[1.8127095]\n",
      "[1.86810794]\n",
      "[1.7814945]\n",
      "[1.97254338]\n",
      "[1.68229883]\n",
      "[2.0568966]\n",
      "tensor([1.8824, 1.8127, 1.8681, 1.7815, 1.9725, 1.6823, 2.0569],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73527676]\n",
      "[1.85457067]\n",
      "[1.71561127]\n",
      "[1.68468789]\n",
      "[1.74260224]\n",
      "[1.81204724]\n",
      "[2.1139114]\n",
      "tensor([1.7353, 1.8546, 1.7156, 1.6847, 1.7426, 1.8120, 2.1139],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83492742]\n",
      "[1.82742736]\n",
      "[1.73520283]\n",
      "[2.04952592]\n",
      "[1.77549089]\n",
      "[1.72889845]\n",
      "[1.80589669]\n",
      "tensor([1.8349, 1.8274, 1.7352, 2.0495, 1.7755, 1.7289, 1.8059],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9246956]\n",
      "[1.84519273]\n",
      "[1.79015858]\n",
      "[1.76400161]\n",
      "[1.86984116]\n",
      "[1.78957404]\n",
      "[1.84203613]\n",
      "tensor([1.9247, 1.8452, 1.7902, 1.7640, 1.8698, 1.7896, 1.8420],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87757651]\n",
      "[2.01289369]\n",
      "[1.68156503]\n",
      "[2.00637433]\n",
      "[1.81579878]\n",
      "[1.79541833]\n",
      "[1.89044034]\n",
      "tensor([1.8776, 2.0129, 1.6816, 2.0064, 1.8158, 1.7954, 1.8904],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84477613]\n",
      "[1.82438371]\n",
      "[1.85648489]\n",
      "[1.81122513]\n",
      "[1.90628982]\n",
      "[2.08331997]\n",
      "[1.80142969]\n",
      "tensor([1.8448, 1.8244, 1.8565, 1.8112, 1.9063, 2.0833, 1.8014],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83689881]\n",
      "[1.90669771]\n",
      "[1.83191078]\n",
      "[1.86179978]\n",
      "[1.94423936]\n",
      "[1.91507871]\n",
      "[1.85672408]\n",
      "tensor([1.8369, 1.9067, 1.8319, 1.8618, 1.9442, 1.9151, 1.8567],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82824841]\n",
      "[1.90154122]\n",
      "[1.82218645]\n",
      "[1.73628544]\n",
      "[1.74429675]\n",
      "[1.91094075]\n",
      "[1.81686813]\n",
      "tensor([1.8282, 1.9015, 1.8222, 1.7363, 1.7443, 1.9109, 1.8169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.64001892]\n",
      "[1.78650312]\n",
      "[1.71734775]\n",
      "[1.69134465]\n",
      "[1.81335968]\n",
      "[1.72324228]\n",
      "[1.78825051]\n",
      "tensor([1.6400, 1.7865, 1.7173, 1.6913, 1.8134, 1.7232, 1.7883],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70494016]\n",
      "[1.73468398]\n",
      "[1.84651894]\n",
      "[1.81595496]\n",
      "[1.80126898]\n",
      "[1.96679022]\n",
      "[1.81213603]\n",
      "tensor([1.7049, 1.7347, 1.8465, 1.8160, 1.8013, 1.9668, 1.8121],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72472661]\n",
      "[1.76367375]\n",
      "[1.93435178]\n",
      "[1.87278626]\n",
      "[1.83722095]\n",
      "[1.86230174]\n",
      "[1.71173788]\n",
      "tensor([1.7247, 1.7637, 1.9344, 1.8728, 1.8372, 1.8623, 1.7117],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93554658]\n",
      "[1.90147166]\n",
      "[1.71572366]\n",
      "[1.69590731]\n",
      "[1.95615707]\n",
      "[1.82067506]\n",
      "[2.04718679]\n",
      "tensor([1.9355, 1.9015, 1.7157, 1.6959, 1.9562, 1.8207, 2.0472],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75585728]\n",
      "[1.68894334]\n",
      "[1.75875503]\n",
      "[1.81665397]\n",
      "[1.80828227]\n",
      "[2.01415967]\n",
      "[1.90316787]\n",
      "tensor([1.7559, 1.6889, 1.7588, 1.8167, 1.8083, 2.0142, 1.9032],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95956498]\n",
      "[1.93532851]\n",
      "[1.68663445]\n",
      "[1.98579798]\n",
      "[1.87220237]\n",
      "[1.80598196]\n",
      "[2.05886172]\n",
      "tensor([1.9596, 1.9353, 1.6866, 1.9858, 1.8722, 1.8060, 2.0589],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74525462]\n",
      "[1.87919626]\n",
      "[1.7932669]\n",
      "[1.84914767]\n",
      "[1.76755304]\n",
      "[1.87878944]\n",
      "[1.95935348]\n",
      "tensor([1.7453, 1.8792, 1.7933, 1.8491, 1.7676, 1.8788, 1.9594],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85391741]\n",
      "[1.80268506]\n",
      "[1.69392111]\n",
      "[1.76093312]\n",
      "[2.15432528]\n",
      "[1.90285978]\n",
      "[1.85517634]\n",
      "tensor([1.8539, 1.8027, 1.6939, 1.7609, 2.1543, 1.9029, 1.8552],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9479266]\n",
      "[1.86328012]\n",
      "[1.86819178]\n",
      "[1.95358138]\n",
      "[1.80872169]\n",
      "[1.80560175]\n",
      "[1.74656712]\n",
      "tensor([1.9479, 1.8633, 1.8682, 1.9536, 1.8087, 1.8056, 1.7466],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74369228]\n",
      "[2.02533395]\n",
      "[1.78940249]\n",
      "[1.64532111]\n",
      "[1.85157666]\n",
      "[1.78183131]\n",
      "[1.89863569]\n",
      "tensor([1.7437, 2.0253, 1.7894, 1.6453, 1.8516, 1.7818, 1.8986],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89725918]\n",
      "[1.93209733]\n",
      "[1.80632955]\n",
      "[1.96640847]\n",
      "[1.87378218]\n",
      "[1.80676637]\n",
      "[1.85751731]\n",
      "tensor([1.8973, 1.9321, 1.8063, 1.9664, 1.8738, 1.8068, 1.8575],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82178491]\n",
      "[1.88592963]\n",
      "[1.75543068]\n",
      "[1.92734579]\n",
      "[2.07016165]\n",
      "[1.88949252]\n",
      "[1.85312045]\n",
      "tensor([1.8218, 1.8859, 1.7554, 1.9273, 2.0702, 1.8895, 1.8531],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80728496]\n",
      "[1.89125657]\n",
      "[1.82726203]\n",
      "[1.92913812]\n",
      "[1.95740588]\n",
      "[1.86486528]\n",
      "[1.8989421]\n",
      "tensor([1.8073, 1.8913, 1.8273, 1.9291, 1.9574, 1.8649, 1.8989],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88862473]\n",
      "[1.72276452]\n",
      "[1.76591394]\n",
      "[1.85938945]\n",
      "[1.7841796]\n",
      "[1.99165421]\n",
      "[1.69265913]\n",
      "tensor([1.8886, 1.7228, 1.7659, 1.8594, 1.7842, 1.9917, 1.6927],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88090217]\n",
      "[1.84690068]\n",
      "[1.7455744]\n",
      "[1.79432761]\n",
      "[1.78796126]\n",
      "[1.87130681]\n",
      "[1.79229528]\n",
      "tensor([1.8809, 1.8469, 1.7456, 1.7943, 1.7880, 1.8713, 1.7923],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.6887908]\n",
      "[1.6658251]\n",
      "[1.75730489]\n",
      "[1.74235738]\n",
      "[1.72869856]\n",
      "[1.72053648]\n",
      "[1.92634501]\n",
      "tensor([1.6888, 1.6658, 1.7573, 1.7424, 1.7287, 1.7205, 1.9263],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77850137]\n",
      "[1.93868869]\n",
      "[1.83972549]\n",
      "[1.69142711]\n",
      "[1.92583147]\n",
      "[1.94111384]\n",
      "[1.88952893]\n",
      "tensor([1.7785, 1.9387, 1.8397, 1.6914, 1.9258, 1.9411, 1.8895],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78943339]\n",
      "[1.76388575]\n",
      "[1.71880208]\n",
      "[1.88390434]\n",
      "[1.78869807]\n",
      "[1.8919812]\n",
      "[1.91442159]\n",
      "tensor([1.7894, 1.7639, 1.7188, 1.8839, 1.7887, 1.8920, 1.9144],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94628851]\n",
      "[1.89685851]\n",
      "[1.80132157]\n",
      "[1.77635512]\n",
      "[1.69242334]\n",
      "[1.80095346]\n",
      "[1.92657778]\n",
      "tensor([1.9463, 1.8969, 1.8013, 1.7764, 1.6924, 1.8010, 1.9266],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85833264]\n",
      "[1.7455149]\n",
      "[1.85165334]\n",
      "[1.80335701]\n",
      "[1.80651141]\n",
      "[2.05063918]\n",
      "[1.78184749]\n",
      "tensor([1.8583, 1.7455, 1.8517, 1.8034, 1.8065, 2.0506, 1.7818],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90015281]\n",
      "[1.85232843]\n",
      "[1.86284161]\n",
      "[1.93854645]\n",
      "[1.81965758]\n",
      "[1.77365386]\n",
      "[2.06008884]\n",
      "tensor([1.9002, 1.8523, 1.8628, 1.9385, 1.8197, 1.7737, 2.0601],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70471889]\n",
      "[1.68004663]\n",
      "[1.6924585]\n",
      "[2.02307138]\n",
      "[1.69583102]\n",
      "[1.87137765]\n",
      "[1.75326843]\n",
      "tensor([1.7047, 1.6800, 1.6925, 2.0231, 1.6958, 1.8714, 1.7533],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.00059233]\n",
      "[1.82867749]\n",
      "[1.72755475]\n",
      "[1.84144727]\n",
      "[1.84846328]\n",
      "[1.90621518]\n",
      "[1.68758407]\n",
      "tensor([2.0006, 1.8287, 1.7276, 1.8414, 1.8485, 1.9062, 1.6876],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82805245]\n",
      "[1.81116138]\n",
      "[2.01865308]\n",
      "[1.86644105]\n",
      "[1.84250576]\n",
      "[1.71362451]\n",
      "[1.76131915]\n",
      "tensor([1.8281, 1.8112, 2.0187, 1.8664, 1.8425, 1.7136, 1.7613],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87269241]\n",
      "[2.03911821]\n",
      "[1.85574958]\n",
      "[1.65124461]\n",
      "[1.83896496]\n",
      "[1.9501214]\n",
      "[1.64398685]\n",
      "tensor([1.8727, 2.0391, 1.8557, 1.6512, 1.8390, 1.9501, 1.6440],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72879511]\n",
      "[1.92042364]\n",
      "[1.87079803]\n",
      "[1.72876309]\n",
      "[1.7248911]\n",
      "[2.01444332]\n",
      "[1.81137462]\n",
      "tensor([1.7288, 1.9204, 1.8708, 1.7288, 1.7249, 2.0144, 1.8114],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84389027]\n",
      "[1.81955165]\n",
      "[1.76682485]\n",
      "[1.76047182]\n",
      "[1.85201746]\n",
      "[1.94063625]\n",
      "[1.83146448]\n",
      "tensor([1.8439, 1.8196, 1.7668, 1.7605, 1.8520, 1.9406, 1.8315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.04328372]\n",
      "[1.94950547]\n",
      "[1.94505188]\n",
      "[1.79795284]\n",
      "[1.87469639]\n",
      "[1.94376252]\n",
      "[1.92145753]\n",
      "tensor([2.0433, 1.9495, 1.9451, 1.7980, 1.8747, 1.9438, 1.9215],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92280618]\n",
      "[1.8114655]\n",
      "[1.77293227]\n",
      "[1.73058011]\n",
      "[1.84520585]\n",
      "[2.02498181]\n",
      "[1.81621975]\n",
      "tensor([1.9228, 1.8115, 1.7729, 1.7306, 1.8452, 2.0250, 1.8162],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.02606502]\n",
      "[1.95068994]\n",
      "[1.73268981]\n",
      "[1.71079263]\n",
      "[1.8095355]\n",
      "[1.80453157]\n",
      "[1.68389541]\n",
      "tensor([2.0261, 1.9507, 1.7327, 1.7108, 1.8095, 1.8045, 1.6839],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82561179]\n",
      "[1.85821057]\n",
      "[2.10179219]\n",
      "[1.75719627]\n",
      "[1.81431195]\n",
      "[1.85990462]\n",
      "[1.9637413]\n",
      "tensor([1.8256, 1.8582, 2.1018, 1.7572, 1.8143, 1.8599, 1.9637],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.20516044]\n",
      "[1.91850683]\n",
      "[1.96404177]\n",
      "[1.73882337]\n",
      "[1.91521734]\n",
      "[1.98577907]\n",
      "[1.78785136]\n",
      "tensor([2.2052, 1.9185, 1.9640, 1.7388, 1.9152, 1.9858, 1.7879],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75564845]\n",
      "[1.93143497]\n",
      "[2.02845657]\n",
      "[1.85470813]\n",
      "[1.86905177]\n",
      "[2.02434706]\n",
      "[1.74367257]\n",
      "tensor([1.7556, 1.9314, 2.0285, 1.8547, 1.8691, 2.0243, 1.7437],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86483721]\n",
      "[2.02660422]\n",
      "[1.70906442]\n",
      "[1.71346758]\n",
      "[1.7892953]\n",
      "[1.85811856]\n",
      "[1.94504507]\n",
      "tensor([1.8648, 2.0266, 1.7091, 1.7135, 1.7893, 1.8581, 1.9450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93404449]\n",
      "[1.77274437]\n",
      "[1.82671847]\n",
      "[1.90026445]\n",
      "[1.77040085]\n",
      "[1.72963514]\n",
      "[1.78349214]\n",
      "tensor([1.9340, 1.7727, 1.8267, 1.9003, 1.7704, 1.7296, 1.7835],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80544677]\n",
      "[1.92251795]\n",
      "[1.83091853]\n",
      "[1.84768528]\n",
      "[1.9089988]\n",
      "[1.82361118]\n",
      "[1.77343749]\n",
      "tensor([1.8054, 1.9225, 1.8309, 1.8477, 1.9090, 1.8236, 1.7734],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80132785]\n",
      "[1.88537295]\n",
      "[1.9127419]\n",
      "[1.83725588]\n",
      "[1.71859981]\n",
      "[2.19355235]\n",
      "[1.82904973]\n",
      "tensor([1.8013, 1.8854, 1.9127, 1.8373, 1.7186, 2.1936, 1.8290],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78303229]\n",
      "[1.72709508]\n",
      "[1.73111747]\n",
      "[1.90214841]\n",
      "[1.74626069]\n",
      "[1.72960187]\n",
      "[1.86479608]\n",
      "tensor([1.7830, 1.7271, 1.7311, 1.9021, 1.7463, 1.7296, 1.8648],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77156113]\n",
      "[1.77628026]\n",
      "[1.62021506]\n",
      "[1.81418478]\n",
      "[1.81859283]\n",
      "[1.68577585]\n",
      "[1.83224774]\n",
      "tensor([1.7716, 1.7763, 1.6202, 1.8142, 1.8186, 1.6858, 1.8322],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98755634]\n",
      "[1.80065033]\n",
      "[2.23377031]\n",
      "[1.93513033]\n",
      "[1.68215227]\n",
      "[1.94536244]\n",
      "[1.73770232]\n",
      "tensor([1.9876, 1.8007, 2.2338, 1.9351, 1.6822, 1.9454, 1.7377],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78048629]\n",
      "[1.99214357]\n",
      "[1.79267522]\n",
      "[1.80814899]\n",
      "[2.0454432]\n",
      "[1.93619096]\n",
      "[2.10931345]\n",
      "tensor([1.7805, 1.9921, 1.7927, 1.8081, 2.0454, 1.9362, 2.1093],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76387557]\n",
      "[2.17079144]\n",
      "[1.99316463]\n",
      "[2.12109516]\n",
      "[1.7841677]\n",
      "[1.85445142]\n",
      "[1.81878717]\n",
      "tensor([1.7639, 2.1708, 1.9932, 2.1211, 1.7842, 1.8545, 1.8188],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73399924]\n",
      "[1.77746829]\n",
      "[2.11947445]\n",
      "[2.12778633]\n",
      "[1.74530278]\n",
      "[1.7360344]\n",
      "[1.73491044]\n",
      "tensor([1.7340, 1.7775, 2.1195, 2.1278, 1.7453, 1.7360, 1.7349],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78815318]\n",
      "[1.82078699]\n",
      "[1.76905361]\n",
      "[1.83979051]\n",
      "[1.93747425]\n",
      "[1.75327035]\n",
      "[1.78273304]\n",
      "tensor([1.7882, 1.8208, 1.7691, 1.8398, 1.9375, 1.7533, 1.7827],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.62189963]\n",
      "[1.74333423]\n",
      "[1.70930805]\n",
      "[1.98322331]\n",
      "[1.90104974]\n",
      "[1.75583972]\n",
      "[1.69150598]\n",
      "tensor([1.6219, 1.7433, 1.7093, 1.9832, 1.9010, 1.7558, 1.6915],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95643027]\n",
      "[1.61829291]\n",
      "[1.64510823]\n",
      "[2.08560464]\n",
      "[1.63886123]\n",
      "[2.03141376]\n",
      "[1.87805502]\n",
      "tensor([1.9564, 1.6183, 1.6451, 2.0856, 1.6389, 2.0314, 1.8781],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88533223]\n",
      "[1.78689282]\n",
      "[1.91049329]\n",
      "[1.8383284]\n",
      "[1.96064703]\n",
      "[2.10499617]\n",
      "[1.86887023]\n",
      "tensor([1.8853, 1.7869, 1.9105, 1.8383, 1.9606, 2.1050, 1.8689],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75670878]\n",
      "[1.74464411]\n",
      "[1.92270822]\n",
      "[1.82105883]\n",
      "[1.9587652]\n",
      "[1.73753343]\n",
      "[1.82158055]\n",
      "tensor([1.7567, 1.7446, 1.9227, 1.8211, 1.9588, 1.7375, 1.8216],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78267095]\n",
      "[1.78788381]\n",
      "[1.88743878]\n",
      "[1.99152676]\n",
      "[1.83913411]\n",
      "[1.81572772]\n",
      "[1.7205447]\n",
      "tensor([1.7827, 1.7879, 1.8874, 1.9915, 1.8391, 1.8157, 1.7205],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79361455]\n",
      "[1.89724064]\n",
      "[1.96069458]\n",
      "[1.79518083]\n",
      "[1.84184138]\n",
      "[1.88508046]\n",
      "[1.91204259]\n",
      "tensor([1.7936, 1.8972, 1.9607, 1.7952, 1.8418, 1.8851, 1.9120],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81794333]\n",
      "[1.97386212]\n",
      "[1.71068012]\n",
      "[1.89217865]\n",
      "[1.77414107]\n",
      "[1.74558225]\n",
      "[1.8350443]\n",
      "tensor([1.8179, 1.9739, 1.7107, 1.8922, 1.7741, 1.7456, 1.8350],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91026002]\n",
      "[1.93402012]\n",
      "[1.72538391]\n",
      "[1.77841101]\n",
      "[1.76194785]\n",
      "[1.93528542]\n",
      "[1.7677422]\n",
      "tensor([1.9103, 1.9340, 1.7254, 1.7784, 1.7619, 1.9353, 1.7677],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71840529]\n",
      "[1.83702798]\n",
      "[1.78419992]\n",
      "[1.74001272]\n",
      "[1.82818839]\n",
      "[1.73431256]\n",
      "[1.8104202]\n",
      "tensor([1.7184, 1.8370, 1.7842, 1.7400, 1.8282, 1.7343, 1.8104],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81436378]\n",
      "[1.95760388]\n",
      "[1.71429456]\n",
      "[1.84313645]\n",
      "[1.87626992]\n",
      "[1.75770827]\n",
      "[1.8324657]\n",
      "tensor([1.8144, 1.9576, 1.7143, 1.8431, 1.8763, 1.7577, 1.8325],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74705576]\n",
      "[1.8518247]\n",
      "[2.00140603]\n",
      "[1.82046777]\n",
      "[1.80713856]\n",
      "[1.82900515]\n",
      "[1.86407878]\n",
      "tensor([1.7471, 1.8518, 2.0014, 1.8205, 1.8071, 1.8290, 1.8641],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77295991]\n",
      "[1.75923549]\n",
      "[1.83252038]\n",
      "[1.88717109]\n",
      "[1.80303993]\n",
      "[1.71211103]\n",
      "[1.83403506]\n",
      "tensor([1.7730, 1.7592, 1.8325, 1.8872, 1.8030, 1.7121, 1.8340],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83187366]\n",
      "[1.87323341]\n",
      "[1.95354866]\n",
      "[1.75205923]\n",
      "[1.86798086]\n",
      "[1.74132844]\n",
      "[1.81230075]\n",
      "tensor([1.8319, 1.8732, 1.9535, 1.7521, 1.8680, 1.7413, 1.8123],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69099631]\n",
      "[1.85014494]\n",
      "[1.93625612]\n",
      "[1.79941643]\n",
      "[1.81357261]\n",
      "[1.69497144]\n",
      "[1.83755915]\n",
      "tensor([1.6910, 1.8501, 1.9363, 1.7994, 1.8136, 1.6950, 1.8376],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77572893]\n",
      "[1.92317613]\n",
      "[2.10806113]\n",
      "[1.88942376]\n",
      "[1.79688796]\n",
      "[1.87652451]\n",
      "[1.83195936]\n",
      "tensor([1.7757, 1.9232, 2.1081, 1.8894, 1.7969, 1.8765, 1.8320],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98372056]\n",
      "[2.04571863]\n",
      "[1.85490435]\n",
      "[1.87750172]\n",
      "[1.9690299]\n",
      "[2.08974295]\n",
      "[1.98001881]\n",
      "tensor([1.9837, 2.0457, 1.8549, 1.8775, 1.9690, 2.0897, 1.9800],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88131366]\n",
      "[2.09265305]\n",
      "[1.68120179]\n",
      "[1.84450142]\n",
      "[1.77026969]\n",
      "[1.82342932]\n",
      "[1.84511977]\n",
      "tensor([1.8813, 2.0927, 1.6812, 1.8445, 1.7703, 1.8234, 1.8451],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77786789]\n",
      "[1.77452188]\n",
      "[1.74321887]\n",
      "[1.88431635]\n",
      "[1.77871934]\n",
      "[1.85646185]\n",
      "[1.71540329]\n",
      "tensor([1.7779, 1.7745, 1.7432, 1.8843, 1.7787, 1.8565, 1.7154],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82617008]\n",
      "[1.83385429]\n",
      "[1.99068861]\n",
      "[1.78266882]\n",
      "[1.99309139]\n",
      "[1.8075282]\n",
      "[1.92377375]\n",
      "tensor([1.8262, 1.8339, 1.9907, 1.7827, 1.9931, 1.8075, 1.9238],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7961096]\n",
      "[1.85334991]\n",
      "[1.84931397]\n",
      "[1.93160485]\n",
      "[1.7871213]\n",
      "[1.91670769]\n",
      "[1.8334007]\n",
      "tensor([1.7961, 1.8533, 1.8493, 1.9316, 1.7871, 1.9167, 1.8334],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83887474]\n",
      "[2.01775881]\n",
      "[1.73784912]\n",
      "[1.95581203]\n",
      "[1.81662998]\n",
      "[1.90378554]\n",
      "[1.92582987]\n",
      "tensor([1.8389, 2.0178, 1.7378, 1.9558, 1.8166, 1.9038, 1.9258],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77102444]\n",
      "[1.72714398]\n",
      "[1.7875638]\n",
      "[1.74699709]\n",
      "[1.96170503]\n",
      "[1.85786905]\n",
      "[1.78951124]\n",
      "tensor([1.7710, 1.7271, 1.7876, 1.7470, 1.9617, 1.8579, 1.7895],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.01434136]\n",
      "[1.83653637]\n",
      "[1.87136602]\n",
      "[1.89870586]\n",
      "[1.79157791]\n",
      "[1.76921041]\n",
      "[1.81161509]\n",
      "tensor([2.0143, 1.8365, 1.8714, 1.8987, 1.7916, 1.7692, 1.8116],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85112801]\n",
      "[1.88410039]\n",
      "[1.73292944]\n",
      "[1.7858342]\n",
      "[1.92250621]\n",
      "[1.88739426]\n",
      "[1.85011277]\n",
      "tensor([1.8511, 1.8841, 1.7329, 1.7858, 1.9225, 1.8874, 1.8501],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82719378]\n",
      "[1.98891564]\n",
      "[1.75386533]\n",
      "[1.77636109]\n",
      "[1.76303508]\n",
      "[1.79476738]\n",
      "[1.77064106]\n",
      "tensor([1.8272, 1.9889, 1.7539, 1.7764, 1.7630, 1.7948, 1.7706],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8392844]\n",
      "[1.79851791]\n",
      "[1.88577275]\n",
      "[1.85623015]\n",
      "[1.85712999]\n",
      "[1.71355497]\n",
      "[1.84968853]\n",
      "tensor([1.8393, 1.7985, 1.8858, 1.8562, 1.8571, 1.7136, 1.8497],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7908679]\n",
      "[1.84509411]\n",
      "[1.91866505]\n",
      "[1.69789569]\n",
      "[1.76136614]\n",
      "[2.03344115]\n",
      "[1.8630965]\n",
      "tensor([1.7909, 1.8451, 1.9187, 1.6979, 1.7614, 2.0334, 1.8631],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84804133]\n",
      "[1.70021754]\n",
      "[1.74123622]\n",
      "[1.87173779]\n",
      "[1.77761009]\n",
      "[1.93529824]\n",
      "[1.95984762]\n",
      "tensor([1.8480, 1.7002, 1.7412, 1.8717, 1.7776, 1.9353, 1.9598],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94161421]\n",
      "[1.78862249]\n",
      "[1.8147996]\n",
      "[1.76120701]\n",
      "[1.8980989]\n",
      "[1.93713536]\n",
      "[1.8430714]\n",
      "tensor([1.9416, 1.7886, 1.8148, 1.7612, 1.8981, 1.9371, 1.8431],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87748098]\n",
      "[1.90011974]\n",
      "[1.92293327]\n",
      "[1.8420533]\n",
      "[1.94761468]\n",
      "[1.76262996]\n",
      "[1.83331009]\n",
      "tensor([1.8775, 1.9001, 1.9229, 1.8421, 1.9476, 1.7626, 1.8333],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71679848]\n",
      "[1.86652467]\n",
      "[1.76543174]\n",
      "[1.73885067]\n",
      "[1.90651108]\n",
      "[1.73554177]\n",
      "[1.87342148]\n",
      "tensor([1.7168, 1.8665, 1.7654, 1.7389, 1.9065, 1.7355, 1.8734],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81716331]\n",
      "[1.68566589]\n",
      "[1.8824582]\n",
      "[1.70511876]\n",
      "[1.92477573]\n",
      "[1.80962276]\n",
      "[1.80586976]\n",
      "tensor([1.8172, 1.6857, 1.8825, 1.7051, 1.9248, 1.8096, 1.8059],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77464715]\n",
      "[1.82704827]\n",
      "[1.82658033]\n",
      "[2.00900301]\n",
      "[1.95782931]\n",
      "[1.97353042]\n",
      "[1.94416991]\n",
      "tensor([1.7746, 1.8270, 1.8266, 2.0090, 1.9578, 1.9735, 1.9442],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78047546]\n",
      "[1.7026763]\n",
      "[1.80882901]\n",
      "[1.94677788]\n",
      "[1.969331]\n",
      "[2.01152989]\n",
      "[1.8308854]\n",
      "tensor([1.7805, 1.7027, 1.8088, 1.9468, 1.9693, 2.0115, 1.8309],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89440451]\n",
      "[1.82452825]\n",
      "[1.77044808]\n",
      "[1.76213997]\n",
      "[2.01143515]\n",
      "[1.80678111]\n",
      "[1.8529821]\n",
      "tensor([1.8944, 1.8245, 1.7704, 1.7621, 2.0114, 1.8068, 1.8530],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86856509]\n",
      "[1.82601575]\n",
      "[1.82024013]\n",
      "[1.76999725]\n",
      "[1.70653774]\n",
      "[1.73749373]\n",
      "[1.73416691]\n",
      "tensor([1.8686, 1.8260, 1.8202, 1.7700, 1.7065, 1.7375, 1.7342],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.03423702]\n",
      "[1.73472462]\n",
      "[1.82189015]\n",
      "[1.74713439]\n",
      "[1.77255936]\n",
      "[1.7551323]\n",
      "[1.82405429]\n",
      "tensor([2.0342, 1.7347, 1.8219, 1.7471, 1.7726, 1.7551, 1.8241],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88760921]\n",
      "[1.78934699]\n",
      "[2.07276933]\n",
      "[1.80627201]\n",
      "[1.74564846]\n",
      "[1.82115117]\n",
      "[1.84027658]\n",
      "tensor([1.8876, 1.7893, 2.0728, 1.8063, 1.7456, 1.8212, 1.8403],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76495832]\n",
      "[1.73132752]\n",
      "[1.96749212]\n",
      "[1.95073258]\n",
      "[1.86251891]\n",
      "[1.7873341]\n",
      "[2.10178241]\n",
      "tensor([1.7650, 1.7313, 1.9675, 1.9507, 1.8625, 1.7873, 2.1018],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88107004]\n",
      "[1.80337084]\n",
      "[1.70982504]\n",
      "[1.84175337]\n",
      "[1.83215367]\n",
      "[1.87433289]\n",
      "[1.81561251]\n",
      "tensor([1.8811, 1.8034, 1.7098, 1.8418, 1.8322, 1.8743, 1.8156],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80732919]\n",
      "[1.89942456]\n",
      "[1.80216877]\n",
      "[1.70588833]\n",
      "[1.77489578]\n",
      "[2.01889874]\n",
      "[1.80668827]\n",
      "tensor([1.8073, 1.8994, 1.8022, 1.7059, 1.7749, 2.0189, 1.8067],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.15598511]\n",
      "[1.83312746]\n",
      "[2.04626972]\n",
      "[1.8276753]\n",
      "[1.82546588]\n",
      "[2.02924976]\n",
      "[1.83898668]\n",
      "tensor([2.1560, 1.8331, 2.0463, 1.8277, 1.8255, 2.0292, 1.8390],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76102019]\n",
      "[1.82540776]\n",
      "[1.85676179]\n",
      "[1.72082947]\n",
      "[1.67958915]\n",
      "[1.67333454]\n",
      "[2.050769]\n",
      "tensor([1.7610, 1.8254, 1.8568, 1.7208, 1.6796, 1.6733, 2.0508],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82153295]\n",
      "[1.86825723]\n",
      "[1.79045673]\n",
      "[1.96599774]\n",
      "[1.96838875]\n",
      "[1.6764648]\n",
      "[1.92506652]\n",
      "tensor([1.8215, 1.8683, 1.7905, 1.9660, 1.9684, 1.6765, 1.9251],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74796401]\n",
      "[1.79533938]\n",
      "[1.79556158]\n",
      "[2.01955764]\n",
      "[2.02019634]\n",
      "[1.84277394]\n",
      "[1.88951605]\n",
      "tensor([1.7480, 1.7953, 1.7956, 2.0196, 2.0202, 1.8428, 1.8895],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81532261]\n",
      "[1.75037643]\n",
      "[1.8728101]\n",
      "[1.86907051]\n",
      "[1.96405262]\n",
      "[1.915076]\n",
      "[1.91813435]\n",
      "tensor([1.8153, 1.7504, 1.8728, 1.8691, 1.9641, 1.9151, 1.9181],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89497963]\n",
      "[1.95659929]\n",
      "[1.94930235]\n",
      "[1.76266462]\n",
      "[2.12441875]\n",
      "[1.77910774]\n",
      "[1.89285581]\n",
      "tensor([1.8950, 1.9566, 1.9493, 1.7627, 2.1244, 1.7791, 1.8929],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.08354158]\n",
      "[2.01247219]\n",
      "[1.80098028]\n",
      "[1.71974009]\n",
      "[1.84477994]\n",
      "[1.94445352]\n",
      "[1.89265491]\n",
      "tensor([2.0835, 2.0125, 1.8010, 1.7197, 1.8448, 1.9445, 1.8927],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81943306]\n",
      "[1.80604065]\n",
      "[1.90396009]\n",
      "[1.96032754]\n",
      "[1.68311748]\n",
      "[1.77553802]\n",
      "[1.72675331]\n",
      "tensor([1.8194, 1.8060, 1.9040, 1.9603, 1.6831, 1.7755, 1.7268],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80494261]\n",
      "[1.69815131]\n",
      "[1.78666742]\n",
      "[1.81459507]\n",
      "[1.76533226]\n",
      "[1.62383419]\n",
      "[1.81058185]\n",
      "tensor([1.8049, 1.6982, 1.7867, 1.8146, 1.7653, 1.6238, 1.8106],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73709966]\n",
      "[1.79652102]\n",
      "[1.84714512]\n",
      "[1.91325486]\n",
      "[1.83990414]\n",
      "[1.77229423]\n",
      "[1.75455688]\n",
      "tensor([1.7371, 1.7965, 1.8471, 1.9133, 1.8399, 1.7723, 1.7546],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84898213]\n",
      "[1.93195845]\n",
      "[1.68729563]\n",
      "[2.03501052]\n",
      "[1.80365847]\n",
      "[1.92247859]\n",
      "[1.92096986]\n",
      "tensor([1.8490, 1.9320, 1.6873, 2.0350, 1.8037, 1.9225, 1.9210],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87765409]\n",
      "[1.87572241]\n",
      "[1.89957279]\n",
      "[1.70770121]\n",
      "[1.9916761]\n",
      "[1.73922912]\n",
      "[2.02153305]\n",
      "tensor([1.8777, 1.8757, 1.8996, 1.7077, 1.9917, 1.7392, 2.0215],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85756209]\n",
      "[1.7348772]\n",
      "[1.87007438]\n",
      "[1.96338946]\n",
      "[1.75728398]\n",
      "[1.75522759]\n",
      "[1.91972256]\n",
      "tensor([1.8576, 1.7349, 1.8701, 1.9634, 1.7573, 1.7552, 1.9197],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73182884]\n",
      "[1.85302237]\n",
      "[1.72298291]\n",
      "[1.71416855]\n",
      "[1.91985199]\n",
      "[1.7517694]\n",
      "[1.93098863]\n",
      "tensor([1.7318, 1.8530, 1.7230, 1.7142, 1.9199, 1.7518, 1.9310],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83691928]\n",
      "[1.95175242]\n",
      "[1.8918389]\n",
      "[1.91948058]\n",
      "[1.97676655]\n",
      "[1.7811754]\n",
      "[1.78463818]\n",
      "tensor([1.8369, 1.9518, 1.8918, 1.9195, 1.9768, 1.7812, 1.7846],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79972965]\n",
      "[1.84469875]\n",
      "[1.87996364]\n",
      "[1.75693232]\n",
      "[1.73860481]\n",
      "[1.80116221]\n",
      "[1.9425278]\n",
      "tensor([1.7997, 1.8447, 1.8800, 1.7569, 1.7386, 1.8012, 1.9425],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8658995]\n",
      "[1.78689303]\n",
      "[1.74883463]\n",
      "[1.76664983]\n",
      "[1.87520305]\n",
      "[1.7089045]\n",
      "[1.76669155]\n",
      "tensor([1.8659, 1.7869, 1.7488, 1.7666, 1.8752, 1.7089, 1.7667],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82501256]\n",
      "[1.73278473]\n",
      "[1.82502812]\n",
      "[1.75947795]\n",
      "[1.82222964]\n",
      "[1.73467024]\n",
      "[1.86779842]\n",
      "tensor([1.8250, 1.7328, 1.8250, 1.7595, 1.8222, 1.7347, 1.8678],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9317331]\n",
      "[1.93953261]\n",
      "[1.76994649]\n",
      "[1.78563734]\n",
      "[1.74463059]\n",
      "[1.80106586]\n",
      "[1.73736878]\n",
      "tensor([1.9317, 1.9395, 1.7699, 1.7856, 1.7446, 1.8011, 1.7374],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86318104]\n",
      "[1.81433287]\n",
      "[1.75665161]\n",
      "[1.9729924]\n",
      "[1.92664189]\n",
      "[1.8436022]\n",
      "[1.94014583]\n",
      "tensor([1.8632, 1.8143, 1.7567, 1.9730, 1.9266, 1.8436, 1.9401],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72800972]\n",
      "[1.89991277]\n",
      "[2.01806615]\n",
      "[1.8782969]\n",
      "[1.77068827]\n",
      "[1.84944711]\n",
      "[2.03177142]\n",
      "tensor([1.7280, 1.8999, 2.0181, 1.8783, 1.7707, 1.8494, 2.0318],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77266755]\n",
      "[1.74451294]\n",
      "[2.10919715]\n",
      "[1.76628776]\n",
      "[1.79252939]\n",
      "[1.7376879]\n",
      "[1.84331433]\n",
      "tensor([1.7727, 1.7445, 2.1092, 1.7663, 1.7925, 1.7377, 1.8433],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.20152655]\n",
      "[1.82707154]\n",
      "[1.76321564]\n",
      "[1.82972514]\n",
      "[1.8924391]\n",
      "[1.82128113]\n",
      "[1.84654527]\n",
      "tensor([2.2015, 1.8271, 1.7632, 1.8297, 1.8924, 1.8213, 1.8465],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70629295]\n",
      "[1.78734396]\n",
      "[1.85738679]\n",
      "[1.75395485]\n",
      "[1.90688421]\n",
      "[1.71099204]\n",
      "[1.79289892]\n",
      "tensor([1.7063, 1.7873, 1.8574, 1.7540, 1.9069, 1.7110, 1.7929],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86123396]\n",
      "[1.79398894]\n",
      "[1.81939942]\n",
      "[1.88986184]\n",
      "[1.9387513]\n",
      "[1.88311896]\n",
      "[1.79363648]\n",
      "tensor([1.8612, 1.7940, 1.8194, 1.8899, 1.9388, 1.8831, 1.7936],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92238356]\n",
      "[1.8436435]\n",
      "[1.82578916]\n",
      "[1.84241002]\n",
      "[1.8198579]\n",
      "[1.69665152]\n",
      "[1.88878521]\n",
      "tensor([1.9224, 1.8436, 1.8258, 1.8424, 1.8199, 1.6967, 1.8888],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.03166511]\n",
      "[1.81741543]\n",
      "[1.71193802]\n",
      "[1.66342213]\n",
      "[1.92912478]\n",
      "[1.97406568]\n",
      "[1.84500444]\n",
      "tensor([2.0317, 1.8174, 1.7119, 1.6634, 1.9291, 1.9741, 1.8450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8944092]\n",
      "[1.96921311]\n",
      "[1.80285477]\n",
      "[1.86050758]\n",
      "[1.88379417]\n",
      "[1.84667745]\n",
      "[1.77105336]\n",
      "tensor([1.8944, 1.9692, 1.8029, 1.8605, 1.8838, 1.8467, 1.7711],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97576495]\n",
      "[1.75420759]\n",
      "[1.89178315]\n",
      "[1.77025816]\n",
      "[1.77257493]\n",
      "[1.73493131]\n",
      "[2.01713809]\n",
      "tensor([1.9758, 1.7542, 1.8918, 1.7703, 1.7726, 1.7349, 2.0171],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85898367]\n",
      "[1.77446092]\n",
      "[1.90654342]\n",
      "[1.7464878]\n",
      "[1.80124693]\n",
      "[1.59658803]\n",
      "[1.94626528]\n",
      "tensor([1.8590, 1.7745, 1.9065, 1.7465, 1.8012, 1.5966, 1.9463],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.16774889]\n",
      "[1.79690462]\n",
      "[1.82504559]\n",
      "[1.71622237]\n",
      "[1.84711276]\n",
      "[1.74603813]\n",
      "[1.96082861]\n",
      "tensor([2.1677, 1.7969, 1.8250, 1.7162, 1.8471, 1.7460, 1.9608],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95588862]\n",
      "[1.76380366]\n",
      "[1.86685694]\n",
      "[1.77634099]\n",
      "[1.79507825]\n",
      "[1.80683185]\n",
      "[1.77643976]\n",
      "tensor([1.9559, 1.7638, 1.8669, 1.7763, 1.7951, 1.8068, 1.7764],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8556407]\n",
      "[1.71900395]\n",
      "[1.73887659]\n",
      "[2.03184949]\n",
      "[1.82356926]\n",
      "[1.93507626]\n",
      "[1.82658576]\n",
      "tensor([1.8556, 1.7190, 1.7389, 2.0318, 1.8236, 1.9351, 1.8266],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71756167]\n",
      "[1.7819961]\n",
      "[1.74304772]\n",
      "[1.71401054]\n",
      "[2.00451087]\n",
      "[1.76340501]\n",
      "[1.98147081]\n",
      "tensor([1.7176, 1.7820, 1.7430, 1.7140, 2.0045, 1.7634, 1.9815],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85466925]\n",
      "[1.73585011]\n",
      "[1.78648415]\n",
      "[1.83964459]\n",
      "[1.96957081]\n",
      "[1.84111347]\n",
      "[1.82127973]\n",
      "tensor([1.8547, 1.7359, 1.7865, 1.8396, 1.9696, 1.8411, 1.8213],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88005614]\n",
      "[1.739835]\n",
      "[1.76405389]\n",
      "[1.93765293]\n",
      "[1.76142142]\n",
      "[1.97094818]\n",
      "[1.85326185]\n",
      "tensor([1.8801, 1.7398, 1.7641, 1.9377, 1.7614, 1.9709, 1.8533],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88407424]\n",
      "[1.75555556]\n",
      "[1.88449243]\n",
      "[1.72072741]\n",
      "[1.97433876]\n",
      "[1.89734362]\n",
      "[1.8948625]\n",
      "tensor([1.8841, 1.7556, 1.8845, 1.7207, 1.9743, 1.8973, 1.8949],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75088987]\n",
      "[1.92758448]\n",
      "[1.82025778]\n",
      "[1.7764516]\n",
      "[1.7501707]\n",
      "[1.91082416]\n",
      "[1.78934486]\n",
      "tensor([1.7509, 1.9276, 1.8203, 1.7765, 1.7502, 1.9108, 1.7893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77021793]\n",
      "[1.78722214]\n",
      "[1.84222506]\n",
      "[1.70730724]\n",
      "[1.7320964]\n",
      "[1.85741405]\n",
      "[1.81840587]\n",
      "tensor([1.7702, 1.7872, 1.8422, 1.7073, 1.7321, 1.8574, 1.8184],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72316141]\n",
      "[1.84863638]\n",
      "[1.86896318]\n",
      "[1.7503047]\n",
      "[1.90766711]\n",
      "[1.76984997]\n",
      "[2.17016443]\n",
      "tensor([1.7232, 1.8486, 1.8690, 1.7503, 1.9077, 1.7698, 2.1702],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99638519]\n",
      "[1.80022068]\n",
      "[1.84194357]\n",
      "[1.89001335]\n",
      "[1.91123307]\n",
      "[1.80731009]\n",
      "[1.83160383]\n",
      "tensor([1.9964, 1.8002, 1.8419, 1.8900, 1.9112, 1.8073, 1.8316],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9894308]\n",
      "[1.85824872]\n",
      "[1.88751122]\n",
      "[2.02931828]\n",
      "[2.19419833]\n",
      "[2.00806392]\n",
      "[1.98636958]\n",
      "tensor([1.9894, 1.8582, 1.8875, 2.0293, 2.1942, 2.0081, 1.9864],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69605107]\n",
      "[1.7392171]\n",
      "[1.66188852]\n",
      "[1.95339848]\n",
      "[1.77770591]\n",
      "[1.87745926]\n",
      "[1.7622628]\n",
      "tensor([1.6961, 1.7392, 1.6619, 1.9534, 1.7777, 1.8775, 1.7623],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71321619]\n",
      "[1.74494484]\n",
      "[1.82995273]\n",
      "[1.80350056]\n",
      "[1.80357226]\n",
      "[1.79976557]\n",
      "[1.76184067]\n",
      "tensor([1.7132, 1.7449, 1.8300, 1.8035, 1.8036, 1.7998, 1.7618],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76523228]\n",
      "[1.92198365]\n",
      "[1.94805247]\n",
      "[1.74794093]\n",
      "[2.06954583]\n",
      "[1.78141455]\n",
      "[1.8832412]\n",
      "tensor([1.7652, 1.9220, 1.9481, 1.7479, 2.0695, 1.7814, 1.8832],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79841825]\n",
      "[1.89896839]\n",
      "[1.71834251]\n",
      "[1.71102448]\n",
      "[1.82520214]\n",
      "[1.77625781]\n",
      "[1.78690393]\n",
      "tensor([1.7984, 1.8990, 1.7183, 1.7110, 1.8252, 1.7763, 1.7869],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90234762]\n",
      "[1.62662414]\n",
      "[1.79319366]\n",
      "[1.66926195]\n",
      "[1.702854]\n",
      "[1.800108]\n",
      "[1.68250899]\n",
      "tensor([1.9023, 1.6266, 1.7932, 1.6693, 1.7029, 1.8001, 1.6825],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91895468]\n",
      "[2.03429953]\n",
      "[1.7192062]\n",
      "[1.89706228]\n",
      "[2.12310782]\n",
      "[1.73058173]\n",
      "[1.93201379]\n",
      "tensor([1.9190, 2.0343, 1.7192, 1.8971, 2.1231, 1.7306, 1.9320],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82392796]\n",
      "[1.84468098]\n",
      "[1.68152404]\n",
      "[1.78415898]\n",
      "[1.70975139]\n",
      "[1.84736894]\n",
      "[1.80291284]\n",
      "tensor([1.8239, 1.8447, 1.6815, 1.7842, 1.7098, 1.8474, 1.8029],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99188408]\n",
      "[1.70734559]\n",
      "[1.81202446]\n",
      "[1.81564481]\n",
      "[1.84023554]\n",
      "[1.88552565]\n",
      "[2.13418446]\n",
      "tensor([1.9919, 1.7073, 1.8120, 1.8156, 1.8402, 1.8855, 2.1342],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94688436]\n",
      "[1.87292347]\n",
      "[1.80033653]\n",
      "[1.73165442]\n",
      "[1.90779927]\n",
      "[1.68751208]\n",
      "[2.09164418]\n",
      "tensor([1.9469, 1.8729, 1.8003, 1.7317, 1.9078, 1.6875, 2.0916],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76335437]\n",
      "[1.83283426]\n",
      "[1.74457872]\n",
      "[1.77390268]\n",
      "[1.90396414]\n",
      "[2.0313639]\n",
      "[1.79646066]\n",
      "tensor([1.7634, 1.8328, 1.7446, 1.7739, 1.9040, 2.0314, 1.7965],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77380065]\n",
      "[1.81639198]\n",
      "[1.81713235]\n",
      "[1.91053692]\n",
      "[1.73934812]\n",
      "[1.83846012]\n",
      "[1.76833225]\n",
      "tensor([1.7738, 1.8164, 1.8171, 1.9105, 1.7393, 1.8385, 1.7683],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77166428]\n",
      "[1.81172969]\n",
      "[1.81675147]\n",
      "[1.70559931]\n",
      "[1.66572489]\n",
      "[1.96486061]\n",
      "[1.96343436]\n",
      "tensor([1.7717, 1.8117, 1.8168, 1.7056, 1.6657, 1.9649, 1.9634],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85911608]\n",
      "[1.79274914]\n",
      "[1.81162797]\n",
      "[1.88121006]\n",
      "[1.97410604]\n",
      "[1.80383728]\n",
      "[1.83629981]\n",
      "tensor([1.8591, 1.7927, 1.8116, 1.8812, 1.9741, 1.8038, 1.8363],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90579605]\n",
      "[1.81223861]\n",
      "[1.80050593]\n",
      "[1.9271028]\n",
      "[1.73291918]\n",
      "[1.95320562]\n",
      "[1.85851491]\n",
      "tensor([1.9058, 1.8122, 1.8005, 1.9271, 1.7329, 1.9532, 1.8585],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80635182]\n",
      "[1.82873639]\n",
      "[1.78715132]\n",
      "[1.84757871]\n",
      "[1.77442639]\n",
      "[1.95360663]\n",
      "[1.90155285]\n",
      "tensor([1.8064, 1.8287, 1.7872, 1.8476, 1.7744, 1.9536, 1.9016],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89870665]\n",
      "[1.89737791]\n",
      "[1.94884692]\n",
      "[1.72133355]\n",
      "[1.8787569]\n",
      "[1.78862414]\n",
      "[1.84893464]\n",
      "tensor([1.8987, 1.8974, 1.9488, 1.7213, 1.8788, 1.7886, 1.8489],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83194868]\n",
      "[1.92126338]\n",
      "[1.79456695]\n",
      "[1.86946687]\n",
      "[1.92169827]\n",
      "[1.81131322]\n",
      "[1.88768699]\n",
      "tensor([1.8319, 1.9213, 1.7946, 1.8695, 1.9217, 1.8113, 1.8877],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86679842]\n",
      "[1.74279742]\n",
      "[1.77930417]\n",
      "[1.77004688]\n",
      "[1.79450241]\n",
      "[1.77311005]\n",
      "[1.80583977]\n",
      "tensor([1.8668, 1.7428, 1.7793, 1.7700, 1.7945, 1.7731, 1.8058],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7433325]\n",
      "[1.71582955]\n",
      "[1.82942508]\n",
      "[1.93980613]\n",
      "[1.69768639]\n",
      "[1.7992255]\n",
      "[1.86146336]\n",
      "tensor([1.7433, 1.7158, 1.8294, 1.9398, 1.6977, 1.7992, 1.8615],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86833267]\n",
      "[1.70130742]\n",
      "[1.91485292]\n",
      "[1.84107023]\n",
      "[1.92789292]\n",
      "[1.83084362]\n",
      "[1.76804684]\n",
      "tensor([1.8683, 1.7013, 1.9149, 1.8411, 1.9279, 1.8308, 1.7680],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75665421]\n",
      "[1.81967529]\n",
      "[1.89910243]\n",
      "[1.79841344]\n",
      "[1.70654556]\n",
      "[1.83016528]\n",
      "[1.71711084]\n",
      "tensor([1.7567, 1.8197, 1.8991, 1.7984, 1.7065, 1.8302, 1.7171],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90969318]\n",
      "[1.99152341]\n",
      "[1.94721151]\n",
      "[1.78922331]\n",
      "[1.93519604]\n",
      "[1.91137287]\n",
      "[1.81317135]\n",
      "tensor([1.9097, 1.9915, 1.9472, 1.7892, 1.9352, 1.9114, 1.8132],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7543425]\n",
      "[1.83565841]\n",
      "[1.75738616]\n",
      "[1.88419546]\n",
      "[1.84916358]\n",
      "[1.92739596]\n",
      "[1.7258336]\n",
      "tensor([1.7543, 1.8357, 1.7574, 1.8842, 1.8492, 1.9274, 1.7258],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96907426]\n",
      "[1.8716317]\n",
      "[1.82511776]\n",
      "[1.92106922]\n",
      "[2.05381186]\n",
      "[1.84045135]\n",
      "[1.81836593]\n",
      "tensor([1.9691, 1.8716, 1.8251, 1.9211, 2.0538, 1.8405, 1.8184],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78581681]\n",
      "[1.85684652]\n",
      "[1.87340338]\n",
      "[1.63084859]\n",
      "[2.02093557]\n",
      "[2.02516429]\n",
      "[1.80384824]\n",
      "tensor([1.7858, 1.8568, 1.8734, 1.6308, 2.0209, 2.0252, 1.8038],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77700151]\n",
      "[1.89007096]\n",
      "[1.85760741]\n",
      "[1.80253522]\n",
      "[1.74044052]\n",
      "[1.75544562]\n",
      "[1.95902277]\n",
      "tensor([1.7770, 1.8901, 1.8576, 1.8025, 1.7404, 1.7554, 1.9590],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.67845101]\n",
      "[1.75296515]\n",
      "[1.80856507]\n",
      "[1.82359486]\n",
      "[1.77377262]\n",
      "[1.87204685]\n",
      "[1.88542401]\n",
      "tensor([1.6785, 1.7530, 1.8086, 1.8236, 1.7738, 1.8720, 1.8854],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81073663]\n",
      "[1.8214095]\n",
      "[1.89642577]\n",
      "[1.66142524]\n",
      "[1.72101955]\n",
      "[1.8752612]\n",
      "[1.83504862]\n",
      "tensor([1.8107, 1.8214, 1.8964, 1.6614, 1.7210, 1.8753, 1.8350],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81673351]\n",
      "[1.8118373]\n",
      "[1.80835593]\n",
      "[1.96302105]\n",
      "[1.80743564]\n",
      "[1.92918284]\n",
      "[1.73910824]\n",
      "tensor([1.8167, 1.8118, 1.8084, 1.9630, 1.8074, 1.9292, 1.7391],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85467704]\n",
      "[1.85087703]\n",
      "[1.87148427]\n",
      "[1.84662892]\n",
      "[1.93278683]\n",
      "[1.80948401]\n",
      "[1.86265569]\n",
      "tensor([1.8547, 1.8509, 1.8715, 1.8466, 1.9328, 1.8095, 1.8627],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75202835]\n",
      "[1.95067706]\n",
      "[1.88224319]\n",
      "[1.91654587]\n",
      "[1.96843154]\n",
      "[1.93931514]\n",
      "[1.67987791]\n",
      "tensor([1.7520, 1.9507, 1.8822, 1.9165, 1.9684, 1.9393, 1.6799],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87419856]\n",
      "[1.83695861]\n",
      "[1.79419812]\n",
      "[1.93475469]\n",
      "[1.95017242]\n",
      "[1.79298663]\n",
      "[1.90434802]\n",
      "tensor([1.8742, 1.8370, 1.7942, 1.9348, 1.9502, 1.7930, 1.9043],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.888051]\n",
      "[1.77504424]\n",
      "[1.8293211]\n",
      "[1.84137899]\n",
      "[1.75090696]\n",
      "[1.76587917]\n",
      "[1.74695109]\n",
      "tensor([1.8881, 1.7750, 1.8293, 1.8414, 1.7509, 1.7659, 1.7470],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82700488]\n",
      "[1.99588791]\n",
      "[1.79825945]\n",
      "[1.83133944]\n",
      "[1.8308877]\n",
      "[1.86099188]\n",
      "[1.99569047]\n",
      "tensor([1.8270, 1.9959, 1.7983, 1.8313, 1.8309, 1.8610, 1.9957],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76162514]\n",
      "[2.03239771]\n",
      "[1.76847441]\n",
      "[1.87710722]\n",
      "[1.7469743]\n",
      "[1.79868184]\n",
      "[1.94314424]\n",
      "tensor([1.7616, 2.0324, 1.7685, 1.8771, 1.7470, 1.7987, 1.9431],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79551639]\n",
      "[1.88620383]\n",
      "[1.91087638]\n",
      "[1.81281881]\n",
      "[1.78771876]\n",
      "[1.77679721]\n",
      "[1.84267833]\n",
      "tensor([1.7955, 1.8862, 1.9109, 1.8128, 1.7877, 1.7768, 1.8427],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85948733]\n",
      "[1.88754578]\n",
      "[2.00945203]\n",
      "[1.81988362]\n",
      "[1.81425718]\n",
      "[1.73879268]\n",
      "[1.852124]\n",
      "tensor([1.8595, 1.8875, 2.0095, 1.8199, 1.8143, 1.7388, 1.8521],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70842993]\n",
      "[1.82119359]\n",
      "[2.12446472]\n",
      "[1.79748624]\n",
      "[1.95131664]\n",
      "[1.95438966]\n",
      "[1.80521264]\n",
      "tensor([1.7084, 1.8212, 2.1245, 1.7975, 1.9513, 1.9544, 1.8052],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92026901]\n",
      "[1.74355194]\n",
      "[1.70333315]\n",
      "[1.80829827]\n",
      "[1.99843778]\n",
      "[1.72523547]\n",
      "[1.78721623]\n",
      "tensor([1.9203, 1.7436, 1.7033, 1.8083, 1.9984, 1.7252, 1.7872],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85906348]\n",
      "[1.7674831]\n",
      "[1.8311866]\n",
      "[1.79199526]\n",
      "[1.6815391]\n",
      "[1.76175226]\n",
      "[1.86148695]\n",
      "tensor([1.8591, 1.7675, 1.8312, 1.7920, 1.6815, 1.7618, 1.8615],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97020126]\n",
      "[1.77988703]\n",
      "[1.82621828]\n",
      "[1.85147371]\n",
      "[1.81631552]\n",
      "[1.83804141]\n",
      "[1.93758459]\n",
      "tensor([1.9702, 1.7799, 1.8262, 1.8515, 1.8163, 1.8380, 1.9376],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78089955]\n",
      "[1.91720932]\n",
      "[1.8607293]\n",
      "[1.93497482]\n",
      "[1.76793205]\n",
      "[1.73396508]\n",
      "[1.7864463]\n",
      "tensor([1.7809, 1.9172, 1.8607, 1.9350, 1.7679, 1.7340, 1.7864],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84357242]\n",
      "[1.91435642]\n",
      "[1.7349391]\n",
      "[1.90663504]\n",
      "[1.85376895]\n",
      "[1.87538487]\n",
      "[1.85376114]\n",
      "tensor([1.8436, 1.9144, 1.7349, 1.9066, 1.8538, 1.8754, 1.8538],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.727135]\n",
      "[1.89191437]\n",
      "[1.90072432]\n",
      "[1.90505123]\n",
      "[1.84803879]\n",
      "[1.71149181]\n",
      "[1.82925697]\n",
      "tensor([1.7271, 1.8919, 1.9007, 1.9051, 1.8480, 1.7115, 1.8293],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83661585]\n",
      "[1.80696644]\n",
      "[1.87898703]\n",
      "[1.86509501]\n",
      "[1.83047656]\n",
      "[1.71199576]\n",
      "[1.91850162]\n",
      "tensor([1.8366, 1.8070, 1.8790, 1.8651, 1.8305, 1.7120, 1.9185],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83679708]\n",
      "[1.87045804]\n",
      "[1.82592734]\n",
      "[1.77615975]\n",
      "[1.88877835]\n",
      "[1.87763386]\n",
      "[1.82530434]\n",
      "tensor([1.8368, 1.8705, 1.8259, 1.7762, 1.8888, 1.8776, 1.8253],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82069971]\n",
      "[1.97073275]\n",
      "[1.82564574]\n",
      "[1.81273482]\n",
      "[1.73767444]\n",
      "[1.87218793]\n",
      "[1.78320867]\n",
      "tensor([1.8207, 1.9707, 1.8256, 1.8127, 1.7377, 1.8722, 1.7832],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93829629]\n",
      "[1.89758871]\n",
      "[1.80056763]\n",
      "[1.90467592]\n",
      "[1.73278702]\n",
      "[1.84015492]\n",
      "[1.78597059]\n",
      "tensor([1.9383, 1.8976, 1.8006, 1.9047, 1.7328, 1.8402, 1.7860],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85531887]\n",
      "[1.85053699]\n",
      "[1.8974839]\n",
      "[1.83644419]\n",
      "[1.92298816]\n",
      "[1.82630717]\n",
      "[1.82963613]\n",
      "tensor([1.8553, 1.8505, 1.8975, 1.8364, 1.9230, 1.8263, 1.8296],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78295423]\n",
      "[1.75448129]\n",
      "[1.80270572]\n",
      "[1.71729378]\n",
      "[1.83474887]\n",
      "[1.89378535]\n",
      "[2.14697092]\n",
      "tensor([1.7830, 1.7545, 1.8027, 1.7173, 1.8347, 1.8938, 2.1470],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87364634]\n",
      "[1.74848114]\n",
      "[1.83107243]\n",
      "[1.77355686]\n",
      "[1.8330093]\n",
      "[1.89552804]\n",
      "[1.81291482]\n",
      "tensor([1.8736, 1.7485, 1.8311, 1.7736, 1.8330, 1.8955, 1.8129],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89244698]\n",
      "[1.95054044]\n",
      "[1.69293871]\n",
      "[1.76049948]\n",
      "[1.91772813]\n",
      "[1.80002749]\n",
      "[1.84701021]\n",
      "tensor([1.8924, 1.9505, 1.6929, 1.7605, 1.9177, 1.8000, 1.8470],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85094126]\n",
      "[1.87510949]\n",
      "[1.95582659]\n",
      "[1.73738118]\n",
      "[1.7241639]\n",
      "[1.83700294]\n",
      "[1.866812]\n",
      "tensor([1.8509, 1.8751, 1.9558, 1.7374, 1.7242, 1.8370, 1.8668],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75993841]\n",
      "[2.07679397]\n",
      "[1.87326506]\n",
      "[1.99622714]\n",
      "[1.87794408]\n",
      "[1.86714033]\n",
      "[1.72669064]\n",
      "tensor([1.7599, 2.0768, 1.8733, 1.9962, 1.8779, 1.8671, 1.7267],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71581315]\n",
      "[1.84239965]\n",
      "[1.7365492]\n",
      "[1.66147946]\n",
      "[1.80846826]\n",
      "[1.72226723]\n",
      "[1.75149895]\n",
      "tensor([1.7158, 1.8424, 1.7365, 1.6615, 1.8085, 1.7223, 1.7515],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91938964]\n",
      "[2.05799235]\n",
      "[2.04421274]\n",
      "[1.89322039]\n",
      "[2.10319177]\n",
      "[1.78938008]\n",
      "[2.16851251]\n",
      "tensor([1.9194, 2.0580, 2.0442, 1.8932, 2.1032, 1.7894, 2.1685],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93867557]\n",
      "[1.88712104]\n",
      "[2.14738843]\n",
      "[1.80676428]\n",
      "[1.86636654]\n",
      "[1.97316548]\n",
      "[2.00912451]\n",
      "tensor([1.9387, 1.8871, 2.1474, 1.8068, 1.8664, 1.9732, 2.0091],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79301681]\n",
      "[1.74058833]\n",
      "[1.87573002]\n",
      "[1.97695703]\n",
      "[1.77522537]\n",
      "[1.74170745]\n",
      "[1.82702175]\n",
      "tensor([1.7930, 1.7406, 1.8757, 1.9770, 1.7752, 1.7417, 1.8270],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05087554]\n",
      "[1.76582929]\n",
      "[1.89194542]\n",
      "[1.96570714]\n",
      "[1.72883708]\n",
      "[1.82072603]\n",
      "[1.84577535]\n",
      "tensor([2.0509, 1.7658, 1.8919, 1.9657, 1.7288, 1.8207, 1.8458],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78468233]\n",
      "[1.84748748]\n",
      "[1.73299145]\n",
      "[1.83517095]\n",
      "[1.88086707]\n",
      "[1.83196257]\n",
      "[1.91580178]\n",
      "tensor([1.7847, 1.8475, 1.7330, 1.8352, 1.8809, 1.8320, 1.9158],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81057515]\n",
      "[1.86613286]\n",
      "[1.83334683]\n",
      "[1.83158063]\n",
      "[1.9171899]\n",
      "[1.87584329]\n",
      "[1.95388621]\n",
      "tensor([1.8106, 1.8661, 1.8333, 1.8316, 1.9172, 1.8758, 1.9539],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80029207]\n",
      "[1.95923619]\n",
      "[1.91837673]\n",
      "[1.96303046]\n",
      "[1.68613143]\n",
      "[1.79721199]\n",
      "[1.76463651]\n",
      "tensor([1.8003, 1.9592, 1.9184, 1.9630, 1.6861, 1.7972, 1.7646],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90708213]\n",
      "[1.78360553]\n",
      "[1.7401926]\n",
      "[1.81704473]\n",
      "[1.98386438]\n",
      "[1.89512927]\n",
      "[1.81506047]\n",
      "tensor([1.9071, 1.7836, 1.7402, 1.8170, 1.9839, 1.8951, 1.8151],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89001812]\n",
      "[1.80145959]\n",
      "[2.11832284]\n",
      "[1.67169139]\n",
      "[1.77502434]\n",
      "[1.86860129]\n",
      "[1.98847497]\n",
      "tensor([1.8900, 1.8015, 2.1183, 1.6717, 1.7750, 1.8686, 1.9885],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84627022]\n",
      "[1.89077874]\n",
      "[1.95199468]\n",
      "[1.97544902]\n",
      "[1.96060349]\n",
      "[1.83658362]\n",
      "[1.88567519]\n",
      "tensor([1.8463, 1.8908, 1.9520, 1.9754, 1.9606, 1.8366, 1.8857],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78472455]\n",
      "[1.92130932]\n",
      "[1.71277803]\n",
      "[1.77933146]\n",
      "[1.91938251]\n",
      "[1.65232171]\n",
      "[2.01192319]\n",
      "tensor([1.7847, 1.9213, 1.7128, 1.7793, 1.9194, 1.6523, 2.0119],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88557889]\n",
      "[1.85747075]\n",
      "[1.82567072]\n",
      "[1.80104734]\n",
      "[1.86745732]\n",
      "[1.92195988]\n",
      "[1.78866044]\n",
      "tensor([1.8856, 1.8575, 1.8257, 1.8010, 1.8675, 1.9220, 1.7887],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92026027]\n",
      "[2.15410669]\n",
      "[1.74584681]\n",
      "[2.04858161]\n",
      "[1.85040724]\n",
      "[1.7949522]\n",
      "[1.99407067]\n",
      "tensor([1.9203, 2.1541, 1.7458, 2.0486, 1.8504, 1.7950, 1.9941],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76527457]\n",
      "[1.83460312]\n",
      "[1.79926574]\n",
      "[1.73481653]\n",
      "[1.97364164]\n",
      "[1.8607834]\n",
      "[1.97348999]\n",
      "tensor([1.7653, 1.8346, 1.7993, 1.7348, 1.9736, 1.8608, 1.9735],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78395792]\n",
      "[1.98686533]\n",
      "[1.78555037]\n",
      "[1.82555386]\n",
      "[1.81927659]\n",
      "[1.82990153]\n",
      "[1.85054911]\n",
      "tensor([1.7840, 1.9869, 1.7856, 1.8256, 1.8193, 1.8299, 1.8505],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.65144601]\n",
      "[1.92787609]\n",
      "[1.89528697]\n",
      "[1.76410388]\n",
      "[1.87847227]\n",
      "[1.87469494]\n",
      "[1.91456277]\n",
      "tensor([1.6514, 1.9279, 1.8953, 1.7641, 1.8785, 1.8747, 1.9146],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76989896]\n",
      "[1.70186503]\n",
      "[1.87842966]\n",
      "[1.95732991]\n",
      "[1.82684268]\n",
      "[1.84482352]\n",
      "[1.87446503]\n",
      "tensor([1.7699, 1.7019, 1.8784, 1.9573, 1.8268, 1.8448, 1.8745],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85911122]\n",
      "[1.73164774]\n",
      "[1.69120787]\n",
      "[1.77627448]\n",
      "[1.88958231]\n",
      "[1.77044044]\n",
      "[1.91316644]\n",
      "tensor([1.8591, 1.7316, 1.6912, 1.7763, 1.8896, 1.7704, 1.9132],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77440767]\n",
      "[1.76719846]\n",
      "[1.87841489]\n",
      "[1.79916343]\n",
      "[1.6945176]\n",
      "[1.94578186]\n",
      "[1.84895381]\n",
      "tensor([1.7744, 1.7672, 1.8784, 1.7992, 1.6945, 1.9458, 1.8490],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85180296]\n",
      "[1.8977212]\n",
      "[1.78788074]\n",
      "[1.98985547]\n",
      "[1.79224484]\n",
      "[1.73207805]\n",
      "[1.66959397]\n",
      "tensor([1.8518, 1.8977, 1.7879, 1.9899, 1.7922, 1.7321, 1.6696],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88884758]\n",
      "[1.81623434]\n",
      "[1.79634853]\n",
      "[1.87431461]\n",
      "[1.85593815]\n",
      "[1.7914369]\n",
      "[1.84038848]\n",
      "tensor([1.8888, 1.8162, 1.7963, 1.8743, 1.8559, 1.7914, 1.8404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91649491]\n",
      "[1.81457358]\n",
      "[1.84840662]\n",
      "[1.91306595]\n",
      "[1.79536239]\n",
      "[1.76466332]\n",
      "[1.93119653]\n",
      "tensor([1.9165, 1.8146, 1.8484, 1.9131, 1.7954, 1.7647, 1.9312],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.6955058]\n",
      "[1.82322695]\n",
      "[1.80336222]\n",
      "[1.8609144]\n",
      "[2.08555737]\n",
      "[1.82480855]\n",
      "[1.79424071]\n",
      "tensor([1.6955, 1.8232, 1.8034, 1.8609, 2.0856, 1.8248, 1.7942],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73472734]\n",
      "[2.08442626]\n",
      "[1.81196274]\n",
      "[2.04529153]\n",
      "[1.86736451]\n",
      "[1.83336415]\n",
      "[1.88098316]\n",
      "tensor([1.7347, 2.0844, 1.8120, 2.0453, 1.8674, 1.8334, 1.8810],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82395018]\n",
      "[1.81357753]\n",
      "[1.90108328]\n",
      "[1.80159885]\n",
      "[1.86474453]\n",
      "[1.6769291]\n",
      "[1.86717331]\n",
      "tensor([1.8240, 1.8136, 1.9011, 1.8016, 1.8647, 1.6769, 1.8672],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8100017]\n",
      "[1.90129121]\n",
      "[1.6720322]\n",
      "[1.73018637]\n",
      "[1.93064361]\n",
      "[1.83033401]\n",
      "[1.66850851]\n",
      "tensor([1.8100, 1.9013, 1.6720, 1.7302, 1.9306, 1.8303, 1.6685],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77280924]\n",
      "[1.84585526]\n",
      "[1.92018216]\n",
      "[1.78034694]\n",
      "[1.85226867]\n",
      "[1.85977029]\n",
      "[2.02672135]\n",
      "tensor([1.7728, 1.8459, 1.9202, 1.7803, 1.8523, 1.8598, 2.0267],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90606219]\n",
      "[1.74568393]\n",
      "[2.01861293]\n",
      "[1.73778294]\n",
      "[1.78332653]\n",
      "[1.91368355]\n",
      "[1.89218742]\n",
      "tensor([1.9061, 1.7457, 2.0186, 1.7378, 1.7833, 1.9137, 1.8922],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87433189]\n",
      "[1.99259746]\n",
      "[1.71325153]\n",
      "[1.76497355]\n",
      "[1.76993094]\n",
      "[1.77123612]\n",
      "[1.82522247]\n",
      "tensor([1.8743, 1.9926, 1.7133, 1.7650, 1.7699, 1.7712, 1.8252],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85411902]\n",
      "[1.81032883]\n",
      "[1.81966462]\n",
      "[1.91614958]\n",
      "[1.75831925]\n",
      "[1.92668619]\n",
      "[1.8315459]\n",
      "tensor([1.8541, 1.8103, 1.8197, 1.9161, 1.7583, 1.9267, 1.8315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80247761]\n",
      "[1.64414104]\n",
      "[1.84553681]\n",
      "[1.76431903]\n",
      "[1.77469485]\n",
      "[2.04200158]\n",
      "[1.8948898]\n",
      "tensor([1.8025, 1.6441, 1.8455, 1.7643, 1.7747, 2.0420, 1.8949],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.917542]\n",
      "[1.70645948]\n",
      "[1.83591284]\n",
      "[1.96326895]\n",
      "[1.89864976]\n",
      "[1.83652882]\n",
      "[1.87813799]\n",
      "tensor([1.9175, 1.7065, 1.8359, 1.9633, 1.8986, 1.8365, 1.8781],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82458407]\n",
      "[1.85067664]\n",
      "[1.86766522]\n",
      "[1.75055902]\n",
      "[1.87466761]\n",
      "[1.81433824]\n",
      "[1.89761262]\n",
      "tensor([1.8246, 1.8507, 1.8677, 1.7506, 1.8747, 1.8143, 1.8976],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76495984]\n",
      "[1.87340399]\n",
      "[2.09813271]\n",
      "[1.84076453]\n",
      "[1.8956319]\n",
      "[1.99123262]\n",
      "[1.86501696]\n",
      "tensor([1.7650, 1.8734, 2.0981, 1.8408, 1.8956, 1.9912, 1.8650],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80911512]\n",
      "[1.94805927]\n",
      "[1.92352245]\n",
      "[1.69440974]\n",
      "[1.73922533]\n",
      "[1.75046654]\n",
      "[1.82734758]\n",
      "tensor([1.8091, 1.9481, 1.9235, 1.6944, 1.7392, 1.7505, 1.8273],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77633253]\n",
      "[1.76419401]\n",
      "[1.77990069]\n",
      "[2.0995522]\n",
      "[1.87938392]\n",
      "[1.88377479]\n",
      "[1.84490116]\n",
      "tensor([1.7763, 1.7642, 1.7799, 2.0996, 1.8794, 1.8838, 1.8449],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83408651]\n",
      "[1.76055677]\n",
      "[1.72534052]\n",
      "[1.86225893]\n",
      "[1.8061559]\n",
      "[1.71613489]\n",
      "[1.79170837]\n",
      "tensor([1.8341, 1.7606, 1.7253, 1.8623, 1.8062, 1.7161, 1.7917],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93330382]\n",
      "[1.81393245]\n",
      "[1.9388889]\n",
      "[1.88242942]\n",
      "[1.82514781]\n",
      "[1.73503994]\n",
      "[1.79400017]\n",
      "tensor([1.9333, 1.8139, 1.9389, 1.8824, 1.8251, 1.7350, 1.7940],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83539814]\n",
      "[1.92440059]\n",
      "[1.80626488]\n",
      "[1.80832429]\n",
      "[1.82117318]\n",
      "[1.84311428]\n",
      "[1.7354501]\n",
      "tensor([1.8354, 1.9244, 1.8063, 1.8083, 1.8212, 1.8431, 1.7355],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88021961]\n",
      "[1.68464243]\n",
      "[1.75656068]\n",
      "[1.8487468]\n",
      "[1.70809068]\n",
      "[1.85377728]\n",
      "[1.76530034]\n",
      "tensor([1.8802, 1.6846, 1.7566, 1.8487, 1.7081, 1.8538, 1.7653],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92978727]\n",
      "[1.72537292]\n",
      "[1.82513477]\n",
      "[1.78612547]\n",
      "[1.75205502]\n",
      "[1.71241449]\n",
      "[1.71828502]\n",
      "tensor([1.9298, 1.7254, 1.8251, 1.7861, 1.7521, 1.7124, 1.7183],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90091882]\n",
      "[1.77788113]\n",
      "[1.82429313]\n",
      "[1.80697463]\n",
      "[1.84604482]\n",
      "[1.85105638]\n",
      "[1.84188883]\n",
      "tensor([1.9009, 1.7779, 1.8243, 1.8070, 1.8460, 1.8511, 1.8419],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79039268]\n",
      "[1.83740054]\n",
      "[1.90404723]\n",
      "[2.01233194]\n",
      "[1.82551928]\n",
      "[1.8826626]\n",
      "[1.74981197]\n",
      "tensor([1.7904, 1.8374, 1.9040, 2.0123, 1.8255, 1.8827, 1.7498],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8240382]\n",
      "[1.83428746]\n",
      "[1.86215721]\n",
      "[1.86413131]\n",
      "[1.80812145]\n",
      "[2.00624135]\n",
      "[1.83048346]\n",
      "tensor([1.8240, 1.8343, 1.8622, 1.8641, 1.8081, 2.0062, 1.8305],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75122694]\n",
      "[1.81979866]\n",
      "[1.88563777]\n",
      "[1.8527898]\n",
      "[1.81030008]\n",
      "[1.86018429]\n",
      "[1.94402763]\n",
      "tensor([1.7512, 1.8198, 1.8856, 1.8528, 1.8103, 1.8602, 1.9440],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7689408]\n",
      "[1.82677727]\n",
      "[1.69591706]\n",
      "[1.76125917]\n",
      "[1.75715033]\n",
      "[1.93391165]\n",
      "[1.73865471]\n",
      "tensor([1.7689, 1.8268, 1.6959, 1.7613, 1.7572, 1.9339, 1.7387],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85310542]\n",
      "[1.79803851]\n",
      "[1.67473091]\n",
      "[1.77504288]\n",
      "[1.89357299]\n",
      "[1.81729182]\n",
      "[1.90444162]\n",
      "tensor([1.8531, 1.7980, 1.6747, 1.7750, 1.8936, 1.8173, 1.9044],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77744147]\n",
      "[1.75426863]\n",
      "[1.76248814]\n",
      "[1.87810392]\n",
      "[1.86016988]\n",
      "[1.80857492]\n",
      "[1.82330763]\n",
      "tensor([1.7774, 1.7543, 1.7625, 1.8781, 1.8602, 1.8086, 1.8233],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92603065]\n",
      "[1.94932857]\n",
      "[1.69306204]\n",
      "[1.77606274]\n",
      "[1.78245137]\n",
      "[1.8055805]\n",
      "[1.68509974]\n",
      "tensor([1.9260, 1.9493, 1.6931, 1.7761, 1.7825, 1.8056, 1.6851],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7614734]\n",
      "[1.82048316]\n",
      "[1.92565967]\n",
      "[1.94061739]\n",
      "[1.78427374]\n",
      "[1.70819964]\n",
      "[1.91564748]\n",
      "tensor([1.7615, 1.8205, 1.9257, 1.9406, 1.7843, 1.7082, 1.9156],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72982834]\n",
      "[1.76720132]\n",
      "[1.79737846]\n",
      "[1.73226624]\n",
      "[1.78217147]\n",
      "[1.84515913]\n",
      "[1.7094008]\n",
      "tensor([1.7298, 1.7672, 1.7974, 1.7323, 1.7822, 1.8452, 1.7094],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80149809]\n",
      "[1.9450846]\n",
      "[1.88297691]\n",
      "[1.77516099]\n",
      "[1.87591595]\n",
      "[1.82059805]\n",
      "[1.95891238]\n",
      "tensor([1.8015, 1.9451, 1.8830, 1.7752, 1.8759, 1.8206, 1.9589],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78925893]\n",
      "[1.80731094]\n",
      "[1.95326914]\n",
      "[1.81306693]\n",
      "[2.06497614]\n",
      "[1.70890648]\n",
      "[1.77198978]\n",
      "tensor([1.7893, 1.8073, 1.9533, 1.8131, 2.0650, 1.7089, 1.7720],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89056696]\n",
      "[1.72011942]\n",
      "[1.73890088]\n",
      "[1.94562234]\n",
      "[1.85039362]\n",
      "[1.77878729]\n",
      "[1.7872539]\n",
      "tensor([1.8906, 1.7201, 1.7389, 1.9456, 1.8504, 1.7788, 1.7873],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89949926]\n",
      "[1.80810361]\n",
      "[1.86513274]\n",
      "[1.93894006]\n",
      "[1.88584554]\n",
      "[1.72199225]\n",
      "[1.84919199]\n",
      "tensor([1.8995, 1.8081, 1.8651, 1.9389, 1.8858, 1.7220, 1.8492],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77337554]\n",
      "[1.87658973]\n",
      "[1.82466203]\n",
      "[1.75073744]\n",
      "[1.76279355]\n",
      "[1.70202569]\n",
      "[1.86120093]\n",
      "tensor([1.7734, 1.8766, 1.8247, 1.7507, 1.7628, 1.7020, 1.8612],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80903112]\n",
      "[1.77061391]\n",
      "[1.7974571]\n",
      "[1.84362821]\n",
      "[1.75088895]\n",
      "[1.74306158]\n",
      "[1.82239241]\n",
      "tensor([1.8090, 1.7706, 1.7975, 1.8436, 1.7509, 1.7431, 1.8224],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93723119]\n",
      "[1.83576173]\n",
      "[1.80166782]\n",
      "[1.77286097]\n",
      "[1.84352998]\n",
      "[1.80549586]\n",
      "[1.7977218]\n",
      "tensor([1.9372, 1.8358, 1.8017, 1.7729, 1.8435, 1.8055, 1.7977],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83141779]\n",
      "[1.88226172]\n",
      "[1.94141545]\n",
      "[1.67676228]\n",
      "[1.88197497]\n",
      "[1.84600089]\n",
      "[1.92869548]\n",
      "tensor([1.8314, 1.8823, 1.9414, 1.6768, 1.8820, 1.8460, 1.9287],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76084428]\n",
      "[1.84877086]\n",
      "[1.84215608]\n",
      "[1.78220549]\n",
      "[1.84741676]\n",
      "[1.88634838]\n",
      "[1.92569618]\n",
      "tensor([1.7608, 1.8488, 1.8422, 1.7822, 1.8474, 1.8863, 1.9257],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78253336]\n",
      "[1.93972846]\n",
      "[1.8173291]\n",
      "[1.86945389]\n",
      "[1.77678148]\n",
      "[1.86104457]\n",
      "[1.6775688]\n",
      "tensor([1.7825, 1.9397, 1.8173, 1.8695, 1.7768, 1.8610, 1.6776],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77062362]\n",
      "[1.84076475]\n",
      "[1.92981693]\n",
      "[1.94978814]\n",
      "[1.74105732]\n",
      "[2.03846653]\n",
      "[1.79351295]\n",
      "tensor([1.7706, 1.8408, 1.9298, 1.9498, 1.7411, 2.0385, 1.7935],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80260056]\n",
      "[1.89300811]\n",
      "[1.84698884]\n",
      "[1.85054281]\n",
      "[1.84246811]\n",
      "[1.785918]\n",
      "[1.76415259]\n",
      "tensor([1.8026, 1.8930, 1.8470, 1.8505, 1.8425, 1.7859, 1.7642],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.692894]\n",
      "[1.71728753]\n",
      "[1.7336624]\n",
      "[1.96561941]\n",
      "[1.99769935]\n",
      "[1.82078173]\n",
      "[1.67014053]\n",
      "tensor([1.6929, 1.7173, 1.7337, 1.9656, 1.9977, 1.8208, 1.6701],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8645407]\n",
      "[1.80698211]\n",
      "[1.83625582]\n",
      "[1.85406113]\n",
      "[1.77956377]\n",
      "[1.78327846]\n",
      "[1.85662923]\n",
      "tensor([1.8645, 1.8070, 1.8363, 1.8541, 1.7796, 1.7833, 1.8566],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93411449]\n",
      "[1.81859184]\n",
      "[1.87737619]\n",
      "[1.73188118]\n",
      "[1.75581567]\n",
      "[1.88151001]\n",
      "[1.98293035]\n",
      "tensor([1.9341, 1.8186, 1.8774, 1.7319, 1.7558, 1.8815, 1.9829],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.07713166]\n",
      "[1.77091101]\n",
      "[1.83508601]\n",
      "[1.89866145]\n",
      "[1.70254003]\n",
      "[1.85039477]\n",
      "[1.81807806]\n",
      "tensor([2.0771, 1.7709, 1.8351, 1.8987, 1.7025, 1.8504, 1.8181],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73954392]\n",
      "[1.86949115]\n",
      "[1.74545552]\n",
      "[1.87528733]\n",
      "[1.82657843]\n",
      "[1.77503421]\n",
      "[1.777918]\n",
      "tensor([1.7395, 1.8695, 1.7455, 1.8753, 1.8266, 1.7750, 1.7779],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79793155]\n",
      "[1.89999251]\n",
      "[1.96970491]\n",
      "[1.81617747]\n",
      "[1.84938325]\n",
      "[1.8562801]\n",
      "[1.77026561]\n",
      "tensor([1.7979, 1.9000, 1.9697, 1.8162, 1.8494, 1.8563, 1.7703],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82454358]\n",
      "[1.78085858]\n",
      "[1.74148823]\n",
      "[1.78986824]\n",
      "[1.73147442]\n",
      "[1.8408725]\n",
      "[1.8124742]\n",
      "tensor([1.8245, 1.7809, 1.7415, 1.7899, 1.7315, 1.8409, 1.8125],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8601846]\n",
      "[1.82943395]\n",
      "[1.76892998]\n",
      "[1.85660275]\n",
      "[1.91023676]\n",
      "[1.80651178]\n",
      "[1.7871379]\n",
      "tensor([1.8602, 1.8294, 1.7689, 1.8566, 1.9102, 1.8065, 1.7871],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79964899]\n",
      "[1.81961102]\n",
      "[1.85696732]\n",
      "[1.83578559]\n",
      "[1.82723983]\n",
      "[1.89498078]\n",
      "[1.82549943]\n",
      "tensor([1.7996, 1.8196, 1.8570, 1.8358, 1.8272, 1.8950, 1.8255],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72894039]\n",
      "[1.8762058]\n",
      "[1.83076312]\n",
      "[1.82272376]\n",
      "[1.89180428]\n",
      "[1.7181336]\n",
      "[1.80086796]\n",
      "tensor([1.7289, 1.8762, 1.8308, 1.8227, 1.8918, 1.7181, 1.8009],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79110479]\n",
      "[1.81043154]\n",
      "[1.88046883]\n",
      "[1.95094095]\n",
      "[1.8248984]\n",
      "[1.78680979]\n",
      "[1.84466935]\n",
      "tensor([1.7911, 1.8104, 1.8805, 1.9509, 1.8249, 1.7868, 1.8447],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79463456]\n",
      "[1.73527131]\n",
      "[1.70029359]\n",
      "[1.73392515]\n",
      "[1.84850059]\n",
      "[1.8235042]\n",
      "[1.8112044]\n",
      "tensor([1.7946, 1.7353, 1.7003, 1.7339, 1.8485, 1.8235, 1.8112],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78587236]\n",
      "[1.84918504]\n",
      "[1.77822723]\n",
      "[1.938405]\n",
      "[1.80720321]\n",
      "[1.85186278]\n",
      "[1.87184329]\n",
      "tensor([1.7859, 1.8492, 1.7782, 1.9384, 1.8072, 1.8519, 1.8718],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75400107]\n",
      "[1.84090663]\n",
      "[1.80230917]\n",
      "[1.80527403]\n",
      "[1.85825146]\n",
      "[1.8165009]\n",
      "[1.79191449]\n",
      "tensor([1.7540, 1.8409, 1.8023, 1.8053, 1.8583, 1.8165, 1.7919],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88456621]\n",
      "[1.89092863]\n",
      "[1.88458316]\n",
      "[1.73936653]\n",
      "[1.75499604]\n",
      "[1.79326736]\n",
      "[1.84852264]\n",
      "tensor([1.8846, 1.8909, 1.8846, 1.7394, 1.7550, 1.7933, 1.8485],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75955849]\n",
      "[1.8137729]\n",
      "[1.88357424]\n",
      "[1.69592272]\n",
      "[1.82802824]\n",
      "[1.86606881]\n",
      "[1.84558226]\n",
      "tensor([1.7596, 1.8138, 1.8836, 1.6959, 1.8280, 1.8661, 1.8456],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80377076]\n",
      "[1.84857268]\n",
      "[2.07817477]\n",
      "[1.8078997]\n",
      "[1.85348193]\n",
      "[1.74325773]\n",
      "[1.81644198]\n",
      "tensor([1.8038, 1.8486, 2.0782, 1.8079, 1.8535, 1.7433, 1.8164],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86434014]\n",
      "[1.94032196]\n",
      "[1.79843146]\n",
      "[1.74653221]\n",
      "[1.68929943]\n",
      "[1.76292171]\n",
      "[1.74411244]\n",
      "tensor([1.8643, 1.9403, 1.7984, 1.7465, 1.6893, 1.7629, 1.7441],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77096687]\n",
      "[1.88411465]\n",
      "[1.82746291]\n",
      "[1.77832736]\n",
      "[1.89788377]\n",
      "[1.84098727]\n",
      "[1.7872928]\n",
      "tensor([1.7710, 1.8841, 1.8275, 1.7783, 1.8979, 1.8410, 1.7873],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82745702]\n",
      "[2.06967972]\n",
      "[1.9618597]\n",
      "[1.94455258]\n",
      "[1.84851103]\n",
      "[1.91921906]\n",
      "[1.84637794]\n",
      "tensor([1.8275, 2.0697, 1.9619, 1.9446, 1.8485, 1.9192, 1.8464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80180782]\n",
      "[1.74927646]\n",
      "[1.86404591]\n",
      "[2.11301391]\n",
      "[1.97959138]\n",
      "[1.80939392]\n",
      "[1.7037795]\n",
      "tensor([1.8018, 1.7493, 1.8640, 2.1130, 1.9796, 1.8094, 1.7038],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87242107]\n",
      "[1.85902563]\n",
      "[1.80423996]\n",
      "[1.75179589]\n",
      "[1.80802099]\n",
      "[1.87314019]\n",
      "[2.14498395]\n",
      "tensor([1.8724, 1.8590, 1.8042, 1.7518, 1.8080, 1.8731, 2.1450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8480025]\n",
      "[1.86203528]\n",
      "[1.76668275]\n",
      "[1.813533]\n",
      "[1.8224253]\n",
      "[1.76457555]\n",
      "[1.80198946]\n",
      "tensor([1.8480, 1.8620, 1.7667, 1.8135, 1.8224, 1.7646, 1.8020],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83106217]\n",
      "[1.857475]\n",
      "[1.8025859]\n",
      "[1.88820339]\n",
      "[1.72269258]\n",
      "[1.81104057]\n",
      "[1.89282199]\n",
      "tensor([1.8311, 1.8575, 1.8026, 1.8882, 1.7227, 1.8110, 1.8928],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80794407]\n",
      "[1.84388715]\n",
      "[1.80349548]\n",
      "[1.99469454]\n",
      "[1.73073663]\n",
      "[1.88158194]\n",
      "[1.86026825]\n",
      "tensor([1.8079, 1.8439, 1.8035, 1.9947, 1.7307, 1.8816, 1.8603],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79092246]\n",
      "[1.97335479]\n",
      "[1.84551036]\n",
      "[1.82396975]\n",
      "[1.93385025]\n",
      "[1.8614521]\n",
      "[1.9240669]\n",
      "tensor([1.7909, 1.9734, 1.8455, 1.8240, 1.9339, 1.8615, 1.9241],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87433494]\n",
      "[1.7480585]\n",
      "[1.77314883]\n",
      "[1.9246284]\n",
      "[1.77670993]\n",
      "[1.70754431]\n",
      "[1.86971256]\n",
      "tensor([1.8743, 1.7481, 1.7731, 1.9246, 1.7767, 1.7075, 1.8697],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75922744]\n",
      "[1.82483873]\n",
      "[1.81213447]\n",
      "[1.81642669]\n",
      "[1.71651856]\n",
      "[1.78442996]\n",
      "[1.71245095]\n",
      "tensor([1.7592, 1.8248, 1.8121, 1.8164, 1.7165, 1.7844, 1.7125],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76841763]\n",
      "[1.86425273]\n",
      "[1.96439582]\n",
      "[1.86883621]\n",
      "[1.90578824]\n",
      "[1.85242061]\n",
      "[1.82188836]\n",
      "tensor([1.7684, 1.8643, 1.9644, 1.8688, 1.9058, 1.8524, 1.8219],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92534255]\n",
      "[1.97663194]\n",
      "[1.7994746]\n",
      "[1.75591289]\n",
      "[1.92709976]\n",
      "[1.88043514]\n",
      "[1.97075845]\n",
      "tensor([1.9253, 1.9766, 1.7995, 1.7559, 1.9271, 1.8804, 1.9708],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84081171]\n",
      "[1.81186696]\n",
      "[1.81095467]\n",
      "[1.68599222]\n",
      "[1.91691952]\n",
      "[1.87158691]\n",
      "[1.86088499]\n",
      "tensor([1.8408, 1.8119, 1.8110, 1.6860, 1.9169, 1.8716, 1.8609],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81887094]\n",
      "[1.88515592]\n",
      "[1.82861637]\n",
      "[1.88692251]\n",
      "[1.81294439]\n",
      "[1.79158275]\n",
      "[1.69681849]\n",
      "tensor([1.8189, 1.8852, 1.8286, 1.8869, 1.8129, 1.7916, 1.6968],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95436405]\n",
      "[1.99583368]\n",
      "[1.82136815]\n",
      "[1.87606667]\n",
      "[1.8111468]\n",
      "[1.8728551]\n",
      "[1.74319353]\n",
      "tensor([1.9544, 1.9958, 1.8214, 1.8761, 1.8111, 1.8729, 1.7432],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87836253]\n",
      "[1.81306022]\n",
      "[1.81478592]\n",
      "[1.74919392]\n",
      "[1.84327209]\n",
      "[2.0198773]\n",
      "[1.79618979]\n",
      "tensor([1.8784, 1.8131, 1.8148, 1.7492, 1.8433, 2.0199, 1.7962],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82455346]\n",
      "[1.72602308]\n",
      "[1.95094709]\n",
      "[1.82211477]\n",
      "[1.95094585]\n",
      "[1.87946897]\n",
      "[1.80880122]\n",
      "tensor([1.8246, 1.7260, 1.9509, 1.8221, 1.9509, 1.8795, 1.8088],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89296836]\n",
      "[1.76322201]\n",
      "[1.75943668]\n",
      "[1.74440772]\n",
      "[1.76633931]\n",
      "[1.8657525]\n",
      "[1.72852007]\n",
      "tensor([1.8930, 1.7632, 1.7594, 1.7444, 1.7663, 1.8658, 1.7285],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75684311]\n",
      "[1.88923104]\n",
      "[1.89710241]\n",
      "[1.8066474]\n",
      "[1.87793815]\n",
      "[1.92186198]\n",
      "[1.69225591]\n",
      "tensor([1.7568, 1.8892, 1.8971, 1.8066, 1.8779, 1.9219, 1.6923],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97345851]\n",
      "[1.73026776]\n",
      "[1.93674002]\n",
      "[1.90418794]\n",
      "[1.87855916]\n",
      "[1.96338716]\n",
      "[1.85000221]\n",
      "tensor([1.9735, 1.7303, 1.9367, 1.9042, 1.8786, 1.9634, 1.8500],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77833853]\n",
      "[1.95878583]\n",
      "[1.8642473]\n",
      "[1.93796186]\n",
      "[1.77210909]\n",
      "[1.85330204]\n",
      "[2.00812464]\n",
      "tensor([1.7783, 1.9588, 1.8642, 1.9380, 1.7721, 1.8533, 2.0081],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89682643]\n",
      "[1.79885058]\n",
      "[1.89853663]\n",
      "[1.77377761]\n",
      "[1.90893536]\n",
      "[1.94583703]\n",
      "[1.81474836]\n",
      "tensor([1.8968, 1.7989, 1.8985, 1.7738, 1.9089, 1.9458, 1.8147],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93683362]\n",
      "[1.84765525]\n",
      "[1.77296919]\n",
      "[1.92438346]\n",
      "[1.85588142]\n",
      "[1.72615316]\n",
      "[1.92339681]\n",
      "tensor([1.9368, 1.8477, 1.7730, 1.9244, 1.8559, 1.7262, 1.9234],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86404432]\n",
      "[1.71945933]\n",
      "[1.83114201]\n",
      "[1.79423623]\n",
      "[1.82740468]\n",
      "[1.84651137]\n",
      "[1.85524457]\n",
      "tensor([1.8640, 1.7195, 1.8311, 1.7942, 1.8274, 1.8465, 1.8552],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74128357]\n",
      "[1.78142125]\n",
      "[1.85144669]\n",
      "[1.82036548]\n",
      "[1.7882343]\n",
      "[1.73153995]\n",
      "[1.90557331]\n",
      "tensor([1.7413, 1.7814, 1.8514, 1.8204, 1.7882, 1.7315, 1.9056],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71138921]\n",
      "[1.77483206]\n",
      "[1.76833462]\n",
      "[1.86259916]\n",
      "[1.72135211]\n",
      "[1.73816242]\n",
      "[1.87014768]\n",
      "tensor([1.7114, 1.7748, 1.7683, 1.8626, 1.7214, 1.7382, 1.8701],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88553457]\n",
      "[1.82435314]\n",
      "[1.86759664]\n",
      "[1.78162723]\n",
      "[1.78271898]\n",
      "[1.90413322]\n",
      "[1.76087108]\n",
      "tensor([1.8855, 1.8244, 1.8676, 1.7816, 1.7827, 1.9041, 1.7609],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82682709]\n",
      "[1.90594146]\n",
      "[1.81540408]\n",
      "[1.81879737]\n",
      "[2.03025789]\n",
      "[1.79341942]\n",
      "[2.08553601]\n",
      "tensor([1.8268, 1.9059, 1.8154, 1.8188, 2.0303, 1.7934, 2.0855],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96499334]\n",
      "[2.02782156]\n",
      "[1.74310871]\n",
      "[1.80220999]\n",
      "[1.8086935]\n",
      "[1.93569414]\n",
      "[1.70697722]\n",
      "tensor([1.9650, 2.0278, 1.7431, 1.8022, 1.8087, 1.9357, 1.7070],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98428271]\n",
      "[1.85409143]\n",
      "[1.84957669]\n",
      "[1.8896175]\n",
      "[1.70524467]\n",
      "[1.90191234]\n",
      "[1.86461396]\n",
      "tensor([1.9843, 1.8541, 1.8496, 1.8896, 1.7052, 1.9019, 1.8646],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.01422092]\n",
      "[1.84759468]\n",
      "[1.83713753]\n",
      "[1.84492567]\n",
      "[1.99120679]\n",
      "[1.75297318]\n",
      "[1.82737652]\n",
      "tensor([2.0142, 1.8476, 1.8371, 1.8449, 1.9912, 1.7530, 1.8274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78293104]\n",
      "[1.95567381]\n",
      "[1.88715848]\n",
      "[1.81094164]\n",
      "[1.81093644]\n",
      "[1.82176139]\n",
      "[1.73582234]\n",
      "tensor([1.7829, 1.9557, 1.8872, 1.8109, 1.8109, 1.8218, 1.7358],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93918228]\n",
      "[1.93953548]\n",
      "[1.75397341]\n",
      "[1.78882586]\n",
      "[1.93888009]\n",
      "[1.81801002]\n",
      "[1.9581589]\n",
      "tensor([1.9392, 1.9395, 1.7540, 1.7888, 1.9389, 1.8180, 1.9582],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88592826]\n",
      "[1.86765215]\n",
      "[2.00745427]\n",
      "[1.84948716]\n",
      "[1.71995217]\n",
      "[1.85604384]\n",
      "[1.75224999]\n",
      "tensor([1.8859, 1.8677, 2.0075, 1.8495, 1.7200, 1.8560, 1.7522],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82324429]\n",
      "[1.91043994]\n",
      "[1.84588079]\n",
      "[1.75179568]\n",
      "[1.81032184]\n",
      "[1.79252054]\n",
      "[1.94990736]\n",
      "tensor([1.8232, 1.9104, 1.8459, 1.7518, 1.8103, 1.7925, 1.9499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79905246]\n",
      "[1.83390463]\n",
      "[1.7678915]\n",
      "[1.83175988]\n",
      "[1.80481801]\n",
      "[1.94580402]\n",
      "[1.78930761]\n",
      "tensor([1.7991, 1.8339, 1.7679, 1.8318, 1.8048, 1.9458, 1.7893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86858724]\n",
      "[1.89603554]\n",
      "[1.83725424]\n",
      "[1.94164399]\n",
      "[1.8477806]\n",
      "[1.81910955]\n",
      "[1.92735571]\n",
      "tensor([1.8686, 1.8960, 1.8373, 1.9416, 1.8478, 1.8191, 1.9274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85704491]\n",
      "[1.84087738]\n",
      "[1.82221864]\n",
      "[1.68625954]\n",
      "[1.84692417]\n",
      "[1.93595834]\n",
      "[1.87710603]\n",
      "tensor([1.8570, 1.8409, 1.8222, 1.6863, 1.8469, 1.9360, 1.8771],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79608354]\n",
      "[1.82012803]\n",
      "[1.79224281]\n",
      "[1.76384228]\n",
      "[1.8609394]\n",
      "[1.8832237]\n",
      "[1.77490388]\n",
      "tensor([1.7961, 1.8201, 1.7922, 1.7638, 1.8609, 1.8832, 1.7749],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82522786]\n",
      "[1.85928069]\n",
      "[1.84064643]\n",
      "[1.94771498]\n",
      "[1.89437458]\n",
      "[2.01956604]\n",
      "[1.71789165]\n",
      "tensor([1.8252, 1.8593, 1.8406, 1.9477, 1.8944, 2.0196, 1.7179],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.02795414]\n",
      "[1.70150236]\n",
      "[1.87342848]\n",
      "[1.91355988]\n",
      "[1.75240041]\n",
      "[1.81967869]\n",
      "[1.82256802]\n",
      "tensor([2.0280, 1.7015, 1.8734, 1.9136, 1.7524, 1.8197, 1.8226],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72286043]\n",
      "[1.84859269]\n",
      "[1.78293811]\n",
      "[1.87528322]\n",
      "[1.81014526]\n",
      "[1.87364854]\n",
      "[1.8876706]\n",
      "tensor([1.7229, 1.8486, 1.7829, 1.8753, 1.8101, 1.8736, 1.8877],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80229241]\n",
      "[1.85462838]\n",
      "[1.84265561]\n",
      "[2.02966264]\n",
      "[1.85471196]\n",
      "[1.84919004]\n",
      "[1.95205002]\n",
      "tensor([1.8023, 1.8546, 1.8427, 2.0297, 1.8547, 1.8492, 1.9521],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.01109854]\n",
      "[1.87149163]\n",
      "[1.83798724]\n",
      "[1.7414192]\n",
      "[1.68702253]\n",
      "[1.83755825]\n",
      "[1.84562415]\n",
      "tensor([2.0111, 1.8715, 1.8380, 1.7414, 1.6870, 1.8376, 1.8456],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78568846]\n",
      "[1.88424311]\n",
      "[1.84324181]\n",
      "[1.8012792]\n",
      "[1.8070572]\n",
      "[1.77173713]\n",
      "[1.88032247]\n",
      "tensor([1.7857, 1.8842, 1.8432, 1.8013, 1.8071, 1.7717, 1.8803],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78876058]\n",
      "[1.71514927]\n",
      "[1.78806087]\n",
      "[1.68906398]\n",
      "[1.92099239]\n",
      "[1.76042873]\n",
      "[1.76922339]\n",
      "tensor([1.7888, 1.7151, 1.7881, 1.6891, 1.9210, 1.7604, 1.7692],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88402157]\n",
      "[1.78026543]\n",
      "[1.84656075]\n",
      "[1.83156618]\n",
      "[1.75909832]\n",
      "[1.92329724]\n",
      "[1.86851875]\n",
      "tensor([1.8840, 1.7803, 1.8466, 1.8316, 1.7591, 1.9233, 1.8685],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80415758]\n",
      "[1.81975437]\n",
      "[1.82911767]\n",
      "[1.75497566]\n",
      "[1.74275159]\n",
      "[1.85816168]\n",
      "[1.84851213]\n",
      "tensor([1.8042, 1.8198, 1.8291, 1.7550, 1.7428, 1.8582, 1.8485],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94493009]\n",
      "[1.78047476]\n",
      "[1.90089886]\n",
      "[1.71285323]\n",
      "[1.96962919]\n",
      "[1.77134955]\n",
      "[1.80192044]\n",
      "tensor([1.9449, 1.7805, 1.9009, 1.7129, 1.9696, 1.7713, 1.8019],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.802193]\n",
      "[1.99873292]\n",
      "[1.95769961]\n",
      "[1.80153727]\n",
      "[1.89106123]\n",
      "[1.94016028]\n",
      "[1.81660638]\n",
      "tensor([1.8022, 1.9987, 1.9577, 1.8015, 1.8911, 1.9402, 1.8166],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84180692]\n",
      "[1.99763818]\n",
      "[1.96522995]\n",
      "[1.82471938]\n",
      "[1.87609511]\n",
      "[1.77256068]\n",
      "[1.95597024]\n",
      "tensor([1.8418, 1.9976, 1.9652, 1.8247, 1.8761, 1.7726, 1.9560],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83381355]\n",
      "[1.86755803]\n",
      "[1.99237323]\n",
      "[1.71259124]\n",
      "[1.76188936]\n",
      "[2.03413785]\n",
      "[1.81604595]\n",
      "tensor([1.8338, 1.8676, 1.9924, 1.7126, 1.7619, 2.0341, 1.8160],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85016413]\n",
      "[1.78548481]\n",
      "[1.82996656]\n",
      "[1.94005436]\n",
      "[1.85630671]\n",
      "[1.82193038]\n",
      "[1.78185682]\n",
      "tensor([1.8502, 1.7855, 1.8300, 1.9401, 1.8563, 1.8219, 1.7819],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8319685]\n",
      "[1.88165532]\n",
      "[1.76826653]\n",
      "[1.72609961]\n",
      "[1.83467619]\n",
      "[1.7886517]\n",
      "[1.91684877]\n",
      "tensor([1.8320, 1.8817, 1.7683, 1.7261, 1.8347, 1.7887, 1.9168],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78862216]\n",
      "[1.74269232]\n",
      "[1.94736737]\n",
      "[1.87764429]\n",
      "[1.86567757]\n",
      "[2.00054656]\n",
      "[1.89317544]\n",
      "tensor([1.7886, 1.7427, 1.9474, 1.8776, 1.8657, 2.0005, 1.8932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82054654]\n",
      "[1.76666852]\n",
      "[1.74204324]\n",
      "[1.78571674]\n",
      "[1.87510343]\n",
      "[1.79179492]\n",
      "[1.86033424]\n",
      "tensor([1.8205, 1.7667, 1.7420, 1.7857, 1.8751, 1.7918, 1.8603],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70850325]\n",
      "[1.86762491]\n",
      "[1.85051081]\n",
      "[1.81761056]\n",
      "[1.94042763]\n",
      "[1.75084526]\n",
      "[1.88615636]\n",
      "tensor([1.7085, 1.8676, 1.8505, 1.8176, 1.9404, 1.7508, 1.8862],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.04458905]\n",
      "[1.87127866]\n",
      "[1.91202296]\n",
      "[1.80211315]\n",
      "[2.02384923]\n",
      "[1.67118176]\n",
      "[2.15312081]\n",
      "tensor([2.0446, 1.8713, 1.9120, 1.8021, 2.0238, 1.6712, 2.1531],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78072777]\n",
      "[1.9599144]\n",
      "[1.69580254]\n",
      "[1.85397404]\n",
      "[1.83295341]\n",
      "[1.95865155]\n",
      "[1.78638247]\n",
      "tensor([1.7807, 1.9599, 1.6958, 1.8540, 1.8330, 1.9587, 1.7864],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79035938]\n",
      "[1.92524743]\n",
      "[1.83688868]\n",
      "[1.72252799]\n",
      "[1.79899257]\n",
      "[1.80180252]\n",
      "[1.96582401]\n",
      "tensor([1.7904, 1.9252, 1.8369, 1.7225, 1.7990, 1.8018, 1.9658],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97097462]\n",
      "[1.85115775]\n",
      "[1.69555175]\n",
      "[1.83992118]\n",
      "[2.15177704]\n",
      "[1.98458721]\n",
      "[1.93686192]\n",
      "tensor([1.9710, 1.8512, 1.6956, 1.8399, 2.1518, 1.9846, 1.9369],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71150133]\n",
      "[1.85441856]\n",
      "[1.79552363]\n",
      "[1.71608733]\n",
      "[1.75812997]\n",
      "[1.78036911]\n",
      "[1.81359001]\n",
      "tensor([1.7115, 1.8544, 1.7955, 1.7161, 1.7581, 1.7804, 1.8136],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72780371]\n",
      "[1.85754287]\n",
      "[1.93599172]\n",
      "[1.88700573]\n",
      "[1.89293208]\n",
      "[1.85435562]\n",
      "[1.87702035]\n",
      "tensor([1.7278, 1.8575, 1.9360, 1.8870, 1.8929, 1.8544, 1.8770],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81661559]\n",
      "[1.88148214]\n",
      "[1.80735636]\n",
      "[1.79885501]\n",
      "[1.82857037]\n",
      "[1.66242449]\n",
      "[1.70082912]\n",
      "tensor([1.8166, 1.8815, 1.8074, 1.7989, 1.8286, 1.6624, 1.7008],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83827678]\n",
      "[1.79726168]\n",
      "[1.69654145]\n",
      "[1.91219509]\n",
      "[1.81774278]\n",
      "[1.81342733]\n",
      "[2.01521661]\n",
      "tensor([1.8383, 1.7973, 1.6965, 1.9122, 1.8177, 1.8134, 2.0152],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80767218]\n",
      "[1.80569376]\n",
      "[1.80810026]\n",
      "[2.03470934]\n",
      "[1.86374039]\n",
      "[1.72915691]\n",
      "[1.80447643]\n",
      "tensor([1.8077, 1.8057, 1.8081, 2.0347, 1.8637, 1.7292, 1.8045],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86123921]\n",
      "[1.86967959]\n",
      "[1.81026828]\n",
      "[1.89859756]\n",
      "[1.92462635]\n",
      "[1.77217811]\n",
      "[1.89954705]\n",
      "tensor([1.8612, 1.8697, 1.8103, 1.8986, 1.9246, 1.7722, 1.8995],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05144323]\n",
      "[1.79607721]\n",
      "[1.88120563]\n",
      "[1.77200378]\n",
      "[1.7179981]\n",
      "[1.75568533]\n",
      "[1.83414755]\n",
      "tensor([2.0514, 1.7961, 1.8812, 1.7720, 1.7180, 1.7557, 1.8341],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93182071]\n",
      "[1.88855864]\n",
      "[1.95660094]\n",
      "[1.71712993]\n",
      "[1.79957149]\n",
      "[1.77233606]\n",
      "[1.94796726]\n",
      "tensor([1.9318, 1.8886, 1.9566, 1.7171, 1.7996, 1.7723, 1.9480],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.01074123]\n",
      "[1.75543431]\n",
      "[1.79446188]\n",
      "[1.87585911]\n",
      "[1.82313861]\n",
      "[1.90645099]\n",
      "[1.85047181]\n",
      "tensor([2.0107, 1.7554, 1.7945, 1.8759, 1.8231, 1.9065, 1.8505],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83657914]\n",
      "[1.78754933]\n",
      "[1.74181724]\n",
      "[1.83575111]\n",
      "[1.74131632]\n",
      "[1.80047563]\n",
      "[1.94767235]\n",
      "tensor([1.8366, 1.7875, 1.7418, 1.8358, 1.7413, 1.8005, 1.9477],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88442178]\n",
      "[1.88597153]\n",
      "[1.86149595]\n",
      "[1.78340206]\n",
      "[1.70642364]\n",
      "[1.8046574]\n",
      "[1.92094756]\n",
      "tensor([1.8844, 1.8860, 1.8615, 1.7834, 1.7064, 1.8047, 1.9209],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81423848]\n",
      "[1.80648906]\n",
      "[1.75029548]\n",
      "[1.81067101]\n",
      "[1.79814072]\n",
      "[1.83276211]\n",
      "[1.74167126]\n",
      "tensor([1.8142, 1.8065, 1.7503, 1.8107, 1.7981, 1.8328, 1.7417],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76343812]\n",
      "[2.04663237]\n",
      "[1.99477536]\n",
      "[1.90902019]\n",
      "[2.09754289]\n",
      "[2.0099495]\n",
      "[1.77869412]\n",
      "tensor([1.7634, 2.0466, 1.9948, 1.9090, 2.0975, 2.0099, 1.7787],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74875121]\n",
      "[1.82706922]\n",
      "[1.79414515]\n",
      "[1.92407848]\n",
      "[1.71680244]\n",
      "[1.78084381]\n",
      "[1.76546254]\n",
      "tensor([1.7488, 1.8271, 1.7941, 1.9241, 1.7168, 1.7808, 1.7655],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77011454]\n",
      "[1.83000901]\n",
      "[1.84365211]\n",
      "[1.83936296]\n",
      "[1.88269858]\n",
      "[1.68267576]\n",
      "[1.77840229]\n",
      "tensor([1.7701, 1.8300, 1.8437, 1.8394, 1.8827, 1.6827, 1.7784],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75462534]\n",
      "[1.71829543]\n",
      "[1.84652007]\n",
      "[1.7925036]\n",
      "[1.76606649]\n",
      "[1.81162751]\n",
      "[1.8398815]\n",
      "tensor([1.7546, 1.7183, 1.8465, 1.7925, 1.7661, 1.8116, 1.8399],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88292593]\n",
      "[2.00899469]\n",
      "[1.77715281]\n",
      "[1.82278894]\n",
      "[1.87692006]\n",
      "[1.87016371]\n",
      "[1.79808449]\n",
      "tensor([1.8829, 2.0090, 1.7772, 1.8228, 1.8769, 1.8702, 1.7981],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90610096]\n",
      "[1.80377146]\n",
      "[1.96789221]\n",
      "[1.76011669]\n",
      "[1.68887932]\n",
      "[1.7980381]\n",
      "[1.82249517]\n",
      "tensor([1.9061, 1.8038, 1.9679, 1.7601, 1.6889, 1.7980, 1.8225],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81588842]\n",
      "[1.89852861]\n",
      "[1.77412142]\n",
      "[1.9498725]\n",
      "[1.80639918]\n",
      "[1.94057321]\n",
      "[1.86394122]\n",
      "tensor([1.8159, 1.8985, 1.7741, 1.9499, 1.8064, 1.9406, 1.8639],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76878787]\n",
      "[1.93546866]\n",
      "[1.93647794]\n",
      "[1.94568967]\n",
      "[1.76546981]\n",
      "[1.81679871]\n",
      "[1.87317504]\n",
      "tensor([1.7688, 1.9355, 1.9365, 1.9457, 1.7655, 1.8168, 1.8732],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83647222]\n",
      "[1.78272976]\n",
      "[1.82447733]\n",
      "[1.80923638]\n",
      "[1.80314124]\n",
      "[1.81948068]\n",
      "[1.7909871]\n",
      "tensor([1.8365, 1.7827, 1.8245, 1.8092, 1.8031, 1.8195, 1.7910],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80284007]\n",
      "[1.85407094]\n",
      "[1.79030051]\n",
      "[1.77184595]\n",
      "[1.78796685]\n",
      "[1.99441921]\n",
      "[1.82283273]\n",
      "tensor([1.8028, 1.8541, 1.7903, 1.7718, 1.7880, 1.9944, 1.8228],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.66671123]\n",
      "[1.7936708]\n",
      "[1.74391438]\n",
      "[1.82480689]\n",
      "[1.8287332]\n",
      "[1.82099019]\n",
      "[1.88225414]\n",
      "tensor([1.6667, 1.7937, 1.7439, 1.8248, 1.8287, 1.8210, 1.8823],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82898727]\n",
      "[1.8282055]\n",
      "[1.79087646]\n",
      "[1.8511841]\n",
      "[1.79310563]\n",
      "[1.84323816]\n",
      "[1.98577467]\n",
      "tensor([1.8290, 1.8282, 1.7909, 1.8512, 1.7931, 1.8432, 1.9858],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88134564]\n",
      "[1.74139988]\n",
      "[1.7389011]\n",
      "[1.91818368]\n",
      "[1.72469]\n",
      "[1.82558666]\n",
      "[1.7633681]\n",
      "tensor([1.8813, 1.7414, 1.7389, 1.9182, 1.7247, 1.8256, 1.7634],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87237297]\n",
      "[1.7230486]\n",
      "[1.90415403]\n",
      "[1.83392295]\n",
      "[1.7637868]\n",
      "[1.80870109]\n",
      "[1.76290607]\n",
      "tensor([1.8724, 1.7230, 1.9042, 1.8339, 1.7638, 1.8087, 1.7629],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77814791]\n",
      "[1.88726521]\n",
      "[1.88442733]\n",
      "[1.69042363]\n",
      "[1.87188067]\n",
      "[1.92964721]\n",
      "[1.79425057]\n",
      "tensor([1.7781, 1.8873, 1.8844, 1.6904, 1.8719, 1.9296, 1.7943],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8966991]\n",
      "[1.84646044]\n",
      "[1.81162829]\n",
      "[1.79271072]\n",
      "[1.8471509]\n",
      "[1.83022716]\n",
      "[1.83646803]\n",
      "tensor([1.8967, 1.8465, 1.8116, 1.7927, 1.8472, 1.8302, 1.8365],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9639448]\n",
      "[2.04582529]\n",
      "[1.8829457]\n",
      "[1.87611047]\n",
      "[1.84214082]\n",
      "[1.73693704]\n",
      "[1.80433922]\n",
      "tensor([1.9639, 2.0458, 1.8829, 1.8761, 1.8421, 1.7369, 1.8043],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81617373]\n",
      "[1.83911562]\n",
      "[1.78896226]\n",
      "[1.80077184]\n",
      "[1.81811697]\n",
      "[1.72971619]\n",
      "[1.77476941]\n",
      "tensor([1.8162, 1.8391, 1.7890, 1.8008, 1.8181, 1.7297, 1.7748],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79804201]\n",
      "[1.86338699]\n",
      "[1.78792036]\n",
      "[1.93671529]\n",
      "[1.74158845]\n",
      "[1.77357357]\n",
      "[1.72156324]\n",
      "tensor([1.7980, 1.8634, 1.7879, 1.9367, 1.7416, 1.7736, 1.7216],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.04000678]\n",
      "[1.94713013]\n",
      "[1.88171362]\n",
      "[1.95432376]\n",
      "[1.9286175]\n",
      "[1.79253882]\n",
      "[1.89281476]\n",
      "tensor([2.0400, 1.9471, 1.8817, 1.9543, 1.9286, 1.7925, 1.8928],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.857866]\n",
      "[1.87619907]\n",
      "[1.71226121]\n",
      "[1.91828014]\n",
      "[1.85039984]\n",
      "[1.80237857]\n",
      "[1.83650963]\n",
      "tensor([1.8579, 1.8762, 1.7123, 1.9183, 1.8504, 1.8024, 1.8365],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83439471]\n",
      "[1.80782251]\n",
      "[1.82824729]\n",
      "[1.87687763]\n",
      "[1.8838852]\n",
      "[2.03321359]\n",
      "[1.85628499]\n",
      "tensor([1.8344, 1.8078, 1.8282, 1.8769, 1.8839, 2.0332, 1.8563],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83608273]\n",
      "[1.76121004]\n",
      "[1.83106865]\n",
      "[1.81986574]\n",
      "[1.84834509]\n",
      "[1.81641502]\n",
      "[1.75910954]\n",
      "tensor([1.8361, 1.7612, 1.8311, 1.8199, 1.8483, 1.8164, 1.7591],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80596723]\n",
      "[1.87638299]\n",
      "[1.78890534]\n",
      "[1.90559571]\n",
      "[1.70766971]\n",
      "[1.81066024]\n",
      "[1.89737268]\n",
      "tensor([1.8060, 1.8764, 1.7889, 1.9056, 1.7077, 1.8107, 1.8974],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7799499]\n",
      "[2.12336244]\n",
      "[1.96296383]\n",
      "[1.75228925]\n",
      "[1.74097592]\n",
      "[1.93678114]\n",
      "[1.90798083]\n",
      "tensor([1.7799, 2.1234, 1.9630, 1.7523, 1.7410, 1.9368, 1.9080],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96663379]\n",
      "[1.85398037]\n",
      "[1.89570131]\n",
      "[1.79776501]\n",
      "[1.82487145]\n",
      "[1.97040234]\n",
      "[1.8595543]\n",
      "tensor([1.9666, 1.8540, 1.8957, 1.7978, 1.8249, 1.9704, 1.8596],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83064209]\n",
      "[1.90994693]\n",
      "[1.80557886]\n",
      "[1.71062547]\n",
      "[1.71384894]\n",
      "[1.76433689]\n",
      "[1.92184507]\n",
      "tensor([1.8306, 1.9099, 1.8056, 1.7106, 1.7138, 1.7643, 1.9218],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79112898]\n",
      "[1.76083119]\n",
      "[1.90464925]\n",
      "[1.88520017]\n",
      "[1.72300237]\n",
      "[1.86433375]\n",
      "[1.79111627]\n",
      "tensor([1.7911, 1.7608, 1.9046, 1.8852, 1.7230, 1.8643, 1.7911],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83703369]\n",
      "[1.74907439]\n",
      "[1.97794527]\n",
      "[1.90759569]\n",
      "[1.70112556]\n",
      "[1.81436844]\n",
      "[1.67000866]\n",
      "tensor([1.8370, 1.7491, 1.9779, 1.9076, 1.7011, 1.8144, 1.6700],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96585277]\n",
      "[1.83464528]\n",
      "[1.75857971]\n",
      "[1.74563658]\n",
      "[1.96989757]\n",
      "[1.82745915]\n",
      "[1.78990874]\n",
      "tensor([1.9659, 1.8346, 1.7586, 1.7456, 1.9699, 1.8275, 1.7899],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7490559]\n",
      "[1.82089701]\n",
      "[2.04089636]\n",
      "[1.84176502]\n",
      "[1.74899195]\n",
      "[1.81939263]\n",
      "[1.74429823]\n",
      "tensor([1.7491, 1.8209, 2.0409, 1.8418, 1.7490, 1.8194, 1.7443],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78357336]\n",
      "[1.75965613]\n",
      "[1.92359756]\n",
      "[1.92251303]\n",
      "[1.85371432]\n",
      "[1.87103837]\n",
      "[1.81585124]\n",
      "tensor([1.7836, 1.7597, 1.9236, 1.9225, 1.8537, 1.8710, 1.8159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83602718]\n",
      "[1.84091094]\n",
      "[1.96698027]\n",
      "[1.77771196]\n",
      "[1.90056322]\n",
      "[1.81639341]\n",
      "[1.75322019]\n",
      "tensor([1.8360, 1.8409, 1.9670, 1.7777, 1.9006, 1.8164, 1.7532],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87777267]\n",
      "[1.82762727]\n",
      "[1.79666573]\n",
      "[1.8170554]\n",
      "[1.79347792]\n",
      "[1.76708231]\n",
      "[1.86460504]\n",
      "tensor([1.8778, 1.8276, 1.7967, 1.8171, 1.7935, 1.7671, 1.8646],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79603288]\n",
      "[1.71350828]\n",
      "[2.0102527]\n",
      "[1.907481]\n",
      "[1.89722071]\n",
      "[1.72522259]\n",
      "[1.7443499]\n",
      "tensor([1.7960, 1.7135, 2.0103, 1.9075, 1.8972, 1.7252, 1.7443],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84336544]\n",
      "[1.97628664]\n",
      "[1.80579382]\n",
      "[1.81133857]\n",
      "[1.81950083]\n",
      "[1.80224422]\n",
      "[1.79315651]\n",
      "tensor([1.8434, 1.9763, 1.8058, 1.8113, 1.8195, 1.8022, 1.7932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.0014062]\n",
      "[1.90860699]\n",
      "[1.80183355]\n",
      "[1.8479641]\n",
      "[1.82514898]\n",
      "[1.78638866]\n",
      "[1.89300109]\n",
      "tensor([2.0014, 1.9086, 1.8018, 1.8480, 1.8251, 1.7864, 1.8930],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84022891]\n",
      "[1.93549756]\n",
      "[1.77744348]\n",
      "[1.86718583]\n",
      "[1.73939131]\n",
      "[1.87548275]\n",
      "[1.8543239]\n",
      "tensor([1.8402, 1.9355, 1.7774, 1.8672, 1.7394, 1.8755, 1.8543],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93747469]\n",
      "[1.83477436]\n",
      "[1.87773957]\n",
      "[1.95417634]\n",
      "[1.83288507]\n",
      "[1.80393016]\n",
      "[1.84736063]\n",
      "tensor([1.9375, 1.8348, 1.8777, 1.9542, 1.8329, 1.8039, 1.8474],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79621304]\n",
      "[1.87776516]\n",
      "[1.87780932]\n",
      "[1.75881957]\n",
      "[1.90763089]\n",
      "[1.82726783]\n",
      "[1.86869857]\n",
      "tensor([1.7962, 1.8778, 1.8778, 1.7588, 1.9076, 1.8273, 1.8687],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79934689]\n",
      "[1.7921871]\n",
      "[1.89861244]\n",
      "[1.81480561]\n",
      "[1.77674141]\n",
      "[1.82603161]\n",
      "[1.90590706]\n",
      "tensor([1.7993, 1.7922, 1.8986, 1.8148, 1.7767, 1.8260, 1.9059],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84330574]\n",
      "[1.83428249]\n",
      "[1.83302089]\n",
      "[1.91402614]\n",
      "[1.91823573]\n",
      "[1.86148876]\n",
      "[1.83407196]\n",
      "tensor([1.8433, 1.8343, 1.8330, 1.9140, 1.9182, 1.8615, 1.8341],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84540105]\n",
      "[1.69686117]\n",
      "[1.8689422]\n",
      "[1.92025246]\n",
      "[1.70115975]\n",
      "[1.91487023]\n",
      "[1.81826335]\n",
      "tensor([1.8454, 1.6969, 1.8689, 1.9203, 1.7012, 1.9149, 1.8183],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91349252]\n",
      "[1.83771197]\n",
      "[1.80402604]\n",
      "[1.8001537]\n",
      "[1.86226242]\n",
      "[1.75307118]\n",
      "[1.79035937]\n",
      "tensor([1.9135, 1.8377, 1.8040, 1.8002, 1.8623, 1.7531, 1.7904],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87731739]\n",
      "[1.83262106]\n",
      "[1.73077563]\n",
      "[1.66108565]\n",
      "[1.8912377]\n",
      "[1.81951414]\n",
      "[1.80912054]\n",
      "tensor([1.8773, 1.8326, 1.7308, 1.6611, 1.8912, 1.8195, 1.8091],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90308433]\n",
      "[1.83100449]\n",
      "[1.92645882]\n",
      "[1.92241715]\n",
      "[1.82768048]\n",
      "[1.84298528]\n",
      "[1.79813614]\n",
      "tensor([1.9031, 1.8310, 1.9265, 1.9224, 1.8277, 1.8430, 1.7981],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78365955]\n",
      "[1.79835466]\n",
      "[1.81000774]\n",
      "[1.81361608]\n",
      "[1.93770143]\n",
      "[1.72424104]\n",
      "[1.88002936]\n",
      "tensor([1.7837, 1.7984, 1.8100, 1.8136, 1.9377, 1.7242, 1.8800],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94044092]\n",
      "[1.89773824]\n",
      "[1.83245583]\n",
      "[1.85897722]\n",
      "[1.79995935]\n",
      "[1.74099535]\n",
      "[2.00960584]\n",
      "tensor([1.9404, 1.8977, 1.8325, 1.8590, 1.8000, 1.7410, 2.0096],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93731049]\n",
      "[1.81902534]\n",
      "[2.04509621]\n",
      "[1.69428403]\n",
      "[1.87820721]\n",
      "[1.95390365]\n",
      "[1.83290893]\n",
      "tensor([1.9373, 1.8190, 2.0451, 1.6943, 1.8782, 1.9539, 1.8329],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79291015]\n",
      "[1.85686097]\n",
      "[1.80807998]\n",
      "[1.83452863]\n",
      "[2.03849487]\n",
      "[1.81650028]\n",
      "[1.77891182]\n",
      "tensor([1.7929, 1.8569, 1.8081, 1.8345, 2.0385, 1.8165, 1.7789],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82267412]\n",
      "[1.70740503]\n",
      "[1.8179543]\n",
      "[1.79128746]\n",
      "[1.76395714]\n",
      "[1.83043291]\n",
      "[1.89362717]\n",
      "tensor([1.8227, 1.7074, 1.8180, 1.7913, 1.7640, 1.8304, 1.8936],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71080325]\n",
      "[1.92484713]\n",
      "[1.90314951]\n",
      "[1.7202733]\n",
      "[1.96114694]\n",
      "[1.77143506]\n",
      "[1.96434008]\n",
      "tensor([1.7108, 1.9248, 1.9031, 1.7203, 1.9611, 1.7714, 1.9643],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81436746]\n",
      "[1.79414064]\n",
      "[1.91215469]\n",
      "[1.70020837]\n",
      "[1.79371079]\n",
      "[1.89965907]\n",
      "[1.70604537]\n",
      "tensor([1.8144, 1.7941, 1.9122, 1.7002, 1.7937, 1.8997, 1.7060],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84999114]\n",
      "[1.93073208]\n",
      "[1.89267221]\n",
      "[1.89266264]\n",
      "[1.90971341]\n",
      "[1.82934096]\n",
      "[1.82973062]\n",
      "tensor([1.8500, 1.9307, 1.8927, 1.8927, 1.9097, 1.8293, 1.8297],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81854011]\n",
      "[1.8212701]\n",
      "[1.72585392]\n",
      "[1.82886953]\n",
      "[1.86947119]\n",
      "[1.77228366]\n",
      "[1.83422193]\n",
      "tensor([1.8185, 1.8213, 1.7259, 1.8289, 1.8695, 1.7723, 1.8342],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81299375]\n",
      "[1.84006913]\n",
      "[1.79439558]\n",
      "[1.94158581]\n",
      "[1.85957655]\n",
      "[1.83552549]\n",
      "[1.71054834]\n",
      "tensor([1.8130, 1.8401, 1.7944, 1.9416, 1.8596, 1.8355, 1.7105],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78887749]\n",
      "[1.83020996]\n",
      "[1.8046199]\n",
      "[1.77016422]\n",
      "[2.00809923]\n",
      "[1.81610063]\n",
      "[1.77586901]\n",
      "tensor([1.7889, 1.8302, 1.8046, 1.7702, 2.0081, 1.8161, 1.7759],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74239752]\n",
      "[1.8232213]\n",
      "[2.01646709]\n",
      "[1.76655253]\n",
      "[1.81977781]\n",
      "[1.80907766]\n",
      "[1.8747203]\n",
      "tensor([1.7424, 1.8232, 2.0165, 1.7666, 1.8198, 1.8091, 1.8747],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9467357]\n",
      "[1.85091235]\n",
      "[1.89374318]\n",
      "[1.84017]\n",
      "[1.96130119]\n",
      "[1.68354962]\n",
      "[1.93579639]\n",
      "tensor([1.9467, 1.8509, 1.8937, 1.8402, 1.9613, 1.6835, 1.9358],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80023491]\n",
      "[1.82554988]\n",
      "[1.83180882]\n",
      "[1.88061087]\n",
      "[1.91149341]\n",
      "[1.77591925]\n",
      "[1.88597055]\n",
      "tensor([1.8002, 1.8255, 1.8318, 1.8806, 1.9115, 1.7759, 1.8860],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77783747]\n",
      "[1.84266214]\n",
      "[1.82595528]\n",
      "[1.8648386]\n",
      "[2.13333045]\n",
      "[1.77161889]\n",
      "[1.85328148]\n",
      "tensor([1.7778, 1.8427, 1.8260, 1.8648, 2.1333, 1.7716, 1.8533],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.10895488]\n",
      "[1.8249419]\n",
      "[1.8374759]\n",
      "[1.76796574]\n",
      "[1.89443167]\n",
      "[1.81251892]\n",
      "[1.80872469]\n",
      "tensor([2.1090, 1.8249, 1.8375, 1.7680, 1.8944, 1.8125, 1.8087],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94180627]\n",
      "[1.80936675]\n",
      "[1.8507893]\n",
      "[1.84673092]\n",
      "[1.85445251]\n",
      "[1.81595212]\n",
      "[2.09493823]\n",
      "tensor([1.9418, 1.8094, 1.8508, 1.8467, 1.8545, 1.8160, 2.0949],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81938027]\n",
      "[1.70610432]\n",
      "[1.8278982]\n",
      "[2.02162365]\n",
      "[1.75443388]\n",
      "[1.72357838]\n",
      "[1.81741436]\n",
      "tensor([1.8194, 1.7061, 1.8279, 2.0216, 1.7544, 1.7236, 1.8174],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79669774]\n",
      "[1.81990679]\n",
      "[1.84205513]\n",
      "[1.68532577]\n",
      "[1.94767981]\n",
      "[1.92725887]\n",
      "[1.89548802]\n",
      "tensor([1.7967, 1.8199, 1.8421, 1.6853, 1.9477, 1.9273, 1.8955],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73902166]\n",
      "[1.96128631]\n",
      "[1.89700902]\n",
      "[1.87988673]\n",
      "[1.77612762]\n",
      "[1.92937675]\n",
      "[1.82120482]\n",
      "tensor([1.7390, 1.9613, 1.8970, 1.8799, 1.7761, 1.9294, 1.8212],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7526548]\n",
      "[1.79424729]\n",
      "[1.75932225]\n",
      "[1.79706529]\n",
      "[1.92884947]\n",
      "[1.9634619]\n",
      "[1.79058451]\n",
      "tensor([1.7527, 1.7942, 1.7593, 1.7971, 1.9288, 1.9635, 1.7906],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77603542]\n",
      "[1.85878027]\n",
      "[1.76408851]\n",
      "[1.89912949]\n",
      "[1.7594565]\n",
      "[1.86777193]\n",
      "[1.8627906]\n",
      "tensor([1.7760, 1.8588, 1.7641, 1.8991, 1.7595, 1.8678, 1.8628],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94691394]\n",
      "[1.88853627]\n",
      "[1.85377542]\n",
      "[1.80670632]\n",
      "[1.76383396]\n",
      "[1.70045473]\n",
      "[1.95686265]\n",
      "tensor([1.9469, 1.8885, 1.8538, 1.8067, 1.7638, 1.7005, 1.9569],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72417303]\n",
      "[1.92581291]\n",
      "[1.97566786]\n",
      "[1.81383818]\n",
      "[1.69841611]\n",
      "[1.74288278]\n",
      "[1.69756677]\n",
      "tensor([1.7242, 1.9258, 1.9757, 1.8138, 1.6984, 1.7429, 1.6976],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78636677]\n",
      "[1.78843428]\n",
      "[2.03523495]\n",
      "[1.89734061]\n",
      "[1.9761272]\n",
      "[1.88912866]\n",
      "[1.71835676]\n",
      "tensor([1.7864, 1.7884, 2.0352, 1.8973, 1.9761, 1.8891, 1.7184],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92587477]\n",
      "[1.80802931]\n",
      "[1.74746069]\n",
      "[1.71622834]\n",
      "[1.80255627]\n",
      "[1.96569771]\n",
      "[1.87614568]\n",
      "tensor([1.9259, 1.8080, 1.7475, 1.7162, 1.8026, 1.9657, 1.8761],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88512992]\n",
      "[1.71359066]\n",
      "[1.84778866]\n",
      "[1.748377]\n",
      "[1.77964889]\n",
      "[1.90572671]\n",
      "[1.71078624]\n",
      "tensor([1.8851, 1.7136, 1.8478, 1.7484, 1.7796, 1.9057, 1.7108],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8505829]\n",
      "[1.94097096]\n",
      "[1.77519717]\n",
      "[1.87704395]\n",
      "[1.71008582]\n",
      "[1.84615578]\n",
      "[1.82464424]\n",
      "tensor([1.8506, 1.9410, 1.7752, 1.8770, 1.7101, 1.8462, 1.8246],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73414125]\n",
      "[1.80081955]\n",
      "[1.81687167]\n",
      "[1.80633845]\n",
      "[1.71367216]\n",
      "[1.91439176]\n",
      "[1.9032783]\n",
      "tensor([1.7341, 1.8008, 1.8169, 1.8063, 1.7137, 1.9144, 1.9033],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83155825]\n",
      "[1.76588716]\n",
      "[1.77459598]\n",
      "[1.78847142]\n",
      "[1.90527084]\n",
      "[2.06697224]\n",
      "[1.82673872]\n",
      "tensor([1.8316, 1.7659, 1.7746, 1.7885, 1.9053, 2.0670, 1.8267],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79345903]\n",
      "[1.8266078]\n",
      "[1.93565693]\n",
      "[1.90923117]\n",
      "[1.89209615]\n",
      "[1.82690417]\n",
      "[1.8356301]\n",
      "tensor([1.7935, 1.8266, 1.9357, 1.9092, 1.8921, 1.8269, 1.8356],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74839086]\n",
      "[1.77393641]\n",
      "[1.8351]\n",
      "[1.83289703]\n",
      "[1.79740708]\n",
      "[2.00901123]\n",
      "[1.76728798]\n",
      "tensor([1.7484, 1.7739, 1.8351, 1.8329, 1.7974, 2.0090, 1.7673],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84661351]\n",
      "[1.7894525]\n",
      "[2.06698622]\n",
      "[1.8268402]\n",
      "[1.88674139]\n",
      "[1.87541848]\n",
      "[1.92494091]\n",
      "tensor([1.8466, 1.7895, 2.0670, 1.8268, 1.8867, 1.8754, 1.9249],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7595591]\n",
      "[1.79116505]\n",
      "[1.80022689]\n",
      "[1.72836392]\n",
      "[1.82284406]\n",
      "[1.71678834]\n",
      "[1.80866796]\n",
      "tensor([1.7596, 1.7912, 1.8002, 1.7284, 1.8228, 1.7168, 1.8087],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71743398]\n",
      "[1.67781041]\n",
      "[2.02048149]\n",
      "[1.83513473]\n",
      "[1.72461445]\n",
      "[1.83928893]\n",
      "[1.84367743]\n",
      "tensor([1.7174, 1.6778, 2.0205, 1.8351, 1.7246, 1.8393, 1.8437],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92298856]\n",
      "[1.88502507]\n",
      "[1.7776641]\n",
      "[1.71920807]\n",
      "[1.81588433]\n",
      "[1.72820839]\n",
      "[1.85108137]\n",
      "tensor([1.9230, 1.8850, 1.7777, 1.7192, 1.8159, 1.7282, 1.8511],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77782764]\n",
      "[1.82113448]\n",
      "[1.83735292]\n",
      "[1.8245286]\n",
      "[1.92886264]\n",
      "[1.99575579]\n",
      "[1.79948788]\n",
      "tensor([1.7778, 1.8211, 1.8374, 1.8245, 1.9289, 1.9958, 1.7995],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80289432]\n",
      "[1.75765539]\n",
      "[1.8635173]\n",
      "[1.82480867]\n",
      "[1.82096662]\n",
      "[1.85557332]\n",
      "[1.74126395]\n",
      "tensor([1.8029, 1.7577, 1.8635, 1.8248, 1.8210, 1.8556, 1.7413],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73241591]\n",
      "[1.78686087]\n",
      "[1.79900866]\n",
      "[1.94840495]\n",
      "[1.80333672]\n",
      "[1.9223644]\n",
      "[1.80304946]\n",
      "tensor([1.7324, 1.7869, 1.7990, 1.9484, 1.8033, 1.9224, 1.8030],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92715384]\n",
      "[1.81473199]\n",
      "[1.88017268]\n",
      "[1.76881968]\n",
      "[1.72148687]\n",
      "[1.79462155]\n",
      "[1.86780254]\n",
      "tensor([1.9272, 1.8147, 1.8802, 1.7688, 1.7215, 1.7946, 1.8678],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96430903]\n",
      "[1.90171696]\n",
      "[1.77909791]\n",
      "[1.89285589]\n",
      "[2.16400322]\n",
      "[1.81548931]\n",
      "[1.7315452]\n",
      "tensor([1.9643, 1.9017, 1.7791, 1.8929, 2.1640, 1.8155, 1.7315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85729112]\n",
      "[1.96085814]\n",
      "[1.79108531]\n",
      "[1.77863889]\n",
      "[1.8208349]\n",
      "[1.9003732]\n",
      "[1.71836826]\n",
      "tensor([1.8573, 1.9609, 1.7911, 1.7786, 1.8208, 1.9004, 1.7184],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79170243]\n",
      "[1.85040619]\n",
      "[1.78566676]\n",
      "[1.74310057]\n",
      "[1.79887666]\n",
      "[1.83772151]\n",
      "[1.88360056]\n",
      "tensor([1.7917, 1.8504, 1.7857, 1.7431, 1.7989, 1.8377, 1.8836],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80349941]\n",
      "[1.8842035]\n",
      "[1.80848715]\n",
      "[1.8246476]\n",
      "[1.82901775]\n",
      "[1.82257679]\n",
      "[1.81908796]\n",
      "tensor([1.8035, 1.8842, 1.8085, 1.8246, 1.8290, 1.8226, 1.8191],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88496473]\n",
      "[1.80623448]\n",
      "[1.81636562]\n",
      "[1.82431201]\n",
      "[1.79416438]\n",
      "[1.75374374]\n",
      "[2.07187302]\n",
      "tensor([1.8850, 1.8062, 1.8164, 1.8243, 1.7942, 1.7537, 2.0719],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87399344]\n",
      "[1.98465374]\n",
      "[1.81339465]\n",
      "[1.78996009]\n",
      "[1.76168529]\n",
      "[1.773153]\n",
      "[1.82229376]\n",
      "tensor([1.8740, 1.9847, 1.8134, 1.7900, 1.7617, 1.7732, 1.8223],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84156809]\n",
      "[1.8269542]\n",
      "[1.84054816]\n",
      "[1.87008014]\n",
      "[1.79083775]\n",
      "[1.82435209]\n",
      "[1.86649911]\n",
      "tensor([1.8416, 1.8270, 1.8405, 1.8701, 1.7908, 1.8244, 1.8665],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77862557]\n",
      "[1.94207262]\n",
      "[1.90050616]\n",
      "[1.70152172]\n",
      "[1.71395761]\n",
      "[1.73878137]\n",
      "[1.87046205]\n",
      "tensor([1.7786, 1.9421, 1.9005, 1.7015, 1.7140, 1.7388, 1.8705],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73844962]\n",
      "[1.77894264]\n",
      "[1.85225937]\n",
      "[1.78289884]\n",
      "[1.96470045]\n",
      "[1.87333115]\n",
      "[1.80221904]\n",
      "tensor([1.7384, 1.7789, 1.8523, 1.7829, 1.9647, 1.8733, 1.8022],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80499562]\n",
      "[1.74272258]\n",
      "[1.81041105]\n",
      "[1.83146352]\n",
      "[1.82996573]\n",
      "[1.80220345]\n",
      "[1.80593058]\n",
      "tensor([1.8050, 1.7427, 1.8104, 1.8315, 1.8300, 1.8022, 1.8059],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81598366]\n",
      "[1.77665861]\n",
      "[1.83371251]\n",
      "[1.78412732]\n",
      "[1.85772843]\n",
      "[1.7598188]\n",
      "[2.00818147]\n",
      "tensor([1.8160, 1.7767, 1.8337, 1.7841, 1.8577, 1.7598, 2.0082],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85376083]\n",
      "[1.77753267]\n",
      "[1.81719488]\n",
      "[1.83195195]\n",
      "[1.817512]\n",
      "[1.85848077]\n",
      "[1.7569002]\n",
      "tensor([1.8538, 1.7775, 1.8172, 1.8320, 1.8175, 1.8585, 1.7569],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79261172]\n",
      "[1.74059806]\n",
      "[1.85277063]\n",
      "[1.83279645]\n",
      "[1.86801734]\n",
      "[1.88990285]\n",
      "[1.78497694]\n",
      "tensor([1.7926, 1.7406, 1.8528, 1.8328, 1.8680, 1.8899, 1.7850],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91228046]\n",
      "[1.80325319]\n",
      "[1.841672]\n",
      "[1.84816846]\n",
      "[1.856901]\n",
      "[1.93783454]\n",
      "[1.82717474]\n",
      "tensor([1.9123, 1.8033, 1.8417, 1.8482, 1.8569, 1.9378, 1.8272],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86650881]\n",
      "[1.76883966]\n",
      "[1.91228738]\n",
      "[1.9335961]\n",
      "[1.85108014]\n",
      "[1.74147776]\n",
      "[1.80977113]\n",
      "tensor([1.8665, 1.7688, 1.9123, 1.9336, 1.8511, 1.7415, 1.8098],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8994512]\n",
      "[1.86707376]\n",
      "[1.84283734]\n",
      "[1.80699893]\n",
      "[1.74157273]\n",
      "[1.88093397]\n",
      "[1.94104764]\n",
      "tensor([1.8995, 1.8671, 1.8428, 1.8070, 1.7416, 1.8809, 1.9410],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82006085]\n",
      "[1.85945446]\n",
      "[1.81224092]\n",
      "[1.85149137]\n",
      "[1.78281236]\n",
      "[1.8501729]\n",
      "[1.79316676]\n",
      "tensor([1.8201, 1.8595, 1.8122, 1.8515, 1.7828, 1.8502, 1.7932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77928061]\n",
      "[1.81545044]\n",
      "[1.80730816]\n",
      "[1.82450863]\n",
      "[1.89477925]\n",
      "[1.92496746]\n",
      "[1.7918597]\n",
      "tensor([1.7793, 1.8155, 1.8073, 1.8245, 1.8948, 1.9250, 1.7919],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79075604]\n",
      "[1.83613572]\n",
      "[1.76641141]\n",
      "[1.84422975]\n",
      "[1.87034411]\n",
      "[1.88786933]\n",
      "[1.79157611]\n",
      "tensor([1.7908, 1.8361, 1.7664, 1.8442, 1.8703, 1.8879, 1.7916],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80505772]\n",
      "[1.83279979]\n",
      "[1.76489463]\n",
      "[1.91446106]\n",
      "[1.81976267]\n",
      "[1.88482524]\n",
      "[1.73978903]\n",
      "tensor([1.8051, 1.8328, 1.7649, 1.9145, 1.8198, 1.8848, 1.7398],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79454913]\n",
      "[1.89044716]\n",
      "[1.97426282]\n",
      "[1.88283966]\n",
      "[1.97759746]\n",
      "[1.82760307]\n",
      "[1.87120414]\n",
      "tensor([1.7945, 1.8904, 1.9743, 1.8828, 1.9776, 1.8276, 1.8712],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85493532]\n",
      "[1.82664434]\n",
      "[1.89084243]\n",
      "[1.80750929]\n",
      "[1.84342625]\n",
      "[1.82964267]\n",
      "[1.86436337]\n",
      "tensor([1.8549, 1.8266, 1.8908, 1.8075, 1.8434, 1.8296, 1.8644],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70936954]\n",
      "[1.89533]\n",
      "[1.84931588]\n",
      "[1.78537335]\n",
      "[1.87332137]\n",
      "[1.85595316]\n",
      "[1.69014998]\n",
      "tensor([1.7094, 1.8953, 1.8493, 1.7854, 1.8733, 1.8560, 1.6901],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72938315]\n",
      "[1.78036678]\n",
      "[1.79107382]\n",
      "[1.83069113]\n",
      "[1.75660625]\n",
      "[1.80435551]\n",
      "[1.86338763]\n",
      "tensor([1.7294, 1.7804, 1.7911, 1.8307, 1.7566, 1.8044, 1.8634],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82928512]\n",
      "[1.97240849]\n",
      "[1.82129959]\n",
      "[1.81140377]\n",
      "[1.86183311]\n",
      "[1.86982004]\n",
      "[1.82913101]\n",
      "tensor([1.8293, 1.9724, 1.8213, 1.8114, 1.8618, 1.8698, 1.8291],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80355945]\n",
      "[1.81529279]\n",
      "[2.04099866]\n",
      "[1.95241351]\n",
      "[1.86941392]\n",
      "[1.83049852]\n",
      "[1.99306209]\n",
      "tensor([1.8036, 1.8153, 2.0410, 1.9524, 1.8694, 1.8305, 1.9931],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7720592]\n",
      "[1.7017603]\n",
      "[1.75481295]\n",
      "[1.936409]\n",
      "[1.72552707]\n",
      "[1.77556333]\n",
      "[1.87250451]\n",
      "tensor([1.7721, 1.7018, 1.7548, 1.9364, 1.7255, 1.7756, 1.8725],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81343393]\n",
      "[1.79227808]\n",
      "[1.8188989]\n",
      "[1.80769076]\n",
      "[1.89435708]\n",
      "[1.88153093]\n",
      "[2.00653122]\n",
      "tensor([1.8134, 1.7923, 1.8189, 1.8077, 1.8944, 1.8815, 2.0065],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90782366]\n",
      "[1.79291535]\n",
      "[1.81562041]\n",
      "[1.80911059]\n",
      "[1.82611622]\n",
      "[1.84264841]\n",
      "[2.02856256]\n",
      "tensor([1.9078, 1.7929, 1.8156, 1.8091, 1.8261, 1.8426, 2.0286],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88164551]\n",
      "[1.76658014]\n",
      "[1.81028686]\n",
      "[1.83968032]\n",
      "[1.76771472]\n",
      "[1.75019202]\n",
      "[1.91260146]\n",
      "tensor([1.8816, 1.7666, 1.8103, 1.8397, 1.7677, 1.7502, 1.9126],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76475136]\n",
      "[1.7798575]\n",
      "[1.75943784]\n",
      "[1.92287607]\n",
      "[1.86445553]\n",
      "[1.8943259]\n",
      "[1.71109604]\n",
      "tensor([1.7648, 1.7799, 1.7594, 1.9229, 1.8645, 1.8943, 1.7111],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83995555]\n",
      "[1.82446142]\n",
      "[1.73282075]\n",
      "[1.71390823]\n",
      "[1.74344317]\n",
      "[1.7782995]\n",
      "[1.81893638]\n",
      "tensor([1.8400, 1.8245, 1.7328, 1.7139, 1.7434, 1.7783, 1.8189],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76314028]\n",
      "[1.97904722]\n",
      "[1.9371846]\n",
      "[1.87309241]\n",
      "[1.93693629]\n",
      "[1.9192259]\n",
      "[1.83284256]\n",
      "tensor([1.7631, 1.9790, 1.9372, 1.8731, 1.9369, 1.9192, 1.8328],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81644514]\n",
      "[1.70387176]\n",
      "[1.8997249]\n",
      "[1.91595376]\n",
      "[1.89030113]\n",
      "[1.81315097]\n",
      "[1.77961409]\n",
      "tensor([1.8164, 1.7039, 1.8997, 1.9160, 1.8903, 1.8132, 1.7796],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73290557]\n",
      "[1.83511323]\n",
      "[1.87529832]\n",
      "[1.94106683]\n",
      "[1.89763483]\n",
      "[1.82025921]\n",
      "[1.84389505]\n",
      "tensor([1.7329, 1.8351, 1.8753, 1.9411, 1.8976, 1.8203, 1.8439],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89336964]\n",
      "[1.81884838]\n",
      "[1.74872768]\n",
      "[1.82149193]\n",
      "[1.79623541]\n",
      "[1.80153912]\n",
      "[1.81645432]\n",
      "tensor([1.8934, 1.8188, 1.7487, 1.8215, 1.7962, 1.8015, 1.8165],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86933088]\n",
      "[1.82652777]\n",
      "[1.86823982]\n",
      "[1.79351866]\n",
      "[1.93729451]\n",
      "[1.88091277]\n",
      "[1.98338026]\n",
      "tensor([1.8693, 1.8265, 1.8682, 1.7935, 1.9373, 1.8809, 1.9834],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88195084]\n",
      "[1.86188496]\n",
      "[2.09546794]\n",
      "[1.83760304]\n",
      "[1.88273094]\n",
      "[1.75886554]\n",
      "[1.82339439]\n",
      "tensor([1.8820, 1.8619, 2.0955, 1.8376, 1.8827, 1.7589, 1.8234],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80490778]\n",
      "[1.81916828]\n",
      "[1.80489678]\n",
      "[1.86393426]\n",
      "[1.90425888]\n",
      "[1.84217901]\n",
      "[1.8478969]\n",
      "tensor([1.8049, 1.8192, 1.8049, 1.8639, 1.9043, 1.8422, 1.8479],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82295186]\n",
      "[1.879584]\n",
      "[1.83238424]\n",
      "[1.81541898]\n",
      "[2.00662914]\n",
      "[1.85407764]\n",
      "[1.83399301]\n",
      "tensor([1.8230, 1.8796, 1.8324, 1.8154, 2.0066, 1.8541, 1.8340],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94481094]\n",
      "[1.80644437]\n",
      "[1.92769498]\n",
      "[1.85220388]\n",
      "[2.00352455]\n",
      "[1.94219359]\n",
      "[1.75358515]\n",
      "tensor([1.9448, 1.8064, 1.9277, 1.8522, 2.0035, 1.9422, 1.7536],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.68707328]\n",
      "[1.90361646]\n",
      "[1.86558977]\n",
      "[1.88362154]\n",
      "[1.8641834]\n",
      "[1.70789998]\n",
      "[1.86266285]\n",
      "tensor([1.6871, 1.9036, 1.8656, 1.8836, 1.8642, 1.7079, 1.8627],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78051209]\n",
      "[1.96528264]\n",
      "[1.89991233]\n",
      "[1.89203244]\n",
      "[1.80261608]\n",
      "[1.9262722]\n",
      "[1.92521495]\n",
      "tensor([1.7805, 1.9653, 1.8999, 1.8920, 1.8026, 1.9263, 1.9252],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81410009]\n",
      "[1.86879722]\n",
      "[1.74360965]\n",
      "[2.06079977]\n",
      "[1.84215136]\n",
      "[1.7385797]\n",
      "[1.83034092]\n",
      "tensor([1.8141, 1.8688, 1.7436, 2.0608, 1.8422, 1.7386, 1.8303],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74970652]\n",
      "[1.72079836]\n",
      "[1.84855173]\n",
      "[1.83270656]\n",
      "[1.89356274]\n",
      "[1.70932078]\n",
      "[1.84031264]\n",
      "tensor([1.7497, 1.7208, 1.8486, 1.8327, 1.8936, 1.7093, 1.8403],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77570418]\n",
      "[1.80770648]\n",
      "[1.86402039]\n",
      "[1.90175158]\n",
      "[1.82837293]\n",
      "[1.7724932]\n",
      "[1.85057134]\n",
      "tensor([1.7757, 1.8077, 1.8640, 1.9018, 1.8284, 1.7725, 1.8506],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7757396]\n",
      "[1.80456743]\n",
      "[1.70075085]\n",
      "[1.79911435]\n",
      "[1.7514082]\n",
      "[1.85047931]\n",
      "[1.98816477]\n",
      "tensor([1.7757, 1.8046, 1.7008, 1.7991, 1.7514, 1.8505, 1.9882],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87111573]\n",
      "[1.81943214]\n",
      "[1.80674873]\n",
      "[1.89405492]\n",
      "[1.86745046]\n",
      "[1.81377453]\n",
      "[1.79747797]\n",
      "tensor([1.8711, 1.8194, 1.8067, 1.8941, 1.8675, 1.8138, 1.7975],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91634947]\n",
      "[1.80697525]\n",
      "[1.84586328]\n",
      "[1.78477629]\n",
      "[1.83634213]\n",
      "[1.84408932]\n",
      "[1.81560048]\n",
      "tensor([1.9163, 1.8070, 1.8459, 1.7848, 1.8363, 1.8441, 1.8156],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80933414]\n",
      "[2.03379595]\n",
      "[1.93318624]\n",
      "[1.82256655]\n",
      "[1.95367973]\n",
      "[1.85806152]\n",
      "[1.80963598]\n",
      "tensor([1.8093, 2.0338, 1.9332, 1.8226, 1.9537, 1.8581, 1.8096],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83768855]\n",
      "[1.80475915]\n",
      "[1.92330683]\n",
      "[1.75866243]\n",
      "[1.76639849]\n",
      "[1.90303476]\n",
      "[1.84266988]\n",
      "tensor([1.8377, 1.8048, 1.9233, 1.7587, 1.7664, 1.9030, 1.8427],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89449338]\n",
      "[1.82002265]\n",
      "[1.80630156]\n",
      "[1.92899637]\n",
      "[1.83261806]\n",
      "[1.90076299]\n",
      "[2.06492348]\n",
      "tensor([1.8945, 1.8200, 1.8063, 1.9290, 1.8326, 1.9008, 2.0649],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86590376]\n",
      "[1.82314252]\n",
      "[1.71550638]\n",
      "[1.81152675]\n",
      "[1.76690239]\n",
      "[1.95589893]\n",
      "[1.93053927]\n",
      "tensor([1.8659, 1.8231, 1.7155, 1.8115, 1.7669, 1.9559, 1.9305],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88224479]\n",
      "[1.77232758]\n",
      "[1.77468149]\n",
      "[1.94346231]\n",
      "[1.85247721]\n",
      "[1.88727147]\n",
      "[1.76537992]\n",
      "tensor([1.8822, 1.7723, 1.7747, 1.9435, 1.8525, 1.8873, 1.7654],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81092088]\n",
      "[1.71412243]\n",
      "[1.70502608]\n",
      "[1.84966263]\n",
      "[1.89340493]\n",
      "[1.80537121]\n",
      "[1.82558168]\n",
      "tensor([1.8109, 1.7141, 1.7050, 1.8497, 1.8934, 1.8054, 1.8256],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83969588]\n",
      "[1.86252202]\n",
      "[1.85574695]\n",
      "[1.91017612]\n",
      "[1.82652092]\n",
      "[2.04869916]\n",
      "[1.73630048]\n",
      "tensor([1.8397, 1.8625, 1.8557, 1.9102, 1.8265, 2.0487, 1.7363],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97856138]\n",
      "[1.86502396]\n",
      "[1.86701668]\n",
      "[1.79602997]\n",
      "[1.92837399]\n",
      "[1.87508641]\n",
      "[1.85836715]\n",
      "tensor([1.9786, 1.8650, 1.8670, 1.7960, 1.9284, 1.8751, 1.8584],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83628397]\n",
      "[1.94496219]\n",
      "[1.86998993]\n",
      "[1.95812107]\n",
      "[1.82937044]\n",
      "[1.95594007]\n",
      "[1.76352313]\n",
      "tensor([1.8363, 1.9450, 1.8700, 1.9581, 1.8294, 1.9559, 1.7635],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80416232]\n",
      "[1.76682214]\n",
      "[1.87773841]\n",
      "[1.78804033]\n",
      "[1.82440999]\n",
      "[1.90218027]\n",
      "[1.83678145]\n",
      "tensor([1.8042, 1.7668, 1.8777, 1.7880, 1.8244, 1.9022, 1.8368],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77766371]\n",
      "[1.83805612]\n",
      "[1.72576101]\n",
      "[1.86507046]\n",
      "[1.6931424]\n",
      "[1.88851663]\n",
      "[1.8851039]\n",
      "tensor([1.7777, 1.8381, 1.7258, 1.8651, 1.6931, 1.8885, 1.8851],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88506286]\n",
      "[1.78161947]\n",
      "[1.80161601]\n",
      "[1.7699063]\n",
      "[1.89444528]\n",
      "[1.77403095]\n",
      "[1.80417722]\n",
      "tensor([1.8851, 1.7816, 1.8016, 1.7699, 1.8944, 1.7740, 1.8042],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90456178]\n",
      "[1.83997659]\n",
      "[1.89082075]\n",
      "[1.74533811]\n",
      "[1.87469046]\n",
      "[1.7492389]\n",
      "[2.09803553]\n",
      "tensor([1.9046, 1.8400, 1.8908, 1.7453, 1.8747, 1.7492, 2.0980],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93351218]\n",
      "[1.93463262]\n",
      "[1.89448063]\n",
      "[1.81430604]\n",
      "[1.80225607]\n",
      "[1.80374955]\n",
      "[1.72961266]\n",
      "tensor([1.9335, 1.9346, 1.8945, 1.8143, 1.8023, 1.8037, 1.7296],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7974223]\n",
      "[1.79851848]\n",
      "[1.79663005]\n",
      "[1.78100076]\n",
      "[1.89727142]\n",
      "[1.74028681]\n",
      "[1.86910133]\n",
      "tensor([1.7974, 1.7985, 1.7966, 1.7810, 1.8973, 1.7403, 1.8691],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85659838]\n",
      "[1.93359365]\n",
      "[1.89086676]\n",
      "[1.7964562]\n",
      "[1.78397973]\n",
      "[1.84111928]\n",
      "[1.81384676]\n",
      "tensor([1.8566, 1.9336, 1.8909, 1.7965, 1.7840, 1.8411, 1.8138],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86711784]\n",
      "[1.72929064]\n",
      "[1.73268595]\n",
      "[1.88206545]\n",
      "[1.74908244]\n",
      "[1.92040964]\n",
      "[1.82784361]\n",
      "tensor([1.8671, 1.7293, 1.7327, 1.8821, 1.7491, 1.9204, 1.8278],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79468617]\n",
      "[1.74390014]\n",
      "[1.78685626]\n",
      "[1.82767876]\n",
      "[1.77022943]\n",
      "[1.83843487]\n",
      "[1.80829761]\n",
      "tensor([1.7947, 1.7439, 1.7869, 1.8277, 1.7702, 1.8384, 1.8083],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85911452]\n",
      "[1.80149046]\n",
      "[1.94413077]\n",
      "[1.83064809]\n",
      "[1.88645284]\n",
      "[1.85490028]\n",
      "[1.79756094]\n",
      "tensor([1.8591, 1.8015, 1.9441, 1.8306, 1.8865, 1.8549, 1.7976],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75541511]\n",
      "[1.82410334]\n",
      "[1.76663034]\n",
      "[1.75653677]\n",
      "[1.85017161]\n",
      "[1.81064625]\n",
      "[1.82821193]\n",
      "tensor([1.7554, 1.8241, 1.7666, 1.7565, 1.8502, 1.8106, 1.8282],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82478055]\n",
      "[1.81979635]\n",
      "[1.76870313]\n",
      "[1.85590377]\n",
      "[1.91699137]\n",
      "[1.87238284]\n",
      "[1.82528151]\n",
      "tensor([1.8248, 1.8198, 1.7687, 1.8559, 1.9170, 1.8724, 1.8253],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80312952]\n",
      "[1.83134549]\n",
      "[1.72386318]\n",
      "[1.80092403]\n",
      "[1.86420406]\n",
      "[1.93086081]\n",
      "[1.75718905]\n",
      "tensor([1.8031, 1.8313, 1.7239, 1.8009, 1.8642, 1.9309, 1.7572],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7726704]\n",
      "[1.84286608]\n",
      "[1.96491975]\n",
      "[1.88035048]\n",
      "[1.89102407]\n",
      "[1.8337491]\n",
      "[1.79398555]\n",
      "tensor([1.7727, 1.8429, 1.9649, 1.8804, 1.8910, 1.8337, 1.7940],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90530019]\n",
      "[1.79425261]\n",
      "[1.82863966]\n",
      "[1.80245648]\n",
      "[1.80465658]\n",
      "[1.70990164]\n",
      "[1.7901585]\n",
      "tensor([1.9053, 1.7943, 1.8286, 1.8025, 1.8047, 1.7099, 1.7902],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88064037]\n",
      "[1.77799028]\n",
      "[1.79281842]\n",
      "[1.87718484]\n",
      "[1.85711921]\n",
      "[1.89024655]\n",
      "[1.79767411]\n",
      "tensor([1.8806, 1.7780, 1.7928, 1.8772, 1.8571, 1.8902, 1.7977],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7392561]\n",
      "[1.81728277]\n",
      "[1.70084279]\n",
      "[1.95516917]\n",
      "[1.71572886]\n",
      "[1.95580785]\n",
      "[1.941236]\n",
      "tensor([1.7393, 1.8173, 1.7008, 1.9552, 1.7157, 1.9558, 1.9412],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8348591]\n",
      "[1.77288612]\n",
      "[1.87564484]\n",
      "[1.84447318]\n",
      "[1.77647079]\n",
      "[1.88706132]\n",
      "[1.85452933]\n",
      "tensor([1.8349, 1.7729, 1.8756, 1.8445, 1.7765, 1.8871, 1.8545],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79218194]\n",
      "[1.75493866]\n",
      "[1.7825763]\n",
      "[1.87458209]\n",
      "[2.00278875]\n",
      "[1.8099351]\n",
      "[1.84405921]\n",
      "tensor([1.7922, 1.7549, 1.7826, 1.8746, 2.0028, 1.8099, 1.8441],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91008181]\n",
      "[1.82431449]\n",
      "[1.83181572]\n",
      "[1.75413492]\n",
      "[1.82422102]\n",
      "[1.89550515]\n",
      "[1.85418915]\n",
      "tensor([1.9101, 1.8243, 1.8318, 1.7541, 1.8242, 1.8955, 1.8542],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84136198]\n",
      "[1.84839377]\n",
      "[1.72453077]\n",
      "[1.77095206]\n",
      "[1.88239962]\n",
      "[1.92977771]\n",
      "[1.90459103]\n",
      "tensor([1.8414, 1.8484, 1.7245, 1.7710, 1.8824, 1.9298, 1.9046],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84110615]\n",
      "[1.87232366]\n",
      "[1.89648752]\n",
      "[1.74136174]\n",
      "[1.78195379]\n",
      "[2.06522654]\n",
      "[1.73717092]\n",
      "tensor([1.8411, 1.8723, 1.8965, 1.7414, 1.7820, 2.0652, 1.7372],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8397895]\n",
      "[1.82646214]\n",
      "[1.76552994]\n",
      "[1.98276389]\n",
      "[2.07865353]\n",
      "[1.87187886]\n",
      "[1.83547667]\n",
      "tensor([1.8398, 1.8265, 1.7655, 1.9828, 2.0787, 1.8719, 1.8355],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7954818]\n",
      "[1.86040502]\n",
      "[1.83850876]\n",
      "[1.71437304]\n",
      "[1.79324839]\n",
      "[1.86042721]\n",
      "[1.87667221]\n",
      "tensor([1.7955, 1.8604, 1.8385, 1.7144, 1.7932, 1.8604, 1.8767],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76294389]\n",
      "[1.862773]\n",
      "[1.77561702]\n",
      "[1.82749712]\n",
      "[1.86184421]\n",
      "[1.88773118]\n",
      "[1.70825785]\n",
      "tensor([1.7629, 1.8628, 1.7756, 1.8275, 1.8618, 1.8877, 1.7083],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86161138]\n",
      "[1.96623654]\n",
      "[1.87388564]\n",
      "[1.86772916]\n",
      "[1.79227867]\n",
      "[1.6974149]\n",
      "[1.85919306]\n",
      "tensor([1.8616, 1.9662, 1.8739, 1.8677, 1.7923, 1.6974, 1.8592],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84572616]\n",
      "[1.84432362]\n",
      "[1.96084439]\n",
      "[1.80942214]\n",
      "[1.78294132]\n",
      "[1.95456132]\n",
      "[1.81070091]\n",
      "tensor([1.8457, 1.8443, 1.9608, 1.8094, 1.7829, 1.9546, 1.8107],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8378229]\n",
      "[1.73515483]\n",
      "[1.7938319]\n",
      "[1.90947064]\n",
      "[1.7440124]\n",
      "[1.77263745]\n",
      "[1.79757491]\n",
      "tensor([1.8378, 1.7352, 1.7938, 1.9095, 1.7440, 1.7726, 1.7976],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8650016]\n",
      "[1.82478282]\n",
      "[1.7673008]\n",
      "[1.90539725]\n",
      "[1.85655835]\n",
      "[1.82653574]\n",
      "[1.82917901]\n",
      "tensor([1.8650, 1.8248, 1.7673, 1.9054, 1.8566, 1.8265, 1.8292],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82268931]\n",
      "[1.75325386]\n",
      "[1.93226121]\n",
      "[1.79926127]\n",
      "[2.02934415]\n",
      "[1.79063888]\n",
      "[1.72767032]\n",
      "tensor([1.8227, 1.7533, 1.9323, 1.7993, 2.0293, 1.7906, 1.7277],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92046738]\n",
      "[1.7836614]\n",
      "[1.83658869]\n",
      "[1.84003657]\n",
      "[1.79797961]\n",
      "[1.88518919]\n",
      "[1.76515982]\n",
      "tensor([1.9205, 1.7837, 1.8366, 1.8400, 1.7980, 1.8852, 1.7652],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81077755]\n",
      "[1.85724298]\n",
      "[1.77928065]\n",
      "[1.82401701]\n",
      "[1.9152808]\n",
      "[1.84935965]\n",
      "[1.84565188]\n",
      "tensor([1.8108, 1.8572, 1.7793, 1.8240, 1.9153, 1.8494, 1.8457],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94016851]\n",
      "[1.83114375]\n",
      "[1.74731436]\n",
      "[1.82951627]\n",
      "[1.71036306]\n",
      "[1.98647946]\n",
      "[1.85736151]\n",
      "tensor([1.9402, 1.8311, 1.7473, 1.8295, 1.7104, 1.9865, 1.8574],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85808086]\n",
      "[1.7999503]\n",
      "[1.83190873]\n",
      "[2.02520395]\n",
      "[1.78402702]\n",
      "[1.82823781]\n",
      "[1.77377545]\n",
      "tensor([1.8581, 1.8000, 1.8319, 2.0252, 1.7840, 1.8282, 1.7738],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75107797]\n",
      "[2.01669788]\n",
      "[1.80411288]\n",
      "[1.83486442]\n",
      "[1.83613509]\n",
      "[1.83907452]\n",
      "[1.87841538]\n",
      "tensor([1.7511, 2.0167, 1.8041, 1.8349, 1.8361, 1.8391, 1.8784],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84069629]\n",
      "[1.80866303]\n",
      "[1.73492244]\n",
      "[1.76427928]\n",
      "[1.84109527]\n",
      "[1.90281883]\n",
      "[1.80062227]\n",
      "tensor([1.8407, 1.8087, 1.7349, 1.7643, 1.8411, 1.9028, 1.8006],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7892443]\n",
      "[1.88403826]\n",
      "[1.78791969]\n",
      "[1.94318488]\n",
      "[1.80746685]\n",
      "[1.85565611]\n",
      "[1.88930612]\n",
      "tensor([1.7892, 1.8840, 1.7879, 1.9432, 1.8075, 1.8557, 1.8893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80674207]\n",
      "[1.79777586]\n",
      "[1.90122822]\n",
      "[1.79443842]\n",
      "[1.83154814]\n",
      "[1.87766447]\n",
      "[1.85401925]\n",
      "tensor([1.8067, 1.7978, 1.9012, 1.7944, 1.8315, 1.8777, 1.8540],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93681556]\n",
      "[1.85332616]\n",
      "[1.9649693]\n",
      "[1.88699217]\n",
      "[1.80938717]\n",
      "[1.75139481]\n",
      "[1.82807939]\n",
      "tensor([1.9368, 1.8533, 1.9650, 1.8870, 1.8094, 1.7514, 1.8281],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74789865]\n",
      "[2.01915903]\n",
      "[1.90526143]\n",
      "[1.86859108]\n",
      "[1.92761265]\n",
      "[1.83237806]\n",
      "[1.90104622]\n",
      "tensor([1.7479, 2.0192, 1.9053, 1.8686, 1.9276, 1.8324, 1.9010],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79613559]\n",
      "[1.91336862]\n",
      "[1.73916352]\n",
      "[1.84121727]\n",
      "[1.87176835]\n",
      "[1.75396992]\n",
      "[2.05812494]\n",
      "tensor([1.7961, 1.9134, 1.7392, 1.8412, 1.8718, 1.7540, 2.0581],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83307254]\n",
      "[1.78518343]\n",
      "[1.77977914]\n",
      "[1.85913252]\n",
      "[1.75539455]\n",
      "[1.85202371]\n",
      "[1.79227021]\n",
      "tensor([1.8331, 1.7852, 1.7798, 1.8591, 1.7554, 1.8520, 1.7923],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95980452]\n",
      "[1.83932672]\n",
      "[1.78470129]\n",
      "[1.80225329]\n",
      "[1.87246283]\n",
      "[1.79296066]\n",
      "[1.95777982]\n",
      "tensor([1.9598, 1.8393, 1.7847, 1.8023, 1.8725, 1.7930, 1.9578],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81377599]\n",
      "[1.84157686]\n",
      "[1.8479961]\n",
      "[1.75316648]\n",
      "[1.84721456]\n",
      "[1.79953405]\n",
      "[1.83073218]\n",
      "tensor([1.8138, 1.8416, 1.8480, 1.7532, 1.8472, 1.7995, 1.8307],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80224979]\n",
      "[1.75904316]\n",
      "[1.88967081]\n",
      "[1.98554071]\n",
      "[1.72825301]\n",
      "[1.98184122]\n",
      "[1.79225695]\n",
      "tensor([1.8022, 1.7590, 1.8897, 1.9855, 1.7283, 1.9818, 1.7923],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89573654]\n",
      "[1.89367048]\n",
      "[1.88506265]\n",
      "[1.88795021]\n",
      "[1.71517374]\n",
      "[1.91762115]\n",
      "[1.93820148]\n",
      "tensor([1.8957, 1.8937, 1.8851, 1.8880, 1.7152, 1.9176, 1.9382],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80152174]\n",
      "[1.95586594]\n",
      "[1.91928076]\n",
      "[1.78197669]\n",
      "[1.89591457]\n",
      "[1.79775797]\n",
      "[1.6924911]\n",
      "tensor([1.8015, 1.9559, 1.9193, 1.7820, 1.8959, 1.7978, 1.6925],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97881514]\n",
      "[1.92632502]\n",
      "[1.68378279]\n",
      "[1.87670183]\n",
      "[1.8768261]\n",
      "[1.75924301]\n",
      "[1.85688831]\n",
      "tensor([1.9788, 1.9263, 1.6838, 1.8767, 1.8768, 1.7592, 1.8569],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72721242]\n",
      "[1.8678254]\n",
      "[1.82939605]\n",
      "[1.83102515]\n",
      "[1.81066459]\n",
      "[1.97145437]\n",
      "[1.7603367]\n",
      "tensor([1.7272, 1.8678, 1.8294, 1.8310, 1.8107, 1.9715, 1.7603],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82299759]\n",
      "[1.80622283]\n",
      "[1.77861174]\n",
      "[1.72444913]\n",
      "[1.91832693]\n",
      "[1.90031691]\n",
      "[1.896707]\n",
      "tensor([1.8230, 1.8062, 1.7786, 1.7244, 1.9183, 1.9003, 1.8967],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74664013]\n",
      "[1.79368904]\n",
      "[1.80353936]\n",
      "[1.89455705]\n",
      "[1.86702868]\n",
      "[1.97479297]\n",
      "[1.7852975]\n",
      "tensor([1.7466, 1.7937, 1.8035, 1.8946, 1.8670, 1.9748, 1.7853],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8599216]\n",
      "[1.86503007]\n",
      "[1.81287871]\n",
      "[1.83832669]\n",
      "[1.91748921]\n",
      "[1.85167006]\n",
      "[1.79187112]\n",
      "tensor([1.8599, 1.8650, 1.8129, 1.8383, 1.9175, 1.8517, 1.7919],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80937873]\n",
      "[1.8806949]\n",
      "[1.80163617]\n",
      "[1.77949961]\n",
      "[1.75360833]\n",
      "[1.77900241]\n",
      "[1.82182165]\n",
      "tensor([1.8094, 1.8807, 1.8016, 1.7795, 1.7536, 1.7790, 1.8218],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90145639]\n",
      "[1.76747758]\n",
      "[1.79747664]\n",
      "[1.83602647]\n",
      "[1.84600201]\n",
      "[1.98367271]\n",
      "[1.79597616]\n",
      "tensor([1.9015, 1.7675, 1.7975, 1.8360, 1.8460, 1.9837, 1.7960],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78102218]\n",
      "[1.88076489]\n",
      "[1.73345535]\n",
      "[1.72022845]\n",
      "[1.84609405]\n",
      "[1.76905788]\n",
      "[1.80881718]\n",
      "tensor([1.7810, 1.8808, 1.7335, 1.7202, 1.8461, 1.7691, 1.8088],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76551213]\n",
      "[1.78357753]\n",
      "[1.78823015]\n",
      "[1.85629867]\n",
      "[1.85082753]\n",
      "[1.88069659]\n",
      "[1.88662815]\n",
      "tensor([1.7655, 1.7836, 1.7882, 1.8563, 1.8508, 1.8807, 1.8866],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98839653]\n",
      "[1.79093459]\n",
      "[1.70151284]\n",
      "[1.77629074]\n",
      "[1.88979148]\n",
      "[1.85403043]\n",
      "[1.77766605]\n",
      "tensor([1.9884, 1.7909, 1.7015, 1.7763, 1.8898, 1.8540, 1.7777],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80132354]\n",
      "[1.86276473]\n",
      "[1.7974977]\n",
      "[1.8153584]\n",
      "[1.8354596]\n",
      "[1.91948521]\n",
      "[1.84680826]\n",
      "tensor([1.8013, 1.8628, 1.7975, 1.8154, 1.8355, 1.9195, 1.8468],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81738868]\n",
      "[1.73220783]\n",
      "[1.75731996]\n",
      "[1.84333893]\n",
      "[1.80633746]\n",
      "[1.74079555]\n",
      "[1.82765154]\n",
      "tensor([1.8174, 1.7322, 1.7573, 1.8433, 1.8063, 1.7408, 1.8277],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76434453]\n",
      "[1.7788545]\n",
      "[1.82193934]\n",
      "[1.82285389]\n",
      "[1.77703995]\n",
      "[1.68736609]\n",
      "[1.84466315]\n",
      "tensor([1.7643, 1.7789, 1.8219, 1.8229, 1.7770, 1.6874, 1.8447],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85605261]\n",
      "[1.81950448]\n",
      "[1.91212081]\n",
      "[1.8723735]\n",
      "[1.96417343]\n",
      "[1.87123597]\n",
      "[1.84649872]\n",
      "tensor([1.8561, 1.8195, 1.9121, 1.8724, 1.9642, 1.8712, 1.8465],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80170979]\n",
      "[1.82657287]\n",
      "[1.83512055]\n",
      "[1.73795556]\n",
      "[1.84846097]\n",
      "[1.92093359]\n",
      "[1.79253893]\n",
      "tensor([1.8017, 1.8266, 1.8351, 1.7380, 1.8485, 1.9209, 1.7925],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79145768]\n",
      "[1.96618019]\n",
      "[1.86826129]\n",
      "[1.90847269]\n",
      "[1.85404924]\n",
      "[1.7989367]\n",
      "[1.89385673]\n",
      "tensor([1.7915, 1.9662, 1.8683, 1.9085, 1.8540, 1.7989, 1.8939],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86993462]\n",
      "[1.81333614]\n",
      "[1.76260988]\n",
      "[1.91634802]\n",
      "[1.82671194]\n",
      "[1.7360203]\n",
      "[1.88656181]\n",
      "tensor([1.8699, 1.8133, 1.7626, 1.9163, 1.8267, 1.7360, 1.8866],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82699835]\n",
      "[1.79062987]\n",
      "[1.82120368]\n",
      "[1.94766093]\n",
      "[1.85472388]\n",
      "[1.84198661]\n",
      "[1.8198515]\n",
      "tensor([1.8270, 1.7906, 1.8212, 1.9477, 1.8547, 1.8420, 1.8199],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82671149]\n",
      "[1.79618011]\n",
      "[1.89195881]\n",
      "[1.93727427]\n",
      "[1.92944207]\n",
      "[1.83459086]\n",
      "[1.90396632]\n",
      "tensor([1.8267, 1.7962, 1.8920, 1.9373, 1.9294, 1.8346, 1.9040],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99086366]\n",
      "[1.860479]\n",
      "[1.83066506]\n",
      "[1.87592278]\n",
      "[1.80750849]\n",
      "[1.92016205]\n",
      "[1.77298539]\n",
      "tensor([1.9909, 1.8605, 1.8307, 1.8759, 1.8075, 1.9202, 1.7730],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.909868]\n",
      "[1.83276356]\n",
      "[1.85542591]\n",
      "[1.96664637]\n",
      "[1.84050806]\n",
      "[1.81111515]\n",
      "[1.86885528]\n",
      "tensor([1.9099, 1.8328, 1.8554, 1.9666, 1.8405, 1.8111, 1.8689],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78250437]\n",
      "[1.81788636]\n",
      "[1.81597012]\n",
      "[1.85809852]\n",
      "[1.80543843]\n",
      "[1.82891129]\n",
      "[1.91286359]\n",
      "tensor([1.7825, 1.8179, 1.8160, 1.8581, 1.8054, 1.8289, 1.9129],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.02410936]\n",
      "[1.80013769]\n",
      "[1.82275093]\n",
      "[1.87740291]\n",
      "[1.88056632]\n",
      "[1.90355465]\n",
      "[1.87290414]\n",
      "tensor([2.0241, 1.8001, 1.8228, 1.8774, 1.8806, 1.9036, 1.8729],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88941678]\n",
      "[1.88300062]\n",
      "[1.77737619]\n",
      "[1.70827659]\n",
      "[1.94201685]\n",
      "[1.85915141]\n",
      "[1.73193066]\n",
      "tensor([1.8894, 1.8830, 1.7774, 1.7083, 1.9420, 1.8592, 1.7319],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92383594]\n",
      "[1.82721587]\n",
      "[1.73467957]\n",
      "[1.7925043]\n",
      "[1.97880954]\n",
      "[1.96220756]\n",
      "[2.01405538]\n",
      "tensor([1.9238, 1.8272, 1.7347, 1.7925, 1.9788, 1.9622, 2.0141],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8579884]\n",
      "[1.82338211]\n",
      "[1.85017275]\n",
      "[1.72320368]\n",
      "[1.76942537]\n",
      "[1.8616058]\n",
      "[1.85578873]\n",
      "tensor([1.8580, 1.8234, 1.8502, 1.7232, 1.7694, 1.8616, 1.8558],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8996986]\n",
      "[1.91558709]\n",
      "[1.88768498]\n",
      "[1.8065491]\n",
      "[1.76492103]\n",
      "[1.81895491]\n",
      "[1.70316674]\n",
      "tensor([1.8997, 1.9156, 1.8877, 1.8065, 1.7649, 1.8190, 1.7032],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7533288]\n",
      "[1.73813975]\n",
      "[1.92439943]\n",
      "[1.84585894]\n",
      "[1.90014855]\n",
      "[1.82179503]\n",
      "[1.79789525]\n",
      "tensor([1.7533, 1.7381, 1.9244, 1.8459, 1.9001, 1.8218, 1.7979],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85754606]\n",
      "[1.75634403]\n",
      "[1.78695669]\n",
      "[1.80298685]\n",
      "[1.66707737]\n",
      "[1.93739615]\n",
      "[1.87625862]\n",
      "tensor([1.8575, 1.7563, 1.7870, 1.8030, 1.6671, 1.9374, 1.8763],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81069116]\n",
      "[1.83635951]\n",
      "[1.7755764]\n",
      "[1.81177523]\n",
      "[1.79589796]\n",
      "[1.85220863]\n",
      "[1.73658243]\n",
      "tensor([1.8107, 1.8364, 1.7756, 1.8118, 1.7959, 1.8522, 1.7366],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8478254]\n",
      "[1.90445971]\n",
      "[1.75819497]\n",
      "[1.8286468]\n",
      "[1.85552627]\n",
      "[1.84407162]\n",
      "[1.71540012]\n",
      "tensor([1.8478, 1.9045, 1.7582, 1.8286, 1.8555, 1.8441, 1.7154],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80413377]\n",
      "[1.83239787]\n",
      "[1.84988969]\n",
      "[1.78777731]\n",
      "[1.80575966]\n",
      "[1.93485174]\n",
      "[1.7978577]\n",
      "tensor([1.8041, 1.8324, 1.8499, 1.7878, 1.8058, 1.9349, 1.7979],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7686867]\n",
      "[1.81427562]\n",
      "[1.89317149]\n",
      "[1.80352621]\n",
      "[1.77171701]\n",
      "[1.92972679]\n",
      "[1.83743515]\n",
      "tensor([1.7687, 1.8143, 1.8932, 1.8035, 1.7717, 1.9297, 1.8374],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77373913]\n",
      "[1.95767964]\n",
      "[1.76749517]\n",
      "[1.80068968]\n",
      "[1.80428615]\n",
      "[2.00003116]\n",
      "[1.93157496]\n",
      "tensor([1.7737, 1.9577, 1.7675, 1.8007, 1.8043, 2.0000, 1.9316],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89230703]\n",
      "[1.74846275]\n",
      "[1.8310895]\n",
      "[1.82169574]\n",
      "[1.84396134]\n",
      "[1.87445279]\n",
      "[1.84984677]\n",
      "tensor([1.8923, 1.7485, 1.8311, 1.8217, 1.8440, 1.8745, 1.8498],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95786672]\n",
      "[1.82950363]\n",
      "[1.84381773]\n",
      "[1.72925301]\n",
      "[1.799295]\n",
      "[2.01167589]\n",
      "[1.83897954]\n",
      "tensor([1.9579, 1.8295, 1.8438, 1.7293, 1.7993, 2.0117, 1.8390],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89956166]\n",
      "[1.86521986]\n",
      "[2.08457471]\n",
      "[1.73841783]\n",
      "[1.82570873]\n",
      "[1.78137558]\n",
      "[1.81936255]\n",
      "tensor([1.8996, 1.8652, 2.0846, 1.7384, 1.8257, 1.7814, 1.8194],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78638763]\n",
      "[1.86171697]\n",
      "[1.87987354]\n",
      "[1.83170041]\n",
      "[1.88434911]\n",
      "[1.79785957]\n",
      "[1.78967062]\n",
      "tensor([1.7864, 1.8617, 1.8799, 1.8317, 1.8843, 1.7979, 1.7897],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82336518]\n",
      "[1.77419752]\n",
      "[1.91279596]\n",
      "[1.79546317]\n",
      "[1.98963852]\n",
      "[1.84008844]\n",
      "[1.94956924]\n",
      "tensor([1.8234, 1.7742, 1.9128, 1.7955, 1.9896, 1.8401, 1.9496],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79348971]\n",
      "[1.84959196]\n",
      "[1.82005077]\n",
      "[1.89948812]\n",
      "[1.84306591]\n",
      "[1.75516135]\n",
      "[1.97375099]\n",
      "tensor([1.7935, 1.8496, 1.8201, 1.8995, 1.8431, 1.7552, 1.9738],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86416476]\n",
      "[1.83334678]\n",
      "[1.76560426]\n",
      "[1.83527921]\n",
      "[1.7415773]\n",
      "[1.94520411]\n",
      "[1.91731588]\n",
      "tensor([1.8642, 1.8333, 1.7656, 1.8353, 1.7416, 1.9452, 1.9173],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89356532]\n",
      "[1.87630575]\n",
      "[1.77589401]\n",
      "[1.78460227]\n",
      "[1.7918959]\n",
      "[1.87036699]\n",
      "[1.80195599]\n",
      "tensor([1.8936, 1.8763, 1.7759, 1.7846, 1.7919, 1.8704, 1.8020],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82177185]\n",
      "[1.85602252]\n",
      "[2.05392485]\n",
      "[1.90888782]\n",
      "[1.81750468]\n",
      "[1.83133732]\n",
      "[1.85529034]\n",
      "tensor([1.8218, 1.8560, 2.0539, 1.9089, 1.8175, 1.8313, 1.8553],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78545962]\n",
      "[1.82322068]\n",
      "[1.84597122]\n",
      "[1.83309336]\n",
      "[1.75401648]\n",
      "[1.85416582]\n",
      "[1.81961138]\n",
      "tensor([1.7855, 1.8232, 1.8460, 1.8331, 1.7540, 1.8542, 1.8196],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93771237]\n",
      "[1.72761881]\n",
      "[1.84066743]\n",
      "[1.83700622]\n",
      "[1.85372168]\n",
      "[1.75343366]\n",
      "[1.81772026]\n",
      "tensor([1.9377, 1.7276, 1.8407, 1.8370, 1.8537, 1.7534, 1.8177],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81135427]\n",
      "[1.78236626]\n",
      "[1.8024282]\n",
      "[1.88353877]\n",
      "[1.80056604]\n",
      "[1.8964051]\n",
      "[1.79340195]\n",
      "tensor([1.8114, 1.7824, 1.8024, 1.8835, 1.8006, 1.8964, 1.7934],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73484282]\n",
      "[1.9932157]\n",
      "[1.78296918]\n",
      "[1.92859381]\n",
      "[1.8119022]\n",
      "[1.87936016]\n",
      "[1.80120531]\n",
      "tensor([1.7348, 1.9932, 1.7830, 1.9286, 1.8119, 1.8794, 1.8012],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75936403]\n",
      "[1.86470439]\n",
      "[1.76685191]\n",
      "[1.73660481]\n",
      "[1.93156796]\n",
      "[1.84113725]\n",
      "[1.76965055]\n",
      "tensor([1.7594, 1.8647, 1.7669, 1.7366, 1.9316, 1.8411, 1.7697],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73046369]\n",
      "[1.84598945]\n",
      "[1.90503878]\n",
      "[1.85354676]\n",
      "[1.81681441]\n",
      "[1.94330717]\n",
      "[1.96397892]\n",
      "tensor([1.7305, 1.8460, 1.9050, 1.8535, 1.8168, 1.9433, 1.9640],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79702964]\n",
      "[1.83793398]\n",
      "[1.86787084]\n",
      "[1.75885422]\n",
      "[1.8659613]\n",
      "[1.87525724]\n",
      "[2.01403191]\n",
      "tensor([1.7970, 1.8379, 1.8679, 1.7589, 1.8660, 1.8753, 2.0140],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82526974]\n",
      "[1.86527409]\n",
      "[1.81816237]\n",
      "[1.78943334]\n",
      "[2.08786003]\n",
      "[1.78279237]\n",
      "[1.72750901]\n",
      "tensor([1.8253, 1.8653, 1.8182, 1.7894, 2.0879, 1.7828, 1.7275],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80834906]\n",
      "[1.84515535]\n",
      "[1.85507733]\n",
      "[1.88300853]\n",
      "[1.95439535]\n",
      "[1.79632073]\n",
      "[1.91965827]\n",
      "tensor([1.8083, 1.8452, 1.8551, 1.8830, 1.9544, 1.7963, 1.9197],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84443004]\n",
      "[1.85132679]\n",
      "[1.95372906]\n",
      "[1.85896369]\n",
      "[1.74104488]\n",
      "[1.86152653]\n",
      "[1.84447705]\n",
      "tensor([1.8444, 1.8513, 1.9537, 1.8590, 1.7410, 1.8615, 1.8445],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8277506]\n",
      "[1.75696161]\n",
      "[1.83233353]\n",
      "[1.83473417]\n",
      "[1.81678137]\n",
      "[1.77224083]\n",
      "[1.92297939]\n",
      "tensor([1.8278, 1.7570, 1.8323, 1.8347, 1.8168, 1.7722, 1.9230],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79706154]\n",
      "[1.81745265]\n",
      "[1.80253733]\n",
      "[1.90405233]\n",
      "[1.8273642]\n",
      "[1.80791581]\n",
      "[1.82109073]\n",
      "tensor([1.7971, 1.8175, 1.8025, 1.9041, 1.8274, 1.8079, 1.8211],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8554763]\n",
      "[1.78743069]\n",
      "[2.01064751]\n",
      "[1.8896291]\n",
      "[1.81616017]\n",
      "[1.91272823]\n",
      "[1.82333854]\n",
      "tensor([1.8555, 1.7874, 2.0106, 1.8896, 1.8162, 1.9127, 1.8233],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80549353]\n",
      "[1.78916929]\n",
      "[1.81919264]\n",
      "[1.9004594]\n",
      "[1.88392]\n",
      "[1.84310204]\n",
      "[1.83772256]\n",
      "tensor([1.8055, 1.7892, 1.8192, 1.9005, 1.8839, 1.8431, 1.8377],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96609039]\n",
      "[1.8957943]\n",
      "[1.87551205]\n",
      "[1.82450784]\n",
      "[1.79066687]\n",
      "[1.77124814]\n",
      "[1.84326159]\n",
      "tensor([1.9661, 1.8958, 1.8755, 1.8245, 1.7907, 1.7712, 1.8433],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97352988]\n",
      "[1.8574438]\n",
      "[1.91592138]\n",
      "[1.82779864]\n",
      "[1.74011735]\n",
      "[1.70879786]\n",
      "[1.89177846]\n",
      "tensor([1.9735, 1.8574, 1.9159, 1.8278, 1.7401, 1.7088, 1.8918],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80910677]\n",
      "[1.74035946]\n",
      "[1.84199442]\n",
      "[1.86166422]\n",
      "[1.77187693]\n",
      "[1.91861061]\n",
      "[1.86555435]\n",
      "tensor([1.8091, 1.7404, 1.8420, 1.8617, 1.7719, 1.9186, 1.8656],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81786098]\n",
      "[1.82457517]\n",
      "[1.73390477]\n",
      "[1.68631856]\n",
      "[1.84474263]\n",
      "[1.7482725]\n",
      "[1.82433143]\n",
      "tensor([1.8179, 1.8246, 1.7339, 1.6863, 1.8447, 1.7483, 1.8243],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98056241]\n",
      "[1.88167448]\n",
      "[1.87031446]\n",
      "[1.71113722]\n",
      "[1.9816291]\n",
      "[1.78197328]\n",
      "[1.81920778]\n",
      "tensor([1.9806, 1.8817, 1.8703, 1.7111, 1.9816, 1.7820, 1.8192],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99499255]\n",
      "[1.87599643]\n",
      "[1.77623038]\n",
      "[1.84329197]\n",
      "[1.72792614]\n",
      "[1.93443296]\n",
      "[1.86984997]\n",
      "tensor([1.9950, 1.8760, 1.7762, 1.8433, 1.7279, 1.9344, 1.8698],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71619873]\n",
      "[1.81718013]\n",
      "[1.82621452]\n",
      "[1.88575324]\n",
      "[1.80984792]\n",
      "[1.84061784]\n",
      "[1.89208763]\n",
      "tensor([1.7162, 1.8172, 1.8262, 1.8858, 1.8098, 1.8406, 1.8921],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85837631]\n",
      "[1.74662737]\n",
      "[1.90954725]\n",
      "[1.73066123]\n",
      "[1.82411336]\n",
      "[1.83297842]\n",
      "[1.7911775]\n",
      "tensor([1.8584, 1.7466, 1.9095, 1.7307, 1.8241, 1.8330, 1.7912],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82015215]\n",
      "[1.99805693]\n",
      "[1.84014072]\n",
      "[1.76950253]\n",
      "[1.84525415]\n",
      "[1.79495241]\n",
      "[1.85054716]\n",
      "tensor([1.8202, 1.9981, 1.8401, 1.7695, 1.8453, 1.7950, 1.8505],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72869077]\n",
      "[1.85853342]\n",
      "[1.99662565]\n",
      "[1.79976252]\n",
      "[1.88066151]\n",
      "[1.90800008]\n",
      "[1.80305911]\n",
      "tensor([1.7287, 1.8585, 1.9966, 1.7998, 1.8807, 1.9080, 1.8031],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80943165]\n",
      "[1.82542552]\n",
      "[1.86818737]\n",
      "[1.73897057]\n",
      "[1.87285843]\n",
      "[2.03998029]\n",
      "[1.78172886]\n",
      "tensor([1.8094, 1.8254, 1.8682, 1.7390, 1.8729, 2.0400, 1.7817],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82716446]\n",
      "[1.78693312]\n",
      "[1.84181486]\n",
      "[1.78543406]\n",
      "[1.72686172]\n",
      "[1.81033537]\n",
      "[1.83354505]\n",
      "tensor([1.8272, 1.7869, 1.8418, 1.7854, 1.7269, 1.8103, 1.8335],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90953275]\n",
      "[1.8765817]\n",
      "[1.94281661]\n",
      "[1.8496281]\n",
      "[1.738413]\n",
      "[1.76711866]\n",
      "[1.8313637]\n",
      "tensor([1.9095, 1.8766, 1.9428, 1.8496, 1.7384, 1.7671, 1.8314],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77259659]\n",
      "[1.81405237]\n",
      "[1.9007821]\n",
      "[1.82222285]\n",
      "[1.87235613]\n",
      "[1.79936711]\n",
      "[1.8730163]\n",
      "tensor([1.7726, 1.8141, 1.9008, 1.8222, 1.8724, 1.7994, 1.8730],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91824996]\n",
      "[1.7191422]\n",
      "[1.82038883]\n",
      "[1.85631123]\n",
      "[1.80557235]\n",
      "[1.86539696]\n",
      "[1.84783272]\n",
      "tensor([1.9182, 1.7191, 1.8204, 1.8563, 1.8056, 1.8654, 1.8478],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87829913]\n",
      "[1.84131442]\n",
      "[1.92251538]\n",
      "[1.77068267]\n",
      "[1.86906958]\n",
      "[1.74537684]\n",
      "[1.85275544]\n",
      "tensor([1.8783, 1.8413, 1.9225, 1.7707, 1.8691, 1.7454, 1.8528],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81446458]\n",
      "[1.85798221]\n",
      "[1.89991935]\n",
      "[1.71053029]\n",
      "[1.8800144]\n",
      "[1.84844847]\n",
      "[1.67041757]\n",
      "tensor([1.8145, 1.8580, 1.8999, 1.7105, 1.8800, 1.8484, 1.6704],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86738104]\n",
      "[1.78907179]\n",
      "[1.88495724]\n",
      "[1.85065848]\n",
      "[1.7937412]\n",
      "[1.85147183]\n",
      "[1.77114476]\n",
      "tensor([1.8674, 1.7891, 1.8850, 1.8507, 1.7937, 1.8515, 1.7711],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80086564]\n",
      "[1.89181208]\n",
      "[1.91620392]\n",
      "[1.85335672]\n",
      "[1.80445186]\n",
      "[1.89931228]\n",
      "[1.82652894]\n",
      "tensor([1.8009, 1.8918, 1.9162, 1.8534, 1.8045, 1.8993, 1.8265],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73207641]\n",
      "[1.68210117]\n",
      "[1.7893791]\n",
      "[1.85961946]\n",
      "[1.78413866]\n",
      "[1.77393481]\n",
      "[1.97786452]\n",
      "tensor([1.7321, 1.6821, 1.7894, 1.8596, 1.7841, 1.7739, 1.9779],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81651773]\n",
      "[1.83801585]\n",
      "[1.81870015]\n",
      "[1.85034651]\n",
      "[1.92252112]\n",
      "[1.78808186]\n",
      "[1.80423677]\n",
      "tensor([1.8165, 1.8380, 1.8187, 1.8503, 1.9225, 1.7881, 1.8042],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88106163]\n",
      "[1.90577847]\n",
      "[1.75644686]\n",
      "[1.72271485]\n",
      "[1.88625417]\n",
      "[1.84399157]\n",
      "[1.70420485]\n",
      "tensor([1.8811, 1.9058, 1.7564, 1.7227, 1.8863, 1.8440, 1.7042],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83154211]\n",
      "[1.71259147]\n",
      "[1.89744868]\n",
      "[1.80730327]\n",
      "[1.79930043]\n",
      "[1.84762158]\n",
      "[1.79793547]\n",
      "tensor([1.8315, 1.7126, 1.8974, 1.8073, 1.7993, 1.8476, 1.7979],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90981719]\n",
      "[1.90042082]\n",
      "[1.84071]\n",
      "[1.8214481]\n",
      "[1.95771374]\n",
      "[1.89395655]\n",
      "[1.75830039]\n",
      "tensor([1.9098, 1.9004, 1.8407, 1.8214, 1.9577, 1.8940, 1.7583],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77753633]\n",
      "[1.83741994]\n",
      "[1.76106263]\n",
      "[1.83488445]\n",
      "[1.8644862]\n",
      "[1.80978715]\n",
      "[1.93489689]\n",
      "tensor([1.7775, 1.8374, 1.7611, 1.8349, 1.8645, 1.8098, 1.9349],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78734084]\n",
      "[1.75798165]\n",
      "[2.01030593]\n",
      "[1.80398378]\n",
      "[1.84850471]\n",
      "[1.85081037]\n",
      "[1.84133564]\n",
      "tensor([1.7873, 1.7580, 2.0103, 1.8040, 1.8485, 1.8508, 1.8413],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72453617]\n",
      "[1.81561242]\n",
      "[1.75354541]\n",
      "[1.80992414]\n",
      "[1.87575422]\n",
      "[1.83840175]\n",
      "[1.8293851]\n",
      "tensor([1.7245, 1.8156, 1.7535, 1.8099, 1.8758, 1.8384, 1.8294],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75146134]\n",
      "[1.81518901]\n",
      "[1.81939566]\n",
      "[1.83328995]\n",
      "[1.92741263]\n",
      "[1.74152792]\n",
      "[1.79128283]\n",
      "tensor([1.7515, 1.8152, 1.8194, 1.8333, 1.9274, 1.7415, 1.7913],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97701267]\n",
      "[1.72305614]\n",
      "[1.88607543]\n",
      "[1.86250276]\n",
      "[1.8106354]\n",
      "[1.91534851]\n",
      "[1.800512]\n",
      "tensor([1.9770, 1.7231, 1.8861, 1.8625, 1.8106, 1.9153, 1.8005],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91988019]\n",
      "[1.81633822]\n",
      "[1.94682053]\n",
      "[1.89216002]\n",
      "[1.75411007]\n",
      "[1.74396829]\n",
      "[1.87967614]\n",
      "tensor([1.9199, 1.8163, 1.9468, 1.8922, 1.7541, 1.7440, 1.8797],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79697]\n",
      "[1.81852176]\n",
      "[1.85151835]\n",
      "[1.87822532]\n",
      "[1.82064774]\n",
      "[1.86210839]\n",
      "[1.75652906]\n",
      "tensor([1.7970, 1.8185, 1.8515, 1.8782, 1.8206, 1.8621, 1.7565],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89104621]\n",
      "[1.83157319]\n",
      "[1.88791668]\n",
      "[1.73141636]\n",
      "[1.79808194]\n",
      "[1.85256157]\n",
      "[1.84399375]\n",
      "tensor([1.8910, 1.8316, 1.8879, 1.7314, 1.7981, 1.8526, 1.8440],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91567393]\n",
      "[1.75728011]\n",
      "[1.69902828]\n",
      "[1.7839022]\n",
      "[1.80491248]\n",
      "[1.8566042]\n",
      "[1.8675955]\n",
      "tensor([1.9157, 1.7573, 1.6990, 1.7839, 1.8049, 1.8566, 1.8676],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.814906]\n",
      "[1.74835181]\n",
      "[1.83122612]\n",
      "[1.80684541]\n",
      "[1.80330806]\n",
      "[1.78631854]\n",
      "[1.89480698]\n",
      "tensor([1.8149, 1.7484, 1.8312, 1.8068, 1.8033, 1.7863, 1.8948],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85307761]\n",
      "[1.88389552]\n",
      "[1.7645948]\n",
      "[1.87822806]\n",
      "[1.88222097]\n",
      "[1.86318333]\n",
      "[2.0650637]\n",
      "tensor([1.8531, 1.8839, 1.7646, 1.8782, 1.8822, 1.8632, 2.0651],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8314865]\n",
      "[1.83967416]\n",
      "[1.79900743]\n",
      "[1.78034996]\n",
      "[1.78944443]\n",
      "[1.76490166]\n",
      "[1.80125561]\n",
      "tensor([1.8315, 1.8397, 1.7990, 1.7803, 1.7894, 1.7649, 1.8013],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83762612]\n",
      "[2.02767745]\n",
      "[1.89020613]\n",
      "[1.84000531]\n",
      "[1.7685392]\n",
      "[1.79781136]\n",
      "[1.90943144]\n",
      "tensor([1.8376, 2.0277, 1.8902, 1.8400, 1.7685, 1.7978, 1.9094],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72987014]\n",
      "[1.81213871]\n",
      "[1.77184218]\n",
      "[1.84542362]\n",
      "[1.79294397]\n",
      "[1.84731076]\n",
      "[1.85521066]\n",
      "tensor([1.7299, 1.8121, 1.7718, 1.8454, 1.7929, 1.8473, 1.8552],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84117947]\n",
      "[1.80069977]\n",
      "[1.84829691]\n",
      "[1.85733011]\n",
      "[1.91846742]\n",
      "[1.86784042]\n",
      "[1.88979629]\n",
      "tensor([1.8412, 1.8007, 1.8483, 1.8573, 1.9185, 1.8678, 1.8898],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83698475]\n",
      "[1.92743637]\n",
      "[1.98595451]\n",
      "[1.7943023]\n",
      "[1.78132141]\n",
      "[1.73150256]\n",
      "[1.78348551]\n",
      "tensor([1.8370, 1.9274, 1.9860, 1.7943, 1.7813, 1.7315, 1.7835],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87928272]\n",
      "[2.09226223]\n",
      "[1.93301262]\n",
      "[1.86248571]\n",
      "[1.83119107]\n",
      "[1.90746059]\n",
      "[1.75899663]\n",
      "tensor([1.8793, 2.0923, 1.9330, 1.8625, 1.8312, 1.9075, 1.7590],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8184998]\n",
      "[1.85576437]\n",
      "[1.77821066]\n",
      "[1.83835744]\n",
      "[1.91385087]\n",
      "[1.86407467]\n",
      "[1.79129894]\n",
      "tensor([1.8185, 1.8558, 1.7782, 1.8384, 1.9139, 1.8641, 1.7913],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7926583]\n",
      "[1.84830882]\n",
      "[1.80497693]\n",
      "[1.91515904]\n",
      "[1.97464938]\n",
      "[1.83761922]\n",
      "[1.73545829]\n",
      "tensor([1.7927, 1.8483, 1.8050, 1.9152, 1.9746, 1.8376, 1.7355],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84715862]\n",
      "[1.83214101]\n",
      "[1.86321201]\n",
      "[1.70765215]\n",
      "[1.79691934]\n",
      "[1.81750219]\n",
      "[1.89671551]\n",
      "tensor([1.8472, 1.8321, 1.8632, 1.7077, 1.7969, 1.8175, 1.8967],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81076574]\n",
      "[1.7241773]\n",
      "[1.79614171]\n",
      "[1.86073284]\n",
      "[1.7978869]\n",
      "[1.83695835]\n",
      "[1.8349121]\n",
      "tensor([1.8108, 1.7242, 1.7961, 1.8607, 1.7979, 1.8370, 1.8349],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80859111]\n",
      "[1.85269647]\n",
      "[1.81880765]\n",
      "[1.97191226]\n",
      "[1.77718151]\n",
      "[1.80040409]\n",
      "[1.82431581]\n",
      "tensor([1.8086, 1.8527, 1.8188, 1.9719, 1.7772, 1.8004, 1.8243],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75066739]\n",
      "[1.83527702]\n",
      "[1.82659686]\n",
      "[1.80787826]\n",
      "[1.8088171]\n",
      "[1.90388298]\n",
      "[1.81723204]\n",
      "tensor([1.7507, 1.8353, 1.8266, 1.8079, 1.8088, 1.9039, 1.8172],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95271131]\n",
      "[1.80869979]\n",
      "[1.87988464]\n",
      "[1.87170855]\n",
      "[1.85044656]\n",
      "[1.78581161]\n",
      "[1.82831795]\n",
      "tensor([1.9527, 1.8087, 1.8799, 1.8717, 1.8504, 1.7858, 1.8283],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74104121]\n",
      "[1.85361986]\n",
      "[1.80383075]\n",
      "[1.77884685]\n",
      "[1.96736125]\n",
      "[1.81282466]\n",
      "[1.84160748]\n",
      "tensor([1.7410, 1.8536, 1.8038, 1.7788, 1.9674, 1.8128, 1.8416],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77589458]\n",
      "[1.82424328]\n",
      "[1.71411879]\n",
      "[1.79698771]\n",
      "[1.77096297]\n",
      "[1.89111238]\n",
      "[1.84753201]\n",
      "tensor([1.7759, 1.8242, 1.7141, 1.7970, 1.7710, 1.8911, 1.8475],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8389865]\n",
      "[1.99279491]\n",
      "[1.84413199]\n",
      "[1.81161492]\n",
      "[1.85372308]\n",
      "[1.77525971]\n",
      "[1.80786155]\n",
      "tensor([1.8390, 1.9928, 1.8441, 1.8116, 1.8537, 1.7753, 1.8079],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79053726]\n",
      "[1.83057202]\n",
      "[1.74318627]\n",
      "[1.82644978]\n",
      "[1.81093323]\n",
      "[1.73800867]\n",
      "[1.99729394]\n",
      "tensor([1.7905, 1.8306, 1.7432, 1.8264, 1.8109, 1.7380, 1.9973],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85414604]\n",
      "[1.81201009]\n",
      "[1.90197244]\n",
      "[1.81488749]\n",
      "[1.79590487]\n",
      "[1.78921908]\n",
      "[1.91156297]\n",
      "tensor([1.8541, 1.8120, 1.9020, 1.8149, 1.7959, 1.7892, 1.9116],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9237819]\n",
      "[1.92726765]\n",
      "[1.77087427]\n",
      "[1.8573294]\n",
      "[1.7034885]\n",
      "[1.84171991]\n",
      "[1.85653359]\n",
      "tensor([1.9238, 1.9273, 1.7709, 1.8573, 1.7035, 1.8417, 1.8565],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76951589]\n",
      "[1.85966892]\n",
      "[1.82967321]\n",
      "[1.82202064]\n",
      "[1.74537898]\n",
      "[1.81441042]\n",
      "[1.6640868]\n",
      "tensor([1.7695, 1.8597, 1.8297, 1.8220, 1.7454, 1.8144, 1.6641],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74302238]\n",
      "[1.81307058]\n",
      "[1.84317065]\n",
      "[1.79659513]\n",
      "[1.7339024]\n",
      "[1.84760845]\n",
      "[1.88337883]\n",
      "tensor([1.7430, 1.8131, 1.8432, 1.7966, 1.7339, 1.8476, 1.8834],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80084072]\n",
      "[1.85401158]\n",
      "[1.73947628]\n",
      "[1.84975035]\n",
      "[1.76499963]\n",
      "[1.83714592]\n",
      "[1.93334579]\n",
      "tensor([1.8008, 1.8540, 1.7395, 1.8498, 1.7650, 1.8371, 1.9333],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76718418]\n",
      "[1.87666774]\n",
      "[1.91442974]\n",
      "[1.80656343]\n",
      "[1.81699127]\n",
      "[1.7934454]\n",
      "[1.89669148]\n",
      "tensor([1.7672, 1.8767, 1.9144, 1.8066, 1.8170, 1.7934, 1.8967],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84842795]\n",
      "[1.71273391]\n",
      "[1.79337761]\n",
      "[1.94564863]\n",
      "[1.82062924]\n",
      "[1.95054982]\n",
      "[1.86066927]\n",
      "tensor([1.8484, 1.7127, 1.7934, 1.9456, 1.8206, 1.9505, 1.8607],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91341667]\n",
      "[1.79036177]\n",
      "[1.73353785]\n",
      "[1.8592326]\n",
      "[1.77295565]\n",
      "[1.91408435]\n",
      "[1.83593972]\n",
      "tensor([1.9134, 1.7904, 1.7335, 1.8592, 1.7730, 1.9141, 1.8359],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81569862]\n",
      "[1.78107325]\n",
      "[1.95374948]\n",
      "[1.73810756]\n",
      "[1.80377035]\n",
      "[1.9246598]\n",
      "[1.82958459]\n",
      "tensor([1.8157, 1.7811, 1.9537, 1.7381, 1.8038, 1.9247, 1.8296],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74327828]\n",
      "[1.82584263]\n",
      "[1.95488236]\n",
      "[1.78203989]\n",
      "[1.91209431]\n",
      "[1.84898329]\n",
      "[1.91108469]\n",
      "tensor([1.7433, 1.8258, 1.9549, 1.7820, 1.9121, 1.8490, 1.9111],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86453683]\n",
      "[1.73332166]\n",
      "[1.82785727]\n",
      "[1.76749266]\n",
      "[1.86221382]\n",
      "[1.93675287]\n",
      "[1.82219638]\n",
      "tensor([1.8645, 1.7333, 1.8279, 1.7675, 1.8622, 1.9368, 1.8222],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81390574]\n",
      "[1.84133838]\n",
      "[1.80715411]\n",
      "[1.85490602]\n",
      "[1.80171511]\n",
      "[1.88778832]\n",
      "[1.90153688]\n",
      "tensor([1.8139, 1.8413, 1.8072, 1.8549, 1.8017, 1.8878, 1.9015],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75104966]\n",
      "[1.84744778]\n",
      "[1.79187444]\n",
      "[1.76530412]\n",
      "[1.73438101]\n",
      "[1.8441294]\n",
      "[1.7783924]\n",
      "tensor([1.7510, 1.8474, 1.7919, 1.7653, 1.7344, 1.8441, 1.7784],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82006975]\n",
      "[1.85256689]\n",
      "[1.89239287]\n",
      "[1.80817786]\n",
      "[1.98357905]\n",
      "[1.89270221]\n",
      "[1.81943927]\n",
      "tensor([1.8201, 1.8526, 1.8924, 1.8082, 1.9836, 1.8927, 1.8194],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84862763]\n",
      "[1.81274846]\n",
      "[1.85857055]\n",
      "[1.89977599]\n",
      "[1.80835096]\n",
      "[1.92438061]\n",
      "[1.83624921]\n",
      "tensor([1.8486, 1.8127, 1.8586, 1.8998, 1.8084, 1.9244, 1.8362],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7668817]\n",
      "[1.78500203]\n",
      "[1.81050659]\n",
      "[1.77052051]\n",
      "[1.78112476]\n",
      "[1.85386788]\n",
      "[1.79294739]\n",
      "tensor([1.7669, 1.7850, 1.8105, 1.7705, 1.7811, 1.8539, 1.7929],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88003843]\n",
      "[1.87736697]\n",
      "[1.79569026]\n",
      "[1.92385195]\n",
      "[1.89022436]\n",
      "[1.77851344]\n",
      "[1.80881362]\n",
      "tensor([1.8800, 1.8774, 1.7957, 1.9239, 1.8902, 1.7785, 1.8088],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76908755]\n",
      "[1.73265231]\n",
      "[1.96623085]\n",
      "[1.92979362]\n",
      "[1.83054623]\n",
      "[1.88958327]\n",
      "[1.87514569]\n",
      "tensor([1.7691, 1.7327, 1.9662, 1.9298, 1.8305, 1.8896, 1.8751],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89714034]\n",
      "[1.86786058]\n",
      "[1.89936515]\n",
      "[1.90994408]\n",
      "[1.79929211]\n",
      "[1.83753229]\n",
      "[1.86725695]\n",
      "tensor([1.8971, 1.8679, 1.8994, 1.9099, 1.7993, 1.8375, 1.8673],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77053913]\n",
      "[1.8066126]\n",
      "[1.7736486]\n",
      "[1.72644141]\n",
      "[1.7335979]\n",
      "[1.89918554]\n",
      "[1.73899822]\n",
      "tensor([1.7705, 1.8066, 1.7736, 1.7264, 1.7336, 1.8992, 1.7390],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86654589]\n",
      "[1.8685133]\n",
      "[1.9654354]\n",
      "[1.92439336]\n",
      "[1.77653462]\n",
      "[1.85897664]\n",
      "[1.76450492]\n",
      "tensor([1.8665, 1.8685, 1.9654, 1.9244, 1.7765, 1.8590, 1.7645],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77992213]\n",
      "[1.79570697]\n",
      "[1.73457569]\n",
      "[1.85429411]\n",
      "[1.71432883]\n",
      "[1.92962199]\n",
      "[1.82868431]\n",
      "tensor([1.7799, 1.7957, 1.7346, 1.8543, 1.7143, 1.9296, 1.8287],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92240341]\n",
      "[1.76422929]\n",
      "[1.81223218]\n",
      "[1.81503535]\n",
      "[1.86833335]\n",
      "[1.823725]\n",
      "[1.85492467]\n",
      "tensor([1.9224, 1.7642, 1.8122, 1.8150, 1.8683, 1.8237, 1.8549],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90264466]\n",
      "[1.87784843]\n",
      "[1.81071599]\n",
      "[1.73540766]\n",
      "[1.84690377]\n",
      "[1.87022997]\n",
      "[2.03949072]\n",
      "tensor([1.9026, 1.8778, 1.8107, 1.7354, 1.8469, 1.8702, 2.0395],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8649411]\n",
      "[1.79342704]\n",
      "[1.97023749]\n",
      "[1.89136068]\n",
      "[1.78746242]\n",
      "[1.79098655]\n",
      "[1.74103627]\n",
      "tensor([1.8649, 1.7934, 1.9702, 1.8914, 1.7875, 1.7910, 1.7410],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81874772]\n",
      "[1.93091464]\n",
      "[1.86802451]\n",
      "[1.89905371]\n",
      "[1.75365785]\n",
      "[1.77602832]\n",
      "[1.80862387]\n",
      "tensor([1.8187, 1.9309, 1.8680, 1.8991, 1.7537, 1.7760, 1.8086],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75340028]\n",
      "[1.83114917]\n",
      "[1.9045674]\n",
      "[1.94341582]\n",
      "[1.85332796]\n",
      "[1.89802309]\n",
      "[1.80641848]\n",
      "tensor([1.7534, 1.8311, 1.9046, 1.9434, 1.8533, 1.8980, 1.8064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83012247]\n",
      "[1.79102603]\n",
      "[1.8342283]\n",
      "[1.80972705]\n",
      "[1.77347736]\n",
      "[1.80877179]\n",
      "[1.76096418]\n",
      "tensor([1.8301, 1.7910, 1.8342, 1.8097, 1.7735, 1.8088, 1.7610],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84260108]\n",
      "[1.7982036]\n",
      "[1.80061221]\n",
      "[1.74404687]\n",
      "[1.83253214]\n",
      "[1.74397037]\n",
      "[1.77833586]\n",
      "tensor([1.8426, 1.7982, 1.8006, 1.7440, 1.8325, 1.7440, 1.7783],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84929162]\n",
      "[1.83883885]\n",
      "[1.85359263]\n",
      "[1.8553709]\n",
      "[1.84626297]\n",
      "[1.80235702]\n",
      "[1.77050318]\n",
      "tensor([1.8493, 1.8388, 1.8536, 1.8554, 1.8463, 1.8024, 1.7705],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91999398]\n",
      "[1.77663865]\n",
      "[1.65699079]\n",
      "[1.8921684]\n",
      "[1.85634521]\n",
      "[1.7893191]\n",
      "[1.74207774]\n",
      "tensor([1.9200, 1.7766, 1.6570, 1.8922, 1.8563, 1.7893, 1.7421],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84764578]\n",
      "[1.8465955]\n",
      "[1.8190777]\n",
      "[1.84796496]\n",
      "[1.85152785]\n",
      "[1.85609952]\n",
      "[1.84608941]\n",
      "tensor([1.8476, 1.8466, 1.8191, 1.8480, 1.8515, 1.8561, 1.8461],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8199056]\n",
      "[1.71645344]\n",
      "[1.81786044]\n",
      "[1.84136268]\n",
      "[1.85946379]\n",
      "[1.8336005]\n",
      "[1.84038546]\n",
      "tensor([1.8199, 1.7165, 1.8179, 1.8414, 1.8595, 1.8336, 1.8404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82972453]\n",
      "[1.76498854]\n",
      "[1.75798613]\n",
      "[1.82065505]\n",
      "[1.82488822]\n",
      "[1.7984646]\n",
      "[1.84387723]\n",
      "tensor([1.8297, 1.7650, 1.7580, 1.8207, 1.8249, 1.7985, 1.8439],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82012547]\n",
      "[1.78364326]\n",
      "[1.77433512]\n",
      "[1.84727458]\n",
      "[1.81814175]\n",
      "[1.99605109]\n",
      "[1.818298]\n",
      "tensor([1.8201, 1.7836, 1.7743, 1.8473, 1.8181, 1.9961, 1.8183],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76800774]\n",
      "[1.82033731]\n",
      "[1.92892167]\n",
      "[1.82626234]\n",
      "[1.75953918]\n",
      "[1.91276224]\n",
      "[1.84124248]\n",
      "tensor([1.7680, 1.8203, 1.9289, 1.8263, 1.7595, 1.9128, 1.8412],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95572617]\n",
      "[2.03046594]\n",
      "[1.81334648]\n",
      "[1.93245034]\n",
      "[1.86817489]\n",
      "[1.78338325]\n",
      "[1.79897089]\n",
      "tensor([1.9557, 2.0305, 1.8133, 1.9325, 1.8682, 1.7834, 1.7990],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82381333]\n",
      "[1.89663415]\n",
      "[1.86031876]\n",
      "[1.80383058]\n",
      "[1.81266952]\n",
      "[1.74007595]\n",
      "[1.79687833]\n",
      "tensor([1.8238, 1.8966, 1.8603, 1.8038, 1.8127, 1.7401, 1.7969],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86065024]\n",
      "[2.08865876]\n",
      "[1.90038739]\n",
      "[1.82460955]\n",
      "[1.87323492]\n",
      "[1.95793568]\n",
      "[1.92238939]\n",
      "tensor([1.8607, 2.0887, 1.9004, 1.8246, 1.8732, 1.9579, 1.9224],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99658104]\n",
      "[1.80356802]\n",
      "[1.90447612]\n",
      "[1.87875912]\n",
      "[1.7696471]\n",
      "[1.87649352]\n",
      "[1.88940012]\n",
      "tensor([1.9966, 1.8036, 1.9045, 1.8788, 1.7696, 1.8765, 1.8894],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85897683]\n",
      "[1.78437093]\n",
      "[1.81979067]\n",
      "[1.8763219]\n",
      "[1.75806295]\n",
      "[1.81436903]\n",
      "[1.82445043]\n",
      "tensor([1.8590, 1.7844, 1.8198, 1.8763, 1.7581, 1.8144, 1.8245],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89434292]\n",
      "[1.86595994]\n",
      "[1.93549469]\n",
      "[1.86831361]\n",
      "[1.79974911]\n",
      "[1.79637604]\n",
      "[1.82470226]\n",
      "tensor([1.8943, 1.8660, 1.9355, 1.8683, 1.7997, 1.7964, 1.8247],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77457235]\n",
      "[1.83441877]\n",
      "[1.92789574]\n",
      "[1.89136859]\n",
      "[1.90008823]\n",
      "[1.82216016]\n",
      "[1.86582544]\n",
      "tensor([1.7746, 1.8344, 1.9279, 1.8914, 1.9001, 1.8222, 1.8658],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75887187]\n",
      "[1.80499891]\n",
      "[1.79747903]\n",
      "[1.72436661]\n",
      "[1.77724854]\n",
      "[1.81625724]\n",
      "[1.92436315]\n",
      "tensor([1.7589, 1.8050, 1.7975, 1.7244, 1.7772, 1.8163, 1.9244],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92484221]\n",
      "[1.82847279]\n",
      "[1.95974089]\n",
      "[1.81284441]\n",
      "[1.74036146]\n",
      "[1.82518343]\n",
      "[1.77398824]\n",
      "tensor([1.9248, 1.8285, 1.9597, 1.8128, 1.7404, 1.8252, 1.7740],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81783957]\n",
      "[1.90842208]\n",
      "[2.0042518]\n",
      "[1.86062437]\n",
      "[1.8428445]\n",
      "[1.85260828]\n",
      "[1.78968308]\n",
      "tensor([1.8178, 1.9084, 2.0043, 1.8606, 1.8428, 1.8526, 1.7897],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82414848]\n",
      "[1.72169724]\n",
      "[1.80830022]\n",
      "[1.82184528]\n",
      "[1.77019789]\n",
      "[1.95523145]\n",
      "[1.86439171]\n",
      "tensor([1.8241, 1.7217, 1.8083, 1.8218, 1.7702, 1.9552, 1.8644],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77912529]\n",
      "[1.96808004]\n",
      "[1.90819895]\n",
      "[1.77224258]\n",
      "[1.86758066]\n",
      "[1.74339803]\n",
      "[1.8647471]\n",
      "tensor([1.7791, 1.9681, 1.9082, 1.7722, 1.8676, 1.7434, 1.8647],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90819523]\n",
      "[1.84233201]\n",
      "[1.99046488]\n",
      "[1.80943841]\n",
      "[1.95482044]\n",
      "[1.726214]\n",
      "[1.80989662]\n",
      "tensor([1.9082, 1.8423, 1.9905, 1.8094, 1.9548, 1.7262, 1.8099],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93823804]\n",
      "[1.87763751]\n",
      "[1.74779037]\n",
      "[1.85241358]\n",
      "[1.99776233]\n",
      "[1.83279101]\n",
      "[1.76779659]\n",
      "tensor([1.9382, 1.8776, 1.7478, 1.8524, 1.9978, 1.8328, 1.7678],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89210153]\n",
      "[1.85256715]\n",
      "[1.81333854]\n",
      "[1.83807997]\n",
      "[1.73756535]\n",
      "[1.8719472]\n",
      "[1.89824873]\n",
      "tensor([1.8921, 1.8526, 1.8133, 1.8381, 1.7376, 1.8719, 1.8982],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80727564]\n",
      "[1.78375061]\n",
      "[1.74340184]\n",
      "[1.74372331]\n",
      "[1.85978531]\n",
      "[1.75184218]\n",
      "[1.97547907]\n",
      "tensor([1.8073, 1.7838, 1.7434, 1.7437, 1.8598, 1.7518, 1.9755],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81174025]\n",
      "[1.77352915]\n",
      "[1.86690251]\n",
      "[1.88965195]\n",
      "[1.87805521]\n",
      "[1.84653034]\n",
      "[1.81526157]\n",
      "tensor([1.8117, 1.7735, 1.8669, 1.8897, 1.8781, 1.8465, 1.8153],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77264736]\n",
      "[1.8229055]\n",
      "[1.80307116]\n",
      "[1.9407102]\n",
      "[1.95184987]\n",
      "[1.8445487]\n",
      "[1.7599807]\n",
      "tensor([1.7726, 1.8229, 1.8031, 1.9407, 1.9518, 1.8445, 1.7600],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81012816]\n",
      "[1.80575274]\n",
      "[1.81467536]\n",
      "[1.87665566]\n",
      "[1.8913775]\n",
      "[1.86976607]\n",
      "[1.82414484]\n",
      "tensor([1.8101, 1.8058, 1.8147, 1.8767, 1.8914, 1.8698, 1.8241],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82635123]\n",
      "[1.83769885]\n",
      "[1.9062035]\n",
      "[1.78386428]\n",
      "[1.87106211]\n",
      "[1.79908919]\n",
      "[1.83160971]\n",
      "tensor([1.8264, 1.8377, 1.9062, 1.7839, 1.8711, 1.7991, 1.8316],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76651011]\n",
      "[1.75588347]\n",
      "[1.75200906]\n",
      "[1.93072664]\n",
      "[1.87570374]\n",
      "[1.81259917]\n",
      "[1.8384159]\n",
      "tensor([1.7665, 1.7559, 1.7520, 1.9307, 1.8757, 1.8126, 1.8384],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9899875]\n",
      "[1.81505987]\n",
      "[1.79377848]\n",
      "[1.81169637]\n",
      "[1.99920803]\n",
      "[1.83870426]\n",
      "[1.80525828]\n",
      "tensor([1.9900, 1.8151, 1.7938, 1.8117, 1.9992, 1.8387, 1.8053],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80584902]\n",
      "[1.84129787]\n",
      "[2.01026286]\n",
      "[1.92696016]\n",
      "[1.83207349]\n",
      "[1.84038005]\n",
      "[1.75422077]\n",
      "tensor([1.8058, 1.8413, 2.0103, 1.9270, 1.8321, 1.8404, 1.7542],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85257625]\n",
      "[1.92829012]\n",
      "[1.73975838]\n",
      "[1.75235037]\n",
      "[1.85874327]\n",
      "[1.79964632]\n",
      "[1.95904569]\n",
      "tensor([1.8526, 1.9283, 1.7398, 1.7524, 1.8587, 1.7996, 1.9590],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81404514]\n",
      "[1.85169024]\n",
      "[1.86478382]\n",
      "[1.79150407]\n",
      "[1.84437037]\n",
      "[1.88410301]\n",
      "[1.84341086]\n",
      "tensor([1.8140, 1.8517, 1.8648, 1.7915, 1.8444, 1.8841, 1.8434],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90262052]\n",
      "[1.81909515]\n",
      "[1.80137782]\n",
      "[1.80668793]\n",
      "[1.82545947]\n",
      "[1.79229759]\n",
      "[1.73793927]\n",
      "tensor([1.9026, 1.8191, 1.8014, 1.8067, 1.8255, 1.7923, 1.7379],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77843778]\n",
      "[1.91029108]\n",
      "[1.83795359]\n",
      "[1.82065947]\n",
      "[1.92675599]\n",
      "[1.79864029]\n",
      "[1.83282442]\n",
      "tensor([1.7784, 1.9103, 1.8380, 1.8207, 1.9268, 1.7986, 1.8328],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84016747]\n",
      "[1.96285776]\n",
      "[1.8433856]\n",
      "[1.74202361]\n",
      "[1.93458906]\n",
      "[1.77494963]\n",
      "[1.77874753]\n",
      "tensor([1.8402, 1.9629, 1.8434, 1.7420, 1.9346, 1.7749, 1.7787],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74781566]\n",
      "[1.80265835]\n",
      "[1.78650323]\n",
      "[1.87591927]\n",
      "[1.8819167]\n",
      "[1.93073322]\n",
      "[1.77136242]\n",
      "tensor([1.7478, 1.8027, 1.7865, 1.8759, 1.8819, 1.9307, 1.7714],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82160943]\n",
      "[1.85165256]\n",
      "[1.76398692]\n",
      "[1.92426946]\n",
      "[1.78474755]\n",
      "[1.98213817]\n",
      "[1.797655]\n",
      "tensor([1.8216, 1.8517, 1.7640, 1.9243, 1.7847, 1.9821, 1.7977],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80671412]\n",
      "[1.82191124]\n",
      "[1.83016964]\n",
      "[1.87239647]\n",
      "[1.81657732]\n",
      "[1.84251372]\n",
      "[1.7965808]\n",
      "tensor([1.8067, 1.8219, 1.8302, 1.8724, 1.8166, 1.8425, 1.7966],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80035857]\n",
      "[1.84256468]\n",
      "[1.79850665]\n",
      "[1.84882625]\n",
      "[1.79890138]\n",
      "[1.76571755]\n",
      "[1.75254746]\n",
      "tensor([1.8004, 1.8426, 1.7985, 1.8488, 1.7989, 1.7657, 1.7525],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72563732]\n",
      "[1.79603102]\n",
      "[1.81936846]\n",
      "[1.825582]\n",
      "[1.85530325]\n",
      "[1.79763679]\n",
      "[1.71398572]\n",
      "tensor([1.7256, 1.7960, 1.8194, 1.8256, 1.8553, 1.7976, 1.7140],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84491485]\n",
      "[1.9089339]\n",
      "[1.85391556]\n",
      "[1.93045977]\n",
      "[1.86616524]\n",
      "[1.69208784]\n",
      "[1.82114457]\n",
      "tensor([1.8449, 1.9089, 1.8539, 1.9305, 1.8662, 1.6921, 1.8211],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86106458]\n",
      "[1.76824148]\n",
      "[1.86527115]\n",
      "[1.84333452]\n",
      "[1.72263516]\n",
      "[1.93339036]\n",
      "[1.91705055]\n",
      "tensor([1.8611, 1.7682, 1.8653, 1.8433, 1.7226, 1.9334, 1.9171],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79962776]\n",
      "[1.77310717]\n",
      "[1.83912959]\n",
      "[2.02762033]\n",
      "[1.91672504]\n",
      "[1.8173253]\n",
      "[1.85540209]\n",
      "tensor([1.7996, 1.7731, 1.8391, 2.0276, 1.9167, 1.8173, 1.8554],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70737027]\n",
      "[1.72983612]\n",
      "[1.808099]\n",
      "[1.77163057]\n",
      "[1.9450577]\n",
      "[1.82536106]\n",
      "[1.77309728]\n",
      "tensor([1.7074, 1.7298, 1.8081, 1.7716, 1.9451, 1.8254, 1.7731],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8061362]\n",
      "[1.84027952]\n",
      "[1.77005662]\n",
      "[1.84983006]\n",
      "[1.8064713]\n",
      "[1.81921307]\n",
      "[1.87474547]\n",
      "tensor([1.8061, 1.8403, 1.7701, 1.8498, 1.8065, 1.8192, 1.8747],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76962531]\n",
      "[1.88569341]\n",
      "[1.8180389]\n",
      "[1.76079003]\n",
      "[1.78783708]\n",
      "[1.86576263]\n",
      "[1.91530193]\n",
      "tensor([1.7696, 1.8857, 1.8180, 1.7608, 1.7878, 1.8658, 1.9153],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86030756]\n",
      "[1.79453022]\n",
      "[1.8018811]\n",
      "[1.74578925]\n",
      "[1.83260119]\n",
      "[1.85403101]\n",
      "[1.95792928]\n",
      "tensor([1.8603, 1.7945, 1.8019, 1.7458, 1.8326, 1.8540, 1.9579],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80618662]\n",
      "[1.83741659]\n",
      "[1.82264568]\n",
      "[1.83539296]\n",
      "[1.75074704]\n",
      "[1.7974152]\n",
      "[1.82263291]\n",
      "tensor([1.8062, 1.8374, 1.8226, 1.8354, 1.7507, 1.7974, 1.8226],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83668078]\n",
      "[1.84061065]\n",
      "[1.85764012]\n",
      "[1.7951586]\n",
      "[1.79900057]\n",
      "[1.84402759]\n",
      "[1.77533016]\n",
      "tensor([1.8367, 1.8406, 1.8576, 1.7952, 1.7990, 1.8440, 1.7753],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82008168]\n",
      "[1.79554984]\n",
      "[1.78269458]\n",
      "[1.79658211]\n",
      "[1.79863999]\n",
      "[1.80274735]\n",
      "[1.76647648]\n",
      "tensor([1.8201, 1.7955, 1.7827, 1.7966, 1.7986, 1.8027, 1.7665],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81346211]\n",
      "[1.83663455]\n",
      "[1.73152046]\n",
      "[1.81460683]\n",
      "[1.79048168]\n",
      "[1.84110368]\n",
      "[1.97635049]\n",
      "tensor([1.8135, 1.8366, 1.7315, 1.8146, 1.7905, 1.8411, 1.9764],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.742285]\n",
      "[1.87300997]\n",
      "[1.70923526]\n",
      "[1.82455063]\n",
      "[1.85760812]\n",
      "[1.85504625]\n",
      "[1.88795123]\n",
      "tensor([1.7423, 1.8730, 1.7092, 1.8246, 1.8576, 1.8550, 1.8880],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82005372]\n",
      "[1.77685171]\n",
      "[1.77793088]\n",
      "[1.87601423]\n",
      "[1.88515227]\n",
      "[1.84410576]\n",
      "[1.82584254]\n",
      "tensor([1.8201, 1.7769, 1.7779, 1.8760, 1.8852, 1.8441, 1.8258],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78484556]\n",
      "[1.80084242]\n",
      "[1.72742661]\n",
      "[1.75378916]\n",
      "[1.7299894]\n",
      "[1.87624637]\n",
      "[2.00248824]\n",
      "tensor([1.7848, 1.8008, 1.7274, 1.7538, 1.7300, 1.8762, 2.0025],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80181316]\n",
      "[1.93048936]\n",
      "[1.80810057]\n",
      "[1.74437625]\n",
      "[1.85180163]\n",
      "[1.92544892]\n",
      "[1.83854113]\n",
      "tensor([1.8018, 1.9305, 1.8081, 1.7444, 1.8518, 1.9254, 1.8385],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81610915]\n",
      "[1.849496]\n",
      "[1.83768938]\n",
      "[1.84861847]\n",
      "[1.75479636]\n",
      "[1.92263982]\n",
      "[1.8386954]\n",
      "tensor([1.8161, 1.8495, 1.8377, 1.8486, 1.7548, 1.9226, 1.8387],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85806464]\n",
      "[1.83308192]\n",
      "[1.81542333]\n",
      "[1.74351868]\n",
      "[1.90541056]\n",
      "[1.76187784]\n",
      "[1.75094419]\n",
      "tensor([1.8581, 1.8331, 1.8154, 1.7435, 1.9054, 1.7619, 1.7509],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77055107]\n",
      "[1.74426579]\n",
      "[1.80270593]\n",
      "[1.79057752]\n",
      "[1.818633]\n",
      "[1.74932846]\n",
      "[1.91005486]\n",
      "tensor([1.7706, 1.7443, 1.8027, 1.7906, 1.8186, 1.7493, 1.9101],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83925096]\n",
      "[1.79306678]\n",
      "[1.89128409]\n",
      "[1.90374789]\n",
      "[1.79484904]\n",
      "[1.83418463]\n",
      "[2.00258231]\n",
      "tensor([1.8393, 1.7931, 1.8913, 1.9037, 1.7948, 1.8342, 2.0026],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84915457]\n",
      "[1.82585096]\n",
      "[1.84591864]\n",
      "[1.82057118]\n",
      "[1.90292376]\n",
      "[1.80357932]\n",
      "[1.86436823]\n",
      "tensor([1.8492, 1.8259, 1.8459, 1.8206, 1.9029, 1.8036, 1.8644],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74267512]\n",
      "[1.87980824]\n",
      "[1.74142353]\n",
      "[1.77859684]\n",
      "[1.82405157]\n",
      "[1.86560146]\n",
      "[1.84519922]\n",
      "tensor([1.7427, 1.8798, 1.7414, 1.7786, 1.8241, 1.8656, 1.8452],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86069111]\n",
      "[1.85104103]\n",
      "[1.87765681]\n",
      "[1.78331677]\n",
      "[1.87137123]\n",
      "[1.81147586]\n",
      "[1.7936304]\n",
      "tensor([1.8607, 1.8510, 1.8777, 1.7833, 1.8714, 1.8115, 1.7936],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90843944]\n",
      "[1.82374215]\n",
      "[1.76060115]\n",
      "[1.85993137]\n",
      "[1.86010535]\n",
      "[1.7965014]\n",
      "[1.73193589]\n",
      "tensor([1.9084, 1.8237, 1.7606, 1.8599, 1.8601, 1.7965, 1.7319],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89771104]\n",
      "[1.89010394]\n",
      "[1.81394122]\n",
      "[1.79635354]\n",
      "[1.74361289]\n",
      "[1.90343345]\n",
      "[1.92258435]\n",
      "tensor([1.8977, 1.8901, 1.8139, 1.7964, 1.7436, 1.9034, 1.9226],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.08821331]\n",
      "[1.84464601]\n",
      "[1.80955883]\n",
      "[1.86359941]\n",
      "[1.87972746]\n",
      "[1.761136]\n",
      "[1.73269323]\n",
      "tensor([2.0882, 1.8446, 1.8096, 1.8636, 1.8797, 1.7611, 1.7327],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88129622]\n",
      "[1.7932791]\n",
      "[1.92430153]\n",
      "[1.79371136]\n",
      "[1.93808345]\n",
      "[1.94159522]\n",
      "[1.96902501]\n",
      "tensor([1.8813, 1.7933, 1.9243, 1.7937, 1.9381, 1.9416, 1.9690],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81052418]\n",
      "[1.94822856]\n",
      "[1.8610123]\n",
      "[1.88260305]\n",
      "[1.8478061]\n",
      "[1.82618052]\n",
      "[2.09581498]\n",
      "tensor([1.8105, 1.9482, 1.8610, 1.8826, 1.8478, 1.8262, 2.0958],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81963702]\n",
      "[1.81122731]\n",
      "[1.7732705]\n",
      "[1.76563464]\n",
      "[1.79655431]\n",
      "[1.82099785]\n",
      "[1.89742292]\n",
      "tensor([1.8196, 1.8112, 1.7733, 1.7656, 1.7966, 1.8210, 1.8974],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84705723]\n",
      "[1.83394045]\n",
      "[1.93420724]\n",
      "[1.83929967]\n",
      "[1.86808911]\n",
      "[1.72543445]\n",
      "[1.83375368]\n",
      "tensor([1.8471, 1.8339, 1.9342, 1.8393, 1.8681, 1.7254, 1.8338],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80718261]\n",
      "[1.80780498]\n",
      "[1.83145089]\n",
      "[1.80298031]\n",
      "[1.96685583]\n",
      "[1.89798252]\n",
      "[1.83133382]\n",
      "tensor([1.8072, 1.8078, 1.8315, 1.8030, 1.9669, 1.8980, 1.8313],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84493294]\n",
      "[1.99584494]\n",
      "[1.76471648]\n",
      "[1.77105691]\n",
      "[1.79573296]\n",
      "[1.87881413]\n",
      "[1.83006364]\n",
      "tensor([1.8449, 1.9958, 1.7647, 1.7711, 1.7957, 1.8788, 1.8301],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76877416]\n",
      "[1.75641039]\n",
      "[1.86184151]\n",
      "[1.78241366]\n",
      "[1.74805356]\n",
      "[1.89945641]\n",
      "[2.00230216]\n",
      "tensor([1.7688, 1.7564, 1.8618, 1.7824, 1.7481, 1.8995, 2.0023],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8880429]\n",
      "[1.77717755]\n",
      "[1.81114433]\n",
      "[1.8770125]\n",
      "[1.76969866]\n",
      "[1.86703356]\n",
      "[2.00522927]\n",
      "tensor([1.8880, 1.7772, 1.8111, 1.8770, 1.7697, 1.8670, 2.0052],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87100179]\n",
      "[1.84712238]\n",
      "[1.80273234]\n",
      "[1.85599315]\n",
      "[1.75487413]\n",
      "[1.76336678]\n",
      "[1.75526369]\n",
      "tensor([1.8710, 1.8471, 1.8027, 1.8560, 1.7549, 1.7634, 1.7553],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80748565]\n",
      "[1.77684382]\n",
      "[1.91157853]\n",
      "[1.83027868]\n",
      "[1.78935413]\n",
      "[1.75679838]\n",
      "[1.83862684]\n",
      "tensor([1.8075, 1.7768, 1.9116, 1.8303, 1.7894, 1.7568, 1.8386],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82516795]\n",
      "[2.00003161]\n",
      "[1.7233565]\n",
      "[1.72896407]\n",
      "[1.86100588]\n",
      "[1.843169]\n",
      "[1.83118689]\n",
      "tensor([1.8252, 2.0000, 1.7234, 1.7290, 1.8610, 1.8432, 1.8312],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80036464]\n",
      "[1.80576385]\n",
      "[1.73950177]\n",
      "[1.78438492]\n",
      "[2.03272136]\n",
      "[1.8035101]\n",
      "[1.86268481]\n",
      "tensor([1.8004, 1.8058, 1.7395, 1.7844, 2.0327, 1.8035, 1.8627],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96586844]\n",
      "[1.82949719]\n",
      "[1.8441973]\n",
      "[1.81318669]\n",
      "[1.83686718]\n",
      "[1.94705034]\n",
      "[1.76684566]\n",
      "tensor([1.9659, 1.8295, 1.8442, 1.8132, 1.8369, 1.9471, 1.7668],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84072283]\n",
      "[2.00540099]\n",
      "[1.85801972]\n",
      "[1.78431444]\n",
      "[1.80599876]\n",
      "[1.82017289]\n",
      "[1.80018794]\n",
      "tensor([1.8407, 2.0054, 1.8580, 1.7843, 1.8060, 1.8202, 1.8002],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86870918]\n",
      "[1.86278074]\n",
      "[1.91766277]\n",
      "[1.77988324]\n",
      "[1.79698739]\n",
      "[1.8215648]\n",
      "[1.89776056]\n",
      "tensor([1.8687, 1.8628, 1.9177, 1.7799, 1.7970, 1.8216, 1.8978],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82312086]\n",
      "[1.76346663]\n",
      "[1.9500384]\n",
      "[1.79081486]\n",
      "[1.82494851]\n",
      "[1.81774389]\n",
      "[1.80891368]\n",
      "tensor([1.8231, 1.7635, 1.9500, 1.7908, 1.8249, 1.8177, 1.8089],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75843318]\n",
      "[1.84034582]\n",
      "[1.75259999]\n",
      "[1.75407636]\n",
      "[1.77238036]\n",
      "[1.69124539]\n",
      "[1.91339883]\n",
      "tensor([1.7584, 1.8403, 1.7526, 1.7541, 1.7724, 1.6912, 1.9134],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75835182]\n",
      "[1.79376162]\n",
      "[1.87276378]\n",
      "[1.82558892]\n",
      "[1.91764472]\n",
      "[1.76612777]\n",
      "[1.76123889]\n",
      "tensor([1.7584, 1.7938, 1.8728, 1.8256, 1.9176, 1.7661, 1.7612],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83329524]\n",
      "[1.81721991]\n",
      "[1.76953872]\n",
      "[1.78434334]\n",
      "[1.8569359]\n",
      "[1.96944836]\n",
      "[1.84682684]\n",
      "tensor([1.8333, 1.8172, 1.7695, 1.7843, 1.8569, 1.9694, 1.8468],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87580039]\n",
      "[1.73509808]\n",
      "[1.86421686]\n",
      "[1.88584642]\n",
      "[1.82927054]\n",
      "[1.81050384]\n",
      "[1.83132851]\n",
      "tensor([1.8758, 1.7351, 1.8642, 1.8858, 1.8293, 1.8105, 1.8313],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78384995]\n",
      "[1.81384997]\n",
      "[1.81488904]\n",
      "[1.90336571]\n",
      "[1.8020256]\n",
      "[1.81722122]\n",
      "[1.81322659]\n",
      "tensor([1.7838, 1.8138, 1.8149, 1.9034, 1.8020, 1.8172, 1.8132],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72729462]\n",
      "[1.98341563]\n",
      "[1.97241706]\n",
      "[1.80496958]\n",
      "[1.83756602]\n",
      "[1.78259055]\n",
      "[1.86822717]\n",
      "tensor([1.7273, 1.9834, 1.9724, 1.8050, 1.8376, 1.7826, 1.8682],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75842767]\n",
      "[1.7993999]\n",
      "[1.93224449]\n",
      "[1.86049554]\n",
      "[1.85584888]\n",
      "[1.8362438]\n",
      "[1.84320432]\n",
      "tensor([1.7584, 1.7994, 1.9322, 1.8605, 1.8558, 1.8362, 1.8432],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71340553]\n",
      "[1.89811265]\n",
      "[1.84137468]\n",
      "[1.93651033]\n",
      "[1.76822363]\n",
      "[1.77060679]\n",
      "[1.76275795]\n",
      "tensor([1.7134, 1.8981, 1.8414, 1.9365, 1.7682, 1.7706, 1.7628],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95650347]\n",
      "[1.73911933]\n",
      "[1.87087597]\n",
      "[1.83284592]\n",
      "[1.80810212]\n",
      "[1.74424722]\n",
      "[1.85502765]\n",
      "tensor([1.9565, 1.7391, 1.8709, 1.8328, 1.8081, 1.7442, 1.8550],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74814003]\n",
      "[1.8427754]\n",
      "[1.83951939]\n",
      "[1.81635467]\n",
      "[1.99418833]\n",
      "[1.76048974]\n",
      "[1.9357746]\n",
      "tensor([1.7481, 1.8428, 1.8395, 1.8164, 1.9942, 1.7605, 1.9358],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87612901]\n",
      "[1.81162181]\n",
      "[1.99145375]\n",
      "[1.81463716]\n",
      "[1.85373271]\n",
      "[1.87530425]\n",
      "[1.73405432]\n",
      "tensor([1.8761, 1.8116, 1.9915, 1.8146, 1.8537, 1.8753, 1.7341],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83918588]\n",
      "[1.81288897]\n",
      "[1.83481665]\n",
      "[1.87586588]\n",
      "[1.79738822]\n",
      "[1.77060698]\n",
      "[1.8253912]\n",
      "tensor([1.8392, 1.8129, 1.8348, 1.8759, 1.7974, 1.7706, 1.8254],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81570592]\n",
      "[1.89375125]\n",
      "[1.87558183]\n",
      "[1.86251144]\n",
      "[1.73014266]\n",
      "[1.77299201]\n",
      "[1.82836922]\n",
      "tensor([1.8157, 1.8938, 1.8756, 1.8625, 1.7301, 1.7730, 1.8284],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72841809]\n",
      "[1.7902725]\n",
      "[1.81588199]\n",
      "[1.87978747]\n",
      "[1.86016011]\n",
      "[1.84780222]\n",
      "[1.84641802]\n",
      "tensor([1.7284, 1.7903, 1.8159, 1.8798, 1.8602, 1.8478, 1.8464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85181153]\n",
      "[1.83300682]\n",
      "[1.92147502]\n",
      "[1.76849183]\n",
      "[1.86779072]\n",
      "[1.84225613]\n",
      "[1.71340903]\n",
      "tensor([1.8518, 1.8330, 1.9215, 1.7685, 1.8678, 1.8423, 1.7134],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82956022]\n",
      "[1.87638285]\n",
      "[1.71271879]\n",
      "[1.8202939]\n",
      "[1.82026697]\n",
      "[1.83620192]\n",
      "[1.83853879]\n",
      "tensor([1.8296, 1.8764, 1.7127, 1.8203, 1.8203, 1.8362, 1.8385],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79901815]\n",
      "[1.83057891]\n",
      "[1.80845464]\n",
      "[1.79657409]\n",
      "[1.90020149]\n",
      "[1.75435343]\n",
      "[1.93554058]\n",
      "tensor([1.7990, 1.8306, 1.8085, 1.7966, 1.9002, 1.7544, 1.9355],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83241367]\n",
      "[1.99307705]\n",
      "[1.86171438]\n",
      "[1.80398349]\n",
      "[1.82255637]\n",
      "[1.84210064]\n",
      "[1.7474836]\n",
      "tensor([1.8324, 1.9931, 1.8617, 1.8040, 1.8226, 1.8421, 1.7475],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73394055]\n",
      "[1.87166412]\n",
      "[1.88260782]\n",
      "[1.80033176]\n",
      "[1.80466136]\n",
      "[1.85694668]\n",
      "[1.74063634]\n",
      "tensor([1.7339, 1.8717, 1.8826, 1.8003, 1.8047, 1.8569, 1.7406],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80837425]\n",
      "[1.82399485]\n",
      "[1.75112182]\n",
      "[1.91895577]\n",
      "[1.92845842]\n",
      "[1.84433582]\n",
      "[1.94379938]\n",
      "tensor([1.8084, 1.8240, 1.7511, 1.9190, 1.9285, 1.8443, 1.9438],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92511384]\n",
      "[1.92326032]\n",
      "[1.77040437]\n",
      "[1.82133728]\n",
      "[1.95263708]\n",
      "[1.8845616]\n",
      "[2.02234233]\n",
      "tensor([1.9251, 1.9233, 1.7704, 1.8213, 1.9526, 1.8846, 2.0223],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77274603]\n",
      "[1.87901968]\n",
      "[1.85384555]\n",
      "[1.89350186]\n",
      "[1.85171472]\n",
      "[1.79098355]\n",
      "[1.97114769]\n",
      "tensor([1.7727, 1.8790, 1.8538, 1.8935, 1.8517, 1.7910, 1.9711],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77200294]\n",
      "[1.81148459]\n",
      "[1.81262519]\n",
      "[1.76445078]\n",
      "[1.96911719]\n",
      "[1.7684195]\n",
      "[1.71585388]\n",
      "tensor([1.7720, 1.8115, 1.8126, 1.7645, 1.9691, 1.7684, 1.7159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74654178]\n",
      "[1.92903438]\n",
      "[1.84512705]\n",
      "[1.74519228]\n",
      "[1.74142443]\n",
      "[1.78391649]\n",
      "[1.79303551]\n",
      "tensor([1.7465, 1.9290, 1.8451, 1.7452, 1.7414, 1.7839, 1.7930],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88059913]\n",
      "[1.75617774]\n",
      "[1.7898625]\n",
      "[1.91352988]\n",
      "[1.80413569]\n",
      "[1.83086585]\n",
      "[1.96821083]\n",
      "tensor([1.8806, 1.7562, 1.7899, 1.9135, 1.8041, 1.8309, 1.9682],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69410616]\n",
      "[1.79605862]\n",
      "[1.71978077]\n",
      "[1.86447452]\n",
      "[1.78609031]\n",
      "[1.94429793]\n",
      "[1.77351264]\n",
      "tensor([1.6941, 1.7961, 1.7198, 1.8645, 1.7861, 1.9443, 1.7735],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84611195]\n",
      "[1.84382674]\n",
      "[1.98636192]\n",
      "[1.782014]\n",
      "[1.80557578]\n",
      "[1.88305401]\n",
      "[1.82942312]\n",
      "tensor([1.8461, 1.8438, 1.9864, 1.7820, 1.8056, 1.8831, 1.8294],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79912094]\n",
      "[1.80528619]\n",
      "[1.90496987]\n",
      "[1.93371732]\n",
      "[1.8730188]\n",
      "[1.87338266]\n",
      "[1.92813767]\n",
      "tensor([1.7991, 1.8053, 1.9050, 1.9337, 1.8730, 1.8734, 1.9281],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85905116]\n",
      "[1.8167002]\n",
      "[1.83072677]\n",
      "[1.95978872]\n",
      "[1.81245887]\n",
      "[1.9180992]\n",
      "[1.96575236]\n",
      "tensor([1.8591, 1.8167, 1.8307, 1.9598, 1.8125, 1.9181, 1.9658],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87087002]\n",
      "[1.80834895]\n",
      "[1.82793744]\n",
      "[1.76530228]\n",
      "[1.83011078]\n",
      "[1.87825373]\n",
      "[1.84176394]\n",
      "tensor([1.8709, 1.8083, 1.8279, 1.7653, 1.8301, 1.8783, 1.8418],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96356752]\n",
      "[1.77453171]\n",
      "[1.83013354]\n",
      "[1.83626856]\n",
      "[1.86285192]\n",
      "[1.8922332]\n",
      "[1.78652864]\n",
      "tensor([1.9636, 1.7745, 1.8301, 1.8363, 1.8629, 1.8922, 1.7865],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88812892]\n",
      "[1.98172857]\n",
      "[2.0036212]\n",
      "[1.94947708]\n",
      "[1.87312817]\n",
      "[1.82328146]\n",
      "[1.80088878]\n",
      "tensor([1.8881, 1.9817, 2.0036, 1.9495, 1.8731, 1.8233, 1.8009],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82446613]\n",
      "[1.81694444]\n",
      "[1.83927507]\n",
      "[1.80510637]\n",
      "[1.79460654]\n",
      "[1.81804135]\n",
      "[1.93532643]\n",
      "tensor([1.8245, 1.8169, 1.8393, 1.8051, 1.7946, 1.8180, 1.9353],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75672392]\n",
      "[1.84483877]\n",
      "[1.91672198]\n",
      "[1.85229744]\n",
      "[1.83003807]\n",
      "[1.85300804]\n",
      "[1.92192016]\n",
      "tensor([1.7567, 1.8448, 1.9167, 1.8523, 1.8300, 1.8530, 1.9219],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79445832]\n",
      "[1.83719284]\n",
      "[1.90328937]\n",
      "[1.81388629]\n",
      "[1.77483574]\n",
      "[1.75953519]\n",
      "[1.84643866]\n",
      "tensor([1.7945, 1.8372, 1.9033, 1.8139, 1.7748, 1.7595, 1.8464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86515419]\n",
      "[1.77926768]\n",
      "[1.78747588]\n",
      "[1.82354207]\n",
      "[1.87545879]\n",
      "[1.90226586]\n",
      "[1.87881769]\n",
      "tensor([1.8652, 1.7793, 1.7875, 1.8235, 1.8755, 1.9023, 1.8788],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8762211]\n",
      "[1.90374823]\n",
      "[1.79715434]\n",
      "[1.7736213]\n",
      "[1.88485392]\n",
      "[1.84897944]\n",
      "[1.75013264]\n",
      "tensor([1.8762, 1.9037, 1.7972, 1.7736, 1.8849, 1.8490, 1.7501],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77654855]\n",
      "[2.07624086]\n",
      "[1.82040272]\n",
      "[1.83827636]\n",
      "[1.74236565]\n",
      "[1.88738863]\n",
      "[1.92640322]\n",
      "tensor([1.7765, 2.0762, 1.8204, 1.8383, 1.7424, 1.8874, 1.9264],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82972066]\n",
      "[1.76562927]\n",
      "[1.79063154]\n",
      "[1.81277373]\n",
      "[1.81501243]\n",
      "[1.80013936]\n",
      "[1.85359174]\n",
      "tensor([1.8297, 1.7656, 1.7906, 1.8128, 1.8150, 1.8001, 1.8536],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91196962]\n",
      "[1.86687495]\n",
      "[1.90827425]\n",
      "[1.81746926]\n",
      "[1.85303863]\n",
      "[1.71052896]\n",
      "[1.84514089]\n",
      "tensor([1.9120, 1.8669, 1.9083, 1.8175, 1.8530, 1.7105, 1.8451],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86594149]\n",
      "[1.85415715]\n",
      "[1.7872812]\n",
      "[1.77469956]\n",
      "[1.78564981]\n",
      "[1.81775548]\n",
      "[1.8793253]\n",
      "tensor([1.8659, 1.8542, 1.7873, 1.7747, 1.7856, 1.8178, 1.8793],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85663148]\n",
      "[1.72081591]\n",
      "[1.79588931]\n",
      "[1.73117397]\n",
      "[1.78958969]\n",
      "[1.85894808]\n",
      "[1.82308733]\n",
      "tensor([1.8566, 1.7208, 1.7959, 1.7312, 1.7896, 1.8589, 1.8231],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89756473]\n",
      "[1.7550046]\n",
      "[1.88912548]\n",
      "[1.87189013]\n",
      "[1.81590438]\n",
      "[1.70270624]\n",
      "[1.93807326]\n",
      "tensor([1.8976, 1.7550, 1.8891, 1.8719, 1.8159, 1.7027, 1.9381],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76367707]\n",
      "[1.92476791]\n",
      "[1.95506146]\n",
      "[1.87974773]\n",
      "[1.86909831]\n",
      "[1.87022705]\n",
      "[1.74115458]\n",
      "tensor([1.7637, 1.9248, 1.9551, 1.8797, 1.8691, 1.8702, 1.7412],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85606441]\n",
      "[1.84244372]\n",
      "[1.81578816]\n",
      "[1.77440889]\n",
      "[1.86747459]\n",
      "[1.90432813]\n",
      "[1.90382922]\n",
      "tensor([1.8561, 1.8424, 1.8158, 1.7744, 1.8675, 1.9043, 1.9038],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85946231]\n",
      "[1.88609906]\n",
      "[1.7994037]\n",
      "[1.89735872]\n",
      "[1.85016747]\n",
      "[1.87628239]\n",
      "[1.80430626]\n",
      "tensor([1.8595, 1.8861, 1.7994, 1.8974, 1.8502, 1.8763, 1.8043],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69280704]\n",
      "[1.93287057]\n",
      "[1.84927995]\n",
      "[1.8121115]\n",
      "[1.77049008]\n",
      "[1.86359724]\n",
      "[1.95145199]\n",
      "tensor([1.6928, 1.9329, 1.8493, 1.8121, 1.7705, 1.8636, 1.9515],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88852338]\n",
      "[1.80649549]\n",
      "[1.97231337]\n",
      "[1.86431801]\n",
      "[1.88849439]\n",
      "[1.92196611]\n",
      "[1.8064039]\n",
      "tensor([1.8885, 1.8065, 1.9723, 1.8643, 1.8885, 1.9220, 1.8064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7753806]\n",
      "[1.82682388]\n",
      "[1.84653872]\n",
      "[1.81780804]\n",
      "[1.80481966]\n",
      "[1.93841732]\n",
      "[1.85206487]\n",
      "tensor([1.7754, 1.8268, 1.8465, 1.8178, 1.8048, 1.9384, 1.8521],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80090646]\n",
      "[1.79085109]\n",
      "[1.79409681]\n",
      "[1.84783134]\n",
      "[1.85510909]\n",
      "[1.84325305]\n",
      "[1.77833433]\n",
      "tensor([1.8009, 1.7909, 1.7941, 1.8478, 1.8551, 1.8433, 1.7783],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85273743]\n",
      "[1.75987872]\n",
      "[1.94675242]\n",
      "[1.89806485]\n",
      "[1.98978021]\n",
      "[1.89521286]\n",
      "[1.82727499]\n",
      "tensor([1.8527, 1.7599, 1.9468, 1.8981, 1.9898, 1.8952, 1.8273],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77264397]\n",
      "[1.75013955]\n",
      "[1.93103637]\n",
      "[1.84763027]\n",
      "[1.82781516]\n",
      "[1.95373904]\n",
      "[1.90641119]\n",
      "tensor([1.7726, 1.7501, 1.9310, 1.8476, 1.8278, 1.9537, 1.9064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81185505]\n",
      "[1.86216598]\n",
      "[1.89096272]\n",
      "[1.74892321]\n",
      "[1.85785767]\n",
      "[1.86151252]\n",
      "[1.89738489]\n",
      "tensor([1.8119, 1.8622, 1.8910, 1.7489, 1.8579, 1.8615, 1.8974],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82803839]\n",
      "[1.72552347]\n",
      "[1.81209899]\n",
      "[1.81004689]\n",
      "[1.84754963]\n",
      "[1.85710087]\n",
      "[1.80489154]\n",
      "tensor([1.8280, 1.7255, 1.8121, 1.8100, 1.8475, 1.8571, 1.8049],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8411815]\n",
      "[2.01546671]\n",
      "[1.74990279]\n",
      "[1.81042942]\n",
      "[1.95072072]\n",
      "[1.89197984]\n",
      "[1.81971277]\n",
      "tensor([1.8412, 2.0155, 1.7499, 1.8104, 1.9507, 1.8920, 1.8197],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73104175]\n",
      "[1.7801972]\n",
      "[1.8510481]\n",
      "[1.81138849]\n",
      "[1.9177799]\n",
      "[1.76260861]\n",
      "[1.80740265]\n",
      "tensor([1.7310, 1.7802, 1.8510, 1.8114, 1.9178, 1.7626, 1.8074],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83735834]\n",
      "[1.86693828]\n",
      "[1.89202167]\n",
      "[1.7418473]\n",
      "[1.74927914]\n",
      "[1.86281915]\n",
      "[1.81259112]\n",
      "tensor([1.8374, 1.8669, 1.8920, 1.7418, 1.7493, 1.8628, 1.8126],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72369705]\n",
      "[1.86332685]\n",
      "[1.83588344]\n",
      "[1.94271998]\n",
      "[1.90043387]\n",
      "[1.85033466]\n",
      "[1.83966755]\n",
      "tensor([1.7237, 1.8633, 1.8359, 1.9427, 1.9004, 1.8503, 1.8397],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83887321]\n",
      "[1.95130156]\n",
      "[1.86578612]\n",
      "[1.87148444]\n",
      "[1.86425573]\n",
      "[1.75894405]\n",
      "[1.93151615]\n",
      "tensor([1.8389, 1.9513, 1.8658, 1.8715, 1.8643, 1.7589, 1.9315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80166227]\n",
      "[1.99245816]\n",
      "[1.91157906]\n",
      "[1.75821285]\n",
      "[1.83577868]\n",
      "[1.87401564]\n",
      "[1.87929603]\n",
      "tensor([1.8017, 1.9925, 1.9116, 1.7582, 1.8358, 1.8740, 1.8793],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86616378]\n",
      "[1.79851982]\n",
      "[1.80956954]\n",
      "[1.85382835]\n",
      "[1.91044066]\n",
      "[1.80601171]\n",
      "[1.85817512]\n",
      "tensor([1.8662, 1.7985, 1.8096, 1.8538, 1.9104, 1.8060, 1.8582],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86760742]\n",
      "[1.79141411]\n",
      "[1.79835489]\n",
      "[1.83840165]\n",
      "[1.818188]\n",
      "[1.77872607]\n",
      "[1.91967987]\n",
      "tensor([1.8676, 1.7914, 1.7984, 1.8384, 1.8182, 1.7787, 1.9197],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95175396]\n",
      "[1.81441799]\n",
      "[1.75227189]\n",
      "[1.87190636]\n",
      "[1.84387647]\n",
      "[1.70393005]\n",
      "[1.78138912]\n",
      "tensor([1.9518, 1.8144, 1.7523, 1.8719, 1.8439, 1.7039, 1.7814],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78785381]\n",
      "[1.94287961]\n",
      "[1.77665682]\n",
      "[1.77401507]\n",
      "[1.84620629]\n",
      "[1.84840427]\n",
      "[1.76546147]\n",
      "tensor([1.7879, 1.9429, 1.7767, 1.7740, 1.8462, 1.8484, 1.7655],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87794678]\n",
      "[1.78132206]\n",
      "[1.92031565]\n",
      "[1.88135862]\n",
      "[1.88115786]\n",
      "[1.7721369]\n",
      "[1.74229425]\n",
      "tensor([1.8779, 1.7813, 1.9203, 1.8814, 1.8812, 1.7721, 1.7423],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88516529]\n",
      "[1.75808197]\n",
      "[1.74150209]\n",
      "[1.83619111]\n",
      "[1.76219504]\n",
      "[1.73896356]\n",
      "[1.92894486]\n",
      "tensor([1.8852, 1.7581, 1.7415, 1.8362, 1.7622, 1.7390, 1.9289],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83280445]\n",
      "[1.90178627]\n",
      "[1.85618373]\n",
      "[1.77600735]\n",
      "[1.82856155]\n",
      "[1.84573605]\n",
      "[1.73314189]\n",
      "tensor([1.8328, 1.9018, 1.8562, 1.7760, 1.8286, 1.8457, 1.7331],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81277047]\n",
      "[1.86509365]\n",
      "[1.89975718]\n",
      "[1.95071229]\n",
      "[1.8271111]\n",
      "[1.89149424]\n",
      "[1.80939373]\n",
      "tensor([1.8128, 1.8651, 1.8998, 1.9507, 1.8271, 1.8915, 1.8094],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90001931]\n",
      "[1.81409116]\n",
      "[1.82467155]\n",
      "[1.82405677]\n",
      "[1.8002675]\n",
      "[1.74521587]\n",
      "[1.77665658]\n",
      "tensor([1.9000, 1.8141, 1.8247, 1.8241, 1.8003, 1.7452, 1.7767],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8421101]\n",
      "[1.80885965]\n",
      "[1.82014095]\n",
      "[1.72882138]\n",
      "[1.83844398]\n",
      "[1.86827978]\n",
      "[1.76638733]\n",
      "tensor([1.8421, 1.8089, 1.8201, 1.7288, 1.8384, 1.8683, 1.7664],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82089142]\n",
      "[1.88920206]\n",
      "[1.70293167]\n",
      "[1.84937717]\n",
      "[1.88108469]\n",
      "[1.74915867]\n",
      "[1.94008421]\n",
      "tensor([1.8209, 1.8892, 1.7029, 1.8494, 1.8811, 1.7492, 1.9401],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77349472]\n",
      "[1.86236696]\n",
      "[1.95167007]\n",
      "[1.71468328]\n",
      "[1.85409566]\n",
      "[1.91709629]\n",
      "[1.85402865]\n",
      "tensor([1.7735, 1.8624, 1.9517, 1.7147, 1.8541, 1.9171, 1.8540],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81223628]\n",
      "[1.77007567]\n",
      "[1.78356064]\n",
      "[2.0060857]\n",
      "[1.86732898]\n",
      "[1.86332463]\n",
      "[1.98800342]\n",
      "tensor([1.8122, 1.7701, 1.7836, 2.0061, 1.8673, 1.8633, 1.9880],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77895297]\n",
      "[1.75301065]\n",
      "[1.88385146]\n",
      "[1.87863083]\n",
      "[1.86475195]\n",
      "[1.80492515]\n",
      "[1.87147176]\n",
      "tensor([1.7790, 1.7530, 1.8839, 1.8786, 1.8648, 1.8049, 1.8715],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79698507]\n",
      "[1.79168805]\n",
      "[1.72368858]\n",
      "[1.86912311]\n",
      "[1.84133973]\n",
      "[1.79394503]\n",
      "[1.73262993]\n",
      "tensor([1.7970, 1.7917, 1.7237, 1.8691, 1.8413, 1.7939, 1.7326],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83763611]\n",
      "[1.83538578]\n",
      "[1.85414947]\n",
      "[1.85804024]\n",
      "[1.88160711]\n",
      "[1.82919759]\n",
      "[1.84472503]\n",
      "tensor([1.8376, 1.8354, 1.8541, 1.8580, 1.8816, 1.8292, 1.8447],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85440949]\n",
      "[1.9305365]\n",
      "[1.75873423]\n",
      "[1.84547061]\n",
      "[1.84095926]\n",
      "[1.99102435]\n",
      "[1.89959314]\n",
      "tensor([1.8544, 1.9305, 1.7587, 1.8455, 1.8410, 1.9910, 1.8996],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9466752]\n",
      "[1.83979897]\n",
      "[1.85201349]\n",
      "[1.87191211]\n",
      "[1.7894271]\n",
      "[1.78815604]\n",
      "[1.79523993]\n",
      "tensor([1.9467, 1.8398, 1.8520, 1.8719, 1.7894, 1.7882, 1.7952],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78763539]\n",
      "[1.8855643]\n",
      "[1.79282396]\n",
      "[1.93375183]\n",
      "[1.93076693]\n",
      "[1.7938013]\n",
      "[1.74504309]\n",
      "tensor([1.7876, 1.8856, 1.7928, 1.9338, 1.9308, 1.7938, 1.7450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82767367]\n",
      "[1.96342314]\n",
      "[1.85931095]\n",
      "[1.81296073]\n",
      "[1.85668752]\n",
      "[1.84429119]\n",
      "[1.80903634]\n",
      "tensor([1.8277, 1.9634, 1.8593, 1.8130, 1.8567, 1.8443, 1.8090],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77578097]\n",
      "[1.84497417]\n",
      "[1.87401267]\n",
      "[1.77189906]\n",
      "[1.82266484]\n",
      "[1.86981429]\n",
      "[1.82878937]\n",
      "tensor([1.7758, 1.8450, 1.8740, 1.7719, 1.8227, 1.8698, 1.8288],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93000616]\n",
      "[1.912846]\n",
      "[1.77212083]\n",
      "[1.87099002]\n",
      "[1.90838856]\n",
      "[1.80928801]\n",
      "[1.8246492]\n",
      "tensor([1.9300, 1.9128, 1.7721, 1.8710, 1.9084, 1.8093, 1.8246],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79855397]\n",
      "[1.77172557]\n",
      "[1.9449091]\n",
      "[1.88391069]\n",
      "[1.82447456]\n",
      "[1.83250772]\n",
      "[1.70376987]\n",
      "tensor([1.7986, 1.7717, 1.9449, 1.8839, 1.8245, 1.8325, 1.7038],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84257073]\n",
      "[1.79277589]\n",
      "[1.81099443]\n",
      "[1.91157849]\n",
      "[1.85068102]\n",
      "[1.93982332]\n",
      "[1.86530901]\n",
      "tensor([1.8426, 1.7928, 1.8110, 1.9116, 1.8507, 1.9398, 1.8653],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79654689]\n",
      "[1.78786482]\n",
      "[1.7329091]\n",
      "[1.85511973]\n",
      "[1.90448378]\n",
      "[1.92158895]\n",
      "[1.81968496]\n",
      "tensor([1.7965, 1.7879, 1.7329, 1.8551, 1.9045, 1.9216, 1.8197],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81478025]\n",
      "[1.73561609]\n",
      "[1.91416202]\n",
      "[1.81555386]\n",
      "[1.80918911]\n",
      "[1.79670693]\n",
      "[1.94875888]\n",
      "tensor([1.8148, 1.7356, 1.9142, 1.8156, 1.8092, 1.7967, 1.9488],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93320257]\n",
      "[1.89726704]\n",
      "[1.7283087]\n",
      "[1.9304063]\n",
      "[1.78268907]\n",
      "[1.7301345]\n",
      "[1.76034674]\n",
      "tensor([1.9332, 1.8973, 1.7283, 1.9304, 1.7827, 1.7301, 1.7603],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80883704]\n",
      "[1.76280779]\n",
      "[1.84393626]\n",
      "[1.79200126]\n",
      "[1.84337317]\n",
      "[1.86408376]\n",
      "[1.91638052]\n",
      "tensor([1.8088, 1.7628, 1.8439, 1.7920, 1.8434, 1.8641, 1.9164],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82526125]\n",
      "[1.84875479]\n",
      "[1.77891269]\n",
      "[1.74330678]\n",
      "[1.84159231]\n",
      "[1.98102771]\n",
      "[1.79453918]\n",
      "tensor([1.8253, 1.8488, 1.7789, 1.7433, 1.8416, 1.9810, 1.7945],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.99092279]\n",
      "[1.77245783]\n",
      "[1.88065803]\n",
      "[1.89001794]\n",
      "[1.96660127]\n",
      "[1.7193278]\n",
      "[2.00813621]\n",
      "tensor([1.9909, 1.7725, 1.8807, 1.8900, 1.9666, 1.7193, 2.0081],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87953252]\n",
      "[1.84403613]\n",
      "[1.7385974]\n",
      "[1.85387774]\n",
      "[1.79323676]\n",
      "[1.79819925]\n",
      "[1.73845757]\n",
      "tensor([1.8795, 1.8440, 1.7386, 1.8539, 1.7932, 1.7982, 1.7385],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87858913]\n",
      "[1.82515141]\n",
      "[1.72901815]\n",
      "[1.89004741]\n",
      "[1.71770139]\n",
      "[1.88208436]\n",
      "[1.91013638]\n",
      "tensor([1.8786, 1.8252, 1.7290, 1.8900, 1.7177, 1.8821, 1.9101],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87051285]\n",
      "[1.75388643]\n",
      "[1.84927615]\n",
      "[1.8467646]\n",
      "[1.85252727]\n",
      "[1.93974842]\n",
      "[1.84507877]\n",
      "tensor([1.8705, 1.7539, 1.8493, 1.8468, 1.8525, 1.9397, 1.8451],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87473312]\n",
      "[1.95282415]\n",
      "[1.86995642]\n",
      "[1.81809807]\n",
      "[1.86938403]\n",
      "[1.76621122]\n",
      "[1.81859453]\n",
      "tensor([1.8747, 1.9528, 1.8700, 1.8181, 1.8694, 1.7662, 1.8186],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7145906]\n",
      "[1.80967814]\n",
      "[1.85191501]\n",
      "[2.01389353]\n",
      "[1.85959567]\n",
      "[1.78434268]\n",
      "[1.83817372]\n",
      "tensor([1.7146, 1.8097, 1.8519, 2.0139, 1.8596, 1.7843, 1.8382],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77869768]\n",
      "[1.93532775]\n",
      "[1.81996047]\n",
      "[1.85371496]\n",
      "[1.79953718]\n",
      "[1.79062136]\n",
      "[1.77462001]\n",
      "tensor([1.7787, 1.9353, 1.8200, 1.8537, 1.7995, 1.7906, 1.7746],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73173851]\n",
      "[1.93262884]\n",
      "[1.87643421]\n",
      "[1.91343533]\n",
      "[1.85963814]\n",
      "[1.84273012]\n",
      "[1.87733583]\n",
      "tensor([1.7317, 1.9326, 1.8764, 1.9134, 1.8596, 1.8427, 1.8773],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84081703]\n",
      "[1.82395421]\n",
      "[1.71707349]\n",
      "[1.94866301]\n",
      "[1.87249588]\n",
      "[1.79677068]\n",
      "[1.80604922]\n",
      "tensor([1.8408, 1.8240, 1.7171, 1.9487, 1.8725, 1.7968, 1.8060],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83637149]\n",
      "[1.84628419]\n",
      "[1.8516433]\n",
      "[1.83126616]\n",
      "[1.85541998]\n",
      "[1.79134037]\n",
      "[1.77217242]\n",
      "tensor([1.8364, 1.8463, 1.8516, 1.8313, 1.8554, 1.7913, 1.7722],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93144311]\n",
      "[1.83609761]\n",
      "[1.83571194]\n",
      "[1.6985119]\n",
      "[1.81673067]\n",
      "[1.96949607]\n",
      "[1.74169901]\n",
      "tensor([1.9314, 1.8361, 1.8357, 1.6985, 1.8167, 1.9695, 1.7417],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96105232]\n",
      "[1.73737347]\n",
      "[1.8517453]\n",
      "[1.81392008]\n",
      "[1.86452656]\n",
      "[1.8821014]\n",
      "[1.84504912]\n",
      "tensor([1.9611, 1.7374, 1.8517, 1.8139, 1.8645, 1.8821, 1.8450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79682274]\n",
      "[1.78405159]\n",
      "[1.80402679]\n",
      "[1.82495109]\n",
      "[1.66927858]\n",
      "[1.82161028]\n",
      "[1.85356788]\n",
      "tensor([1.7968, 1.7841, 1.8040, 1.8250, 1.6693, 1.8216, 1.8536],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74768785]\n",
      "[1.74748288]\n",
      "[1.81113241]\n",
      "[1.74882152]\n",
      "[1.87045726]\n",
      "[1.84419329]\n",
      "[1.81454007]\n",
      "tensor([1.7477, 1.7475, 1.8111, 1.7488, 1.8705, 1.8442, 1.8145],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77306534]\n",
      "[1.8960561]\n",
      "[1.94840627]\n",
      "[1.78160674]\n",
      "[1.92515135]\n",
      "[1.93922386]\n",
      "[1.89719211]\n",
      "tensor([1.7731, 1.8961, 1.9484, 1.7816, 1.9252, 1.9392, 1.8972],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80682369]\n",
      "[1.83119358]\n",
      "[1.73261393]\n",
      "[1.95206571]\n",
      "[1.80879174]\n",
      "[1.7674201]\n",
      "[1.84908221]\n",
      "tensor([1.8068, 1.8312, 1.7326, 1.9521, 1.8088, 1.7674, 1.8491],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92052801]\n",
      "[1.80951222]\n",
      "[1.84952742]\n",
      "[1.88316079]\n",
      "[1.78016099]\n",
      "[1.89325882]\n",
      "[1.99779374]\n",
      "tensor([1.9205, 1.8095, 1.8495, 1.8832, 1.7802, 1.8933, 1.9978],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89760845]\n",
      "[1.85404956]\n",
      "[1.86893389]\n",
      "[1.7897085]\n",
      "[1.79344105]\n",
      "[1.93254597]\n",
      "[1.84979386]\n",
      "tensor([1.8976, 1.8540, 1.8689, 1.7897, 1.7934, 1.9325, 1.8498],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75908539]\n",
      "[1.84527627]\n",
      "[1.76024067]\n",
      "[1.76275374]\n",
      "[1.93719923]\n",
      "[1.83800104]\n",
      "[1.81185674]\n",
      "tensor([1.7591, 1.8453, 1.7602, 1.7628, 1.9372, 1.8380, 1.8119],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79609092]\n",
      "[1.94614902]\n",
      "[2.00164006]\n",
      "[1.80982039]\n",
      "[1.81676013]\n",
      "[1.79737627]\n",
      "[1.91686543]\n",
      "tensor([1.7961, 1.9461, 2.0016, 1.8098, 1.8168, 1.7974, 1.9169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84875601]\n",
      "[1.91536517]\n",
      "[1.79123054]\n",
      "[1.97683717]\n",
      "[1.93062927]\n",
      "[1.83029427]\n",
      "[1.81573718]\n",
      "tensor([1.8488, 1.9154, 1.7912, 1.9768, 1.9306, 1.8303, 1.8157],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69007313]\n",
      "[1.78175792]\n",
      "[1.72380894]\n",
      "[1.85508642]\n",
      "[1.83819759]\n",
      "[1.85848255]\n",
      "[1.84331164]\n",
      "tensor([1.6901, 1.7818, 1.7238, 1.8551, 1.8382, 1.8585, 1.8433],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82985222]\n",
      "[1.87234638]\n",
      "[1.95884285]\n",
      "[1.96728252]\n",
      "[1.85866849]\n",
      "[1.87468376]\n",
      "[1.88446507]\n",
      "tensor([1.8299, 1.8723, 1.9588, 1.9673, 1.8587, 1.8747, 1.8845],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84792912]\n",
      "[1.73551771]\n",
      "[1.8228076]\n",
      "[1.83552012]\n",
      "[1.74288151]\n",
      "[1.77734413]\n",
      "[1.8645184]\n",
      "tensor([1.8479, 1.7355, 1.8228, 1.8355, 1.7429, 1.7773, 1.8645],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74920065]\n",
      "[1.93540883]\n",
      "[1.89462958]\n",
      "[1.79887774]\n",
      "[1.8716105]\n",
      "[1.81351]\n",
      "[1.90752835]\n",
      "tensor([1.7492, 1.9354, 1.8946, 1.7989, 1.8716, 1.8135, 1.9075],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91309181]\n",
      "[1.76455529]\n",
      "[1.76421042]\n",
      "[1.77864678]\n",
      "[1.91473628]\n",
      "[1.8351645]\n",
      "[1.77801753]\n",
      "tensor([1.9131, 1.7646, 1.7642, 1.7786, 1.9147, 1.8352, 1.7780],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87448554]\n",
      "[1.77007073]\n",
      "[1.82250728]\n",
      "[1.73141485]\n",
      "[1.84626315]\n",
      "[2.00037889]\n",
      "[1.75173947]\n",
      "tensor([1.8745, 1.7701, 1.8225, 1.7314, 1.8463, 2.0004, 1.7517],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84368539]\n",
      "[1.89223337]\n",
      "[1.82685668]\n",
      "[1.82992162]\n",
      "[1.83774145]\n",
      "[1.86716409]\n",
      "[1.83518395]\n",
      "tensor([1.8437, 1.8922, 1.8269, 1.8299, 1.8377, 1.8672, 1.8352],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92112302]\n",
      "[1.78443549]\n",
      "[1.88467518]\n",
      "[1.84044084]\n",
      "[1.80235837]\n",
      "[1.81722851]\n",
      "[1.81710413]\n",
      "tensor([1.9211, 1.7844, 1.8847, 1.8404, 1.8024, 1.8172, 1.8171],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74518359]\n",
      "[1.71674362]\n",
      "[1.8244307]\n",
      "[1.87910628]\n",
      "[1.72112661]\n",
      "[1.84418476]\n",
      "[1.79527743]\n",
      "tensor([1.7452, 1.7167, 1.8244, 1.8791, 1.7211, 1.8442, 1.7953],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81430055]\n",
      "[1.7540924]\n",
      "[1.79966755]\n",
      "[1.76838093]\n",
      "[1.81112533]\n",
      "[1.81366656]\n",
      "[1.84987429]\n",
      "tensor([1.8143, 1.7541, 1.7997, 1.7684, 1.8111, 1.8137, 1.8499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80937569]\n",
      "[1.72253442]\n",
      "[1.92837096]\n",
      "[1.81293561]\n",
      "[1.83149772]\n",
      "[1.81264877]\n",
      "[1.90520403]\n",
      "tensor([1.8094, 1.7225, 1.9284, 1.8129, 1.8315, 1.8126, 1.9052],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83442641]\n",
      "[1.87909554]\n",
      "[1.75720094]\n",
      "[1.9089858]\n",
      "[1.84934155]\n",
      "[1.78641014]\n",
      "[1.93728798]\n",
      "tensor([1.8344, 1.8791, 1.7572, 1.9090, 1.8493, 1.7864, 1.9373],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80016469]\n",
      "[1.86713529]\n",
      "[1.90119208]\n",
      "[1.79525505]\n",
      "[1.79337466]\n",
      "[1.8677514]\n",
      "[1.79741213]\n",
      "tensor([1.8002, 1.8671, 1.9012, 1.7953, 1.7934, 1.8678, 1.7974],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76007475]\n",
      "[1.70195522]\n",
      "[1.84531677]\n",
      "[1.76555382]\n",
      "[1.78469898]\n",
      "[1.81380771]\n",
      "[1.77038255]\n",
      "tensor([1.7601, 1.7020, 1.8453, 1.7656, 1.7847, 1.8138, 1.7704],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80101767]\n",
      "[1.88462003]\n",
      "[1.76343532]\n",
      "[1.72436676]\n",
      "[2.0112053]\n",
      "[1.85250655]\n",
      "[1.78762791]\n",
      "tensor([1.8010, 1.8846, 1.7634, 1.7244, 2.0112, 1.8525, 1.7876],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83026356]\n",
      "[1.79254181]\n",
      "[1.8112378]\n",
      "[1.99571586]\n",
      "[1.84178927]\n",
      "[1.83934142]\n",
      "[1.84464641]\n",
      "tensor([1.8303, 1.7925, 1.8112, 1.9957, 1.8418, 1.8393, 1.8446],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84540089]\n",
      "[1.78507499]\n",
      "[1.7633614]\n",
      "[1.76086549]\n",
      "[1.7051414]\n",
      "[1.81617618]\n",
      "[1.77035635]\n",
      "tensor([1.8454, 1.7851, 1.7634, 1.7609, 1.7051, 1.8162, 1.7704],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81591647]\n",
      "[1.95588531]\n",
      "[1.81063518]\n",
      "[1.79171993]\n",
      "[1.74891241]\n",
      "[1.85208904]\n",
      "[1.81624702]\n",
      "tensor([1.8159, 1.9559, 1.8106, 1.7917, 1.7489, 1.8521, 1.8162],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79579802]\n",
      "[1.79334654]\n",
      "[1.73569391]\n",
      "[1.80205299]\n",
      "[1.8020687]\n",
      "[1.78408852]\n",
      "[1.81783598]\n",
      "tensor([1.7958, 1.7933, 1.7357, 1.8021, 1.8021, 1.7841, 1.8178],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80137985]\n",
      "[1.91030691]\n",
      "[1.80623291]\n",
      "[1.874486]\n",
      "[1.83419949]\n",
      "[1.82890299]\n",
      "[1.83752023]\n",
      "tensor([1.8014, 1.9103, 1.8062, 1.8745, 1.8342, 1.8289, 1.8375],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78346348]\n",
      "[1.81512043]\n",
      "[1.73195227]\n",
      "[1.98078648]\n",
      "[1.81440921]\n",
      "[1.80308218]\n",
      "[1.82096023]\n",
      "tensor([1.7835, 1.8151, 1.7320, 1.9808, 1.8144, 1.8031, 1.8210],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7836349]\n",
      "[1.88243191]\n",
      "[1.78699757]\n",
      "[1.84374018]\n",
      "[1.79164145]\n",
      "[1.73991571]\n",
      "[1.98843354]\n",
      "tensor([1.7836, 1.8824, 1.7870, 1.8437, 1.7916, 1.7399, 1.9884],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8086673]\n",
      "[1.90806075]\n",
      "[1.96979665]\n",
      "[1.88665517]\n",
      "[1.8372007]\n",
      "[1.8266436]\n",
      "[1.82530563]\n",
      "tensor([1.8087, 1.9081, 1.9698, 1.8867, 1.8372, 1.8266, 1.8253],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89050488]\n",
      "[1.88838919]\n",
      "[1.84883106]\n",
      "[1.87872282]\n",
      "[1.8377127]\n",
      "[1.81478466]\n",
      "[1.9459149]\n",
      "tensor([1.8905, 1.8884, 1.8488, 1.8787, 1.8377, 1.8148, 1.9459],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91276347]\n",
      "[1.76275391]\n",
      "[1.85342795]\n",
      "[1.87179478]\n",
      "[1.788209]\n",
      "[1.9022643]\n",
      "[1.81144863]\n",
      "tensor([1.9128, 1.7628, 1.8534, 1.8718, 1.7882, 1.9023, 1.8114],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83883172]\n",
      "[1.91214105]\n",
      "[1.83357345]\n",
      "[1.89706326]\n",
      "[1.79522278]\n",
      "[1.84428142]\n",
      "[1.78169685]\n",
      "tensor([1.8388, 1.9121, 1.8336, 1.8971, 1.7952, 1.8443, 1.7817],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80876937]\n",
      "[1.80816844]\n",
      "[1.81217094]\n",
      "[1.75143499]\n",
      "[1.81110156]\n",
      "[1.80194728]\n",
      "[1.80637321]\n",
      "tensor([1.8088, 1.8082, 1.8122, 1.7514, 1.8111, 1.8019, 1.8064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78364761]\n",
      "[1.76661077]\n",
      "[1.82374277]\n",
      "[1.83438815]\n",
      "[1.84652936]\n",
      "[1.82601049]\n",
      "[1.86976663]\n",
      "tensor([1.7836, 1.7666, 1.8237, 1.8344, 1.8465, 1.8260, 1.8698],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94324279]\n",
      "[1.90223796]\n",
      "[1.82593007]\n",
      "[1.80564059]\n",
      "[1.72832794]\n",
      "[1.85444962]\n",
      "[1.94095647]\n",
      "tensor([1.9432, 1.9022, 1.8259, 1.8056, 1.7283, 1.8544, 1.9410],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88172274]\n",
      "[1.72932955]\n",
      "[1.83800763]\n",
      "[1.89147706]\n",
      "[1.80183373]\n",
      "[1.89151704]\n",
      "[1.84705068]\n",
      "tensor([1.8817, 1.7293, 1.8380, 1.8915, 1.8018, 1.8915, 1.8471],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70431836]\n",
      "[1.83336611]\n",
      "[1.86678309]\n",
      "[1.83878297]\n",
      "[1.8587922]\n",
      "[1.85047874]\n",
      "[1.8410903]\n",
      "tensor([1.7043, 1.8334, 1.8668, 1.8388, 1.8588, 1.8505, 1.8411],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83117163]\n",
      "[1.80724777]\n",
      "[1.73375565]\n",
      "[1.90137169]\n",
      "[1.81829557]\n",
      "[1.814727]\n",
      "[1.74486699]\n",
      "tensor([1.8312, 1.8072, 1.7338, 1.9014, 1.8183, 1.8147, 1.7449],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85248282]\n",
      "[1.79890224]\n",
      "[1.87131999]\n",
      "[1.84196525]\n",
      "[1.84060887]\n",
      "[1.78320002]\n",
      "[1.80915514]\n",
      "tensor([1.8525, 1.7989, 1.8713, 1.8420, 1.8406, 1.7832, 1.8092],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81313138]\n",
      "[1.78614823]\n",
      "[1.91162769]\n",
      "[1.83323198]\n",
      "[1.92932971]\n",
      "[1.84388891]\n",
      "[1.77526557]\n",
      "tensor([1.8131, 1.7861, 1.9116, 1.8332, 1.9293, 1.8439, 1.7753],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78124315]\n",
      "[1.81234202]\n",
      "[1.76577168]\n",
      "[1.84174306]\n",
      "[1.8195286]\n",
      "[1.78327367]\n",
      "[1.74685112]\n",
      "tensor([1.7812, 1.8123, 1.7658, 1.8417, 1.8195, 1.7833, 1.7469],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77267003]\n",
      "[1.78174174]\n",
      "[1.8443078]\n",
      "[1.75110443]\n",
      "[1.79402692]\n",
      "[1.8251902]\n",
      "[1.81449767]\n",
      "tensor([1.7727, 1.7817, 1.8443, 1.7511, 1.7940, 1.8252, 1.8145],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8158223]\n",
      "[1.84716562]\n",
      "[1.84836468]\n",
      "[1.75649738]\n",
      "[1.76717256]\n",
      "[1.74083381]\n",
      "[1.68828957]\n",
      "tensor([1.8158, 1.8472, 1.8484, 1.7565, 1.7672, 1.7408, 1.6883],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83304573]\n",
      "[1.92959152]\n",
      "[1.86252658]\n",
      "[1.83870414]\n",
      "[1.84788274]\n",
      "[1.82300099]\n",
      "[1.87540646]\n",
      "tensor([1.8330, 1.9296, 1.8625, 1.8387, 1.8479, 1.8230, 1.8754],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83312085]\n",
      "[1.83103492]\n",
      "[1.86664156]\n",
      "[1.82795224]\n",
      "[1.86638454]\n",
      "[1.9475977]\n",
      "[1.85294733]\n",
      "tensor([1.8331, 1.8310, 1.8666, 1.8280, 1.8664, 1.9476, 1.8529],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7937526]\n",
      "[1.79309381]\n",
      "[1.91323902]\n",
      "[1.77406076]\n",
      "[1.81132604]\n",
      "[1.81414729]\n",
      "[1.81426209]\n",
      "tensor([1.7938, 1.7931, 1.9132, 1.7741, 1.8113, 1.8141, 1.8143],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81663924]\n",
      "[1.87475318]\n",
      "[1.79902185]\n",
      "[1.80384769]\n",
      "[1.80504913]\n",
      "[1.82631782]\n",
      "[1.81583838]\n",
      "tensor([1.8166, 1.8748, 1.7990, 1.8038, 1.8050, 1.8263, 1.8158],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89918202]\n",
      "[1.79860056]\n",
      "[1.90450338]\n",
      "[1.76990467]\n",
      "[1.77738112]\n",
      "[1.85330503]\n",
      "[1.90439177]\n",
      "tensor([1.8992, 1.7986, 1.9045, 1.7699, 1.7774, 1.8533, 1.9044],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90884276]\n",
      "[1.77850214]\n",
      "[1.8730753]\n",
      "[1.88479809]\n",
      "[1.84892542]\n",
      "[1.8713618]\n",
      "[2.01883585]\n",
      "tensor([1.9088, 1.7785, 1.8731, 1.8848, 1.8489, 1.8714, 2.0188],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92329394]\n",
      "[1.79560319]\n",
      "[1.92918153]\n",
      "[1.79662879]\n",
      "[1.80347264]\n",
      "[1.85164208]\n",
      "[1.7085651]\n",
      "tensor([1.9233, 1.7956, 1.9292, 1.7966, 1.8035, 1.8516, 1.7086],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90904937]\n",
      "[1.87552543]\n",
      "[1.88303231]\n",
      "[1.75577362]\n",
      "[1.79198274]\n",
      "[1.80190332]\n",
      "[1.70239066]\n",
      "tensor([1.9090, 1.8755, 1.8830, 1.7558, 1.7920, 1.8019, 1.7024],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81053709]\n",
      "[1.87704895]\n",
      "[1.86109809]\n",
      "[1.78802522]\n",
      "[1.8096868]\n",
      "[1.7829021]\n",
      "[1.82251127]\n",
      "tensor([1.8105, 1.8770, 1.8611, 1.7880, 1.8097, 1.7829, 1.8225],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7826031]\n",
      "[1.80173479]\n",
      "[1.86766083]\n",
      "[1.79734094]\n",
      "[1.76195749]\n",
      "[1.93086982]\n",
      "[1.78731627]\n",
      "tensor([1.7826, 1.8017, 1.8677, 1.7973, 1.7620, 1.9309, 1.7873],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8390143]\n",
      "[1.85881439]\n",
      "[1.69876149]\n",
      "[1.86891067]\n",
      "[1.91455053]\n",
      "[1.7788142]\n",
      "[1.73094378]\n",
      "tensor([1.8390, 1.8588, 1.6988, 1.8689, 1.9146, 1.7788, 1.7309],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97843589]\n",
      "[1.89964679]\n",
      "[1.72644382]\n",
      "[1.81825545]\n",
      "[1.79222959]\n",
      "[1.82529649]\n",
      "[1.82539939]\n",
      "tensor([1.9784, 1.8996, 1.7264, 1.8183, 1.7922, 1.8253, 1.8254],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81070521]\n",
      "[1.92460989]\n",
      "[1.92881242]\n",
      "[1.80167001]\n",
      "[1.85124096]\n",
      "[1.8030121]\n",
      "[1.79375523]\n",
      "tensor([1.8107, 1.9246, 1.9288, 1.8017, 1.8512, 1.8030, 1.7938],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70383696]\n",
      "[1.79035602]\n",
      "[1.81027605]\n",
      "[1.82467714]\n",
      "[1.79764218]\n",
      "[1.73645394]\n",
      "[1.95369734]\n",
      "tensor([1.7038, 1.7904, 1.8103, 1.8247, 1.7976, 1.7365, 1.9537],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92344285]\n",
      "[1.86303733]\n",
      "[1.79656554]\n",
      "[1.91917346]\n",
      "[1.83139319]\n",
      "[1.7581507]\n",
      "[1.7998273]\n",
      "tensor([1.9234, 1.8630, 1.7966, 1.9192, 1.8314, 1.7582, 1.7998],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83011563]\n",
      "[1.95244887]\n",
      "[1.85813538]\n",
      "[1.72932423]\n",
      "[1.7522123]\n",
      "[1.7414131]\n",
      "[1.87728179]\n",
      "tensor([1.8301, 1.9524, 1.8581, 1.7293, 1.7522, 1.7414, 1.8773],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87029349]\n",
      "[1.82059854]\n",
      "[1.93217547]\n",
      "[1.7535434]\n",
      "[1.84835597]\n",
      "[1.76775254]\n",
      "[1.81796038]\n",
      "tensor([1.8703, 1.8206, 1.9322, 1.7535, 1.8484, 1.7678, 1.8180],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82224887]\n",
      "[1.89549028]\n",
      "[1.85811229]\n",
      "[1.82439668]\n",
      "[1.90395366]\n",
      "[1.95886818]\n",
      "[1.74728148]\n",
      "tensor([1.8222, 1.8955, 1.8581, 1.8244, 1.9040, 1.9589, 1.7473],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7759363]\n",
      "[1.71814715]\n",
      "[1.81035504]\n",
      "[1.97613308]\n",
      "[1.83454338]\n",
      "[1.73542614]\n",
      "[1.8711221]\n",
      "tensor([1.7759, 1.7181, 1.8104, 1.9761, 1.8345, 1.7354, 1.8711],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84302523]\n",
      "[1.78631694]\n",
      "[1.88145157]\n",
      "[1.83561243]\n",
      "[1.86134485]\n",
      "[1.81309354]\n",
      "[1.75245862]\n",
      "tensor([1.8430, 1.7863, 1.8815, 1.8356, 1.8613, 1.8131, 1.7525],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81431888]\n",
      "[1.89184015]\n",
      "[1.88121207]\n",
      "[1.86034282]\n",
      "[1.9036527]\n",
      "[1.94960649]\n",
      "[1.87477322]\n",
      "tensor([1.8143, 1.8918, 1.8812, 1.8603, 1.9037, 1.9496, 1.8748],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81131598]\n",
      "[1.76859933]\n",
      "[1.73965471]\n",
      "[1.8910811]\n",
      "[1.89198902]\n",
      "[1.73308615]\n",
      "[1.81700296]\n",
      "tensor([1.8113, 1.7686, 1.7397, 1.8911, 1.8920, 1.7331, 1.8170],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74060781]\n",
      "[1.82542551]\n",
      "[1.86272897]\n",
      "[1.76744523]\n",
      "[1.77944257]\n",
      "[1.80857059]\n",
      "[1.97080603]\n",
      "tensor([1.7406, 1.8254, 1.8627, 1.7674, 1.7794, 1.8086, 1.9708],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.858788]\n",
      "[1.84709713]\n",
      "[1.74744025]\n",
      "[1.82845365]\n",
      "[1.79123515]\n",
      "[1.75035089]\n",
      "[1.85313927]\n",
      "tensor([1.8588, 1.8471, 1.7474, 1.8285, 1.7912, 1.7504, 1.8531],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86377875]\n",
      "[1.74714504]\n",
      "[1.84020926]\n",
      "[1.7825495]\n",
      "[1.87201912]\n",
      "[1.84871761]\n",
      "[1.93385605]\n",
      "tensor([1.8638, 1.7471, 1.8402, 1.7825, 1.8720, 1.8487, 1.9339],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80422417]\n",
      "[1.74080487]\n",
      "[1.9044542]\n",
      "[1.76865965]\n",
      "[1.8392473]\n",
      "[1.83272622]\n",
      "[1.8384138]\n",
      "tensor([1.8042, 1.7408, 1.9045, 1.7687, 1.8392, 1.8327, 1.8384],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79576601]\n",
      "[1.73249124]\n",
      "[1.82577395]\n",
      "[1.83339438]\n",
      "[1.89615181]\n",
      "[1.8137677]\n",
      "[1.8331868]\n",
      "tensor([1.7958, 1.7325, 1.8258, 1.8334, 1.8962, 1.8138, 1.8332],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78648693]\n",
      "[1.81568056]\n",
      "[1.87493775]\n",
      "[1.81151788]\n",
      "[1.86316053]\n",
      "[1.83792912]\n",
      "[1.87449821]\n",
      "tensor([1.7865, 1.8157, 1.8749, 1.8115, 1.8632, 1.8379, 1.8745],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77511133]\n",
      "[1.9202464]\n",
      "[1.79846002]\n",
      "[1.78833668]\n",
      "[1.68394376]\n",
      "[1.77384735]\n",
      "[1.8097015]\n",
      "tensor([1.7751, 1.9202, 1.7985, 1.7883, 1.6839, 1.7738, 1.8097],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85296532]\n",
      "[1.84633207]\n",
      "[1.78919829]\n",
      "[1.80550505]\n",
      "[1.72492712]\n",
      "[1.81234107]\n",
      "[1.82635902]\n",
      "tensor([1.8530, 1.8463, 1.7892, 1.8055, 1.7249, 1.8123, 1.8264],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77810264]\n",
      "[1.78691696]\n",
      "[2.07796233]\n",
      "[1.88355061]\n",
      "[1.86338285]\n",
      "[1.71508262]\n",
      "[1.75250151]\n",
      "tensor([1.7781, 1.7869, 2.0780, 1.8836, 1.8634, 1.7151, 1.7525],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80851881]\n",
      "[1.73856577]\n",
      "[1.81630301]\n",
      "[1.89372011]\n",
      "[1.83618828]\n",
      "[1.87750357]\n",
      "[1.85816662]\n",
      "tensor([1.8085, 1.7386, 1.8163, 1.8937, 1.8362, 1.8775, 1.8582],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88012503]\n",
      "[1.83749235]\n",
      "[1.78745013]\n",
      "[1.79952379]\n",
      "[1.71075403]\n",
      "[1.73273375]\n",
      "[1.8294407]\n",
      "tensor([1.8801, 1.8375, 1.7875, 1.7995, 1.7108, 1.7327, 1.8294],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89287112]\n",
      "[1.8547235]\n",
      "[1.97525008]\n",
      "[1.81985466]\n",
      "[1.92104358]\n",
      "[1.81905994]\n",
      "[1.76448194]\n",
      "tensor([1.8929, 1.8547, 1.9753, 1.8199, 1.9210, 1.8191, 1.7645],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80118384]\n",
      "[1.7938176]\n",
      "[1.82063868]\n",
      "[1.79473739]\n",
      "[1.86139776]\n",
      "[1.85090103]\n",
      "[1.94959053]\n",
      "tensor([1.8012, 1.7938, 1.8206, 1.7947, 1.8614, 1.8509, 1.9496],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87718364]\n",
      "[1.89195448]\n",
      "[1.79458356]\n",
      "[1.75377281]\n",
      "[1.8016893]\n",
      "[1.96125445]\n",
      "[1.79974952]\n",
      "tensor([1.8772, 1.8920, 1.7946, 1.7538, 1.8017, 1.9613, 1.7997],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83996556]\n",
      "[1.78654152]\n",
      "[1.77876803]\n",
      "[1.80650595]\n",
      "[1.80850213]\n",
      "[1.8847588]\n",
      "[1.83022487]\n",
      "tensor([1.8400, 1.7865, 1.7788, 1.8065, 1.8085, 1.8848, 1.8302],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86159909]\n",
      "[1.73463536]\n",
      "[1.80831239]\n",
      "[1.89095814]\n",
      "[1.90793843]\n",
      "[1.86311232]\n",
      "[1.87360768]\n",
      "tensor([1.8616, 1.7346, 1.8083, 1.8910, 1.9079, 1.8631, 1.8736],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73901927]\n",
      "[1.84572897]\n",
      "[1.87926481]\n",
      "[1.90868027]\n",
      "[1.95931844]\n",
      "[1.83871853]\n",
      "[1.88182074]\n",
      "tensor([1.7390, 1.8457, 1.8793, 1.9087, 1.9593, 1.8387, 1.8818],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83349092]\n",
      "[1.66183972]\n",
      "[1.92939595]\n",
      "[1.81683032]\n",
      "[1.91669177]\n",
      "[1.87364731]\n",
      "[1.8131627]\n",
      "tensor([1.8335, 1.6618, 1.9294, 1.8168, 1.9167, 1.8736, 1.8132],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77776717]\n",
      "[1.92950017]\n",
      "[1.86051259]\n",
      "[1.8632532]\n",
      "[1.85754752]\n",
      "[2.02439728]\n",
      "[1.68901577]\n",
      "tensor([1.7778, 1.9295, 1.8605, 1.8633, 1.8575, 2.0244, 1.6890],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86214454]\n",
      "[1.82475919]\n",
      "[1.75804897]\n",
      "[1.75069926]\n",
      "[1.90641888]\n",
      "[1.80958771]\n",
      "[1.87665628]\n",
      "tensor([1.8621, 1.8248, 1.7580, 1.7507, 1.9064, 1.8096, 1.8767],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86934503]\n",
      "[1.69588707]\n",
      "[1.87907953]\n",
      "[1.82628571]\n",
      "[1.76592734]\n",
      "[1.88018366]\n",
      "[1.81722659]\n",
      "tensor([1.8693, 1.6959, 1.8791, 1.8263, 1.7659, 1.8802, 1.8172],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95030541]\n",
      "[1.86874812]\n",
      "[1.85034869]\n",
      "[1.85638908]\n",
      "[1.91582796]\n",
      "[1.8339299]\n",
      "[1.78303254]\n",
      "tensor([1.9503, 1.8687, 1.8503, 1.8564, 1.9158, 1.8339, 1.7830],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75996035]\n",
      "[1.83082724]\n",
      "[1.9263375]\n",
      "[1.79553945]\n",
      "[1.75520668]\n",
      "[1.837519]\n",
      "[1.78704267]\n",
      "tensor([1.7600, 1.8308, 1.9263, 1.7955, 1.7552, 1.8375, 1.7870],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79853781]\n",
      "[1.7329717]\n",
      "[1.80642241]\n",
      "[1.81238896]\n",
      "[1.8762172]\n",
      "[1.91390352]\n",
      "[1.84372505]\n",
      "tensor([1.7985, 1.7330, 1.8064, 1.8124, 1.8762, 1.9139, 1.8437],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84291169]\n",
      "[1.81587161]\n",
      "[1.77406548]\n",
      "[1.85176276]\n",
      "[1.94022121]\n",
      "[1.91830022]\n",
      "[1.75553346]\n",
      "tensor([1.8429, 1.8159, 1.7741, 1.8518, 1.9402, 1.9183, 1.7555],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72523881]\n",
      "[1.85337056]\n",
      "[1.8967867]\n",
      "[1.79930372]\n",
      "[1.80289561]\n",
      "[1.91575841]\n",
      "[1.84323146]\n",
      "tensor([1.7252, 1.8534, 1.8968, 1.7993, 1.8029, 1.9158, 1.8432],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75226197]\n",
      "[1.97006339]\n",
      "[1.89695359]\n",
      "[1.9245308]\n",
      "[1.81184853]\n",
      "[1.74610131]\n",
      "[1.8816537]\n",
      "tensor([1.7523, 1.9701, 1.8970, 1.9245, 1.8118, 1.7461, 1.8817],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8509784]\n",
      "[1.7628554]\n",
      "[1.93880388]\n",
      "[1.99794762]\n",
      "[1.7048981]\n",
      "[1.75122902]\n",
      "[1.84617265]\n",
      "tensor([1.8510, 1.7629, 1.9388, 1.9979, 1.7049, 1.7512, 1.8462],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84479145]\n",
      "[1.78730932]\n",
      "[1.85402451]\n",
      "[1.82918756]\n",
      "[1.77823893]\n",
      "[1.75672249]\n",
      "[1.80017043]\n",
      "tensor([1.8448, 1.7873, 1.8540, 1.8292, 1.7782, 1.7567, 1.8002],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82329923]\n",
      "[1.84214995]\n",
      "[1.80604143]\n",
      "[1.74965571]\n",
      "[1.84259053]\n",
      "[1.79319428]\n",
      "[1.79656531]\n",
      "tensor([1.8233, 1.8421, 1.8060, 1.7497, 1.8426, 1.7932, 1.7966],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85040179]\n",
      "[1.92509344]\n",
      "[1.77356088]\n",
      "[1.81136881]\n",
      "[1.82437242]\n",
      "[1.84427913]\n",
      "[1.83062668]\n",
      "tensor([1.8504, 1.9251, 1.7736, 1.8114, 1.8244, 1.8443, 1.8306],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78479628]\n",
      "[1.79808314]\n",
      "[2.08061469]\n",
      "[1.88027803]\n",
      "[1.82979659]\n",
      "[1.80190428]\n",
      "[1.80780768]\n",
      "tensor([1.7848, 1.7981, 2.0806, 1.8803, 1.8298, 1.8019, 1.8078],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75537083]\n",
      "[1.90776368]\n",
      "[1.83515952]\n",
      "[1.75389367]\n",
      "[1.82856434]\n",
      "[1.9367034]\n",
      "[1.82375271]\n",
      "tensor([1.7554, 1.9078, 1.8352, 1.7539, 1.8286, 1.9367, 1.8238],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77474011]\n",
      "[1.83944244]\n",
      "[1.80737122]\n",
      "[1.8406774]\n",
      "[1.81141937]\n",
      "[1.78942679]\n",
      "[1.80855158]\n",
      "tensor([1.7747, 1.8394, 1.8074, 1.8407, 1.8114, 1.7894, 1.8086],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87679787]\n",
      "[1.84405965]\n",
      "[1.81125026]\n",
      "[1.93458161]\n",
      "[1.72993762]\n",
      "[1.87778678]\n",
      "[1.80819954]\n",
      "tensor([1.8768, 1.8441, 1.8113, 1.9346, 1.7299, 1.8778, 1.8082],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87889661]\n",
      "[1.84861335]\n",
      "[1.80913522]\n",
      "[1.86477375]\n",
      "[1.81599609]\n",
      "[1.93156039]\n",
      "[1.89443067]\n",
      "tensor([1.8789, 1.8486, 1.8091, 1.8648, 1.8160, 1.9316, 1.8944],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8470129]\n",
      "[1.73995942]\n",
      "[1.81014687]\n",
      "[1.90263677]\n",
      "[1.80750943]\n",
      "[1.77016112]\n",
      "[1.83871189]\n",
      "tensor([1.8470, 1.7400, 1.8101, 1.9026, 1.8075, 1.7702, 1.8387],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79599344]\n",
      "[1.81851153]\n",
      "[1.83840082]\n",
      "[1.84389238]\n",
      "[1.9899648]\n",
      "[1.82505619]\n",
      "[1.78687623]\n",
      "tensor([1.7960, 1.8185, 1.8384, 1.8439, 1.9900, 1.8251, 1.7869],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81961211]\n",
      "[1.85668671]\n",
      "[1.9111526]\n",
      "[1.8856974]\n",
      "[1.91051307]\n",
      "[1.72025487]\n",
      "[1.79886153]\n",
      "tensor([1.8196, 1.8567, 1.9112, 1.8857, 1.9105, 1.7203, 1.7989],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91419109]\n",
      "[1.85576674]\n",
      "[1.78181561]\n",
      "[1.92751541]\n",
      "[1.86929922]\n",
      "[1.79986244]\n",
      "[1.86814284]\n",
      "tensor([1.9142, 1.8558, 1.7818, 1.9275, 1.8693, 1.7999, 1.8681],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86828164]\n",
      "[1.78881674]\n",
      "[1.8506039]\n",
      "[1.80163524]\n",
      "[1.69197013]\n",
      "[1.9498242]\n",
      "[1.85505589]\n",
      "tensor([1.8683, 1.7888, 1.8506, 1.8016, 1.6920, 1.9498, 1.8551],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71819952]\n",
      "[1.8682292]\n",
      "[1.96031402]\n",
      "[1.74524773]\n",
      "[1.85036589]\n",
      "[1.81300724]\n",
      "[1.8499458]\n",
      "tensor([1.7182, 1.8682, 1.9603, 1.7452, 1.8504, 1.8130, 1.8499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81494364]\n",
      "[1.78221751]\n",
      "[1.85644027]\n",
      "[1.80993909]\n",
      "[1.81440076]\n",
      "[1.80620992]\n",
      "[1.87030883]\n",
      "tensor([1.8149, 1.7822, 1.8564, 1.8099, 1.8144, 1.8062, 1.8703],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79681552]\n",
      "[1.80445755]\n",
      "[1.79994513]\n",
      "[1.78914645]\n",
      "[1.77030393]\n",
      "[2.02361197]\n",
      "[1.80599204]\n",
      "tensor([1.7968, 1.8045, 1.7999, 1.7891, 1.7703, 2.0236, 1.8060],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83666609]\n",
      "[1.94376316]\n",
      "[1.82406968]\n",
      "[1.88820214]\n",
      "[1.82050236]\n",
      "[1.80215101]\n",
      "[1.82916979]\n",
      "tensor([1.8367, 1.9438, 1.8241, 1.8882, 1.8205, 1.8022, 1.8292],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87079129]\n",
      "[1.85707036]\n",
      "[1.86893014]\n",
      "[1.88649252]\n",
      "[1.92643692]\n",
      "[1.85346153]\n",
      "[1.77944195]\n",
      "tensor([1.8708, 1.8571, 1.8689, 1.8865, 1.9264, 1.8535, 1.7794],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95403593]\n",
      "[1.81491542]\n",
      "[1.83727445]\n",
      "[1.7018068]\n",
      "[1.73399374]\n",
      "[1.79808493]\n",
      "[1.78682727]\n",
      "tensor([1.9540, 1.8149, 1.8373, 1.7018, 1.7340, 1.7981, 1.7868],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93237094]\n",
      "[1.75709178]\n",
      "[1.81671221]\n",
      "[1.85156991]\n",
      "[1.87349103]\n",
      "[1.918182]\n",
      "[1.8433661]\n",
      "tensor([1.9324, 1.7571, 1.8167, 1.8516, 1.8735, 1.9182, 1.8434],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85570371]\n",
      "[1.96578228]\n",
      "[1.86581263]\n",
      "[1.84522815]\n",
      "[1.78806733]\n",
      "[1.78552111]\n",
      "[1.69323966]\n",
      "tensor([1.8557, 1.9658, 1.8658, 1.8452, 1.7881, 1.7855, 1.6932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84358602]\n",
      "[1.77077564]\n",
      "[1.84004992]\n",
      "[1.807487]\n",
      "[1.91301495]\n",
      "[1.80388055]\n",
      "[1.77977048]\n",
      "tensor([1.8436, 1.7708, 1.8400, 1.8075, 1.9130, 1.8039, 1.7798],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84599531]\n",
      "[1.8308701]\n",
      "[2.05195085]\n",
      "[1.86579062]\n",
      "[1.76627131]\n",
      "[1.81613659]\n",
      "[1.8013064]\n",
      "tensor([1.8460, 1.8309, 2.0520, 1.8658, 1.7663, 1.8161, 1.8013],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91092712]\n",
      "[1.79969378]\n",
      "[1.82447551]\n",
      "[1.84465614]\n",
      "[1.9677221]\n",
      "[1.93906426]\n",
      "[1.73023735]\n",
      "tensor([1.9109, 1.7997, 1.8245, 1.8447, 1.9677, 1.9391, 1.7302],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93494259]\n",
      "[1.80537777]\n",
      "[1.92028204]\n",
      "[1.84350272]\n",
      "[1.93362414]\n",
      "[1.99076866]\n",
      "[1.74252012]\n",
      "tensor([1.9349, 1.8054, 1.9203, 1.8435, 1.9336, 1.9908, 1.7425],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70365331]\n",
      "[1.81230434]\n",
      "[1.73627982]\n",
      "[1.85953898]\n",
      "[1.8261534]\n",
      "[1.79227753]\n",
      "[1.79834158]\n",
      "tensor([1.7037, 1.8123, 1.7363, 1.8595, 1.8262, 1.7923, 1.7983],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74782445]\n",
      "[1.85142418]\n",
      "[1.79630557]\n",
      "[1.71345311]\n",
      "[1.96092029]\n",
      "[2.06474459]\n",
      "[1.8464213]\n",
      "tensor([1.7478, 1.8514, 1.7963, 1.7135, 1.9609, 2.0647, 1.8464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83598527]\n",
      "[1.8066663]\n",
      "[1.80097753]\n",
      "[1.83182361]\n",
      "[1.89839126]\n",
      "[1.87780998]\n",
      "[2.00607007]\n",
      "tensor([1.8360, 1.8067, 1.8010, 1.8318, 1.8984, 1.8778, 2.0061],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88135697]\n",
      "[1.82031841]\n",
      "[1.85972137]\n",
      "[1.83855268]\n",
      "[1.75649764]\n",
      "[1.80674307]\n",
      "[1.93964518]\n",
      "tensor([1.8814, 1.8203, 1.8597, 1.8386, 1.7565, 1.8067, 1.9396],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77147649]\n",
      "[1.81827952]\n",
      "[1.82105598]\n",
      "[1.92278733]\n",
      "[1.75507018]\n",
      "[1.73270442]\n",
      "[1.9460451]\n",
      "tensor([1.7715, 1.8183, 1.8211, 1.9228, 1.7551, 1.7327, 1.9460],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76276898]\n",
      "[1.97140628]\n",
      "[1.7937946]\n",
      "[1.77862239]\n",
      "[1.80220991]\n",
      "[1.82726671]\n",
      "[1.83100469]\n",
      "tensor([1.7628, 1.9714, 1.7938, 1.7786, 1.8022, 1.8273, 1.8310],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79776095]\n",
      "[1.83291292]\n",
      "[1.77413163]\n",
      "[1.80821214]\n",
      "[1.81113948]\n",
      "[1.90836828]\n",
      "[1.83357116]\n",
      "tensor([1.7978, 1.8329, 1.7741, 1.8082, 1.8111, 1.9084, 1.8336],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80880153]\n",
      "[1.77281385]\n",
      "[1.74908894]\n",
      "[1.85110974]\n",
      "[1.7928718]\n",
      "[1.91391284]\n",
      "[1.82523367]\n",
      "tensor([1.8088, 1.7728, 1.7491, 1.8511, 1.7929, 1.9139, 1.8252],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79548498]\n",
      "[1.84176483]\n",
      "[1.83103592]\n",
      "[1.758678]\n",
      "[1.81093068]\n",
      "[1.6941608]\n",
      "[1.80206071]\n",
      "tensor([1.7955, 1.8418, 1.8310, 1.7587, 1.8109, 1.6942, 1.8021],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96015165]\n",
      "[1.80481697]\n",
      "[1.72456605]\n",
      "[1.93000306]\n",
      "[1.83137647]\n",
      "[1.78500375]\n",
      "[1.98444281]\n",
      "tensor([1.9602, 1.8048, 1.7246, 1.9300, 1.8314, 1.7850, 1.9844],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92550879]\n",
      "[1.77090247]\n",
      "[1.80740768]\n",
      "[1.82453043]\n",
      "[1.81522427]\n",
      "[1.8559177]\n",
      "[1.80579726]\n",
      "tensor([1.9255, 1.7709, 1.8074, 1.8245, 1.8152, 1.8559, 1.8058],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75535358]\n",
      "[1.86540374]\n",
      "[1.74954678]\n",
      "[1.84387717]\n",
      "[1.7311272]\n",
      "[1.76156895]\n",
      "[1.83084953]\n",
      "tensor([1.7554, 1.8654, 1.7495, 1.8439, 1.7311, 1.7616, 1.8308],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88615913]\n",
      "[1.80764686]\n",
      "[1.84090372]\n",
      "[1.80703186]\n",
      "[1.8397266]\n",
      "[2.00456532]\n",
      "[1.82653477]\n",
      "tensor([1.8862, 1.8076, 1.8409, 1.8070, 1.8397, 2.0046, 1.8265],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93229365]\n",
      "[1.85077181]\n",
      "[1.80283872]\n",
      "[1.87026542]\n",
      "[1.83593693]\n",
      "[1.84025081]\n",
      "[1.74902328]\n",
      "tensor([1.9323, 1.8508, 1.8028, 1.8703, 1.8359, 1.8403, 1.7490],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7169579]\n",
      "[1.85648593]\n",
      "[1.90948634]\n",
      "[1.77671205]\n",
      "[1.87325889]\n",
      "[1.67979162]\n",
      "[1.87811296]\n",
      "tensor([1.7170, 1.8565, 1.9095, 1.7767, 1.8733, 1.6798, 1.8781],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71387977]\n",
      "[1.81667]\n",
      "[1.85182945]\n",
      "[1.94109632]\n",
      "[1.80806705]\n",
      "[1.77902526]\n",
      "[1.78922039]\n",
      "tensor([1.7139, 1.8167, 1.8518, 1.9411, 1.8081, 1.7790, 1.7892],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74920927]\n",
      "[1.72102034]\n",
      "[1.85153475]\n",
      "[1.87409571]\n",
      "[1.85854344]\n",
      "[1.89266526]\n",
      "[1.96571745]\n",
      "tensor([1.7492, 1.7210, 1.8515, 1.8741, 1.8585, 1.8927, 1.9657],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76698011]\n",
      "[1.83015657]\n",
      "[1.83789506]\n",
      "[1.84596878]\n",
      "[1.87675512]\n",
      "[1.87180287]\n",
      "[1.85782752]\n",
      "tensor([1.7670, 1.8302, 1.8379, 1.8460, 1.8768, 1.8718, 1.8578],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81915511]\n",
      "[1.88407356]\n",
      "[1.85114301]\n",
      "[1.82361898]\n",
      "[1.808731]\n",
      "[1.89102204]\n",
      "[1.74956594]\n",
      "tensor([1.8192, 1.8841, 1.8511, 1.8236, 1.8087, 1.8910, 1.7496],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79714345]\n",
      "[1.8703378]\n",
      "[1.90686565]\n",
      "[1.94509826]\n",
      "[1.83268965]\n",
      "[1.97531351]\n",
      "[1.81594774]\n",
      "tensor([1.7971, 1.8703, 1.9069, 1.9451, 1.8327, 1.9753, 1.8159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90348599]\n",
      "[1.88617349]\n",
      "[1.83255365]\n",
      "[1.90688385]\n",
      "[1.8353817]\n",
      "[1.84790409]\n",
      "[1.84797963]\n",
      "tensor([1.9035, 1.8862, 1.8326, 1.9069, 1.8354, 1.8479, 1.8480],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86499037]\n",
      "[1.92047404]\n",
      "[1.85623621]\n",
      "[1.95707311]\n",
      "[1.8379606]\n",
      "[1.91764978]\n",
      "[1.78009298]\n",
      "tensor([1.8650, 1.9205, 1.8562, 1.9571, 1.8380, 1.9176, 1.7801],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83530512]\n",
      "[1.84749468]\n",
      "[1.85123551]\n",
      "[2.06322424]\n",
      "[1.81804733]\n",
      "[1.80301146]\n",
      "[1.82968593]\n",
      "tensor([1.8353, 1.8475, 1.8512, 2.0632, 1.8180, 1.8030, 1.8297],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87791114]\n",
      "[1.84942141]\n",
      "[1.93821898]\n",
      "[1.78613873]\n",
      "[1.84733305]\n",
      "[1.91414054]\n",
      "[1.85356908]\n",
      "tensor([1.8779, 1.8494, 1.9382, 1.7861, 1.8473, 1.9141, 1.8536],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85721954]\n",
      "[1.70059797]\n",
      "[1.80525671]\n",
      "[1.7639918]\n",
      "[1.81650743]\n",
      "[1.75248543]\n",
      "[1.81481054]\n",
      "tensor([1.8572, 1.7006, 1.8053, 1.7640, 1.8165, 1.7525, 1.8148],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81664336]\n",
      "[1.79121481]\n",
      "[1.84931512]\n",
      "[1.9323867]\n",
      "[1.93054907]\n",
      "[1.76540674]\n",
      "[1.88045908]\n",
      "tensor([1.8166, 1.7912, 1.8493, 1.9324, 1.9305, 1.7654, 1.8805],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8132874]\n",
      "[1.79902597]\n",
      "[1.84645093]\n",
      "[1.87268423]\n",
      "[1.78541642]\n",
      "[1.7887721]\n",
      "[1.82145385]\n",
      "tensor([1.8133, 1.7990, 1.8465, 1.8727, 1.7854, 1.7888, 1.8215],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77664587]\n",
      "[1.80122836]\n",
      "[1.90991792]\n",
      "[1.81154169]\n",
      "[1.83243202]\n",
      "[1.73961576]\n",
      "[1.81178481]\n",
      "tensor([1.7766, 1.8012, 1.9099, 1.8115, 1.8324, 1.7396, 1.8118],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75640411]\n",
      "[1.77490796]\n",
      "[1.821863]\n",
      "[1.85832099]\n",
      "[1.81472662]\n",
      "[1.81362759]\n",
      "[1.7993114]\n",
      "tensor([1.7564, 1.7749, 1.8219, 1.8583, 1.8147, 1.8136, 1.7993],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85352053]\n",
      "[1.88002456]\n",
      "[1.82585254]\n",
      "[1.84141083]\n",
      "[1.81344519]\n",
      "[1.79379444]\n",
      "[1.8459249]\n",
      "tensor([1.8535, 1.8800, 1.8259, 1.8414, 1.8134, 1.7938, 1.8459],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89274619]\n",
      "[1.87532204]\n",
      "[1.77754174]\n",
      "[1.82512515]\n",
      "[1.89295987]\n",
      "[1.89283811]\n",
      "[1.84476887]\n",
      "tensor([1.8927, 1.8753, 1.7775, 1.8251, 1.8930, 1.8928, 1.8448],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73827443]\n",
      "[1.91097884]\n",
      "[1.88523804]\n",
      "[1.72015691]\n",
      "[1.87513533]\n",
      "[1.8533642]\n",
      "[1.91110762]\n",
      "tensor([1.7383, 1.9110, 1.8852, 1.7202, 1.8751, 1.8534, 1.9111],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84469239]\n",
      "[1.81494278]\n",
      "[1.89311183]\n",
      "[1.82424828]\n",
      "[1.82026005]\n",
      "[1.81092727]\n",
      "[1.83567746]\n",
      "tensor([1.8447, 1.8149, 1.8931, 1.8242, 1.8203, 1.8109, 1.8357],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92081535]\n",
      "[1.89894088]\n",
      "[1.79625167]\n",
      "[1.88443912]\n",
      "[1.91382543]\n",
      "[1.95719636]\n",
      "[1.85775502]\n",
      "tensor([1.9208, 1.8989, 1.7963, 1.8844, 1.9138, 1.9572, 1.8578],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82780144]\n",
      "[1.83644099]\n",
      "[1.84907978]\n",
      "[1.89096078]\n",
      "[1.80591934]\n",
      "[1.81071629]\n",
      "[1.8239972]\n",
      "tensor([1.8278, 1.8364, 1.8491, 1.8910, 1.8059, 1.8107, 1.8240],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82434865]\n",
      "[1.98099349]\n",
      "[1.85650635]\n",
      "[1.72800297]\n",
      "[1.87527164]\n",
      "[1.83041723]\n",
      "[1.79488352]\n",
      "tensor([1.8243, 1.9810, 1.8565, 1.7280, 1.8753, 1.8304, 1.7949],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89173931]\n",
      "[1.76561646]\n",
      "[1.90971897]\n",
      "[1.86390145]\n",
      "[1.87390131]\n",
      "[1.9133209]\n",
      "[1.91744401]\n",
      "tensor([1.8917, 1.7656, 1.9097, 1.8639, 1.8739, 1.9133, 1.9174],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7946669]\n",
      "[1.81773911]\n",
      "[1.90148146]\n",
      "[1.88931076]\n",
      "[1.73988764]\n",
      "[1.75012661]\n",
      "[1.78231835]\n",
      "tensor([1.7947, 1.8177, 1.9015, 1.8893, 1.7399, 1.7501, 1.7823],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86288466]\n",
      "[1.82940803]\n",
      "[1.87353566]\n",
      "[1.7420174]\n",
      "[1.811553]\n",
      "[1.98639954]\n",
      "[1.81721506]\n",
      "tensor([1.8629, 1.8294, 1.8735, 1.7420, 1.8116, 1.9864, 1.8172],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88397373]\n",
      "[1.76662937]\n",
      "[1.81819535]\n",
      "[1.8428386]\n",
      "[1.84251638]\n",
      "[1.9070946]\n",
      "[1.93284447]\n",
      "tensor([1.8840, 1.7666, 1.8182, 1.8428, 1.8425, 1.9071, 1.9328],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76438001]\n",
      "[1.84487079]\n",
      "[1.67666941]\n",
      "[1.80124214]\n",
      "[1.94751467]\n",
      "[1.8835066]\n",
      "[1.73791385]\n",
      "tensor([1.7644, 1.8449, 1.6767, 1.8012, 1.9475, 1.8835, 1.7379],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75798832]\n",
      "[1.94100522]\n",
      "[1.80510917]\n",
      "[1.77498518]\n",
      "[1.8081205]\n",
      "[1.82109197]\n",
      "[1.84993482]\n",
      "tensor([1.7580, 1.9410, 1.8051, 1.7750, 1.8081, 1.8211, 1.8499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81123881]\n",
      "[1.86109111]\n",
      "[1.89355696]\n",
      "[1.80994281]\n",
      "[1.78791472]\n",
      "[1.75186942]\n",
      "[1.82492213]\n",
      "tensor([1.8112, 1.8611, 1.8936, 1.8099, 1.7879, 1.7519, 1.8249],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93121383]\n",
      "[1.84110191]\n",
      "[1.83234131]\n",
      "[1.79921708]\n",
      "[1.80753669]\n",
      "[1.78590903]\n",
      "[1.74759948]\n",
      "tensor([1.9312, 1.8411, 1.8323, 1.7992, 1.8075, 1.7859, 1.7476],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7577255]\n",
      "[1.88771343]\n",
      "[1.72552082]\n",
      "[1.79272668]\n",
      "[1.85437451]\n",
      "[1.85615184]\n",
      "[1.85344262]\n",
      "tensor([1.7577, 1.8877, 1.7255, 1.7927, 1.8544, 1.8562, 1.8534],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79525333]\n",
      "[1.86904134]\n",
      "[1.80294893]\n",
      "[1.80323464]\n",
      "[1.84322441]\n",
      "[1.76961534]\n",
      "[1.91897776]\n",
      "tensor([1.7953, 1.8690, 1.8029, 1.8032, 1.8432, 1.7696, 1.9190],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86249419]\n",
      "[1.78100193]\n",
      "[1.91307103]\n",
      "[1.84115983]\n",
      "[1.9172434]\n",
      "[1.78946103]\n",
      "[1.79879134]\n",
      "tensor([1.8625, 1.7810, 1.9131, 1.8412, 1.9172, 1.7895, 1.7988],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85334073]\n",
      "[1.90638993]\n",
      "[1.9772159]\n",
      "[1.8411029]\n",
      "[1.81066992]\n",
      "[1.74262946]\n",
      "[1.82061008]\n",
      "tensor([1.8533, 1.9064, 1.9772, 1.8411, 1.8107, 1.7426, 1.8206],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79148927]\n",
      "[1.84668323]\n",
      "[1.86805726]\n",
      "[1.77553988]\n",
      "[1.93092943]\n",
      "[1.74213609]\n",
      "[1.81842272]\n",
      "tensor([1.7915, 1.8467, 1.8681, 1.7755, 1.9309, 1.7421, 1.8184],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.758925]\n",
      "[1.8496278]\n",
      "[1.86297312]\n",
      "[1.85547009]\n",
      "[1.80200055]\n",
      "[1.78582281]\n",
      "[1.87358082]\n",
      "tensor([1.7589, 1.8496, 1.8630, 1.8555, 1.8020, 1.7858, 1.8736],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88017854]\n",
      "[1.76075343]\n",
      "[1.7351006]\n",
      "[1.81994673]\n",
      "[1.84692579]\n",
      "[1.7372304]\n",
      "[1.8436739]\n",
      "tensor([1.8802, 1.7608, 1.7351, 1.8199, 1.8469, 1.7372, 1.8437],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80018988]\n",
      "[1.84474128]\n",
      "[1.79237654]\n",
      "[1.83777124]\n",
      "[1.86429524]\n",
      "[1.87479891]\n",
      "[1.82088441]\n",
      "tensor([1.8002, 1.8447, 1.7924, 1.8378, 1.8643, 1.8748, 1.8209],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88637238]\n",
      "[1.75368042]\n",
      "[1.82641398]\n",
      "[1.97173414]\n",
      "[1.83620771]\n",
      "[1.74035303]\n",
      "[1.69084252]\n",
      "tensor([1.8864, 1.7537, 1.8264, 1.9717, 1.8362, 1.7404, 1.6908],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82196746]\n",
      "[1.86893065]\n",
      "[1.80118887]\n",
      "[1.82249565]\n",
      "[1.92247105]\n",
      "[1.88441392]\n",
      "[1.82736723]\n",
      "tensor([1.8220, 1.8689, 1.8012, 1.8225, 1.9225, 1.8844, 1.8274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73925079]\n",
      "[1.84737189]\n",
      "[1.82092108]\n",
      "[1.82757068]\n",
      "[1.79268488]\n",
      "[1.80143868]\n",
      "[1.88929061]\n",
      "tensor([1.7393, 1.8474, 1.8209, 1.8276, 1.7927, 1.8014, 1.8893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7654494]\n",
      "[1.84322608]\n",
      "[1.9125943]\n",
      "[1.80369939]\n",
      "[1.79995361]\n",
      "[1.89258326]\n",
      "[1.82433945]\n",
      "tensor([1.7654, 1.8432, 1.9126, 1.8037, 1.8000, 1.8926, 1.8243],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82279864]\n",
      "[1.97550759]\n",
      "[1.73023964]\n",
      "[1.84787942]\n",
      "[1.70903025]\n",
      "[2.01936485]\n",
      "[1.80722897]\n",
      "tensor([1.8228, 1.9755, 1.7302, 1.8479, 1.7090, 2.0194, 1.8072],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76078577]\n",
      "[1.87109568]\n",
      "[1.79321252]\n",
      "[1.87599167]\n",
      "[1.88360148]\n",
      "[1.81808468]\n",
      "[1.90557393]\n",
      "tensor([1.7608, 1.8711, 1.7932, 1.8760, 1.8836, 1.8181, 1.9056],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79645154]\n",
      "[1.78918692]\n",
      "[1.79063278]\n",
      "[1.87743595]\n",
      "[1.92481241]\n",
      "[1.82081973]\n",
      "[1.91534663]\n",
      "tensor([1.7965, 1.7892, 1.7906, 1.8774, 1.9248, 1.8208, 1.9153],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81055886]\n",
      "[1.74547851]\n",
      "[1.74533279]\n",
      "[1.80834285]\n",
      "[1.87285331]\n",
      "[1.83281044]\n",
      "[1.94888026]\n",
      "tensor([1.8106, 1.7455, 1.7453, 1.8083, 1.8729, 1.8328, 1.9489],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86041574]\n",
      "[1.79300251]\n",
      "[1.86468361]\n",
      "[1.78775062]\n",
      "[1.8427827]\n",
      "[1.92036847]\n",
      "[1.85321534]\n",
      "tensor([1.8604, 1.7930, 1.8647, 1.7878, 1.8428, 1.9204, 1.8532],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8002178]\n",
      "[1.87325136]\n",
      "[1.82366793]\n",
      "[1.89542151]\n",
      "[1.77357026]\n",
      "[1.86299322]\n",
      "[1.92533691]\n",
      "tensor([1.8002, 1.8733, 1.8237, 1.8954, 1.7736, 1.8630, 1.9253],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82472949]\n",
      "[1.8460842]\n",
      "[1.796113]\n",
      "[1.85706817]\n",
      "[1.90421117]\n",
      "[1.90621815]\n",
      "[1.85170518]\n",
      "tensor([1.8247, 1.8461, 1.7961, 1.8571, 1.9042, 1.9062, 1.8517],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79770881]\n",
      "[1.73944209]\n",
      "[1.87246835]\n",
      "[1.86624868]\n",
      "[1.86627678]\n",
      "[1.92901104]\n",
      "[1.84230998]\n",
      "tensor([1.7977, 1.7394, 1.8725, 1.8662, 1.8663, 1.9290, 1.8423],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81436071]\n",
      "[1.79273264]\n",
      "[1.83633848]\n",
      "[1.79514239]\n",
      "[1.78734833]\n",
      "[1.80636963]\n",
      "[1.75933204]\n",
      "tensor([1.8144, 1.7927, 1.8363, 1.7951, 1.7873, 1.8064, 1.7593],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92016952]\n",
      "[1.83609093]\n",
      "[1.91767648]\n",
      "[1.84426692]\n",
      "[1.84839557]\n",
      "[1.81278776]\n",
      "[1.8568768]\n",
      "tensor([1.9202, 1.8361, 1.9177, 1.8443, 1.8484, 1.8128, 1.8569],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80056754]\n",
      "[1.97201709]\n",
      "[1.83757259]\n",
      "[1.79552637]\n",
      "[1.80435383]\n",
      "[1.72057111]\n",
      "[1.85469801]\n",
      "tensor([1.8006, 1.9720, 1.8376, 1.7955, 1.8044, 1.7206, 1.8547],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89165829]\n",
      "[1.85957102]\n",
      "[1.81855127]\n",
      "[1.79783124]\n",
      "[1.83115807]\n",
      "[1.73583782]\n",
      "[1.88352157]\n",
      "tensor([1.8917, 1.8596, 1.8186, 1.7978, 1.8312, 1.7358, 1.8835],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8869743]\n",
      "[1.8436117]\n",
      "[1.85053111]\n",
      "[1.82512906]\n",
      "[1.92181217]\n",
      "[1.9535279]\n",
      "[1.84133783]\n",
      "tensor([1.8870, 1.8436, 1.8505, 1.8251, 1.9218, 1.9535, 1.8413],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82012947]\n",
      "[1.80215101]\n",
      "[1.7602834]\n",
      "[1.8354811]\n",
      "[1.79023024]\n",
      "[1.96605968]\n",
      "[1.81014606]\n",
      "tensor([1.8201, 1.8022, 1.7603, 1.8355, 1.7902, 1.9661, 1.8101],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74343874]\n",
      "[1.81788618]\n",
      "[1.79878296]\n",
      "[1.93026807]\n",
      "[1.77975955]\n",
      "[1.87263929]\n",
      "[1.8398629]\n",
      "tensor([1.7434, 1.8179, 1.7988, 1.9303, 1.7798, 1.8726, 1.8399],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87119983]\n",
      "[1.85798326]\n",
      "[1.80368374]\n",
      "[1.796213]\n",
      "[1.85867378]\n",
      "[1.81254752]\n",
      "[1.85239611]\n",
      "tensor([1.8712, 1.8580, 1.8037, 1.7962, 1.8587, 1.8125, 1.8524],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8962006]\n",
      "[1.81237309]\n",
      "[1.90327139]\n",
      "[1.71189404]\n",
      "[1.84399055]\n",
      "[1.84167865]\n",
      "[1.79092782]\n",
      "tensor([1.8962, 1.8124, 1.9033, 1.7119, 1.8440, 1.8417, 1.7909],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79452735]\n",
      "[1.87034589]\n",
      "[1.86529998]\n",
      "[1.94492258]\n",
      "[1.75940239]\n",
      "[1.82039587]\n",
      "[1.80430546]\n",
      "tensor([1.7945, 1.8703, 1.8653, 1.9449, 1.7594, 1.8204, 1.8043],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90498886]\n",
      "[1.87448891]\n",
      "[1.96701975]\n",
      "[1.84911053]\n",
      "[1.8965742]\n",
      "[1.79879587]\n",
      "[1.93050576]\n",
      "tensor([1.9050, 1.8745, 1.9670, 1.8491, 1.8966, 1.7988, 1.9305],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82411805]\n",
      "[1.8145483]\n",
      "[1.85125368]\n",
      "[1.90958884]\n",
      "[1.85939583]\n",
      "[1.80167993]\n",
      "[1.85681892]\n",
      "tensor([1.8241, 1.8145, 1.8513, 1.9096, 1.8594, 1.8017, 1.8568],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8569648]\n",
      "[1.90716032]\n",
      "[1.80677262]\n",
      "[1.8332691]\n",
      "[1.89037976]\n",
      "[1.80934238]\n",
      "[1.92326161]\n",
      "tensor([1.8570, 1.9072, 1.8068, 1.8333, 1.8904, 1.8093, 1.9233],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87455474]\n",
      "[1.74488632]\n",
      "[1.85592088]\n",
      "[1.76000463]\n",
      "[1.77839293]\n",
      "[1.80424253]\n",
      "[1.90538405]\n",
      "tensor([1.8746, 1.7449, 1.8559, 1.7600, 1.7784, 1.8042, 1.9054],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79963713]\n",
      "[1.8822488]\n",
      "[1.80052415]\n",
      "[1.78687907]\n",
      "[1.84464751]\n",
      "[1.82704884]\n",
      "[1.87261001]\n",
      "tensor([1.7996, 1.8822, 1.8005, 1.7869, 1.8446, 1.8270, 1.8726],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7542896]\n",
      "[1.74943853]\n",
      "[1.80485802]\n",
      "[1.8814029]\n",
      "[1.79196646]\n",
      "[1.89783448]\n",
      "[1.81502509]\n",
      "tensor([1.7543, 1.7494, 1.8049, 1.8814, 1.7920, 1.8978, 1.8150],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89260046]\n",
      "[1.90370548]\n",
      "[1.86820093]\n",
      "[1.79748642]\n",
      "[1.93050497]\n",
      "[1.84112332]\n",
      "[1.9686078]\n",
      "tensor([1.8926, 1.9037, 1.8682, 1.7975, 1.9305, 1.8411, 1.9686],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73743737]\n",
      "[1.8018525]\n",
      "[1.87805603]\n",
      "[1.81382449]\n",
      "[1.90529659]\n",
      "[1.78501403]\n",
      "[1.84065171]\n",
      "tensor([1.7374, 1.8019, 1.8781, 1.8138, 1.9053, 1.7850, 1.8407],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8002586]\n",
      "[1.77152126]\n",
      "[1.7499612]\n",
      "[1.80759792]\n",
      "[1.79864736]\n",
      "[1.91429451]\n",
      "[2.00098799]\n",
      "tensor([1.8003, 1.7715, 1.7500, 1.8076, 1.7986, 1.9143, 2.0010],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82655194]\n",
      "[1.93169599]\n",
      "[1.76161724]\n",
      "[1.86713994]\n",
      "[1.72987239]\n",
      "[1.91357891]\n",
      "[1.83014591]\n",
      "tensor([1.8266, 1.9317, 1.7616, 1.8671, 1.7299, 1.9136, 1.8301],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7850975]\n",
      "[1.91097379]\n",
      "[1.82412564]\n",
      "[1.83503065]\n",
      "[1.94379602]\n",
      "[1.78602084]\n",
      "[1.79566621]\n",
      "tensor([1.7851, 1.9110, 1.8241, 1.8350, 1.9438, 1.7860, 1.7957],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75408463]\n",
      "[1.92915261]\n",
      "[1.74399365]\n",
      "[1.87823427]\n",
      "[1.79217704]\n",
      "[1.77945569]\n",
      "[1.73897739]\n",
      "tensor([1.7541, 1.9292, 1.7440, 1.8782, 1.7922, 1.7795, 1.7390],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71003947]\n",
      "[1.79886712]\n",
      "[1.70937931]\n",
      "[1.92327945]\n",
      "[1.84865605]\n",
      "[1.81461396]\n",
      "[1.77774388]\n",
      "tensor([1.7100, 1.7989, 1.7094, 1.9233, 1.8487, 1.8146, 1.7777],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83071941]\n",
      "[1.80257036]\n",
      "[1.86315852]\n",
      "[1.73381831]\n",
      "[1.84594389]\n",
      "[1.85565925]\n",
      "[1.84884328]\n",
      "tensor([1.8307, 1.8026, 1.8632, 1.7338, 1.8459, 1.8557, 1.8488],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81002914]\n",
      "[1.96712254]\n",
      "[1.90407853]\n",
      "[1.84603463]\n",
      "[1.84428926]\n",
      "[1.85774928]\n",
      "[1.83009126]\n",
      "tensor([1.8100, 1.9671, 1.9041, 1.8460, 1.8443, 1.8577, 1.8301],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81810336]\n",
      "[1.80266675]\n",
      "[1.81985485]\n",
      "[1.8717457]\n",
      "[1.81042575]\n",
      "[1.81982831]\n",
      "[1.80268058]\n",
      "tensor([1.8181, 1.8027, 1.8199, 1.8717, 1.8104, 1.8198, 1.8027],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79122477]\n",
      "[1.78709257]\n",
      "[1.90011724]\n",
      "[1.87709731]\n",
      "[1.7831439]\n",
      "[1.91906295]\n",
      "[1.76829202]\n",
      "tensor([1.7912, 1.7871, 1.9001, 1.8771, 1.7831, 1.9191, 1.7683],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80039347]\n",
      "[1.83976733]\n",
      "[1.87647862]\n",
      "[1.88168537]\n",
      "[1.75194654]\n",
      "[1.88682882]\n",
      "[1.84730369]\n",
      "tensor([1.8004, 1.8398, 1.8765, 1.8817, 1.7519, 1.8868, 1.8473],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85754706]\n",
      "[1.80623187]\n",
      "[1.83978547]\n",
      "[1.75540358]\n",
      "[1.74283953]\n",
      "[1.79531388]\n",
      "[1.86133155]\n",
      "tensor([1.8575, 1.8062, 1.8398, 1.7554, 1.7428, 1.7953, 1.8613],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87373244]\n",
      "[1.95272351]\n",
      "[1.96006666]\n",
      "[1.9887861]\n",
      "[1.75755262]\n",
      "[1.91263962]\n",
      "[1.81715963]\n",
      "tensor([1.8737, 1.9527, 1.9601, 1.9888, 1.7576, 1.9126, 1.8172],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84568542]\n",
      "[1.70886984]\n",
      "[1.82333525]\n",
      "[1.75202335]\n",
      "[1.73718163]\n",
      "[2.01443174]\n",
      "[1.83624168]\n",
      "tensor([1.8457, 1.7089, 1.8233, 1.7520, 1.7372, 2.0144, 1.8362],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81111421]\n",
      "[1.77855347]\n",
      "[1.89034057]\n",
      "[1.89909017]\n",
      "[1.69366258]\n",
      "[1.85223155]\n",
      "[1.84636829]\n",
      "tensor([1.8111, 1.7786, 1.8903, 1.8991, 1.6937, 1.8522, 1.8464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90303147]\n",
      "[1.84021876]\n",
      "[1.80709226]\n",
      "[1.85675313]\n",
      "[1.82508086]\n",
      "[1.8039153]\n",
      "[1.89065956]\n",
      "tensor([1.9030, 1.8402, 1.8071, 1.8568, 1.8251, 1.8039, 1.8907],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80779599]\n",
      "[1.80548135]\n",
      "[1.81311063]\n",
      "[1.8687853]\n",
      "[1.74157479]\n",
      "[1.79760579]\n",
      "[1.80288228]\n",
      "tensor([1.8078, 1.8055, 1.8131, 1.8688, 1.7416, 1.7976, 1.8029],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83779326]\n",
      "[1.85108065]\n",
      "[1.86171103]\n",
      "[1.86239939]\n",
      "[1.85934767]\n",
      "[1.79632962]\n",
      "[1.75681288]\n",
      "tensor([1.8378, 1.8511, 1.8617, 1.8624, 1.8593, 1.7963, 1.7568],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80635408]\n",
      "[1.85602294]\n",
      "[1.8463631]\n",
      "[1.85702527]\n",
      "[1.84829723]\n",
      "[1.79276703]\n",
      "[1.78606125]\n",
      "tensor([1.8064, 1.8560, 1.8464, 1.8570, 1.8483, 1.7928, 1.7861],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8548035]\n",
      "[1.81654991]\n",
      "[1.92053152]\n",
      "[1.80885386]\n",
      "[2.05887232]\n",
      "[1.85925025]\n",
      "[1.8335287]\n",
      "tensor([1.8548, 1.8165, 1.9205, 1.8089, 2.0589, 1.8593, 1.8335],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94677886]\n",
      "[1.85287617]\n",
      "[1.86821266]\n",
      "[1.8182864]\n",
      "[1.72530626]\n",
      "[1.76555653]\n",
      "[1.79639783]\n",
      "tensor([1.9468, 1.8529, 1.8682, 1.8183, 1.7253, 1.7656, 1.7964],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8555792]\n",
      "[1.90999151]\n",
      "[1.82472339]\n",
      "[1.91840734]\n",
      "[1.74095789]\n",
      "[1.77381023]\n",
      "[1.81836636]\n",
      "tensor([1.8556, 1.9100, 1.8247, 1.9184, 1.7410, 1.7738, 1.8184],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71732244]\n",
      "[1.94451936]\n",
      "[1.81355345]\n",
      "[1.97618267]\n",
      "[1.90759494]\n",
      "[1.71557282]\n",
      "[1.85696008]\n",
      "tensor([1.7173, 1.9445, 1.8136, 1.9762, 1.9076, 1.7156, 1.8570],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8154277]\n",
      "[1.81894549]\n",
      "[1.87571961]\n",
      "[1.81999763]\n",
      "[1.92617152]\n",
      "[1.81809198]\n",
      "[1.82158904]\n",
      "tensor([1.8154, 1.8189, 1.8757, 1.8200, 1.9262, 1.8181, 1.8216],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79476674]\n",
      "[1.80976542]\n",
      "[1.84179739]\n",
      "[1.87415366]\n",
      "[1.73577324]\n",
      "[1.8473132]\n",
      "[1.83798315]\n",
      "tensor([1.7948, 1.8098, 1.8418, 1.8742, 1.7358, 1.8473, 1.8380],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83286459]\n",
      "[1.89440223]\n",
      "[1.84736587]\n",
      "[1.73551221]\n",
      "[1.92244768]\n",
      "[1.88870618]\n",
      "[1.81907212]\n",
      "tensor([1.8329, 1.8944, 1.8474, 1.7355, 1.9224, 1.8887, 1.8191],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82959874]\n",
      "[1.7262422]\n",
      "[1.84387432]\n",
      "[1.79136078]\n",
      "[1.88171974]\n",
      "[1.84828175]\n",
      "[1.85820666]\n",
      "tensor([1.8296, 1.7262, 1.8439, 1.7914, 1.8817, 1.8483, 1.8582],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89551441]\n",
      "[1.8292943]\n",
      "[1.83789323]\n",
      "[1.7280017]\n",
      "[1.79054846]\n",
      "[1.81936865]\n",
      "[1.72740232]\n",
      "tensor([1.8955, 1.8293, 1.8379, 1.7280, 1.7905, 1.8194, 1.7274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87371979]\n",
      "[1.79012704]\n",
      "[1.8034805]\n",
      "[1.96562756]\n",
      "[1.69469635]\n",
      "[1.81346166]\n",
      "[1.81563489]\n",
      "tensor([1.8737, 1.7901, 1.8035, 1.9656, 1.6947, 1.8135, 1.8156],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78866885]\n",
      "[1.84854118]\n",
      "[1.84432372]\n",
      "[1.86760374]\n",
      "[1.96542284]\n",
      "[1.87510725]\n",
      "[1.84711735]\n",
      "tensor([1.7887, 1.8485, 1.8443, 1.8676, 1.9654, 1.8751, 1.8471],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8081407]\n",
      "[1.80866122]\n",
      "[1.83394554]\n",
      "[1.78532406]\n",
      "[1.83998793]\n",
      "[1.84681128]\n",
      "[1.80155863]\n",
      "tensor([1.8081, 1.8087, 1.8339, 1.7853, 1.8400, 1.8468, 1.8016],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74636864]\n",
      "[1.79755356]\n",
      "[1.8271224]\n",
      "[1.95336316]\n",
      "[1.78734398]\n",
      "[1.80640411]\n",
      "[1.84282858]\n",
      "tensor([1.7464, 1.7976, 1.8271, 1.9534, 1.7873, 1.8064, 1.8428],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88110885]\n",
      "[1.78999235]\n",
      "[1.87523731]\n",
      "[1.80986793]\n",
      "[1.91287615]\n",
      "[1.82649899]\n",
      "[1.82243791]\n",
      "tensor([1.8811, 1.7900, 1.8752, 1.8099, 1.9129, 1.8265, 1.8224],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81821907]\n",
      "[1.90919817]\n",
      "[1.88139723]\n",
      "[1.77336677]\n",
      "[1.90994633]\n",
      "[1.76174126]\n",
      "[1.71687868]\n",
      "tensor([1.8182, 1.9092, 1.8814, 1.7734, 1.9099, 1.7617, 1.7169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93078901]\n",
      "[1.90825814]\n",
      "[1.76523294]\n",
      "[1.87657733]\n",
      "[1.81756383]\n",
      "[1.80404047]\n",
      "[1.76084833]\n",
      "tensor([1.9308, 1.9083, 1.7652, 1.8766, 1.8176, 1.8040, 1.7608],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84959772]\n",
      "[1.88406075]\n",
      "[1.96669359]\n",
      "[1.86872686]\n",
      "[1.87116551]\n",
      "[1.72748255]\n",
      "[1.98075457]\n",
      "tensor([1.8496, 1.8841, 1.9667, 1.8687, 1.8712, 1.7275, 1.9808],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77314785]\n",
      "[1.75307185]\n",
      "[1.83010153]\n",
      "[1.88898568]\n",
      "[1.81057034]\n",
      "[1.83671235]\n",
      "[1.77536147]\n",
      "tensor([1.7731, 1.7531, 1.8301, 1.8890, 1.8106, 1.8367, 1.7754],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91989684]\n",
      "[1.86613731]\n",
      "[1.81339969]\n",
      "[1.83933488]\n",
      "[1.88766198]\n",
      "[1.90816005]\n",
      "[1.89514468]\n",
      "tensor([1.9199, 1.8661, 1.8134, 1.8393, 1.8877, 1.9082, 1.8951],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82329245]\n",
      "[1.83043931]\n",
      "[1.74947721]\n",
      "[1.74995774]\n",
      "[1.83626156]\n",
      "[1.83148689]\n",
      "[1.73887171]\n",
      "tensor([1.8233, 1.8304, 1.7495, 1.7500, 1.8363, 1.8315, 1.7389],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82598188]\n",
      "[1.82411429]\n",
      "[1.78443893]\n",
      "[1.85442918]\n",
      "[1.84589195]\n",
      "[1.88581277]\n",
      "[1.86999713]\n",
      "tensor([1.8260, 1.8241, 1.7844, 1.8544, 1.8459, 1.8858, 1.8700],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86976171]\n",
      "[1.72116708]\n",
      "[1.83611444]\n",
      "[1.90846324]\n",
      "[1.85278354]\n",
      "[1.80048549]\n",
      "[1.9767353]\n",
      "tensor([1.8698, 1.7212, 1.8361, 1.9085, 1.8528, 1.8005, 1.9767],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74890239]\n",
      "[1.83054347]\n",
      "[1.83580621]\n",
      "[1.7588768]\n",
      "[1.80414366]\n",
      "[1.77585697]\n",
      "[1.83718923]\n",
      "tensor([1.7489, 1.8305, 1.8358, 1.7589, 1.8041, 1.7759, 1.8372],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82644207]\n",
      "[1.7123835]\n",
      "[2.04373829]\n",
      "[1.95991459]\n",
      "[1.87635533]\n",
      "[1.93009309]\n",
      "[1.85569222]\n",
      "tensor([1.8264, 1.7124, 2.0437, 1.9599, 1.8764, 1.9301, 1.8557],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82543707]\n",
      "[1.91127627]\n",
      "[1.79989099]\n",
      "[1.91103449]\n",
      "[1.75908586]\n",
      "[1.85705277]\n",
      "[1.82514721]\n",
      "tensor([1.8254, 1.9113, 1.7999, 1.9110, 1.7591, 1.8571, 1.8251],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76420599]\n",
      "[1.90279584]\n",
      "[1.79040512]\n",
      "[1.77412124]\n",
      "[1.82692318]\n",
      "[1.76558576]\n",
      "[1.75054688]\n",
      "tensor([1.7642, 1.9028, 1.7904, 1.7741, 1.8269, 1.7656, 1.7505],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98441367]\n",
      "[1.79506726]\n",
      "[1.82633273]\n",
      "[1.88143516]\n",
      "[1.90519558]\n",
      "[1.87006297]\n",
      "[1.84529295]\n",
      "tensor([1.9844, 1.7951, 1.8263, 1.8814, 1.9052, 1.8701, 1.8453],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8645866]\n",
      "[1.9071483]\n",
      "[1.92160109]\n",
      "[1.92575161]\n",
      "[1.79655873]\n",
      "[1.76364314]\n",
      "[1.89390279]\n",
      "tensor([1.8646, 1.9071, 1.9216, 1.9258, 1.7966, 1.7636, 1.8939],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81196157]\n",
      "[1.84983362]\n",
      "[1.79670901]\n",
      "[1.72329873]\n",
      "[1.87323785]\n",
      "[1.83853682]\n",
      "[1.82636095]\n",
      "tensor([1.8120, 1.8498, 1.7967, 1.7233, 1.8732, 1.8385, 1.8264],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83194169]\n",
      "[1.96779103]\n",
      "[1.85697562]\n",
      "[1.92872942]\n",
      "[1.79982883]\n",
      "[1.84937128]\n",
      "[1.75124295]\n",
      "tensor([1.8319, 1.9678, 1.8570, 1.9287, 1.7998, 1.8494, 1.7512],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8120491]\n",
      "[1.81904793]\n",
      "[1.85199597]\n",
      "[1.9180023]\n",
      "[1.75693923]\n",
      "[1.9447498]\n",
      "[1.76847188]\n",
      "tensor([1.8120, 1.8190, 1.8520, 1.9180, 1.7569, 1.9447, 1.7685],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72491781]\n",
      "[1.84310529]\n",
      "[1.81817783]\n",
      "[1.81629981]\n",
      "[1.87715235]\n",
      "[1.85186726]\n",
      "[1.81907886]\n",
      "tensor([1.7249, 1.8431, 1.8182, 1.8163, 1.8772, 1.8519, 1.8191],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91604667]\n",
      "[1.78595796]\n",
      "[1.89586833]\n",
      "[1.85825632]\n",
      "[1.71908873]\n",
      "[1.80149395]\n",
      "[1.78167322]\n",
      "tensor([1.9160, 1.7860, 1.8959, 1.8583, 1.7191, 1.8015, 1.7817],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93435881]\n",
      "[1.76158954]\n",
      "[1.93495964]\n",
      "[1.85823916]\n",
      "[1.80429325]\n",
      "[1.87784994]\n",
      "[1.79235743]\n",
      "tensor([1.9344, 1.7616, 1.9350, 1.8582, 1.8043, 1.8778, 1.7924],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80597712]\n",
      "[1.80190167]\n",
      "[1.76284147]\n",
      "[1.75382955]\n",
      "[1.80680498]\n",
      "[1.88991508]\n",
      "[1.91562138]\n",
      "tensor([1.8060, 1.8019, 1.7628, 1.7538, 1.8068, 1.8899, 1.9156],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89572603]\n",
      "[1.82856044]\n",
      "[1.90654922]\n",
      "[1.77468454]\n",
      "[1.84977443]\n",
      "[1.83783934]\n",
      "[1.84266006]\n",
      "tensor([1.8957, 1.8286, 1.9065, 1.7747, 1.8498, 1.8378, 1.8427],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88331467]\n",
      "[1.88580842]\n",
      "[1.72953569]\n",
      "[1.79783618]\n",
      "[1.81828079]\n",
      "[1.82072536]\n",
      "[1.7631434]\n",
      "tensor([1.8833, 1.8858, 1.7295, 1.7978, 1.8183, 1.8207, 1.7631],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86301378]\n",
      "[1.89068462]\n",
      "[1.79549263]\n",
      "[1.73661491]\n",
      "[1.81073686]\n",
      "[1.8607757]\n",
      "[1.83548182]\n",
      "tensor([1.8630, 1.8907, 1.7955, 1.7366, 1.8107, 1.8608, 1.8355],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82471195]\n",
      "[1.88582268]\n",
      "[1.82692503]\n",
      "[1.83018668]\n",
      "[1.88989075]\n",
      "[1.78523687]\n",
      "[1.76903718]\n",
      "tensor([1.8247, 1.8858, 1.8269, 1.8302, 1.8899, 1.7852, 1.7690],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92143784]\n",
      "[1.89510291]\n",
      "[1.82468825]\n",
      "[1.82285807]\n",
      "[1.79012071]\n",
      "[1.80667472]\n",
      "[1.70326012]\n",
      "tensor([1.9214, 1.8951, 1.8247, 1.8229, 1.7901, 1.8067, 1.7033],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90059586]\n",
      "[1.83222129]\n",
      "[1.75416949]\n",
      "[1.79889827]\n",
      "[1.90238898]\n",
      "[1.80834355]\n",
      "[1.76594932]\n",
      "tensor([1.9006, 1.8322, 1.7542, 1.7989, 1.9024, 1.8083, 1.7659],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75918013]\n",
      "[1.71322507]\n",
      "[1.82595381]\n",
      "[1.75092175]\n",
      "[1.85180614]\n",
      "[1.95319159]\n",
      "[1.84120502]\n",
      "tensor([1.7592, 1.7132, 1.8260, 1.7509, 1.8518, 1.9532, 1.8412],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9045659]\n",
      "[1.82407917]\n",
      "[1.74847993]\n",
      "[1.79949037]\n",
      "[1.7354996]\n",
      "[1.8100168]\n",
      "[1.68935318]\n",
      "tensor([1.9046, 1.8241, 1.7485, 1.7995, 1.7355, 1.8100, 1.6894],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82136194]\n",
      "[1.83648748]\n",
      "[1.79656225]\n",
      "[1.96287222]\n",
      "[1.80734658]\n",
      "[1.82760211]\n",
      "[1.89296938]\n",
      "tensor([1.8214, 1.8365, 1.7966, 1.9629, 1.8073, 1.8276, 1.8930],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84515719]\n",
      "[1.89265422]\n",
      "[1.92908862]\n",
      "[1.90652958]\n",
      "[1.84778977]\n",
      "[1.72111353]\n",
      "[1.7916608]\n",
      "tensor([1.8452, 1.8927, 1.9291, 1.9065, 1.8478, 1.7211, 1.7917],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7667096]\n",
      "[1.8344847]\n",
      "[1.84388008]\n",
      "[1.92962466]\n",
      "[1.9299219]\n",
      "[1.80381663]\n",
      "[1.7896932]\n",
      "tensor([1.7667, 1.8345, 1.8439, 1.9296, 1.9299, 1.8038, 1.7897],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81225154]\n",
      "[1.8294956]\n",
      "[1.8155879]\n",
      "[1.8077794]\n",
      "[1.84591495]\n",
      "[1.7972864]\n",
      "[1.90594636]\n",
      "tensor([1.8123, 1.8295, 1.8156, 1.8078, 1.8459, 1.7973, 1.9059],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91450801]\n",
      "[1.9016256]\n",
      "[1.81139923]\n",
      "[1.89128236]\n",
      "[1.83046358]\n",
      "[1.92660441]\n",
      "[1.81335331]\n",
      "tensor([1.9145, 1.9016, 1.8114, 1.8913, 1.8305, 1.9266, 1.8134],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84559126]\n",
      "[1.73758887]\n",
      "[1.8812753]\n",
      "[1.79937535]\n",
      "[1.81281368]\n",
      "[1.79811327]\n",
      "[1.90122917]\n",
      "tensor([1.8456, 1.7376, 1.8813, 1.7994, 1.8128, 1.7981, 1.9012],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81338282]\n",
      "[1.86190391]\n",
      "[1.89809356]\n",
      "[1.84343691]\n",
      "[1.75959702]\n",
      "[1.69482955]\n",
      "[1.78242509]\n",
      "tensor([1.8134, 1.8619, 1.8981, 1.8434, 1.7596, 1.6948, 1.7824],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78927463]\n",
      "[1.85402923]\n",
      "[1.87924988]\n",
      "[1.83226399]\n",
      "[1.92021197]\n",
      "[1.80643979]\n",
      "[1.93433213]\n",
      "tensor([1.7893, 1.8540, 1.8792, 1.8323, 1.9202, 1.8064, 1.9343],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85914166]\n",
      "[1.85463322]\n",
      "[1.79939516]\n",
      "[1.90523055]\n",
      "[1.83382349]\n",
      "[1.84041411]\n",
      "[1.82412229]\n",
      "tensor([1.8591, 1.8546, 1.7994, 1.9052, 1.8338, 1.8404, 1.8241],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96514235]\n",
      "[1.90320741]\n",
      "[1.84792972]\n",
      "[1.84871541]\n",
      "[1.76426141]\n",
      "[1.90464453]\n",
      "[1.78945959]\n",
      "tensor([1.9651, 1.9032, 1.8479, 1.8487, 1.7643, 1.9046, 1.7895],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81377118]\n",
      "[1.94588106]\n",
      "[1.81245186]\n",
      "[1.86945366]\n",
      "[1.74233213]\n",
      "[1.83004666]\n",
      "[1.87665889]\n",
      "tensor([1.8138, 1.9459, 1.8125, 1.8695, 1.7423, 1.8300, 1.8767],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78201913]\n",
      "[1.80399612]\n",
      "[1.81469753]\n",
      "[1.85261843]\n",
      "[1.88758405]\n",
      "[1.90047061]\n",
      "[1.76902648]\n",
      "tensor([1.7820, 1.8040, 1.8147, 1.8526, 1.8876, 1.9005, 1.7690],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74002272]\n",
      "[1.86577743]\n",
      "[1.76336282]\n",
      "[1.90731437]\n",
      "[1.9109078]\n",
      "[1.80523401]\n",
      "[1.84786425]\n",
      "tensor([1.7400, 1.8658, 1.7634, 1.9073, 1.9109, 1.8052, 1.8479],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95306317]\n",
      "[1.77128507]\n",
      "[1.90276733]\n",
      "[1.83209404]\n",
      "[1.84944282]\n",
      "[1.82988633]\n",
      "[1.74387183]\n",
      "tensor([1.9531, 1.7713, 1.9028, 1.8321, 1.8494, 1.8299, 1.7439],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79147056]\n",
      "[1.87417273]\n",
      "[1.80148607]\n",
      "[1.84410169]\n",
      "[1.86571839]\n",
      "[1.73336287]\n",
      "[1.84362583]\n",
      "tensor([1.7915, 1.8742, 1.8015, 1.8441, 1.8657, 1.7334, 1.8436],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93868035]\n",
      "[1.82054111]\n",
      "[1.87220744]\n",
      "[1.8053081]\n",
      "[1.88578018]\n",
      "[1.87420196]\n",
      "[1.79958613]\n",
      "tensor([1.9387, 1.8205, 1.8722, 1.8053, 1.8858, 1.8742, 1.7996],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84125633]\n",
      "[1.86765053]\n",
      "[1.81099294]\n",
      "[1.82785126]\n",
      "[1.85053927]\n",
      "[1.87710256]\n",
      "[1.84101366]\n",
      "tensor([1.8413, 1.8677, 1.8110, 1.8279, 1.8505, 1.8771, 1.8410],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87117243]\n",
      "[1.76133216]\n",
      "[1.83979553]\n",
      "[1.85982215]\n",
      "[1.77148551]\n",
      "[1.83405063]\n",
      "[1.78806542]\n",
      "tensor([1.8712, 1.7613, 1.8398, 1.8598, 1.7715, 1.8341, 1.7881],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8232142]\n",
      "[1.7611578]\n",
      "[1.92622215]\n",
      "[1.84981817]\n",
      "[1.82014172]\n",
      "[1.87831494]\n",
      "[1.82175317]\n",
      "tensor([1.8232, 1.7612, 1.9262, 1.8498, 1.8201, 1.8783, 1.8218],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70853355]\n",
      "[1.94435109]\n",
      "[1.81413972]\n",
      "[1.73998048]\n",
      "[1.85369774]\n",
      "[1.8025067]\n",
      "[1.81073011]\n",
      "tensor([1.7085, 1.9444, 1.8141, 1.7400, 1.8537, 1.8025, 1.8107],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85972328]\n",
      "[1.77472013]\n",
      "[1.84608907]\n",
      "[1.82285241]\n",
      "[1.92821198]\n",
      "[1.88267013]\n",
      "[1.85663031]\n",
      "tensor([1.8597, 1.7747, 1.8461, 1.8229, 1.9282, 1.8827, 1.8566],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79133759]\n",
      "[1.73537487]\n",
      "[1.82651014]\n",
      "[1.7319186]\n",
      "[1.80641287]\n",
      "[1.92291775]\n",
      "[1.91139353]\n",
      "tensor([1.7913, 1.7354, 1.8265, 1.7319, 1.8064, 1.9229, 1.9114],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95348793]\n",
      "[1.87918594]\n",
      "[1.93430966]\n",
      "[1.85659015]\n",
      "[1.77104658]\n",
      "[1.91258106]\n",
      "[1.82307823]\n",
      "tensor([1.9535, 1.8792, 1.9343, 1.8566, 1.7710, 1.9126, 1.8231],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84793649]\n",
      "[1.91469511]\n",
      "[1.8108383]\n",
      "[1.8324348]\n",
      "[1.88692515]\n",
      "[1.81081891]\n",
      "[1.79429908]\n",
      "tensor([1.8479, 1.9147, 1.8108, 1.8324, 1.8869, 1.8108, 1.7943],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82268338]\n",
      "[1.84152212]\n",
      "[1.79591024]\n",
      "[1.81867144]\n",
      "[1.93598601]\n",
      "[1.85184479]\n",
      "[1.88415319]\n",
      "tensor([1.8227, 1.8415, 1.7959, 1.8187, 1.9360, 1.8518, 1.8842],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84876657]\n",
      "[1.86369663]\n",
      "[1.8172246]\n",
      "[1.86125845]\n",
      "[1.78552415]\n",
      "[1.90999683]\n",
      "[1.7771117]\n",
      "tensor([1.8488, 1.8637, 1.8172, 1.8613, 1.7855, 1.9100, 1.7771],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84227424]\n",
      "[1.82485926]\n",
      "[1.82604718]\n",
      "[1.82484635]\n",
      "[1.83970988]\n",
      "[1.83544397]\n",
      "[1.81513694]\n",
      "tensor([1.8423, 1.8249, 1.8260, 1.8248, 1.8397, 1.8354, 1.8151],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8317986]\n",
      "[1.91025888]\n",
      "[1.87160426]\n",
      "[1.91728859]\n",
      "[1.85519015]\n",
      "[2.06318152]\n",
      "[1.84774111]\n",
      "tensor([1.8318, 1.9103, 1.8716, 1.9173, 1.8552, 2.0632, 1.8477],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85036353]\n",
      "[1.79396244]\n",
      "[1.78520086]\n",
      "[1.86624024]\n",
      "[1.94481469]\n",
      "[1.84532762]\n",
      "[1.91207798]\n",
      "tensor([1.8504, 1.7940, 1.7852, 1.8662, 1.9448, 1.8453, 1.9121],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80079175]\n",
      "[1.84659053]\n",
      "[1.81532409]\n",
      "[1.91612834]\n",
      "[1.73786508]\n",
      "[1.86543223]\n",
      "[1.88186049]\n",
      "tensor([1.8008, 1.8466, 1.8153, 1.9161, 1.7379, 1.8654, 1.8819],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84006895]\n",
      "[1.80715958]\n",
      "[1.87911572]\n",
      "[1.85632147]\n",
      "[1.81212342]\n",
      "[1.73874124]\n",
      "[1.84948714]\n",
      "tensor([1.8401, 1.8072, 1.8791, 1.8563, 1.8121, 1.7387, 1.8495],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8368463]\n",
      "[1.81988794]\n",
      "[1.7920438]\n",
      "[1.79867181]\n",
      "[1.73541538]\n",
      "[1.85863644]\n",
      "[1.74036005]\n",
      "tensor([1.8368, 1.8199, 1.7920, 1.7987, 1.7354, 1.8586, 1.7404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85893486]\n",
      "[1.86184127]\n",
      "[1.92079217]\n",
      "[1.70714927]\n",
      "[1.78413002]\n",
      "[1.81970358]\n",
      "[1.83995255]\n",
      "tensor([1.8589, 1.8618, 1.9208, 1.7071, 1.7841, 1.8197, 1.8400],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.794295]\n",
      "[1.83919075]\n",
      "[1.86740543]\n",
      "[1.83416566]\n",
      "[1.90556617]\n",
      "[1.71304249]\n",
      "[1.92323873]\n",
      "tensor([1.7943, 1.8392, 1.8674, 1.8342, 1.9056, 1.7130, 1.9232],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81807484]\n",
      "[1.79303114]\n",
      "[1.75728443]\n",
      "[1.83757269]\n",
      "[1.97333316]\n",
      "[1.75271094]\n",
      "[1.81858678]\n",
      "tensor([1.8181, 1.7930, 1.7573, 1.8376, 1.9733, 1.7527, 1.8186],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75646898]\n",
      "[1.87214068]\n",
      "[1.84467243]\n",
      "[1.82907155]\n",
      "[1.8063047]\n",
      "[1.83985485]\n",
      "[1.82145227]\n",
      "tensor([1.7565, 1.8721, 1.8447, 1.8291, 1.8063, 1.8399, 1.8215],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88355539]\n",
      "[1.75507855]\n",
      "[1.83213669]\n",
      "[1.80570878]\n",
      "[1.92675958]\n",
      "[1.87580413]\n",
      "[1.77240583]\n",
      "tensor([1.8836, 1.7551, 1.8321, 1.8057, 1.9268, 1.8758, 1.7724],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81375619]\n",
      "[1.83569731]\n",
      "[1.7508348]\n",
      "[1.74670407]\n",
      "[1.87663482]\n",
      "[1.82254861]\n",
      "[1.83546654]\n",
      "tensor([1.8138, 1.8357, 1.7508, 1.7467, 1.8766, 1.8225, 1.8355],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84711525]\n",
      "[1.84406169]\n",
      "[1.75168208]\n",
      "[1.78090436]\n",
      "[1.83971547]\n",
      "[1.79404904]\n",
      "[1.83296007]\n",
      "tensor([1.8471, 1.8441, 1.7517, 1.7809, 1.8397, 1.7940, 1.8330],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78505241]\n",
      "[1.76217515]\n",
      "[1.69932679]\n",
      "[1.85080596]\n",
      "[1.73831573]\n",
      "[1.80427946]\n",
      "[1.70534967]\n",
      "tensor([1.7851, 1.7622, 1.6993, 1.8508, 1.7383, 1.8043, 1.7053],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88215482]\n",
      "[1.77726277]\n",
      "[1.81471131]\n",
      "[1.75249534]\n",
      "[1.85739058]\n",
      "[1.96264833]\n",
      "[1.79422162]\n",
      "tensor([1.8822, 1.7773, 1.8147, 1.7525, 1.8574, 1.9626, 1.7942],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80003843]\n",
      "[1.75772473]\n",
      "[1.96209595]\n",
      "[1.79521959]\n",
      "[1.8507214]\n",
      "[1.8174462]\n",
      "[1.8419855]\n",
      "tensor([1.8000, 1.7577, 1.9621, 1.7952, 1.8507, 1.8174, 1.8420],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84244946]\n",
      "[1.82217851]\n",
      "[1.90631811]\n",
      "[1.83692786]\n",
      "[1.97524201]\n",
      "[1.87901865]\n",
      "[1.89680907]\n",
      "tensor([1.8424, 1.8222, 1.9063, 1.8369, 1.9752, 1.8790, 1.8968],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82267138]\n",
      "[1.83998111]\n",
      "[1.86633272]\n",
      "[1.77252806]\n",
      "[1.74867998]\n",
      "[1.83116429]\n",
      "[1.90403411]\n",
      "tensor([1.8227, 1.8400, 1.8663, 1.7725, 1.7487, 1.8312, 1.9040],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74076759]\n",
      "[1.78800745]\n",
      "[1.81727514]\n",
      "[1.82933108]\n",
      "[1.80017983]\n",
      "[1.77356102]\n",
      "[1.76879404]\n",
      "tensor([1.7408, 1.7880, 1.8173, 1.8293, 1.8002, 1.7736, 1.7688],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87734117]\n",
      "[1.79153824]\n",
      "[1.88594507]\n",
      "[1.9071174]\n",
      "[1.75595166]\n",
      "[1.81157336]\n",
      "[1.70526773]\n",
      "tensor([1.8773, 1.7915, 1.8859, 1.9071, 1.7560, 1.8116, 1.7053],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84959586]\n",
      "[1.78196856]\n",
      "[1.80355305]\n",
      "[1.73712986]\n",
      "[1.78708192]\n",
      "[1.90094395]\n",
      "[1.83569517]\n",
      "tensor([1.8496, 1.7820, 1.8036, 1.7371, 1.7871, 1.9009, 1.8357],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97834211]\n",
      "[1.83840352]\n",
      "[1.86592271]\n",
      "[1.75744362]\n",
      "[1.90107669]\n",
      "[1.8194069]\n",
      "[1.84781966]\n",
      "tensor([1.9783, 1.8384, 1.8659, 1.7574, 1.9011, 1.8194, 1.8478],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79416948]\n",
      "[1.83053989]\n",
      "[1.75167978]\n",
      "[1.8586501]\n",
      "[1.95320172]\n",
      "[1.85019675]\n",
      "[1.78885358]\n",
      "tensor([1.7942, 1.8305, 1.7517, 1.8587, 1.9532, 1.8502, 1.7889],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86065376]\n",
      "[1.87207566]\n",
      "[1.95526804]\n",
      "[1.81305498]\n",
      "[1.88881087]\n",
      "[1.89085674]\n",
      "[1.81440957]\n",
      "tensor([1.8607, 1.8721, 1.9553, 1.8131, 1.8888, 1.8909, 1.8144],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89807002]\n",
      "[1.82528376]\n",
      "[1.77971212]\n",
      "[1.83911792]\n",
      "[1.83900347]\n",
      "[1.73464296]\n",
      "[1.85884175]\n",
      "tensor([1.8981, 1.8253, 1.7797, 1.8391, 1.8390, 1.7346, 1.8588],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82131079]\n",
      "[1.87888929]\n",
      "[1.86822012]\n",
      "[1.84195619]\n",
      "[1.85865683]\n",
      "[1.85886635]\n",
      "[1.83690205]\n",
      "tensor([1.8213, 1.8789, 1.8682, 1.8420, 1.8587, 1.8589, 1.8369],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83762921]\n",
      "[1.88851738]\n",
      "[1.74394088]\n",
      "[1.81262506]\n",
      "[1.80465364]\n",
      "[1.85384633]\n",
      "[1.7957063]\n",
      "tensor([1.8376, 1.8885, 1.7439, 1.8126, 1.8047, 1.8538, 1.7957],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71392267]\n",
      "[1.74121061]\n",
      "[1.80097716]\n",
      "[1.81406051]\n",
      "[1.73735011]\n",
      "[1.84804766]\n",
      "[1.81847587]\n",
      "tensor([1.7139, 1.7412, 1.8010, 1.8141, 1.7374, 1.8480, 1.8185],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7602482]\n",
      "[1.78685585]\n",
      "[1.8818943]\n",
      "[1.86353003]\n",
      "[1.95587146]\n",
      "[1.77911662]\n",
      "[1.79104652]\n",
      "tensor([1.7602, 1.7869, 1.8819, 1.8635, 1.9559, 1.7791, 1.7910],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84954577]\n",
      "[1.73472635]\n",
      "[1.85747104]\n",
      "[1.78505557]\n",
      "[1.79678283]\n",
      "[1.8833938]\n",
      "[1.92070727]\n",
      "tensor([1.8495, 1.7347, 1.8575, 1.7851, 1.7968, 1.8834, 1.9207],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79982671]\n",
      "[1.87700747]\n",
      "[1.85063725]\n",
      "[1.8985426]\n",
      "[1.86219496]\n",
      "[1.80584171]\n",
      "[1.95254371]\n",
      "tensor([1.7998, 1.8770, 1.8506, 1.8985, 1.8622, 1.8058, 1.9525],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87893626]\n",
      "[1.80021855]\n",
      "[1.85202091]\n",
      "[1.75143657]\n",
      "[1.83852537]\n",
      "[1.87322071]\n",
      "[1.8101527]\n",
      "tensor([1.8789, 1.8002, 1.8520, 1.7514, 1.8385, 1.8732, 1.8102],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84804049]\n",
      "[1.79377851]\n",
      "[1.85809655]\n",
      "[1.98116264]\n",
      "[1.88739031]\n",
      "[1.77722728]\n",
      "[1.68307448]\n",
      "tensor([1.8480, 1.7938, 1.8581, 1.9812, 1.8874, 1.7772, 1.6831],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85119645]\n",
      "[1.82755637]\n",
      "[1.79294835]\n",
      "[1.76155856]\n",
      "[1.72552091]\n",
      "[1.83745223]\n",
      "[1.76927447]\n",
      "tensor([1.8512, 1.8276, 1.7929, 1.7616, 1.7255, 1.8375, 1.7693],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81928394]\n",
      "[1.8801814]\n",
      "[1.88926059]\n",
      "[1.90665325]\n",
      "[1.80314781]\n",
      "[1.84306331]\n",
      "[1.8271122]\n",
      "tensor([1.8193, 1.8802, 1.8893, 1.9067, 1.8031, 1.8431, 1.8271],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78742881]\n",
      "[1.89272739]\n",
      "[1.81183087]\n",
      "[1.8009401]\n",
      "[1.86506025]\n",
      "[1.81027992]\n",
      "[1.7622327]\n",
      "tensor([1.7874, 1.8927, 1.8118, 1.8009, 1.8651, 1.8103, 1.7622],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80451543]\n",
      "[1.83693548]\n",
      "[1.87535522]\n",
      "[1.91703526]\n",
      "[1.89516048]\n",
      "[1.93871282]\n",
      "[1.77836693]\n",
      "tensor([1.8045, 1.8369, 1.8754, 1.9170, 1.8952, 1.9387, 1.7784],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77152543]\n",
      "[1.93119166]\n",
      "[1.87264152]\n",
      "[1.74292784]\n",
      "[1.94875937]\n",
      "[1.83939834]\n",
      "[1.94040853]\n",
      "tensor([1.7715, 1.9312, 1.8726, 1.7429, 1.9488, 1.8394, 1.9404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74924597]\n",
      "[1.8524017]\n",
      "[1.81013297]\n",
      "[1.91002462]\n",
      "[1.80632768]\n",
      "[1.79479775]\n",
      "[1.7978938]\n",
      "tensor([1.7492, 1.8524, 1.8101, 1.9100, 1.8063, 1.7948, 1.7979],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90549755]\n",
      "[1.81547354]\n",
      "[2.00058616]\n",
      "[1.86034411]\n",
      "[1.84942809]\n",
      "[1.92360978]\n",
      "[1.8153871]\n",
      "tensor([1.9055, 1.8155, 2.0006, 1.8603, 1.8494, 1.9236, 1.8154],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84123376]\n",
      "[1.83088105]\n",
      "[1.97717707]\n",
      "[1.90784246]\n",
      "[1.83986502]\n",
      "[1.81121109]\n",
      "[1.75031312]\n",
      "tensor([1.8412, 1.8309, 1.9772, 1.9078, 1.8399, 1.8112, 1.7503],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91384723]\n",
      "[1.98361939]\n",
      "[1.74241782]\n",
      "[1.83923926]\n",
      "[1.7904655]\n",
      "[1.90289391]\n",
      "[1.80553224]\n",
      "tensor([1.9138, 1.9836, 1.7424, 1.8392, 1.7905, 1.9029, 1.8055],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81088403]\n",
      "[1.77143682]\n",
      "[1.91593993]\n",
      "[1.84757891]\n",
      "[1.94420192]\n",
      "[1.86563703]\n",
      "[1.96486719]\n",
      "tensor([1.8109, 1.7714, 1.9159, 1.8476, 1.9442, 1.8656, 1.9649],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75393296]\n",
      "[1.76240969]\n",
      "[1.87604028]\n",
      "[1.94825782]\n",
      "[1.91401979]\n",
      "[1.84680338]\n",
      "[1.86155864]\n",
      "tensor([1.7539, 1.7624, 1.8760, 1.9483, 1.9140, 1.8468, 1.8616],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8744099]\n",
      "[1.74411306]\n",
      "[1.7313816]\n",
      "[1.87186758]\n",
      "[1.91788214]\n",
      "[1.82869241]\n",
      "[1.83527973]\n",
      "tensor([1.8744, 1.7441, 1.7314, 1.8719, 1.9179, 1.8287, 1.8353],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83126379]\n",
      "[1.87748422]\n",
      "[1.85039468]\n",
      "[1.82018566]\n",
      "[1.78912742]\n",
      "[1.86326506]\n",
      "[1.71029277]\n",
      "tensor([1.8313, 1.8775, 1.8504, 1.8202, 1.7891, 1.8633, 1.7103],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8272057]\n",
      "[1.82571586]\n",
      "[1.74215479]\n",
      "[1.73756682]\n",
      "[1.85541784]\n",
      "[1.85212968]\n",
      "[1.75352271]\n",
      "tensor([1.8272, 1.8257, 1.7422, 1.7376, 1.8554, 1.8521, 1.7535],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88460633]\n",
      "[1.94525875]\n",
      "[1.8398559]\n",
      "[1.86419966]\n",
      "[1.90001954]\n",
      "[1.79462506]\n",
      "[1.82306556]\n",
      "tensor([1.8846, 1.9453, 1.8399, 1.8642, 1.9000, 1.7946, 1.8231],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94428482]\n",
      "[1.72182028]\n",
      "[1.91163203]\n",
      "[1.87071714]\n",
      "[1.75851393]\n",
      "[1.87934427]\n",
      "[1.816537]\n",
      "tensor([1.9443, 1.7218, 1.9116, 1.8707, 1.7585, 1.8793, 1.8165],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90006492]\n",
      "[1.93807991]\n",
      "[1.85394186]\n",
      "[1.85669907]\n",
      "[1.88650326]\n",
      "[1.81713947]\n",
      "[1.81588674]\n",
      "tensor([1.9001, 1.9381, 1.8539, 1.8567, 1.8865, 1.8171, 1.8159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7888725]\n",
      "[1.91157962]\n",
      "[1.77400111]\n",
      "[1.75963534]\n",
      "[2.06226966]\n",
      "[1.84129081]\n",
      "[1.77482073]\n",
      "tensor([1.7889, 1.9116, 1.7740, 1.7596, 2.0623, 1.8413, 1.7748],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82512956]\n",
      "[1.9140738]\n",
      "[1.94838149]\n",
      "[1.84683467]\n",
      "[1.82821021]\n",
      "[1.97566999]\n",
      "[1.73417677]\n",
      "tensor([1.8251, 1.9141, 1.9484, 1.8468, 1.8282, 1.9757, 1.7342],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90651252]\n",
      "[1.86611477]\n",
      "[1.8698819]\n",
      "[1.83886178]\n",
      "[1.85415627]\n",
      "[1.79964212]\n",
      "[1.84619616]\n",
      "tensor([1.9065, 1.8661, 1.8699, 1.8389, 1.8542, 1.7996, 1.8462],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88191777]\n",
      "[1.8033262]\n",
      "[1.7448614]\n",
      "[1.90327334]\n",
      "[1.81540163]\n",
      "[1.77373008]\n",
      "[1.83349209]\n",
      "tensor([1.8819, 1.8033, 1.7449, 1.9033, 1.8154, 1.7737, 1.8335],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88102526]\n",
      "[1.90814287]\n",
      "[1.75170947]\n",
      "[1.76939586]\n",
      "[1.88153794]\n",
      "[1.82663761]\n",
      "[1.76034026]\n",
      "tensor([1.8810, 1.9081, 1.7517, 1.7694, 1.8815, 1.8266, 1.7603],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75843606]\n",
      "[1.80023263]\n",
      "[1.89654418]\n",
      "[1.81905128]\n",
      "[1.88282531]\n",
      "[1.70699036]\n",
      "[1.76425737]\n",
      "tensor([1.7584, 1.8002, 1.8965, 1.8191, 1.8828, 1.7070, 1.7643],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8664703]\n",
      "[1.77291831]\n",
      "[1.82753259]\n",
      "[1.74529222]\n",
      "[1.80597816]\n",
      "[1.78284899]\n",
      "[1.77743909]\n",
      "tensor([1.8665, 1.7729, 1.8275, 1.7453, 1.8060, 1.7828, 1.7774],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86425859]\n",
      "[1.85444682]\n",
      "[1.81520321]\n",
      "[1.75206439]\n",
      "[1.95155531]\n",
      "[1.84224622]\n",
      "[1.88686959]\n",
      "tensor([1.8643, 1.8544, 1.8152, 1.7521, 1.9516, 1.8422, 1.8869],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92698665]\n",
      "[1.86536389]\n",
      "[1.88790827]\n",
      "[1.6972223]\n",
      "[1.83495745]\n",
      "[1.79765129]\n",
      "[1.94299536]\n",
      "tensor([1.9270, 1.8654, 1.8879, 1.6972, 1.8350, 1.7977, 1.9430],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86402401]\n",
      "[1.8223587]\n",
      "[1.8582453]\n",
      "[1.81967299]\n",
      "[1.83615412]\n",
      "[1.78958465]\n",
      "[1.80925781]\n",
      "tensor([1.8640, 1.8224, 1.8582, 1.8197, 1.8362, 1.7896, 1.8093],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80392874]\n",
      "[1.88449049]\n",
      "[1.91304168]\n",
      "[1.81852558]\n",
      "[1.82723696]\n",
      "[1.77717733]\n",
      "[1.81259862]\n",
      "tensor([1.8039, 1.8845, 1.9130, 1.8185, 1.8272, 1.7772, 1.8126],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74121668]\n",
      "[1.74463128]\n",
      "[1.81536893]\n",
      "[1.83052729]\n",
      "[1.78184279]\n",
      "[1.93211844]\n",
      "[1.80619661]\n",
      "tensor([1.7412, 1.7446, 1.8154, 1.8305, 1.7818, 1.9321, 1.8062],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73545815]\n",
      "[1.84105213]\n",
      "[1.94151285]\n",
      "[1.90937996]\n",
      "[1.87694398]\n",
      "[1.80780525]\n",
      "[1.84830202]\n",
      "tensor([1.7355, 1.8411, 1.9415, 1.9094, 1.8769, 1.8078, 1.8483],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82779751]\n",
      "[1.95074876]\n",
      "[1.80987839]\n",
      "[1.84868341]\n",
      "[1.88051301]\n",
      "[1.83450739]\n",
      "[1.84001061]\n",
      "tensor([1.8278, 1.9507, 1.8099, 1.8487, 1.8805, 1.8345, 1.8400],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75709997]\n",
      "[1.7859705]\n",
      "[1.77723351]\n",
      "[1.79540465]\n",
      "[1.79748406]\n",
      "[1.85892273]\n",
      "[1.82564196]\n",
      "tensor([1.7571, 1.7860, 1.7772, 1.7954, 1.7975, 1.8589, 1.8256],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.70554711]\n",
      "[1.74677134]\n",
      "[1.76956992]\n",
      "[2.01698462]\n",
      "[1.79264867]\n",
      "[1.8396069]\n",
      "[1.79025378]\n",
      "tensor([1.7055, 1.7468, 1.7696, 2.0170, 1.7926, 1.8396, 1.7903],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86237013]\n",
      "[1.86979808]\n",
      "[1.91162684]\n",
      "[1.85214733]\n",
      "[1.79476932]\n",
      "[1.8237084]\n",
      "[1.91216301]\n",
      "tensor([1.8624, 1.8698, 1.9116, 1.8521, 1.7948, 1.8237, 1.9122],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80709479]\n",
      "[1.8093288]\n",
      "[1.78150085]\n",
      "[1.82497207]\n",
      "[1.81772671]\n",
      "[1.87436677]\n",
      "[1.9268523]\n",
      "tensor([1.8071, 1.8093, 1.7815, 1.8250, 1.8177, 1.8744, 1.9269],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80455112]\n",
      "[1.88329722]\n",
      "[1.80638536]\n",
      "[1.80340174]\n",
      "[1.77200969]\n",
      "[1.89506261]\n",
      "[1.76823586]\n",
      "tensor([1.8046, 1.8833, 1.8064, 1.8034, 1.7720, 1.8951, 1.7682],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98801323]\n",
      "[1.83548886]\n",
      "[1.8327035]\n",
      "[1.80425299]\n",
      "[1.83443196]\n",
      "[1.95751985]\n",
      "[1.83938144]\n",
      "tensor([1.9880, 1.8355, 1.8327, 1.8043, 1.8344, 1.9575, 1.8394],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81365592]\n",
      "[1.83514839]\n",
      "[1.79240695]\n",
      "[1.81633193]\n",
      "[1.87950953]\n",
      "[1.87599705]\n",
      "[1.82742227]\n",
      "tensor([1.8137, 1.8351, 1.7924, 1.8163, 1.8795, 1.8760, 1.8274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83667176]\n",
      "[1.91552205]\n",
      "[1.92258794]\n",
      "[1.77883446]\n",
      "[1.84225583]\n",
      "[1.75038015]\n",
      "[1.86765367]\n",
      "tensor([1.8367, 1.9155, 1.9226, 1.7788, 1.8423, 1.7504, 1.8677],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91657295]\n",
      "[1.83312184]\n",
      "[1.8220707]\n",
      "[1.76554708]\n",
      "[1.81630123]\n",
      "[1.76958111]\n",
      "[1.74155482]\n",
      "tensor([1.9166, 1.8331, 1.8221, 1.7655, 1.8163, 1.7696, 1.7416],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84132472]\n",
      "[1.76706722]\n",
      "[1.87996269]\n",
      "[1.85883579]\n",
      "[1.78176777]\n",
      "[1.8333635]\n",
      "[1.70471268]\n",
      "tensor([1.8413, 1.7671, 1.8800, 1.8588, 1.7818, 1.8334, 1.7047],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84842042]\n",
      "[1.76695045]\n",
      "[1.93000067]\n",
      "[1.74452499]\n",
      "[1.75058048]\n",
      "[1.79707885]\n",
      "[1.8202937]\n",
      "tensor([1.8484, 1.7670, 1.9300, 1.7445, 1.7506, 1.7971, 1.8203],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91443015]\n",
      "[1.94325132]\n",
      "[1.82494438]\n",
      "[1.77837362]\n",
      "[1.85772061]\n",
      "[1.8033003]\n",
      "[1.88960819]\n",
      "tensor([1.9144, 1.9433, 1.8249, 1.7784, 1.8577, 1.8033, 1.8896],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81706759]\n",
      "[1.88275012]\n",
      "[1.80171211]\n",
      "[1.96024588]\n",
      "[1.91958191]\n",
      "[1.8849618]\n",
      "[1.80374878]\n",
      "tensor([1.8171, 1.8828, 1.8017, 1.9602, 1.9196, 1.8850, 1.8037],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8791022]\n",
      "[1.80697128]\n",
      "[1.83545305]\n",
      "[1.85050496]\n",
      "[1.81755385]\n",
      "[1.94363435]\n",
      "[1.82465199]\n",
      "tensor([1.8791, 1.8070, 1.8355, 1.8505, 1.8176, 1.9436, 1.8247],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90573309]\n",
      "[1.96986272]\n",
      "[1.8814837]\n",
      "[1.80844087]\n",
      "[1.77748055]\n",
      "[1.76998707]\n",
      "[1.89340073]\n",
      "tensor([1.9057, 1.9699, 1.8815, 1.8084, 1.7775, 1.7700, 1.8934],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7291039]\n",
      "[1.78185569]\n",
      "[1.83444065]\n",
      "[1.82719243]\n",
      "[1.79023279]\n",
      "[1.83599663]\n",
      "[1.83003037]\n",
      "tensor([1.7291, 1.7819, 1.8344, 1.8272, 1.7902, 1.8360, 1.8300],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90243932]\n",
      "[1.80903482]\n",
      "[1.75285588]\n",
      "[1.75094453]\n",
      "[1.82313191]\n",
      "[1.79957846]\n",
      "[1.73460515]\n",
      "tensor([1.9024, 1.8090, 1.7529, 1.7509, 1.8231, 1.7996, 1.7346],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78348308]\n",
      "[1.78695091]\n",
      "[1.78478513]\n",
      "[1.77304525]\n",
      "[1.86186128]\n",
      "[1.86521797]\n",
      "[1.87542647]\n",
      "tensor([1.7835, 1.7870, 1.7848, 1.7730, 1.8619, 1.8652, 1.8754],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74051018]\n",
      "[1.96027916]\n",
      "[1.76787159]\n",
      "[1.82617725]\n",
      "[1.81702735]\n",
      "[1.73119934]\n",
      "[1.84345798]\n",
      "tensor([1.7405, 1.9603, 1.7679, 1.8262, 1.8170, 1.7312, 1.8435],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79462712]\n",
      "[1.7904164]\n",
      "[1.86836335]\n",
      "[1.94194568]\n",
      "[1.8109787]\n",
      "[1.84877965]\n",
      "[1.88727671]\n",
      "tensor([1.7946, 1.7904, 1.8684, 1.9419, 1.8110, 1.8488, 1.8873],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8287807]\n",
      "[1.8773025]\n",
      "[1.85354332]\n",
      "[1.77525864]\n",
      "[1.9085833]\n",
      "[1.85763599]\n",
      "[1.91318335]\n",
      "tensor([1.8288, 1.8773, 1.8535, 1.7753, 1.9086, 1.8576, 1.9132],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89612027]\n",
      "[1.89412228]\n",
      "[1.84372121]\n",
      "[1.79879086]\n",
      "[1.8383918]\n",
      "[1.8466191]\n",
      "[1.76619636]\n",
      "tensor([1.8961, 1.8941, 1.8437, 1.7988, 1.8384, 1.8466, 1.7662],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90576217]\n",
      "[1.86853614]\n",
      "[1.89838256]\n",
      "[1.77555661]\n",
      "[1.90587777]\n",
      "[1.88830142]\n",
      "[1.96987357]\n",
      "tensor([1.9058, 1.8685, 1.8984, 1.7756, 1.9059, 1.8883, 1.9699],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89874057]\n",
      "[1.84038073]\n",
      "[2.00108717]\n",
      "[1.83959479]\n",
      "[1.92124542]\n",
      "[1.95866609]\n",
      "[1.90653436]\n",
      "tensor([1.8987, 1.8404, 2.0011, 1.8396, 1.9212, 1.9587, 1.9065],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86622991]\n",
      "[1.79260334]\n",
      "[1.7874793]\n",
      "[1.8169221]\n",
      "[1.79504258]\n",
      "[1.92325644]\n",
      "[1.86398695]\n",
      "tensor([1.8662, 1.7926, 1.7875, 1.8169, 1.7950, 1.9233, 1.8640],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91373815]\n",
      "[1.80513269]\n",
      "[1.93582875]\n",
      "[1.86721111]\n",
      "[1.93807135]\n",
      "[1.94468765]\n",
      "[1.88114522]\n",
      "tensor([1.9137, 1.8051, 1.9358, 1.8672, 1.9381, 1.9447, 1.8811],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86856784]\n",
      "[1.81450871]\n",
      "[1.89288878]\n",
      "[1.88128486]\n",
      "[1.81618623]\n",
      "[1.86453542]\n",
      "[1.81046889]\n",
      "tensor([1.8686, 1.8145, 1.8929, 1.8813, 1.8162, 1.8645, 1.8105],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85421517]\n",
      "[1.97826259]\n",
      "[1.83485597]\n",
      "[1.81709452]\n",
      "[1.76218233]\n",
      "[1.91139934]\n",
      "[1.80283704]\n",
      "tensor([1.8542, 1.9783, 1.8349, 1.8171, 1.7622, 1.9114, 1.8028],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81327001]\n",
      "[1.78764592]\n",
      "[1.84958172]\n",
      "[1.76016724]\n",
      "[1.84997658]\n",
      "[1.789894]\n",
      "[1.76344178]\n",
      "tensor([1.8133, 1.7876, 1.8496, 1.7602, 1.8500, 1.7899, 1.7634],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85361063]\n",
      "[1.73415948]\n",
      "[1.86751769]\n",
      "[1.796235]\n",
      "[1.96316386]\n",
      "[1.84839793]\n",
      "[1.8963335]\n",
      "tensor([1.8536, 1.7342, 1.8675, 1.7962, 1.9632, 1.8484, 1.8963],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81248881]\n",
      "[1.8397359]\n",
      "[1.92056317]\n",
      "[1.85366009]\n",
      "[1.78270054]\n",
      "[1.79383439]\n",
      "[1.79031393]\n",
      "tensor([1.8125, 1.8397, 1.9206, 1.8537, 1.7827, 1.7938, 1.7903],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75494788]\n",
      "[1.74216345]\n",
      "[1.83677302]\n",
      "[1.85267814]\n",
      "[1.85170127]\n",
      "[1.85291622]\n",
      "[1.78824393]\n",
      "tensor([1.7549, 1.7422, 1.8368, 1.8527, 1.8517, 1.8529, 1.7882],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92874411]\n",
      "[1.79273235]\n",
      "[1.90195165]\n",
      "[1.87112225]\n",
      "[1.83638918]\n",
      "[1.87749861]\n",
      "[1.84621916]\n",
      "tensor([1.9287, 1.7927, 1.9020, 1.8711, 1.8364, 1.8775, 1.8462],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81125827]\n",
      "[1.82369255]\n",
      "[1.7642105]\n",
      "[1.82358541]\n",
      "[1.82920358]\n",
      "[1.81327565]\n",
      "[1.84655734]\n",
      "tensor([1.8113, 1.8237, 1.7642, 1.8236, 1.8292, 1.8133, 1.8466],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81989759]\n",
      "[1.779471]\n",
      "[1.84597562]\n",
      "[1.87736086]\n",
      "[1.84525496]\n",
      "[1.83623621]\n",
      "[1.8283406]\n",
      "tensor([1.8199, 1.7795, 1.8460, 1.8774, 1.8453, 1.8362, 1.8283],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91249765]\n",
      "[1.88555797]\n",
      "[1.9194266]\n",
      "[1.79312822]\n",
      "[1.81486588]\n",
      "[1.89432735]\n",
      "[1.7483434]\n",
      "tensor([1.9125, 1.8856, 1.9194, 1.7931, 1.8149, 1.8943, 1.7483],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78619554]\n",
      "[1.85657018]\n",
      "[1.89705549]\n",
      "[1.79548712]\n",
      "[1.86934793]\n",
      "[1.72553131]\n",
      "[1.84688113]\n",
      "tensor([1.7862, 1.8566, 1.8971, 1.7955, 1.8693, 1.7255, 1.8469],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80951517]\n",
      "[1.77021163]\n",
      "[1.94839834]\n",
      "[1.77844715]\n",
      "[1.8458031]\n",
      "[1.88762376]\n",
      "[1.82414173]\n",
      "tensor([1.8095, 1.7702, 1.9484, 1.7784, 1.8458, 1.8876, 1.8241],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74633855]\n",
      "[1.81628042]\n",
      "[1.89245608]\n",
      "[1.82252462]\n",
      "[1.85543135]\n",
      "[1.86240934]\n",
      "[1.91788666]\n",
      "tensor([1.7463, 1.8163, 1.8925, 1.8225, 1.8554, 1.8624, 1.9179],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88737168]\n",
      "[1.75890486]\n",
      "[1.8322768]\n",
      "[1.76036302]\n",
      "[1.89835996]\n",
      "[1.97540739]\n",
      "[1.82770088]\n",
      "tensor([1.8874, 1.7589, 1.8323, 1.7604, 1.8984, 1.9754, 1.8277],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79784355]\n",
      "[1.85543702]\n",
      "[1.842226]\n",
      "[1.82047574]\n",
      "[1.84738429]\n",
      "[1.90355777]\n",
      "[1.94089339]\n",
      "tensor([1.7978, 1.8554, 1.8422, 1.8205, 1.8474, 1.9036, 1.9409],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88811818]\n",
      "[1.84863427]\n",
      "[1.79164441]\n",
      "[1.80570193]\n",
      "[1.82385592]\n",
      "[1.88893995]\n",
      "[1.85498495]\n",
      "tensor([1.8881, 1.8486, 1.7916, 1.8057, 1.8239, 1.8889, 1.8550],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93113106]\n",
      "[1.78409509]\n",
      "[1.8325915]\n",
      "[1.80565439]\n",
      "[1.7831568]\n",
      "[1.80969886]\n",
      "[1.84817317]\n",
      "tensor([1.9311, 1.7841, 1.8326, 1.8057, 1.7832, 1.8097, 1.8482],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8175611]\n",
      "[1.84362605]\n",
      "[1.8515133]\n",
      "[1.92183547]\n",
      "[1.89858027]\n",
      "[1.74880394]\n",
      "[1.80663935]\n",
      "tensor([1.8176, 1.8436, 1.8515, 1.9218, 1.8986, 1.7488, 1.8066],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86433906]\n",
      "[1.88679818]\n",
      "[1.87408783]\n",
      "[1.83572562]\n",
      "[1.8042943]\n",
      "[1.76443722]\n",
      "[1.79329755]\n",
      "tensor([1.8643, 1.8868, 1.8741, 1.8357, 1.8043, 1.7644, 1.7933],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82006568]\n",
      "[1.89377723]\n",
      "[1.77599717]\n",
      "[1.8488171]\n",
      "[1.83853605]\n",
      "[1.81927956]\n",
      "[1.89321375]\n",
      "tensor([1.8201, 1.8938, 1.7760, 1.8488, 1.8385, 1.8193, 1.8932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95839785]\n",
      "[1.79242684]\n",
      "[1.89903654]\n",
      "[1.84299684]\n",
      "[1.75443709]\n",
      "[1.81194416]\n",
      "[1.95399321]\n",
      "tensor([1.9584, 1.7924, 1.8990, 1.8430, 1.7544, 1.8119, 1.9540],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79258046]\n",
      "[1.73876432]\n",
      "[1.913016]\n",
      "[1.81405402]\n",
      "[1.88399602]\n",
      "[1.86911057]\n",
      "[1.84429086]\n",
      "tensor([1.7926, 1.7388, 1.9130, 1.8141, 1.8840, 1.8691, 1.8443],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82545885]\n",
      "[1.79878076]\n",
      "[1.84190896]\n",
      "[1.88302971]\n",
      "[1.93098627]\n",
      "[1.84387102]\n",
      "[1.74546331]\n",
      "tensor([1.8255, 1.7988, 1.8419, 1.8830, 1.9310, 1.8439, 1.7455],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82098745]\n",
      "[1.81663483]\n",
      "[1.79999998]\n",
      "[1.73815518]\n",
      "[1.79664114]\n",
      "[1.84881194]\n",
      "[1.88669215]\n",
      "tensor([1.8210, 1.8166, 1.8000, 1.7382, 1.7966, 1.8488, 1.8867],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97854856]\n",
      "[1.81593509]\n",
      "[1.89859146]\n",
      "[1.81843581]\n",
      "[1.80022096]\n",
      "[1.84887908]\n",
      "[1.83172832]\n",
      "tensor([1.9785, 1.8159, 1.8986, 1.8184, 1.8002, 1.8489, 1.8317],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98250756]\n",
      "[1.85023416]\n",
      "[1.81387885]\n",
      "[1.7345015]\n",
      "[1.85747135]\n",
      "[1.8168727]\n",
      "[1.82587931]\n",
      "tensor([1.9825, 1.8502, 1.8139, 1.7345, 1.8575, 1.8169, 1.8259],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74430692]\n",
      "[1.84503425]\n",
      "[1.81120872]\n",
      "[1.88145028]\n",
      "[1.90775336]\n",
      "[1.87049769]\n",
      "[1.91157443]\n",
      "tensor([1.7443, 1.8450, 1.8112, 1.8815, 1.9078, 1.8705, 1.9116],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80949877]\n",
      "[1.82912778]\n",
      "[1.82825772]\n",
      "[1.84799765]\n",
      "[1.96627334]\n",
      "[1.8854588]\n",
      "[1.7974267]\n",
      "tensor([1.8095, 1.8291, 1.8283, 1.8480, 1.9663, 1.8855, 1.7974],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84285586]\n",
      "[1.95931334]\n",
      "[1.78720551]\n",
      "[1.77049651]\n",
      "[1.79395453]\n",
      "[1.84212099]\n",
      "[1.86971049]\n",
      "tensor([1.8429, 1.9593, 1.7872, 1.7705, 1.7940, 1.8421, 1.8697],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76509418]\n",
      "[1.83229361]\n",
      "[1.92084434]\n",
      "[1.83845829]\n",
      "[1.84537882]\n",
      "[1.8199927]\n",
      "[1.74093582]\n",
      "tensor([1.7651, 1.8323, 1.9208, 1.8385, 1.8454, 1.8200, 1.7409],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92221556]\n",
      "[1.80088141]\n",
      "[1.95203024]\n",
      "[1.95034255]\n",
      "[1.79639766]\n",
      "[1.73947876]\n",
      "[1.74405071]\n",
      "tensor([1.9222, 1.8009, 1.9520, 1.9503, 1.7964, 1.7395, 1.7441],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92546692]\n",
      "[1.83213899]\n",
      "[1.88602485]\n",
      "[1.81889803]\n",
      "[1.88984556]\n",
      "[1.81028954]\n",
      "[1.80516368]\n",
      "tensor([1.9255, 1.8321, 1.8860, 1.8189, 1.8898, 1.8103, 1.8052],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84006426]\n",
      "[1.81202513]\n",
      "[1.79026331]\n",
      "[1.81752656]\n",
      "[1.853072]\n",
      "[1.80013977]\n",
      "[1.80006896]\n",
      "tensor([1.8401, 1.8120, 1.7903, 1.8175, 1.8531, 1.8001, 1.8001],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90504011]\n",
      "[1.79165173]\n",
      "[1.74851556]\n",
      "[1.88090024]\n",
      "[1.87723106]\n",
      "[1.92566326]\n",
      "[1.79039704]\n",
      "tensor([1.9050, 1.7917, 1.7485, 1.8809, 1.8772, 1.9257, 1.7904],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83625878]\n",
      "[1.84329407]\n",
      "[1.86971458]\n",
      "[1.84276962]\n",
      "[1.94471591]\n",
      "[1.71645631]\n",
      "[1.79728233]\n",
      "tensor([1.8363, 1.8433, 1.8697, 1.8428, 1.9447, 1.7165, 1.7973],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79232039]\n",
      "[1.83026453]\n",
      "[1.822525]\n",
      "[1.84893408]\n",
      "[1.73945628]\n",
      "[1.81931375]\n",
      "[1.71451647]\n",
      "tensor([1.7923, 1.8303, 1.8225, 1.8489, 1.7395, 1.8193, 1.7145],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91790824]\n",
      "[1.87864584]\n",
      "[1.85527222]\n",
      "[1.8131378]\n",
      "[1.95039791]\n",
      "[1.80707636]\n",
      "[1.75976357]\n",
      "tensor([1.9179, 1.8786, 1.8553, 1.8131, 1.9504, 1.8071, 1.7598],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82676071]\n",
      "[1.74887851]\n",
      "[1.88209106]\n",
      "[1.75414891]\n",
      "[1.84895732]\n",
      "[1.76080579]\n",
      "[1.84501806]\n",
      "tensor([1.8268, 1.7489, 1.8821, 1.7541, 1.8490, 1.7608, 1.8450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80960314]\n",
      "[1.86343412]\n",
      "[1.83317843]\n",
      "[1.77535527]\n",
      "[1.82446818]\n",
      "[1.87713932]\n",
      "[1.8383939]\n",
      "tensor([1.8096, 1.8634, 1.8332, 1.7754, 1.8245, 1.8771, 1.8384],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8154487]\n",
      "[1.79567357]\n",
      "[1.86735094]\n",
      "[1.90577156]\n",
      "[1.90010954]\n",
      "[1.81877822]\n",
      "[1.849183]\n",
      "tensor([1.8154, 1.7957, 1.8674, 1.9058, 1.9001, 1.8188, 1.8492],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9717539]\n",
      "[1.83694164]\n",
      "[1.81329052]\n",
      "[1.82847218]\n",
      "[1.72260447]\n",
      "[1.84502998]\n",
      "[1.77892813]\n",
      "tensor([1.9718, 1.8369, 1.8133, 1.8285, 1.7226, 1.8450, 1.7789],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86838291]\n",
      "[1.87729412]\n",
      "[1.7740194]\n",
      "[1.88459293]\n",
      "[1.89687065]\n",
      "[1.81924407]\n",
      "[1.79224573]\n",
      "tensor([1.8684, 1.8773, 1.7740, 1.8846, 1.8969, 1.8192, 1.7922],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89853919]\n",
      "[1.87401218]\n",
      "[1.8194579]\n",
      "[1.81657641]\n",
      "[1.76123496]\n",
      "[1.7398391]\n",
      "[1.86723394]\n",
      "tensor([1.8985, 1.8740, 1.8195, 1.8166, 1.7612, 1.7398, 1.8672],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92548955]\n",
      "[1.8407567]\n",
      "[1.81317674]\n",
      "[1.80153546]\n",
      "[1.88690814]\n",
      "[1.81162901]\n",
      "[1.78926873]\n",
      "tensor([1.9255, 1.8408, 1.8132, 1.8015, 1.8869, 1.8116, 1.7893],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88569491]\n",
      "[1.89817453]\n",
      "[1.85286627]\n",
      "[1.80005741]\n",
      "[1.92142354]\n",
      "[1.90212834]\n",
      "[1.73602614]\n",
      "tensor([1.8857, 1.8982, 1.8529, 1.8001, 1.9214, 1.9021, 1.7360],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77508898]\n",
      "[1.84734363]\n",
      "[1.82877616]\n",
      "[1.8131602]\n",
      "[1.90998507]\n",
      "[1.86307968]\n",
      "[1.88021545]\n",
      "tensor([1.7751, 1.8473, 1.8288, 1.8132, 1.9100, 1.8631, 1.8802],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80402933]\n",
      "[1.90242536]\n",
      "[1.84188541]\n",
      "[1.99002259]\n",
      "[1.86683887]\n",
      "[1.75033102]\n",
      "[1.85336082]\n",
      "tensor([1.8040, 1.9024, 1.8419, 1.9900, 1.8668, 1.7503, 1.8534],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75135978]\n",
      "[1.79325011]\n",
      "[1.94717849]\n",
      "[1.92071928]\n",
      "[1.86000611]\n",
      "[1.81580896]\n",
      "[1.93153989]\n",
      "tensor([1.7514, 1.7933, 1.9472, 1.9207, 1.8600, 1.8158, 1.9315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79693321]\n",
      "[1.86878698]\n",
      "[1.86453782]\n",
      "[1.83973708]\n",
      "[1.85130039]\n",
      "[1.82500981]\n",
      "[1.81181442]\n",
      "tensor([1.7969, 1.8688, 1.8645, 1.8397, 1.8513, 1.8250, 1.8118],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78800413]\n",
      "[1.84200839]\n",
      "[1.82446452]\n",
      "[1.84334706]\n",
      "[1.73736566]\n",
      "[1.84307803]\n",
      "[1.80574924]\n",
      "tensor([1.7880, 1.8420, 1.8245, 1.8433, 1.7374, 1.8431, 1.8057],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98407586]\n",
      "[1.85554196]\n",
      "[1.82570474]\n",
      "[1.84050931]\n",
      "[1.91183863]\n",
      "[1.91456446]\n",
      "[1.81077655]\n",
      "tensor([1.9841, 1.8555, 1.8257, 1.8405, 1.9118, 1.9146, 1.8108],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83805444]\n",
      "[1.82028841]\n",
      "[1.87361678]\n",
      "[1.87653458]\n",
      "[1.80286477]\n",
      "[1.86702097]\n",
      "[1.77129728]\n",
      "tensor([1.8381, 1.8203, 1.8736, 1.8765, 1.8029, 1.8670, 1.7713],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84771346]\n",
      "[1.79382132]\n",
      "[1.83682957]\n",
      "[1.87940361]\n",
      "[1.77200027]\n",
      "[1.77520121]\n",
      "[1.81587288]\n",
      "tensor([1.8477, 1.7938, 1.8368, 1.8794, 1.7720, 1.7752, 1.8159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79669219]\n",
      "[1.89208898]\n",
      "[1.80186619]\n",
      "[1.83329278]\n",
      "[1.79774882]\n",
      "[1.87299623]\n",
      "[1.98638098]\n",
      "tensor([1.7967, 1.8921, 1.8019, 1.8333, 1.7977, 1.8730, 1.9864],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84252678]\n",
      "[1.76601979]\n",
      "[1.81466364]\n",
      "[1.71855724]\n",
      "[1.93189324]\n",
      "[1.87359976]\n",
      "[1.77159812]\n",
      "tensor([1.8425, 1.7660, 1.8147, 1.7186, 1.9319, 1.8736, 1.7716],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84811221]\n",
      "[1.82036846]\n",
      "[1.81805896]\n",
      "[1.86805508]\n",
      "[1.86317422]\n",
      "[1.74441221]\n",
      "[1.92399787]\n",
      "tensor([1.8481, 1.8204, 1.8181, 1.8681, 1.8632, 1.7444, 1.9240],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84233201]\n",
      "[1.9263183]\n",
      "[1.83572869]\n",
      "[1.80560462]\n",
      "[1.87787582]\n",
      "[1.77303547]\n",
      "[1.81481089]\n",
      "tensor([1.8423, 1.9263, 1.8357, 1.8056, 1.8779, 1.7730, 1.8148],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86644962]\n",
      "[1.87895164]\n",
      "[1.83728473]\n",
      "[1.80467558]\n",
      "[1.84111848]\n",
      "[1.8141633]\n",
      "[1.78651234]\n",
      "tensor([1.8664, 1.8790, 1.8373, 1.8047, 1.8411, 1.8142, 1.7865],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86091698]\n",
      "[1.76218135]\n",
      "[1.96119459]\n",
      "[1.8840502]\n",
      "[1.91383684]\n",
      "[1.8740592]\n",
      "[1.81605606]\n",
      "tensor([1.8609, 1.7622, 1.9612, 1.8841, 1.9138, 1.8741, 1.8161],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72582641]\n",
      "[1.75753875]\n",
      "[1.87706432]\n",
      "[1.75814914]\n",
      "[1.8155789]\n",
      "[1.79631429]\n",
      "[1.91606222]\n",
      "tensor([1.7258, 1.7575, 1.8771, 1.7581, 1.8156, 1.7963, 1.9161],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75986122]\n",
      "[1.87671268]\n",
      "[1.81833204]\n",
      "[1.791024]\n",
      "[1.81692529]\n",
      "[1.85163625]\n",
      "[1.83112653]\n",
      "tensor([1.7599, 1.8767, 1.8183, 1.7910, 1.8169, 1.8516, 1.8311],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84595752]\n",
      "[1.81202893]\n",
      "[1.84037461]\n",
      "[1.8524245]\n",
      "[1.92222726]\n",
      "[1.84766816]\n",
      "[1.90942911]\n",
      "tensor([1.8460, 1.8120, 1.8404, 1.8524, 1.9222, 1.8477, 1.9094],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81538979]\n",
      "[1.80496969]\n",
      "[1.84323928]\n",
      "[1.71378373]\n",
      "[1.96293902]\n",
      "[1.85801799]\n",
      "[1.80486804]\n",
      "tensor([1.8154, 1.8050, 1.8432, 1.7138, 1.9629, 1.8580, 1.8049],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81246968]\n",
      "[1.88876964]\n",
      "[1.82190201]\n",
      "[1.83913406]\n",
      "[1.75881572]\n",
      "[1.82171617]\n",
      "[1.80214562]\n",
      "tensor([1.8125, 1.8888, 1.8219, 1.8391, 1.7588, 1.8217, 1.8021],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80084291]\n",
      "[1.85747744]\n",
      "[1.81947764]\n",
      "[1.81701437]\n",
      "[1.87634631]\n",
      "[1.71445284]\n",
      "[1.80619588]\n",
      "tensor([1.8008, 1.8575, 1.8195, 1.8170, 1.8763, 1.7145, 1.8062],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8221999]\n",
      "[1.75970519]\n",
      "[1.81888475]\n",
      "[1.84609358]\n",
      "[1.81457162]\n",
      "[1.89799551]\n",
      "[1.796655]\n",
      "tensor([1.8222, 1.7597, 1.8189, 1.8461, 1.8146, 1.8980, 1.7967],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83499438]\n",
      "[1.83818153]\n",
      "[1.82015378]\n",
      "[1.84083825]\n",
      "[1.80979542]\n",
      "[1.80594561]\n",
      "[1.92178253]\n",
      "tensor([1.8350, 1.8382, 1.8202, 1.8408, 1.8098, 1.8059, 1.9218],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83672255]\n",
      "[1.83038451]\n",
      "[1.86680117]\n",
      "[1.71140057]\n",
      "[1.83043023]\n",
      "[1.76990015]\n",
      "[1.89477089]\n",
      "tensor([1.8367, 1.8304, 1.8668, 1.7114, 1.8304, 1.7699, 1.8948],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83827096]\n",
      "[1.79975039]\n",
      "[1.77000098]\n",
      "[1.87190388]\n",
      "[1.74481297]\n",
      "[1.69984477]\n",
      "[1.91693755]\n",
      "tensor([1.8383, 1.7998, 1.7700, 1.8719, 1.7448, 1.6998, 1.9169],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78516784]\n",
      "[1.82228651]\n",
      "[1.8479551]\n",
      "[1.75229459]\n",
      "[1.94151433]\n",
      "[1.82625778]\n",
      "[1.8298207]\n",
      "tensor([1.7852, 1.8223, 1.8480, 1.7523, 1.9415, 1.8263, 1.8298],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8792931]\n",
      "[1.76101229]\n",
      "[1.79869105]\n",
      "[1.83200221]\n",
      "[1.72089111]\n",
      "[1.85563944]\n",
      "[1.88908533]\n",
      "tensor([1.8793, 1.7610, 1.7987, 1.8320, 1.7209, 1.8556, 1.8891],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80455793]\n",
      "[1.87802357]\n",
      "[1.94739194]\n",
      "[1.77816172]\n",
      "[1.78734314]\n",
      "[1.94778537]\n",
      "[1.7474054]\n",
      "tensor([1.8046, 1.8780, 1.9474, 1.7782, 1.7873, 1.9478, 1.7474],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77442071]\n",
      "[1.81326403]\n",
      "[1.84545169]\n",
      "[1.88022512]\n",
      "[1.77069098]\n",
      "[1.81142417]\n",
      "[1.85582722]\n",
      "tensor([1.7744, 1.8133, 1.8455, 1.8802, 1.7707, 1.8114, 1.8558],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80496607]\n",
      "[1.83992869]\n",
      "[1.83866753]\n",
      "[1.86937872]\n",
      "[1.78573901]\n",
      "[1.84176576]\n",
      "[1.8555169]\n",
      "tensor([1.8050, 1.8399, 1.8387, 1.8694, 1.7857, 1.8418, 1.8555],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82311513]\n",
      "[1.79316593]\n",
      "[1.8011189]\n",
      "[1.98016355]\n",
      "[1.976022]\n",
      "[1.83966087]\n",
      "[1.84647831]\n",
      "tensor([1.8231, 1.7932, 1.8011, 1.9802, 1.9760, 1.8397, 1.8465],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80053592]\n",
      "[1.96825705]\n",
      "[2.06304047]\n",
      "[1.92197858]\n",
      "[1.80260405]\n",
      "[1.91781153]\n",
      "[1.83799778]\n",
      "tensor([1.8005, 1.9683, 2.0630, 1.9220, 1.8026, 1.9178, 1.8380],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8526504]\n",
      "[1.90280365]\n",
      "[1.83385645]\n",
      "[1.86460872]\n",
      "[1.86806268]\n",
      "[1.83775416]\n",
      "[1.86804452]\n",
      "tensor([1.8527, 1.9028, 1.8339, 1.8646, 1.8681, 1.8378, 1.8680],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81653685]\n",
      "[1.81331626]\n",
      "[1.88710921]\n",
      "[1.83165183]\n",
      "[1.8247802]\n",
      "[1.95180897]\n",
      "[1.77232442]\n",
      "tensor([1.8165, 1.8133, 1.8871, 1.8317, 1.8248, 1.9518, 1.7723],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78278753]\n",
      "[1.80002539]\n",
      "[1.84223248]\n",
      "[1.7550292]\n",
      "[1.8860686]\n",
      "[1.84972664]\n",
      "[1.88815334]\n",
      "tensor([1.7828, 1.8000, 1.8422, 1.7550, 1.8861, 1.8497, 1.8882],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77109779]\n",
      "[1.83733867]\n",
      "[1.98777252]\n",
      "[1.81591721]\n",
      "[1.81492295]\n",
      "[1.79311393]\n",
      "[1.7769006]\n",
      "tensor([1.7711, 1.8373, 1.9878, 1.8159, 1.8149, 1.7931, 1.7769],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81809596]\n",
      "[1.7955695]\n",
      "[1.86525114]\n",
      "[1.7933695]\n",
      "[1.88403537]\n",
      "[1.83951012]\n",
      "[1.87820165]\n",
      "tensor([1.8181, 1.7956, 1.8653, 1.7934, 1.8840, 1.8395, 1.8782],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91689368]\n",
      "[1.85102037]\n",
      "[1.8520653]\n",
      "[1.91644149]\n",
      "[1.8437037]\n",
      "[1.84159797]\n",
      "[1.88391684]\n",
      "tensor([1.9169, 1.8510, 1.8521, 1.9164, 1.8437, 1.8416, 1.8839],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95681829]\n",
      "[1.96566424]\n",
      "[1.82991096]\n",
      "[1.92342552]\n",
      "[1.90312495]\n",
      "[1.83078009]\n",
      "[1.77160428]\n",
      "tensor([1.9568, 1.9657, 1.8299, 1.9234, 1.9031, 1.8308, 1.7716],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86708579]\n",
      "[1.73986912]\n",
      "[1.9084761]\n",
      "[1.82450079]\n",
      "[1.83135804]\n",
      "[1.81162421]\n",
      "[1.7860741]\n",
      "tensor([1.8671, 1.7399, 1.9085, 1.8245, 1.8314, 1.8116, 1.7861],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81700258]\n",
      "[1.9132751]\n",
      "[1.73281684]\n",
      "[1.81260971]\n",
      "[1.78724532]\n",
      "[1.89151464]\n",
      "[1.85130976]\n",
      "tensor([1.8170, 1.9133, 1.7328, 1.8126, 1.7872, 1.8915, 1.8513],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81481057]\n",
      "[1.70990649]\n",
      "[1.81946289]\n",
      "[1.7367004]\n",
      "[1.94994313]\n",
      "[1.77043103]\n",
      "[1.89185612]\n",
      "tensor([1.8148, 1.7099, 1.8195, 1.7367, 1.9499, 1.7704, 1.8919],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73187514]\n",
      "[1.85259417]\n",
      "[1.77119408]\n",
      "[1.92417788]\n",
      "[1.81970947]\n",
      "[1.74138237]\n",
      "[1.89029023]\n",
      "tensor([1.7319, 1.8526, 1.7712, 1.9242, 1.8197, 1.7414, 1.8903],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80962041]\n",
      "[1.84689698]\n",
      "[1.85425814]\n",
      "[1.84494942]\n",
      "[1.86242723]\n",
      "[1.81152596]\n",
      "[1.89648679]\n",
      "tensor([1.8096, 1.8469, 1.8543, 1.8449, 1.8624, 1.8115, 1.8965],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80850314]\n",
      "[1.92115144]\n",
      "[1.9125737]\n",
      "[1.79889458]\n",
      "[1.70359897]\n",
      "[1.81120282]\n",
      "[1.84380841]\n",
      "tensor([1.8085, 1.9212, 1.9126, 1.7989, 1.7036, 1.8112, 1.8438],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91367647]\n",
      "[1.94851736]\n",
      "[1.82414692]\n",
      "[1.83222167]\n",
      "[1.84864523]\n",
      "[1.79522828]\n",
      "[1.94071782]\n",
      "tensor([1.9137, 1.9485, 1.8241, 1.8322, 1.8486, 1.7952, 1.9407],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88045852]\n",
      "[1.76312656]\n",
      "[1.85497357]\n",
      "[1.88477575]\n",
      "[1.85147287]\n",
      "[1.8206066]\n",
      "[1.81864182]\n",
      "tensor([1.8805, 1.7631, 1.8550, 1.8848, 1.8515, 1.8206, 1.8186],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79525787]\n",
      "[1.760164]\n",
      "[1.78774241]\n",
      "[1.92334407]\n",
      "[1.74801664]\n",
      "[1.87709376]\n",
      "[1.9189245]\n",
      "tensor([1.7953, 1.7602, 1.7877, 1.9233, 1.7480, 1.8771, 1.9189],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85050299]\n",
      "[2.00262734]\n",
      "[1.92544408]\n",
      "[1.86261641]\n",
      "[1.83780246]\n",
      "[1.83031147]\n",
      "[1.78831328]\n",
      "tensor([1.8505, 2.0026, 1.9254, 1.8626, 1.8378, 1.8303, 1.7883],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83480332]\n",
      "[1.88195233]\n",
      "[1.88475322]\n",
      "[1.9885106]\n",
      "[1.79788457]\n",
      "[1.8866577]\n",
      "[1.84042801]\n",
      "tensor([1.8348, 1.8820, 1.8848, 1.9885, 1.7979, 1.8867, 1.8404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85159199]\n",
      "[1.85139819]\n",
      "[1.69981464]\n",
      "[1.80457695]\n",
      "[1.89565038]\n",
      "[1.82519211]\n",
      "[1.90752178]\n",
      "tensor([1.8516, 1.8514, 1.6998, 1.8046, 1.8957, 1.8252, 1.9075],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89349043]\n",
      "[1.77207392]\n",
      "[1.73551511]\n",
      "[1.70170727]\n",
      "[1.83285969]\n",
      "[1.85368379]\n",
      "[1.74848007]\n",
      "tensor([1.8935, 1.7721, 1.7355, 1.7017, 1.8329, 1.8537, 1.7485],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86140213]\n",
      "[1.83557095]\n",
      "[1.74654118]\n",
      "[1.91782561]\n",
      "[1.86901909]\n",
      "[1.75675129]\n",
      "[1.8422533]\n",
      "tensor([1.8614, 1.8356, 1.7465, 1.9178, 1.8690, 1.7568, 1.8423],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95327927]\n",
      "[1.85648188]\n",
      "[1.8331928]\n",
      "[1.88382449]\n",
      "[1.89482531]\n",
      "[1.94809837]\n",
      "[1.75975906]\n",
      "tensor([1.9533, 1.8565, 1.8332, 1.8838, 1.8948, 1.9481, 1.7598],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95384359]\n",
      "[1.90261203]\n",
      "[1.850459]\n",
      "[1.85471116]\n",
      "[1.87670805]\n",
      "[1.82480425]\n",
      "[1.75769253]\n",
      "tensor([1.9538, 1.9026, 1.8505, 1.8547, 1.8767, 1.8248, 1.7577],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75407002]\n",
      "[1.75343296]\n",
      "[1.84927197]\n",
      "[1.85079606]\n",
      "[1.89403086]\n",
      "[2.07278907]\n",
      "[1.91125655]\n",
      "tensor([1.7541, 1.7534, 1.8493, 1.8508, 1.8940, 2.0728, 1.9113],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78510043]\n",
      "[1.89601827]\n",
      "[1.85226834]\n",
      "[1.8424688]\n",
      "[1.74551879]\n",
      "[1.74137204]\n",
      "[1.81792215]\n",
      "tensor([1.7851, 1.8960, 1.8523, 1.8425, 1.7455, 1.7414, 1.8179],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76114298]\n",
      "[1.87530367]\n",
      "[1.77186797]\n",
      "[1.82063486]\n",
      "[1.84981989]\n",
      "[1.8186466]\n",
      "[1.8451834]\n",
      "tensor([1.7611, 1.8753, 1.7719, 1.8206, 1.8498, 1.8186, 1.8452],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7401705]\n",
      "[1.91558704]\n",
      "[1.85719904]\n",
      "[1.90742055]\n",
      "[1.83584572]\n",
      "[1.93665975]\n",
      "[1.83152688]\n",
      "tensor([1.7402, 1.9156, 1.8572, 1.9074, 1.8358, 1.9367, 1.8315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77619771]\n",
      "[1.79967207]\n",
      "[1.80131709]\n",
      "[1.81551687]\n",
      "[1.91118698]\n",
      "[1.84201226]\n",
      "[1.80304428]\n",
      "tensor([1.7762, 1.7997, 1.8013, 1.8155, 1.9112, 1.8420, 1.8030],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8706255]\n",
      "[1.80665965]\n",
      "[1.84125309]\n",
      "[1.9046284]\n",
      "[1.88849371]\n",
      "[1.76945347]\n",
      "[1.87183757]\n",
      "tensor([1.8706, 1.8067, 1.8413, 1.9046, 1.8885, 1.7695, 1.8718],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84108443]\n",
      "[1.87610869]\n",
      "[1.81405315]\n",
      "[1.98247163]\n",
      "[1.7777606]\n",
      "[1.83511539]\n",
      "[1.73820544]\n",
      "tensor([1.8411, 1.8761, 1.8141, 1.9825, 1.7778, 1.8351, 1.7382],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71892421]\n",
      "[1.80505146]\n",
      "[1.86788133]\n",
      "[1.81472839]\n",
      "[1.81955171]\n",
      "[1.88196428]\n",
      "[1.82437466]\n",
      "tensor([1.7189, 1.8051, 1.8679, 1.8147, 1.8196, 1.8820, 1.8244],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77623461]\n",
      "[1.76211916]\n",
      "[1.83106242]\n",
      "[1.81705301]\n",
      "[1.79650694]\n",
      "[1.80375765]\n",
      "[1.86171066]\n",
      "tensor([1.7762, 1.7621, 1.8311, 1.8171, 1.7965, 1.8038, 1.8617],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81332039]\n",
      "[1.85427676]\n",
      "[1.7800432]\n",
      "[1.79962222]\n",
      "[1.78814356]\n",
      "[1.84344607]\n",
      "[1.80403795]\n",
      "tensor([1.8133, 1.8543, 1.7800, 1.7996, 1.7881, 1.8434, 1.8040],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81940062]\n",
      "[1.73930086]\n",
      "[1.9151042]\n",
      "[1.92902081]\n",
      "[1.79176382]\n",
      "[1.92345927]\n",
      "[1.69317269]\n",
      "tensor([1.8194, 1.7393, 1.9151, 1.9290, 1.7918, 1.9235, 1.6932],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79889553]\n",
      "[1.8454379]\n",
      "[1.82784567]\n",
      "[1.91943811]\n",
      "[1.84352594]\n",
      "[1.86430809]\n",
      "[1.8487352]\n",
      "tensor([1.7989, 1.8454, 1.8278, 1.9194, 1.8435, 1.8643, 1.8487],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79304417]\n",
      "[1.83645447]\n",
      "[1.98530821]\n",
      "[1.79427881]\n",
      "[1.7869047]\n",
      "[1.82296275]\n",
      "[1.8453699]\n",
      "tensor([1.7930, 1.8365, 1.9853, 1.7943, 1.7869, 1.8230, 1.8454],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80040994]\n",
      "[1.77907822]\n",
      "[1.92978356]\n",
      "[1.92095053]\n",
      "[1.926232]\n",
      "[1.79886736]\n",
      "[1.84333658]\n",
      "tensor([1.8004, 1.7791, 1.9298, 1.9210, 1.9262, 1.7989, 1.8433],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87269492]\n",
      "[1.87815322]\n",
      "[1.85821016]\n",
      "[1.88620755]\n",
      "[1.79731153]\n",
      "[1.83947884]\n",
      "[1.79109063]\n",
      "tensor([1.8727, 1.8782, 1.8582, 1.8862, 1.7973, 1.8395, 1.7911],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98037094]\n",
      "[1.82948368]\n",
      "[1.7250477]\n",
      "[1.81363536]\n",
      "[1.85630891]\n",
      "[1.78475406]\n",
      "[1.85119987]\n",
      "tensor([1.9804, 1.8295, 1.7250, 1.8136, 1.8563, 1.7848, 1.8512],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78246563]\n",
      "[1.78761976]\n",
      "[1.81901888]\n",
      "[1.82226734]\n",
      "[1.76002713]\n",
      "[1.93388675]\n",
      "[1.85598655]\n",
      "tensor([1.7825, 1.7876, 1.8190, 1.8223, 1.7600, 1.9339, 1.8560],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97857248]\n",
      "[1.76831915]\n",
      "[1.79618056]\n",
      "[1.95032715]\n",
      "[1.93041985]\n",
      "[1.78866836]\n",
      "[1.81720414]\n",
      "tensor([1.9786, 1.7683, 1.7962, 1.9503, 1.9304, 1.7887, 1.8172],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91292598]\n",
      "[1.84703069]\n",
      "[1.80871139]\n",
      "[1.81837896]\n",
      "[1.85318787]\n",
      "[1.80467914]\n",
      "[1.85392591]\n",
      "tensor([1.9129, 1.8470, 1.8087, 1.8184, 1.8532, 1.8047, 1.8539],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89399744]\n",
      "[1.73663958]\n",
      "[1.85837487]\n",
      "[1.85617576]\n",
      "[1.76678972]\n",
      "[1.80078414]\n",
      "[1.81474648]\n",
      "tensor([1.8940, 1.7366, 1.8584, 1.8562, 1.7668, 1.8008, 1.8147],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88560974]\n",
      "[1.92438647]\n",
      "[1.83637301]\n",
      "[1.81630508]\n",
      "[1.97576866]\n",
      "[1.87467417]\n",
      "[1.77291659]\n",
      "tensor([1.8856, 1.9244, 1.8364, 1.8163, 1.9758, 1.8747, 1.7729],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81676111]\n",
      "[1.85012012]\n",
      "[1.92607273]\n",
      "[1.97976241]\n",
      "[1.80804306]\n",
      "[1.83946487]\n",
      "[1.83092729]\n",
      "tensor([1.8168, 1.8501, 1.9261, 1.9798, 1.8080, 1.8395, 1.8309],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82395207]\n",
      "[1.79623305]\n",
      "[1.82367243]\n",
      "[1.90860733]\n",
      "[1.78621655]\n",
      "[1.95218316]\n",
      "[1.82736166]\n",
      "tensor([1.8240, 1.7962, 1.8237, 1.9086, 1.7862, 1.9522, 1.8274],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71726282]\n",
      "[1.78955514]\n",
      "[1.94037489]\n",
      "[1.77765224]\n",
      "[1.8186043]\n",
      "[1.81675374]\n",
      "[1.75777947]\n",
      "tensor([1.7173, 1.7896, 1.9404, 1.7777, 1.8186, 1.8168, 1.7578],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81678095]\n",
      "[1.78461833]\n",
      "[1.88624357]\n",
      "[1.86899621]\n",
      "[1.81763694]\n",
      "[1.77806822]\n",
      "[1.7861439]\n",
      "tensor([1.8168, 1.7846, 1.8862, 1.8690, 1.8176, 1.7781, 1.7861],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86100625]\n",
      "[1.9760331]\n",
      "[1.87833536]\n",
      "[1.78655944]\n",
      "[1.78205258]\n",
      "[1.84698844]\n",
      "[1.96629649]\n",
      "tensor([1.8610, 1.9760, 1.8783, 1.7866, 1.7821, 1.8470, 1.9663],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76810726]\n",
      "[1.94041207]\n",
      "[1.84009371]\n",
      "[1.81683311]\n",
      "[1.83189754]\n",
      "[1.81806636]\n",
      "[1.8090286]\n",
      "tensor([1.7681, 1.9404, 1.8401, 1.8168, 1.8319, 1.8181, 1.8090],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.902341]\n",
      "[1.69366539]\n",
      "[1.79577019]\n",
      "[1.88932002]\n",
      "[1.75607393]\n",
      "[1.82680112]\n",
      "[1.85764781]\n",
      "tensor([1.9023, 1.6937, 1.7958, 1.8893, 1.7561, 1.8268, 1.8576],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.98443681]\n",
      "[1.81606722]\n",
      "[1.85050362]\n",
      "[1.85337643]\n",
      "[1.80154833]\n",
      "[1.90598952]\n",
      "[1.80668441]\n",
      "tensor([1.9844, 1.8161, 1.8505, 1.8534, 1.8015, 1.9060, 1.8067],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79247085]\n",
      "[1.90942359]\n",
      "[1.7399808]\n",
      "[1.83627387]\n",
      "[1.90944677]\n",
      "[1.87498344]\n",
      "[1.83415147]\n",
      "tensor([1.7925, 1.9094, 1.7400, 1.8363, 1.9094, 1.8750, 1.8342],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82892036]\n",
      "[1.87417858]\n",
      "[1.76265309]\n",
      "[1.77005679]\n",
      "[1.78077394]\n",
      "[1.7605785]\n",
      "[1.78519772]\n",
      "tensor([1.8289, 1.8742, 1.7627, 1.7701, 1.7808, 1.7606, 1.7852],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87697996]\n",
      "[1.80480285]\n",
      "[1.86766227]\n",
      "[1.81929052]\n",
      "[1.83035855]\n",
      "[1.88672792]\n",
      "[1.98514969]\n",
      "tensor([1.8770, 1.8048, 1.8677, 1.8193, 1.8304, 1.8867, 1.9851],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83700611]\n",
      "[1.8162203]\n",
      "[1.70983241]\n",
      "[1.88281954]\n",
      "[1.81171053]\n",
      "[1.87171856]\n",
      "[1.89018419]\n",
      "tensor([1.8370, 1.8162, 1.7098, 1.8828, 1.8117, 1.8717, 1.8902],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80151919]\n",
      "[1.80475075]\n",
      "[1.8219732]\n",
      "[1.79844657]\n",
      "[1.75646883]\n",
      "[2.0667275]\n",
      "[1.78716244]\n",
      "tensor([1.8015, 1.8048, 1.8220, 1.7984, 1.7565, 2.0667, 1.7872],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79145959]\n",
      "[1.94571111]\n",
      "[1.86532209]\n",
      "[1.8655218]\n",
      "[1.79059503]\n",
      "[1.80062016]\n",
      "[1.81048051]\n",
      "tensor([1.7915, 1.9457, 1.8653, 1.8655, 1.7906, 1.8006, 1.8105],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92836895]\n",
      "[1.8861925]\n",
      "[1.8856794]\n",
      "[1.82492973]\n",
      "[1.84310768]\n",
      "[1.95112889]\n",
      "[1.83844594]\n",
      "tensor([1.9284, 1.8862, 1.8857, 1.8249, 1.8431, 1.9511, 1.8384],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79382168]\n",
      "[1.92729104]\n",
      "[1.89020252]\n",
      "[1.88461171]\n",
      "[1.74169013]\n",
      "[1.81431586]\n",
      "[1.76627895]\n",
      "tensor([1.7938, 1.9273, 1.8902, 1.8846, 1.7417, 1.8143, 1.7663],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87634002]\n",
      "[1.82235032]\n",
      "[1.85312863]\n",
      "[1.82128958]\n",
      "[1.7529689]\n",
      "[1.82539852]\n",
      "[1.83293072]\n",
      "tensor([1.8763, 1.8224, 1.8531, 1.8213, 1.7530, 1.8254, 1.8329],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84037351]\n",
      "[1.83305088]\n",
      "[1.9031212]\n",
      "[1.85366576]\n",
      "[1.75893087]\n",
      "[1.88409836]\n",
      "[1.9317208]\n",
      "tensor([1.8404, 1.8331, 1.9031, 1.8537, 1.7589, 1.8841, 1.9317],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78837211]\n",
      "[1.87903172]\n",
      "[1.84966433]\n",
      "[1.83897845]\n",
      "[1.73832014]\n",
      "[1.88743822]\n",
      "[1.92340823]\n",
      "tensor([1.7884, 1.8790, 1.8497, 1.8390, 1.7383, 1.8874, 1.9234],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8405292]\n",
      "[1.83721666]\n",
      "[1.89019629]\n",
      "[1.77195436]\n",
      "[1.8530435]\n",
      "[1.83133084]\n",
      "[1.80477684]\n",
      "tensor([1.8405, 1.8372, 1.8902, 1.7720, 1.8530, 1.8313, 1.8048],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82889779]\n",
      "[1.90126497]\n",
      "[1.81346536]\n",
      "[1.79641508]\n",
      "[1.8724376]\n",
      "[1.92428552]\n",
      "[1.79784634]\n",
      "tensor([1.8289, 1.9013, 1.8135, 1.7964, 1.8724, 1.9243, 1.7978],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82667281]\n",
      "[1.8453259]\n",
      "[1.8688399]\n",
      "[1.78225611]\n",
      "[1.84924782]\n",
      "[1.79634409]\n",
      "[1.76077338]\n",
      "tensor([1.8267, 1.8453, 1.8688, 1.7823, 1.8492, 1.7963, 1.7608],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88035632]\n",
      "[1.83345574]\n",
      "[1.84010411]\n",
      "[1.88558897]\n",
      "[1.80732946]\n",
      "[1.88940962]\n",
      "[1.81567656]\n",
      "tensor([1.8804, 1.8335, 1.8401, 1.8856, 1.8073, 1.8894, 1.8157],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72220385]\n",
      "[1.82190851]\n",
      "[1.78459033]\n",
      "[1.85085658]\n",
      "[1.79045097]\n",
      "[1.79741536]\n",
      "[1.7317295]\n",
      "tensor([1.7222, 1.8219, 1.7846, 1.8509, 1.7905, 1.7974, 1.7317],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88385181]\n",
      "[1.78297737]\n",
      "[1.9030102]\n",
      "[1.84974381]\n",
      "[1.8432603]\n",
      "[1.82329126]\n",
      "[1.82662985]\n",
      "tensor([1.8839, 1.7830, 1.9030, 1.8497, 1.8433, 1.8233, 1.8266],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86748328]\n",
      "[1.79265397]\n",
      "[1.79857898]\n",
      "[1.91815345]\n",
      "[1.81078463]\n",
      "[1.76347398]\n",
      "[1.84270301]\n",
      "tensor([1.8675, 1.7927, 1.7986, 1.9182, 1.8108, 1.7635, 1.8427],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74246968]\n",
      "[1.8079521]\n",
      "[1.76002787]\n",
      "[1.86172122]\n",
      "[1.84262567]\n",
      "[1.87749568]\n",
      "[1.8134423]\n",
      "tensor([1.7425, 1.8080, 1.7600, 1.8617, 1.8426, 1.8775, 1.8134],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88116984]\n",
      "[1.74695086]\n",
      "[1.8244834]\n",
      "[1.89384182]\n",
      "[1.89631526]\n",
      "[1.88578578]\n",
      "[1.83261929]\n",
      "tensor([1.8812, 1.7470, 1.8245, 1.8938, 1.8963, 1.8858, 1.8326],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84532413]\n",
      "[1.81199188]\n",
      "[1.8444153]\n",
      "[1.81308225]\n",
      "[1.92499157]\n",
      "[1.80367005]\n",
      "[1.84829987]\n",
      "tensor([1.8453, 1.8120, 1.8444, 1.8131, 1.9250, 1.8037, 1.8483],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88557968]\n",
      "[1.75445446]\n",
      "[1.80625279]\n",
      "[1.70813487]\n",
      "[1.80415155]\n",
      "[1.80916334]\n",
      "[1.83154229]\n",
      "tensor([1.8856, 1.7545, 1.8063, 1.7081, 1.8042, 1.8092, 1.8315],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76770472]\n",
      "[1.76580954]\n",
      "[1.8019995]\n",
      "[1.823506]\n",
      "[1.84125887]\n",
      "[1.8438621]\n",
      "[1.9661758]\n",
      "tensor([1.7677, 1.7658, 1.8020, 1.8235, 1.8413, 1.8439, 1.9662],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84118977]\n",
      "[1.71007115]\n",
      "[1.88532168]\n",
      "[1.83592603]\n",
      "[1.85855102]\n",
      "[1.85580164]\n",
      "[1.82174944]\n",
      "tensor([1.8412, 1.7101, 1.8853, 1.8359, 1.8586, 1.8558, 1.8217],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82274359]\n",
      "[1.8378597]\n",
      "[1.80566556]\n",
      "[1.86426012]\n",
      "[1.84114094]\n",
      "[1.80949147]\n",
      "[1.75851536]\n",
      "tensor([1.8227, 1.8379, 1.8057, 1.8643, 1.8411, 1.8095, 1.7585],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83979697]\n",
      "[1.87925057]\n",
      "[1.79700114]\n",
      "[1.900161]\n",
      "[1.83058845]\n",
      "[1.95058919]\n",
      "[1.78278787]\n",
      "tensor([1.8398, 1.8793, 1.7970, 1.9002, 1.8306, 1.9506, 1.7828],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77294391]\n",
      "[1.8131582]\n",
      "[1.76459878]\n",
      "[1.86468774]\n",
      "[1.75217938]\n",
      "[1.88190893]\n",
      "[1.80147576]\n",
      "tensor([1.7729, 1.8132, 1.7646, 1.8647, 1.7522, 1.8819, 1.8015],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84662188]\n",
      "[1.90818755]\n",
      "[1.81314237]\n",
      "[1.92362604]\n",
      "[1.88557006]\n",
      "[1.84271759]\n",
      "[1.80144824]\n",
      "tensor([1.8466, 1.9082, 1.8131, 1.9236, 1.8856, 1.8427, 1.8014],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83280683]\n",
      "[1.76871637]\n",
      "[1.78982925]\n",
      "[1.92376892]\n",
      "[1.81604227]\n",
      "[1.86395617]\n",
      "[1.87780201]\n",
      "tensor([1.8328, 1.7687, 1.7898, 1.9238, 1.8160, 1.8640, 1.8778],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.829859]\n",
      "[1.91896839]\n",
      "[1.81848195]\n",
      "[1.87222002]\n",
      "[1.88162013]\n",
      "[1.82176258]\n",
      "[1.87813504]\n",
      "tensor([1.8299, 1.9190, 1.8185, 1.8722, 1.8816, 1.8218, 1.8781],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80740311]\n",
      "[1.88126693]\n",
      "[1.87715199]\n",
      "[1.84877508]\n",
      "[1.96609868]\n",
      "[1.92940864]\n",
      "[1.80957452]\n",
      "tensor([1.8074, 1.8813, 1.8772, 1.8488, 1.9661, 1.9294, 1.8096],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87082182]\n",
      "[1.81913876]\n",
      "[1.84583545]\n",
      "[1.79429129]\n",
      "[1.92581978]\n",
      "[1.8185136]\n",
      "[1.8260822]\n",
      "tensor([1.8708, 1.8191, 1.8458, 1.7943, 1.9258, 1.8185, 1.8261],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77908664]\n",
      "[1.78358188]\n",
      "[1.80304958]\n",
      "[1.75497475]\n",
      "[1.69240448]\n",
      "[1.88321453]\n",
      "[1.75764181]\n",
      "tensor([1.7791, 1.7836, 1.8030, 1.7550, 1.6924, 1.8832, 1.7576],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72014956]\n",
      "[1.8319771]\n",
      "[1.87960869]\n",
      "[1.87114178]\n",
      "[1.81200895]\n",
      "[1.83425327]\n",
      "[1.79443073]\n",
      "tensor([1.7201, 1.8320, 1.8796, 1.8711, 1.8120, 1.8343, 1.7944],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80763953]\n",
      "[1.83616316]\n",
      "[1.83154067]\n",
      "[1.8131797]\n",
      "[1.92633927]\n",
      "[1.78034801]\n",
      "[1.90054145]\n",
      "tensor([1.8076, 1.8362, 1.8315, 1.8132, 1.9263, 1.7803, 1.9005],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74213625]\n",
      "[1.91462855]\n",
      "[1.82568996]\n",
      "[1.82594246]\n",
      "[1.80441793]\n",
      "[1.88996025]\n",
      "[1.87505289]\n",
      "tensor([1.7421, 1.9146, 1.8257, 1.8259, 1.8044, 1.8900, 1.8751],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87182032]\n",
      "[1.74427695]\n",
      "[1.77595274]\n",
      "[1.79751994]\n",
      "[1.82383152]\n",
      "[1.74064288]\n",
      "[1.84842257]\n",
      "tensor([1.8718, 1.7443, 1.7760, 1.7975, 1.8238, 1.7406, 1.8484],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82825948]\n",
      "[1.83063656]\n",
      "[1.74716704]\n",
      "[1.80185623]\n",
      "[1.86813642]\n",
      "[1.80653018]\n",
      "[1.91351959]\n",
      "tensor([1.8283, 1.8306, 1.7472, 1.8019, 1.8681, 1.8065, 1.9135],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80951123]\n",
      "[1.89933025]\n",
      "[1.80715466]\n",
      "[1.88229939]\n",
      "[1.76424083]\n",
      "[1.81641265]\n",
      "[1.80577468]\n",
      "tensor([1.8095, 1.8993, 1.8072, 1.8823, 1.7642, 1.8164, 1.8058],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73967251]\n",
      "[1.86364847]\n",
      "[1.81999637]\n",
      "[1.81308133]\n",
      "[1.80605077]\n",
      "[1.81828994]\n",
      "[1.83400214]\n",
      "tensor([1.7397, 1.8636, 1.8200, 1.8131, 1.8061, 1.8183, 1.8340],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8314765]\n",
      "[1.86384003]\n",
      "[1.79591768]\n",
      "[1.94916664]\n",
      "[1.94474806]\n",
      "[1.82936074]\n",
      "[1.84656302]\n",
      "tensor([1.8315, 1.8638, 1.7959, 1.9492, 1.9447, 1.8294, 1.8466],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87343885]\n",
      "[1.88991026]\n",
      "[1.82256141]\n",
      "[1.84139332]\n",
      "[1.97510219]\n",
      "[1.68757349]\n",
      "[1.7979477]\n",
      "tensor([1.8734, 1.8899, 1.8226, 1.8414, 1.9751, 1.6876, 1.7979],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86718189]\n",
      "[1.82967222]\n",
      "[1.89030302]\n",
      "[1.86921339]\n",
      "[1.84482706]\n",
      "[1.80386164]\n",
      "[1.84812486]\n",
      "tensor([1.8672, 1.8297, 1.8903, 1.8692, 1.8448, 1.8039, 1.8481],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82855986]\n",
      "[1.81341233]\n",
      "[1.8180463]\n",
      "[1.84066399]\n",
      "[1.76584682]\n",
      "[1.88901896]\n",
      "[1.80284934]\n",
      "tensor([1.8286, 1.8134, 1.8180, 1.8407, 1.7658, 1.8890, 1.8028],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86936774]\n",
      "[1.87047772]\n",
      "[1.74294938]\n",
      "[1.83425599]\n",
      "[1.88037311]\n",
      "[1.81535048]\n",
      "[1.85309575]\n",
      "tensor([1.8694, 1.8705, 1.7429, 1.8343, 1.8804, 1.8154, 1.8531],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8095061]\n",
      "[1.91572452]\n",
      "[1.78584684]\n",
      "[1.90015337]\n",
      "[1.78022525]\n",
      "[1.79420976]\n",
      "[1.75652967]\n",
      "tensor([1.8095, 1.9157, 1.7858, 1.9002, 1.7802, 1.7942, 1.7565],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88609203]\n",
      "[1.94069424]\n",
      "[1.7622085]\n",
      "[1.82509084]\n",
      "[1.83446365]\n",
      "[1.77319198]\n",
      "[1.80597092]\n",
      "tensor([1.8861, 1.9407, 1.7622, 1.8251, 1.8345, 1.7732, 1.8060],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75888761]\n",
      "[1.89895821]\n",
      "[1.86894978]\n",
      "[1.83826096]\n",
      "[1.75827556]\n",
      "[1.90669414]\n",
      "[1.86855204]\n",
      "tensor([1.7589, 1.8990, 1.8689, 1.8383, 1.7583, 1.9067, 1.8686],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87619493]\n",
      "[1.83307711]\n",
      "[1.74895436]\n",
      "[1.9161746]\n",
      "[1.9792531]\n",
      "[1.91956289]\n",
      "[1.81117235]\n",
      "tensor([1.8762, 1.8331, 1.7490, 1.9162, 1.9793, 1.9196, 1.8112],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79372328]\n",
      "[1.91941654]\n",
      "[1.84410424]\n",
      "[1.74014123]\n",
      "[1.89988919]\n",
      "[1.81798863]\n",
      "[1.8521114]\n",
      "tensor([1.7937, 1.9194, 1.8441, 1.7401, 1.8999, 1.8180, 1.8521],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97206737]\n",
      "[1.81218199]\n",
      "[1.85926052]\n",
      "[1.81514348]\n",
      "[1.84199865]\n",
      "[1.75868282]\n",
      "[1.91850745]\n",
      "tensor([1.9721, 1.8122, 1.8593, 1.8151, 1.8420, 1.7587, 1.9185],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82222607]\n",
      "[1.8722927]\n",
      "[1.83795509]\n",
      "[1.83305176]\n",
      "[1.75172386]\n",
      "[1.79978092]\n",
      "[1.83822121]\n",
      "tensor([1.8222, 1.8723, 1.8380, 1.8331, 1.7517, 1.7998, 1.8382],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88573876]\n",
      "[1.86837135]\n",
      "[1.74022127]\n",
      "[1.81891855]\n",
      "[1.8359185]\n",
      "[1.84292307]\n",
      "[1.82352392]\n",
      "tensor([1.8857, 1.8684, 1.7402, 1.8189, 1.8359, 1.8429, 1.8235],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82286325]\n",
      "[1.79519113]\n",
      "[1.84191177]\n",
      "[1.82490813]\n",
      "[1.79170293]\n",
      "[1.80091752]\n",
      "[1.82118806]\n",
      "tensor([1.8229, 1.7952, 1.8419, 1.8249, 1.7917, 1.8009, 1.8212],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92710504]\n",
      "[1.73173786]\n",
      "[1.84303612]\n",
      "[1.83328691]\n",
      "[1.87958009]\n",
      "[1.82527063]\n",
      "[1.89067397]\n",
      "tensor([1.9271, 1.7317, 1.8430, 1.8333, 1.8796, 1.8253, 1.8907],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91856303]\n",
      "[1.76057567]\n",
      "[1.8024807]\n",
      "[1.84336327]\n",
      "[1.7394994]\n",
      "[1.73209994]\n",
      "[1.87309407]\n",
      "tensor([1.9186, 1.7606, 1.8025, 1.8434, 1.7395, 1.7321, 1.8731],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85012941]\n",
      "[1.80761158]\n",
      "[1.85526561]\n",
      "[1.85472336]\n",
      "[1.86692653]\n",
      "[1.92576284]\n",
      "[1.87232464]\n",
      "tensor([1.8501, 1.8076, 1.8553, 1.8547, 1.8669, 1.9258, 1.8723],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75245783]\n",
      "[1.83162879]\n",
      "[1.79499885]\n",
      "[1.83635024]\n",
      "[1.98471857]\n",
      "[1.89056133]\n",
      "[1.70433466]\n",
      "tensor([1.7525, 1.8316, 1.7950, 1.8364, 1.9847, 1.8906, 1.7043],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80322146]\n",
      "[1.81496667]\n",
      "[1.90956327]\n",
      "[1.79983963]\n",
      "[1.81749819]\n",
      "[1.79767367]\n",
      "[1.80770534]\n",
      "tensor([1.8032, 1.8150, 1.9096, 1.7998, 1.8175, 1.7977, 1.8077],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84248018]\n",
      "[1.98051225]\n",
      "[1.7881134]\n",
      "[1.76538649]\n",
      "[1.93005449]\n",
      "[1.8302766]\n",
      "[1.87710363]\n",
      "tensor([1.8425, 1.9805, 1.7881, 1.7654, 1.9301, 1.8303, 1.8771],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81654908]\n",
      "[1.71839492]\n",
      "[1.9312987]\n",
      "[1.77988812]\n",
      "[1.80463859]\n",
      "[1.7634697]\n",
      "[1.83559787]\n",
      "tensor([1.8165, 1.7184, 1.9313, 1.7799, 1.8046, 1.7635, 1.8356],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84047236]\n",
      "[1.83805429]\n",
      "[1.78058246]\n",
      "[1.98291775]\n",
      "[1.87712204]\n",
      "[1.79522426]\n",
      "[1.90782076]\n",
      "tensor([1.8405, 1.8381, 1.7806, 1.9829, 1.8771, 1.7952, 1.9078],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81295196]\n",
      "[1.7604424]\n",
      "[1.84376973]\n",
      "[1.91657287]\n",
      "[1.88124409]\n",
      "[1.82154024]\n",
      "[1.8245496]\n",
      "tensor([1.8130, 1.7604, 1.8438, 1.9166, 1.8812, 1.8215, 1.8245],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86620038]\n",
      "[1.75939091]\n",
      "[1.80759335]\n",
      "[1.80454968]\n",
      "[1.94935264]\n",
      "[1.9832103]\n",
      "[1.80828711]\n",
      "tensor([1.8662, 1.7594, 1.8076, 1.8045, 1.9494, 1.9832, 1.8083],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82550786]\n",
      "[1.69406358]\n",
      "[1.81806836]\n",
      "[1.8008949]\n",
      "[1.83009462]\n",
      "[1.87911845]\n",
      "[1.75854825]\n",
      "tensor([1.8255, 1.6941, 1.8181, 1.8009, 1.8301, 1.8791, 1.7585],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93814508]\n",
      "[1.80946995]\n",
      "[1.86887402]\n",
      "[1.86037766]\n",
      "[1.88588106]\n",
      "[1.82172381]\n",
      "[1.85250356]\n",
      "tensor([1.9381, 1.8095, 1.8689, 1.8604, 1.8859, 1.8217, 1.8525],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81787339]\n",
      "[1.8281705]\n",
      "[1.81543734]\n",
      "[1.86917217]\n",
      "[1.92432197]\n",
      "[1.82381077]\n",
      "[1.74087994]\n",
      "tensor([1.8179, 1.8282, 1.8154, 1.8692, 1.9243, 1.8238, 1.7409],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80312675]\n",
      "[1.86487501]\n",
      "[1.84863089]\n",
      "[1.81474716]\n",
      "[1.79774634]\n",
      "[1.92744133]\n",
      "[1.85491914]\n",
      "tensor([1.8031, 1.8649, 1.8486, 1.8147, 1.7977, 1.9274, 1.8549],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89049382]\n",
      "[1.96505802]\n",
      "[1.80838197]\n",
      "[1.80284719]\n",
      "[1.93224127]\n",
      "[1.90270255]\n",
      "[1.80644656]\n",
      "tensor([1.8905, 1.9651, 1.8084, 1.8028, 1.9322, 1.9027, 1.8064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84087213]\n",
      "[1.82130394]\n",
      "[1.824953]\n",
      "[1.74201987]\n",
      "[1.80798654]\n",
      "[1.87479694]\n",
      "[1.77301081]\n",
      "tensor([1.8409, 1.8213, 1.8250, 1.7420, 1.8080, 1.8748, 1.7730],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78262491]\n",
      "[1.81872468]\n",
      "[1.8829405]\n",
      "[1.82866037]\n",
      "[1.96788821]\n",
      "[1.90270458]\n",
      "[1.88431619]\n",
      "tensor([1.7826, 1.8187, 1.8829, 1.8287, 1.9679, 1.9027, 1.8843],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87774411]\n",
      "[1.85920486]\n",
      "[1.90006419]\n",
      "[1.83896121]\n",
      "[1.84776621]\n",
      "[1.82933437]\n",
      "[1.82585589]\n",
      "tensor([1.8777, 1.8592, 1.9001, 1.8390, 1.8478, 1.8293, 1.8259],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85288052]\n",
      "[1.81471924]\n",
      "[1.86127686]\n",
      "[1.77306036]\n",
      "[1.80593392]\n",
      "[1.83808744]\n",
      "[1.81431146]\n",
      "tensor([1.8529, 1.8147, 1.8613, 1.7731, 1.8059, 1.8381, 1.8143],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84487619]\n",
      "[1.9244875]\n",
      "[1.81636627]\n",
      "[1.75469403]\n",
      "[1.96673751]\n",
      "[1.85478899]\n",
      "[1.87113934]\n",
      "tensor([1.8449, 1.9245, 1.8164, 1.7547, 1.9667, 1.8548, 1.8711],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92159013]\n",
      "[1.82134532]\n",
      "[1.78112106]\n",
      "[1.89695007]\n",
      "[1.76798846]\n",
      "[1.78715054]\n",
      "[1.86245304]\n",
      "tensor([1.9216, 1.8213, 1.7811, 1.8970, 1.7680, 1.7872, 1.8625],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85528859]\n",
      "[1.91835075]\n",
      "[1.86537524]\n",
      "[1.85753322]\n",
      "[1.85396469]\n",
      "[1.79907709]\n",
      "[1.81590681]\n",
      "tensor([1.8553, 1.9184, 1.8654, 1.8575, 1.8540, 1.7991, 1.8159],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83215604]\n",
      "[1.89308156]\n",
      "[1.76063615]\n",
      "[1.89959267]\n",
      "[1.76117641]\n",
      "[1.80774645]\n",
      "[1.75798243]\n",
      "tensor([1.8322, 1.8931, 1.7606, 1.8996, 1.7612, 1.8077, 1.7580],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81359181]\n",
      "[1.83098893]\n",
      "[1.84593672]\n",
      "[1.8131348]\n",
      "[1.83697765]\n",
      "[1.84158741]\n",
      "[1.82843392]\n",
      "tensor([1.8136, 1.8310, 1.8459, 1.8131, 1.8370, 1.8416, 1.8284],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74942195]\n",
      "[1.78701743]\n",
      "[1.84880685]\n",
      "[1.73181137]\n",
      "[1.79562899]\n",
      "[1.77120001]\n",
      "[1.91423142]\n",
      "tensor([1.7494, 1.7870, 1.8488, 1.7318, 1.7956, 1.7712, 1.9142],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88752311]\n",
      "[1.76697595]\n",
      "[1.81504751]\n",
      "[1.8029299]\n",
      "[1.83023819]\n",
      "[1.88198661]\n",
      "[1.82190332]\n",
      "tensor([1.8875, 1.7670, 1.8150, 1.8029, 1.8302, 1.8820, 1.8219],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82179236]\n",
      "[1.85163697]\n",
      "[1.89762093]\n",
      "[1.78445768]\n",
      "[1.78331059]\n",
      "[1.91950552]\n",
      "[1.82219207]\n",
      "tensor([1.8218, 1.8516, 1.8976, 1.7845, 1.7833, 1.9195, 1.8222],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83322383]\n",
      "[1.82333267]\n",
      "[1.87160234]\n",
      "[1.8555612]\n",
      "[1.90757778]\n",
      "[1.86439302]\n",
      "[1.84278544]\n",
      "tensor([1.8332, 1.8233, 1.8716, 1.8556, 1.9076, 1.8644, 1.8428],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86098216]\n",
      "[1.8248863]\n",
      "[1.76942173]\n",
      "[1.8801272]\n",
      "[1.86212526]\n",
      "[1.82241402]\n",
      "[1.88432584]\n",
      "tensor([1.8610, 1.8249, 1.7694, 1.8801, 1.8621, 1.8224, 1.8843],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88300745]\n",
      "[1.75330859]\n",
      "[1.79763051]\n",
      "[1.69554247]\n",
      "[1.84446149]\n",
      "[1.77211014]\n",
      "[1.74592738]\n",
      "tensor([1.8830, 1.7533, 1.7976, 1.6955, 1.8445, 1.7721, 1.7459],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91369778]\n",
      "[1.84002478]\n",
      "[1.84340528]\n",
      "[1.82626309]\n",
      "[1.70649153]\n",
      "[1.83744103]\n",
      "[1.84345942]\n",
      "tensor([1.9137, 1.8400, 1.8434, 1.8263, 1.7065, 1.8374, 1.8435],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74475487]\n",
      "[1.76716713]\n",
      "[1.83300501]\n",
      "[1.82216541]\n",
      "[1.78939844]\n",
      "[1.81825352]\n",
      "[1.82994485]\n",
      "tensor([1.7448, 1.7672, 1.8330, 1.8222, 1.7894, 1.8183, 1.8299],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74869606]\n",
      "[1.95015696]\n",
      "[1.79350818]\n",
      "[1.80503428]\n",
      "[1.85746685]\n",
      "[1.80163423]\n",
      "[1.80016895]\n",
      "tensor([1.7487, 1.9502, 1.7935, 1.8050, 1.8575, 1.8016, 1.8002],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75914524]\n",
      "[1.88718315]\n",
      "[1.85814136]\n",
      "[1.9078237]\n",
      "[1.98480241]\n",
      "[1.75156795]\n",
      "[1.95239482]\n",
      "tensor([1.7591, 1.8872, 1.8581, 1.9078, 1.9848, 1.7516, 1.9524],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81871744]\n",
      "[1.80560973]\n",
      "[1.82004384]\n",
      "[1.77319867]\n",
      "[1.73760851]\n",
      "[1.86871944]\n",
      "[1.83193589]\n",
      "tensor([1.8187, 1.8056, 1.8200, 1.7732, 1.7376, 1.8687, 1.8319],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84497991]\n",
      "[1.79697529]\n",
      "[1.81454732]\n",
      "[1.80396866]\n",
      "[1.85199949]\n",
      "[1.78609178]\n",
      "[1.80220335]\n",
      "tensor([1.8450, 1.7970, 1.8145, 1.8040, 1.8520, 1.7861, 1.8022],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9696506]\n",
      "[1.83994781]\n",
      "[1.84303383]\n",
      "[1.91467248]\n",
      "[1.84025394]\n",
      "[1.82603879]\n",
      "[1.82431573]\n",
      "tensor([1.9697, 1.8399, 1.8430, 1.9147, 1.8403, 1.8260, 1.8243],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84454867]\n",
      "[1.80168023]\n",
      "[1.80984001]\n",
      "[1.81778308]\n",
      "[1.75724691]\n",
      "[1.78845739]\n",
      "[1.97027947]\n",
      "tensor([1.8445, 1.8017, 1.8098, 1.8178, 1.7572, 1.7885, 1.9703],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05691587]\n",
      "[1.84617981]\n",
      "[1.86477431]\n",
      "[1.78478768]\n",
      "[1.88467651]\n",
      "[1.81889953]\n",
      "[1.85180864]\n",
      "tensor([2.0569, 1.8462, 1.8648, 1.7848, 1.8847, 1.8189, 1.8518],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79945053]\n",
      "[1.82715157]\n",
      "[1.88086077]\n",
      "[1.82041061]\n",
      "[1.89031851]\n",
      "[1.84415606]\n",
      "[1.84438539]\n",
      "tensor([1.7995, 1.8272, 1.8809, 1.8204, 1.8903, 1.8442, 1.8444],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84220917]\n",
      "[1.88465847]\n",
      "[1.87129659]\n",
      "[1.83903577]\n",
      "[1.80759282]\n",
      "[1.84018981]\n",
      "[1.85024568]\n",
      "tensor([1.8422, 1.8847, 1.8713, 1.8390, 1.8076, 1.8402, 1.8502],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8918848]\n",
      "[1.78518442]\n",
      "[1.84268274]\n",
      "[1.89255693]\n",
      "[1.83920053]\n",
      "[1.91935709]\n",
      "[1.8538152]\n",
      "tensor([1.8919, 1.7852, 1.8427, 1.8926, 1.8392, 1.9194, 1.8538],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81088695]\n",
      "[1.7662495]\n",
      "[1.82795793]\n",
      "[1.85134236]\n",
      "[1.84873208]\n",
      "[1.84274808]\n",
      "[1.83946086]\n",
      "tensor([1.8109, 1.7662, 1.8280, 1.8513, 1.8487, 1.8427, 1.8395],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85434166]\n",
      "[1.86122928]\n",
      "[1.81623285]\n",
      "[1.79108591]\n",
      "[1.90594412]\n",
      "[1.81387408]\n",
      "[2.05968637]\n",
      "tensor([1.8543, 1.8612, 1.8162, 1.7911, 1.9059, 1.8139, 2.0597],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85389786]\n",
      "[1.79188793]\n",
      "[1.85275646]\n",
      "[1.74643879]\n",
      "[2.06491072]\n",
      "[1.81654116]\n",
      "[1.88212935]\n",
      "tensor([1.8539, 1.7919, 1.8528, 1.7464, 2.0649, 1.8165, 1.8821],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87875267]\n",
      "[1.77661354]\n",
      "[1.80325561]\n",
      "[1.92549553]\n",
      "[1.89132828]\n",
      "[1.81406765]\n",
      "[1.80152627]\n",
      "tensor([1.8788, 1.7766, 1.8033, 1.9255, 1.8913, 1.8141, 1.8015],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78544444]\n",
      "[1.80846437]\n",
      "[1.84200513]\n",
      "[2.01133149]\n",
      "[1.74744154]\n",
      "[1.81173069]\n",
      "[1.77828882]\n",
      "tensor([1.7854, 1.8085, 1.8420, 2.0113, 1.7474, 1.8117, 1.7783],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76359074]\n",
      "[1.85659367]\n",
      "[1.72206718]\n",
      "[1.88998356]\n",
      "[1.79227543]\n",
      "[1.95161073]\n",
      "[1.79093844]\n",
      "tensor([1.7636, 1.8566, 1.7221, 1.8900, 1.7923, 1.9516, 1.7909],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88552628]\n",
      "[1.79536758]\n",
      "[1.75568221]\n",
      "[1.80429334]\n",
      "[1.90326039]\n",
      "[1.7854839]\n",
      "[1.73513356]\n",
      "tensor([1.8855, 1.7954, 1.7557, 1.8043, 1.9033, 1.7855, 1.7351],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82716249]\n",
      "[1.87826647]\n",
      "[1.84669664]\n",
      "[1.824532]\n",
      "[1.84616246]\n",
      "[1.73514182]\n",
      "[1.92878535]\n",
      "tensor([1.8272, 1.8783, 1.8467, 1.8245, 1.8462, 1.7351, 1.9288],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88519552]\n",
      "[1.835252]\n",
      "[1.87491828]\n",
      "[1.83289858]\n",
      "[1.86626201]\n",
      "[1.84832485]\n",
      "[1.69130353]\n",
      "tensor([1.8852, 1.8353, 1.8749, 1.8329, 1.8663, 1.8483, 1.6913],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80113472]\n",
      "[1.88334029]\n",
      "[1.86586481]\n",
      "[1.95253774]\n",
      "[1.80515153]\n",
      "[1.87754372]\n",
      "[1.90525181]\n",
      "tensor([1.8011, 1.8833, 1.8659, 1.9525, 1.8052, 1.8775, 1.9053],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79733129]\n",
      "[1.8203244]\n",
      "[1.8786311]\n",
      "[1.89204068]\n",
      "[1.73933746]\n",
      "[1.8104362]\n",
      "[1.82923868]\n",
      "tensor([1.7973, 1.8203, 1.8786, 1.8920, 1.7393, 1.8104, 1.8292],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84861937]\n",
      "[1.90495125]\n",
      "[1.80961804]\n",
      "[1.78796852]\n",
      "[1.82581121]\n",
      "[1.86290242]\n",
      "[1.85473282]\n",
      "tensor([1.8486, 1.9050, 1.8096, 1.7880, 1.8258, 1.8629, 1.8547],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91943351]\n",
      "[1.77749287]\n",
      "[1.90982578]\n",
      "[1.90719492]\n",
      "[1.90689611]\n",
      "[1.82827075]\n",
      "[1.84844686]\n",
      "tensor([1.9194, 1.7775, 1.9098, 1.9072, 1.9069, 1.8283, 1.8484],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95424899]\n",
      "[1.95853883]\n",
      "[1.77309524]\n",
      "[1.8306015]\n",
      "[1.82483515]\n",
      "[1.8547502]\n",
      "[1.88682179]\n",
      "tensor([1.9542, 1.9585, 1.7731, 1.8306, 1.8248, 1.8548, 1.8868],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79647784]\n",
      "[1.91741005]\n",
      "[1.83398523]\n",
      "[1.89676704]\n",
      "[1.76197489]\n",
      "[1.84870526]\n",
      "[1.87877989]\n",
      "tensor([1.7965, 1.9174, 1.8340, 1.8968, 1.7620, 1.8487, 1.8788],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74420398]\n",
      "[1.83098582]\n",
      "[1.80184249]\n",
      "[1.77198677]\n",
      "[1.86940569]\n",
      "[1.70582234]\n",
      "[1.87492651]\n",
      "tensor([1.7442, 1.8310, 1.8018, 1.7720, 1.8694, 1.7058, 1.8749],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84781221]\n",
      "[1.81498635]\n",
      "[1.79069001]\n",
      "[1.82557955]\n",
      "[1.7793649]\n",
      "[1.89818441]\n",
      "[1.82123585]\n",
      "tensor([1.8478, 1.8150, 1.7907, 1.8256, 1.7794, 1.8982, 1.8212],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85098405]\n",
      "[1.89853078]\n",
      "[1.84448907]\n",
      "[1.82794585]\n",
      "[1.84835688]\n",
      "[1.85009909]\n",
      "[1.977209]\n",
      "tensor([1.8510, 1.8985, 1.8445, 1.8279, 1.8484, 1.8501, 1.9772],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94828483]\n",
      "[1.85786847]\n",
      "[1.88670378]\n",
      "[1.92074019]\n",
      "[1.76938897]\n",
      "[1.75527063]\n",
      "[1.81925213]\n",
      "tensor([1.9483, 1.8579, 1.8867, 1.9207, 1.7694, 1.7553, 1.8193],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82147481]\n",
      "[1.84717968]\n",
      "[1.90171577]\n",
      "[1.87249316]\n",
      "[1.82846251]\n",
      "[1.84606499]\n",
      "[1.86943909]\n",
      "tensor([1.8215, 1.8472, 1.9017, 1.8725, 1.8285, 1.8461, 1.8694],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86899847]\n",
      "[1.73571376]\n",
      "[1.81154935]\n",
      "[1.80025119]\n",
      "[1.87764018]\n",
      "[1.85734966]\n",
      "[1.75968522]\n",
      "tensor([1.8690, 1.7357, 1.8115, 1.8003, 1.8776, 1.8573, 1.7597],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90745566]\n",
      "[1.8297107]\n",
      "[1.83683351]\n",
      "[1.8009619]\n",
      "[1.86829645]\n",
      "[1.85534358]\n",
      "[1.83028465]\n",
      "tensor([1.9075, 1.8297, 1.8368, 1.8010, 1.8683, 1.8553, 1.8303],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78623615]\n",
      "[1.87138561]\n",
      "[1.843523]\n",
      "[1.78162854]\n",
      "[1.84683478]\n",
      "[1.81050878]\n",
      "[1.83040113]\n",
      "tensor([1.7862, 1.8714, 1.8435, 1.7816, 1.8468, 1.8105, 1.8304],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89691773]\n",
      "[1.83576139]\n",
      "[1.81082242]\n",
      "[1.78606368]\n",
      "[1.75427073]\n",
      "[1.75879829]\n",
      "[1.83475788]\n",
      "tensor([1.8969, 1.8358, 1.8108, 1.7861, 1.7543, 1.7588, 1.8348],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86523681]\n",
      "[1.80595878]\n",
      "[1.7583783]\n",
      "[1.83807641]\n",
      "[1.8553678]\n",
      "[1.69538192]\n",
      "[1.79597812]\n",
      "tensor([1.8652, 1.8060, 1.7584, 1.8381, 1.8554, 1.6954, 1.7960],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87768468]\n",
      "[1.78977522]\n",
      "[1.81717275]\n",
      "[1.86577098]\n",
      "[1.77064535]\n",
      "[1.86769664]\n",
      "[1.90984809]\n",
      "tensor([1.8777, 1.7898, 1.8172, 1.8658, 1.7706, 1.8677, 1.9098],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8686573]\n",
      "[1.94480935]\n",
      "[1.86297989]\n",
      "[1.85475463]\n",
      "[1.87881261]\n",
      "[1.97576255]\n",
      "[1.91513253]\n",
      "tensor([1.8687, 1.9448, 1.8630, 1.8548, 1.8788, 1.9758, 1.9151],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.68407215]\n",
      "[1.83595144]\n",
      "[1.81030303]\n",
      "[1.81595018]\n",
      "[1.82408625]\n",
      "[1.88359396]\n",
      "[1.82155977]\n",
      "tensor([1.6841, 1.8360, 1.8103, 1.8160, 1.8241, 1.8836, 1.8216],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77840562]\n",
      "[1.78979614]\n",
      "[1.79859996]\n",
      "[1.88678761]\n",
      "[1.81970966]\n",
      "[1.84767011]\n",
      "[1.85884423]\n",
      "tensor([1.7784, 1.7898, 1.7986, 1.8868, 1.8197, 1.8477, 1.8588],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81495192]\n",
      "[1.79812499]\n",
      "[1.8255694]\n",
      "[1.81704955]\n",
      "[1.97777066]\n",
      "[1.79564719]\n",
      "[1.79925142]\n",
      "tensor([1.8150, 1.7981, 1.8256, 1.8170, 1.9778, 1.7956, 1.7993],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87943307]\n",
      "[1.89597647]\n",
      "[1.77118915]\n",
      "[1.75473675]\n",
      "[1.76501172]\n",
      "[1.71857287]\n",
      "[1.81745041]\n",
      "tensor([1.8794, 1.8960, 1.7712, 1.7547, 1.7650, 1.7186, 1.8175],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80408159]\n",
      "[1.92116236]\n",
      "[1.83303987]\n",
      "[1.94840715]\n",
      "[1.90010488]\n",
      "[1.80316011]\n",
      "[1.85635989]\n",
      "tensor([1.8041, 1.9212, 1.8330, 1.9484, 1.9001, 1.8032, 1.8564],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8162227]\n",
      "[1.85715036]\n",
      "[1.80887673]\n",
      "[1.80357963]\n",
      "[1.85474353]\n",
      "[1.84927363]\n",
      "[1.85368285]\n",
      "tensor([1.8162, 1.8572, 1.8089, 1.8036, 1.8547, 1.8493, 1.8537],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78946069]\n",
      "[1.88175656]\n",
      "[1.81718652]\n",
      "[1.88506164]\n",
      "[1.90671115]\n",
      "[1.82295305]\n",
      "[1.82888549]\n",
      "tensor([1.7895, 1.8818, 1.8172, 1.8851, 1.9067, 1.8230, 1.8289],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82182502]\n",
      "[1.83180981]\n",
      "[1.84637378]\n",
      "[1.85643486]\n",
      "[1.8149171]\n",
      "[1.80856978]\n",
      "[1.9496242]\n",
      "tensor([1.8218, 1.8318, 1.8464, 1.8564, 1.8149, 1.8086, 1.9496],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80106731]\n",
      "[1.82896723]\n",
      "[1.91608229]\n",
      "[1.81889209]\n",
      "[1.88614229]\n",
      "[1.84543519]\n",
      "[1.7719978]\n",
      "tensor([1.8011, 1.8290, 1.9161, 1.8189, 1.8861, 1.8454, 1.7720],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79616382]\n",
      "[1.85505158]\n",
      "[1.80253327]\n",
      "[1.94711572]\n",
      "[1.83903797]\n",
      "[1.92801759]\n",
      "[1.90474396]\n",
      "tensor([1.7962, 1.8551, 1.8025, 1.9471, 1.8390, 1.9280, 1.9047],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80516309]\n",
      "[1.80310457]\n",
      "[1.88456634]\n",
      "[1.858347]\n",
      "[1.80497823]\n",
      "[1.75555395]\n",
      "[1.75543359]\n",
      "tensor([1.8052, 1.8031, 1.8846, 1.8583, 1.8050, 1.7556, 1.7554],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84008132]\n",
      "[1.82284457]\n",
      "[1.88520186]\n",
      "[1.75715641]\n",
      "[1.82963915]\n",
      "[1.83384609]\n",
      "[1.74615428]\n",
      "tensor([1.8401, 1.8228, 1.8852, 1.7572, 1.8296, 1.8338, 1.7462],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8541261]\n",
      "[1.82345298]\n",
      "[1.80209914]\n",
      "[1.77056651]\n",
      "[1.74002799]\n",
      "[1.85321044]\n",
      "[1.79367229]\n",
      "tensor([1.8541, 1.8235, 1.8021, 1.7706, 1.7400, 1.8532, 1.7937],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79674439]\n",
      "[1.83700105]\n",
      "[1.85873762]\n",
      "[1.88403215]\n",
      "[1.85218032]\n",
      "[1.85480627]\n",
      "[1.80300007]\n",
      "tensor([1.7967, 1.8370, 1.8587, 1.8840, 1.8522, 1.8548, 1.8030],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81659284]\n",
      "[1.91090029]\n",
      "[1.78794221]\n",
      "[1.83725232]\n",
      "[1.87545622]\n",
      "[1.85712775]\n",
      "[1.78679716]\n",
      "tensor([1.8166, 1.9109, 1.7879, 1.8373, 1.8755, 1.8571, 1.7868],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85935522]\n",
      "[1.92556232]\n",
      "[1.81485479]\n",
      "[1.81216426]\n",
      "[1.8184534]\n",
      "[2.06429684]\n",
      "[1.84432314]\n",
      "tensor([1.8594, 1.9256, 1.8149, 1.8122, 1.8185, 2.0643, 1.8443],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95179046]\n",
      "[1.95215725]\n",
      "[1.81864539]\n",
      "[1.84215305]\n",
      "[1.74707534]\n",
      "[1.89836644]\n",
      "[1.74235718]\n",
      "tensor([1.9518, 1.9522, 1.8186, 1.8422, 1.7471, 1.8984, 1.7424],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81478084]\n",
      "[1.82277721]\n",
      "[1.82708907]\n",
      "[1.89321471]\n",
      "[1.88698664]\n",
      "[1.92073436]\n",
      "[1.86242895]\n",
      "tensor([1.8148, 1.8228, 1.8271, 1.8932, 1.8870, 1.9207, 1.8624],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.06238595]\n",
      "[1.88889201]\n",
      "[1.79409068]\n",
      "[1.80862247]\n",
      "[1.83295648]\n",
      "[1.91719417]\n",
      "[1.85444149]\n",
      "tensor([2.0624, 1.8889, 1.7941, 1.8086, 1.8330, 1.9172, 1.8544],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8410194]\n",
      "[1.77436672]\n",
      "[1.73682682]\n",
      "[1.8108329]\n",
      "[1.78706844]\n",
      "[1.82087631]\n",
      "[1.81757907]\n",
      "tensor([1.8410, 1.7744, 1.7368, 1.8108, 1.7871, 1.8209, 1.8176],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81968965]\n",
      "[1.79898243]\n",
      "[1.80695447]\n",
      "[1.85975414]\n",
      "[1.8313266]\n",
      "[1.83223922]\n",
      "[1.83079056]\n",
      "tensor([1.8197, 1.7990, 1.8070, 1.8598, 1.8313, 1.8322, 1.8308],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88067542]\n",
      "[1.91772125]\n",
      "[1.80918552]\n",
      "[1.80636096]\n",
      "[1.96533919]\n",
      "[1.87042912]\n",
      "[1.85562134]\n",
      "tensor([1.8807, 1.9177, 1.8092, 1.8064, 1.9653, 1.8704, 1.8556],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80965434]\n",
      "[1.84941967]\n",
      "[1.8221228]\n",
      "[1.8439413]\n",
      "[1.84736477]\n",
      "[1.80893333]\n",
      "[1.7943641]\n",
      "tensor([1.8097, 1.8494, 1.8221, 1.8439, 1.8474, 1.8089, 1.7944],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76407897]\n",
      "[1.86904457]\n",
      "[1.8095962]\n",
      "[1.89480466]\n",
      "[1.93051227]\n",
      "[1.80669022]\n",
      "[1.82096334]\n",
      "tensor([1.7641, 1.8690, 1.8096, 1.8948, 1.9305, 1.8067, 1.8210],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91513757]\n",
      "[1.91921163]\n",
      "[1.95410572]\n",
      "[1.93175845]\n",
      "[1.73239609]\n",
      "[1.88810141]\n",
      "[1.84573433]\n",
      "tensor([1.9151, 1.9192, 1.9541, 1.9318, 1.7324, 1.8881, 1.8457],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79297189]\n",
      "[1.87147378]\n",
      "[1.82635204]\n",
      "[1.86160712]\n",
      "[1.8302911]\n",
      "[1.83319291]\n",
      "[1.8095449]\n",
      "tensor([1.7930, 1.8715, 1.8264, 1.8616, 1.8303, 1.8332, 1.8095],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91386098]\n",
      "[1.77847226]\n",
      "[1.70256586]\n",
      "[1.7566249]\n",
      "[1.85309069]\n",
      "[1.73794]\n",
      "[1.94638093]\n",
      "tensor([1.9139, 1.7785, 1.7026, 1.7566, 1.8531, 1.7379, 1.9464],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85535893]\n",
      "[1.98558912]\n",
      "[1.79551682]\n",
      "[1.76051613]\n",
      "[1.78487683]\n",
      "[1.92689665]\n",
      "[1.82940327]\n",
      "tensor([1.8554, 1.9856, 1.7955, 1.7605, 1.7849, 1.9269, 1.8294],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78182931]\n",
      "[1.86117772]\n",
      "[1.87393433]\n",
      "[1.92060047]\n",
      "[1.79941761]\n",
      "[1.77135568]\n",
      "[1.79480841]\n",
      "tensor([1.7818, 1.8612, 1.8739, 1.9206, 1.7994, 1.7714, 1.7948],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83571389]\n",
      "[1.78102187]\n",
      "[1.81712804]\n",
      "[1.84122739]\n",
      "[1.85835299]\n",
      "[1.84196272]\n",
      "[1.74076614]\n",
      "tensor([1.8357, 1.7810, 1.8171, 1.8412, 1.8584, 1.8420, 1.7408],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84044593]\n",
      "[1.84930174]\n",
      "[1.86916326]\n",
      "[2.0651244]\n",
      "[1.79466282]\n",
      "[1.74197723]\n",
      "[1.8420823]\n",
      "tensor([1.8404, 1.8493, 1.8692, 2.0651, 1.7947, 1.7420, 1.8421],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80498696]\n",
      "[1.75197468]\n",
      "[1.78742627]\n",
      "[1.81388555]\n",
      "[1.79989513]\n",
      "[1.91129237]\n",
      "[1.79908519]\n",
      "tensor([1.8050, 1.7520, 1.7874, 1.8139, 1.7999, 1.9113, 1.7991],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82083473]\n",
      "[1.90700287]\n",
      "[1.90078468]\n",
      "[1.75431535]\n",
      "[1.755199]\n",
      "[1.82055427]\n",
      "[1.75384774]\n",
      "tensor([1.8208, 1.9070, 1.9008, 1.7543, 1.7552, 1.8206, 1.7538],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92551261]\n",
      "[1.83717791]\n",
      "[1.88305866]\n",
      "[1.91067064]\n",
      "[1.74599417]\n",
      "[1.79920359]\n",
      "[1.82097041]\n",
      "tensor([1.9255, 1.8372, 1.8831, 1.9107, 1.7460, 1.7992, 1.8210],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95157765]\n",
      "[1.92043539]\n",
      "[1.81554543]\n",
      "[1.76594257]\n",
      "[1.85389239]\n",
      "[1.81941843]\n",
      "[1.88338654]\n",
      "tensor([1.9516, 1.9204, 1.8155, 1.7659, 1.8539, 1.8194, 1.8834],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81086855]\n",
      "[1.81645118]\n",
      "[1.79791197]\n",
      "[1.81257784]\n",
      "[1.76248599]\n",
      "[1.83801401]\n",
      "[1.80147461]\n",
      "tensor([1.8109, 1.8165, 1.7979, 1.8126, 1.7625, 1.8380, 1.8015],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82448928]\n",
      "[1.82086103]\n",
      "[1.72339406]\n",
      "[1.88254395]\n",
      "[1.75936691]\n",
      "[1.83824314]\n",
      "[1.87094926]\n",
      "tensor([1.8245, 1.8209, 1.7234, 1.8825, 1.7594, 1.8382, 1.8709],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77094809]\n",
      "[1.79505209]\n",
      "[1.85375229]\n",
      "[1.84309497]\n",
      "[1.85406791]\n",
      "[1.8158918]\n",
      "[1.82662654]\n",
      "tensor([1.7709, 1.7951, 1.8538, 1.8431, 1.8541, 1.8159, 1.8266],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93248067]\n",
      "[1.74473451]\n",
      "[1.80737147]\n",
      "[1.80500187]\n",
      "[1.80118167]\n",
      "[1.82739014]\n",
      "[1.82917283]\n",
      "tensor([1.9325, 1.7447, 1.8074, 1.8050, 1.8012, 1.8274, 1.8292],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75986259]\n",
      "[1.85161119]\n",
      "[1.78806188]\n",
      "[1.88362588]\n",
      "[1.92950239]\n",
      "[1.82391891]\n",
      "[1.82937476]\n",
      "tensor([1.7599, 1.8516, 1.7881, 1.8836, 1.9295, 1.8239, 1.8294],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05919192]\n",
      "[1.81797293]\n",
      "[1.84201183]\n",
      "[1.79704775]\n",
      "[1.86312436]\n",
      "[1.82960654]\n",
      "[1.88703284]\n",
      "tensor([2.0592, 1.8180, 1.8420, 1.7970, 1.8631, 1.8296, 1.8870],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82082158]\n",
      "[1.92384375]\n",
      "[1.90359316]\n",
      "[1.75919135]\n",
      "[1.87252655]\n",
      "[1.85312812]\n",
      "[1.72260756]\n",
      "tensor([1.8208, 1.9238, 1.9036, 1.7592, 1.8725, 1.8531, 1.7226],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86123136]\n",
      "[1.76369634]\n",
      "[1.81812788]\n",
      "[1.87177106]\n",
      "[1.755775]\n",
      "[1.89781681]\n",
      "[1.81567355]\n",
      "tensor([1.8612, 1.7637, 1.8181, 1.8718, 1.7558, 1.8978, 1.8157],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78644112]\n",
      "[1.81888804]\n",
      "[1.7996613]\n",
      "[1.86980684]\n",
      "[1.90404256]\n",
      "[1.84126503]\n",
      "[1.94857559]\n",
      "tensor([1.7864, 1.8189, 1.7997, 1.8698, 1.9040, 1.8413, 1.9486],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8573517]\n",
      "[1.78161497]\n",
      "[1.82702801]\n",
      "[1.82937376]\n",
      "[1.82721322]\n",
      "[1.84667531]\n",
      "[1.74046452]\n",
      "tensor([1.8574, 1.7816, 1.8270, 1.8294, 1.8272, 1.8467, 1.7405],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75565723]\n",
      "[1.81559039]\n",
      "[1.88359793]\n",
      "[1.82082241]\n",
      "[1.83350425]\n",
      "[1.79830827]\n",
      "[1.84735825]\n",
      "tensor([1.7557, 1.8156, 1.8836, 1.8208, 1.8335, 1.7983, 1.8474],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80826741]\n",
      "[1.79658318]\n",
      "[1.88143829]\n",
      "[1.80174787]\n",
      "[1.7879706]\n",
      "[1.79782851]\n",
      "[1.95139165]\n",
      "tensor([1.8083, 1.7966, 1.8814, 1.8017, 1.7880, 1.7978, 1.9514],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76475145]\n",
      "[1.856594]\n",
      "[1.84611546]\n",
      "[1.82910281]\n",
      "[1.83918456]\n",
      "[1.84465297]\n",
      "[1.81900156]\n",
      "tensor([1.7648, 1.8566, 1.8461, 1.8291, 1.8392, 1.8447, 1.8190],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.97758233]\n",
      "[1.85106889]\n",
      "[1.82757692]\n",
      "[1.83847361]\n",
      "[1.85022251]\n",
      "[1.77576528]\n",
      "[1.93166466]\n",
      "tensor([1.9776, 1.8511, 1.8276, 1.8385, 1.8502, 1.7758, 1.9317],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82535856]\n",
      "[1.82051535]\n",
      "[1.81389158]\n",
      "[1.76402113]\n",
      "[1.85794132]\n",
      "[1.84152809]\n",
      "[1.73292253]\n",
      "tensor([1.8254, 1.8205, 1.8139, 1.7640, 1.8579, 1.8415, 1.7329],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93495464]\n",
      "[1.75765758]\n",
      "[1.78569014]\n",
      "[1.87850865]\n",
      "[1.80712509]\n",
      "[1.846934]\n",
      "[1.81682836]\n",
      "tensor([1.9350, 1.7577, 1.7857, 1.8785, 1.8071, 1.8469, 1.8168],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8748829]\n",
      "[1.75164582]\n",
      "[1.78818921]\n",
      "[1.78525082]\n",
      "[1.73789292]\n",
      "[1.85206887]\n",
      "[1.81380481]\n",
      "tensor([1.8749, 1.7516, 1.7882, 1.7853, 1.7379, 1.8521, 1.8138],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79598438]\n",
      "[1.79862136]\n",
      "[1.77583513]\n",
      "[1.76744373]\n",
      "[1.86595138]\n",
      "[1.84315076]\n",
      "[1.82114714]\n",
      "tensor([1.7960, 1.7986, 1.7758, 1.7674, 1.8660, 1.8432, 1.8211],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84198373]\n",
      "[1.73904783]\n",
      "[1.83574275]\n",
      "[1.84236111]\n",
      "[1.84345047]\n",
      "[1.92653349]\n",
      "[1.84035585]\n",
      "tensor([1.8420, 1.7390, 1.8357, 1.8424, 1.8435, 1.9265, 1.8404],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84426234]\n",
      "[1.81580132]\n",
      "[1.8801551]\n",
      "[1.83092257]\n",
      "[1.92029231]\n",
      "[1.87144323]\n",
      "[1.81117743]\n",
      "tensor([1.8443, 1.8158, 1.8802, 1.8309, 1.9203, 1.8714, 1.8112],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8188028]\n",
      "[1.87857457]\n",
      "[1.85202721]\n",
      "[1.86838549]\n",
      "[1.92854307]\n",
      "[1.8043165]\n",
      "[1.97115267]\n",
      "tensor([1.8188, 1.8786, 1.8520, 1.8684, 1.9285, 1.8043, 1.9712],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73889141]\n",
      "[1.90483362]\n",
      "[1.85148985]\n",
      "[1.74659388]\n",
      "[1.82084256]\n",
      "[1.8298025]\n",
      "[1.80454952]\n",
      "tensor([1.7389, 1.9048, 1.8515, 1.7466, 1.8208, 1.8298, 1.8045],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89454443]\n",
      "[1.78435059]\n",
      "[1.81514187]\n",
      "[1.8871543]\n",
      "[1.79834434]\n",
      "[1.73209115]\n",
      "[1.79623212]\n",
      "tensor([1.8945, 1.7844, 1.8151, 1.8872, 1.7983, 1.7321, 1.7962],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88685715]\n",
      "[1.85610907]\n",
      "[1.7861003]\n",
      "[1.85517604]\n",
      "[1.86590399]\n",
      "[1.82713809]\n",
      "[1.74632943]\n",
      "tensor([1.8869, 1.8561, 1.7861, 1.8552, 1.8659, 1.8271, 1.7463],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.819872]\n",
      "[1.81868858]\n",
      "[1.84335049]\n",
      "[1.72754127]\n",
      "[1.79568925]\n",
      "[1.80442722]\n",
      "[1.9535008]\n",
      "tensor([1.8199, 1.8187, 1.8434, 1.7275, 1.7957, 1.8044, 1.9535],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88854601]\n",
      "[1.79970521]\n",
      "[1.92899624]\n",
      "[1.80478058]\n",
      "[1.77489591]\n",
      "[1.82091512]\n",
      "[1.73622717]\n",
      "tensor([1.8885, 1.7997, 1.9290, 1.8048, 1.7749, 1.8209, 1.7362],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83416777]\n",
      "[1.84939798]\n",
      "[1.82559457]\n",
      "[1.70630414]\n",
      "[1.87662809]\n",
      "[1.84266916]\n",
      "[1.96991383]\n",
      "tensor([1.8342, 1.8494, 1.8256, 1.7063, 1.8766, 1.8427, 1.9699],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81861224]\n",
      "[1.7854427]\n",
      "[1.82145383]\n",
      "[1.99122286]\n",
      "[1.86996157]\n",
      "[1.96618313]\n",
      "[1.87783442]\n",
      "tensor([1.8186, 1.7854, 1.8215, 1.9912, 1.8700, 1.9662, 1.8778],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82912921]\n",
      "[1.82504644]\n",
      "[1.82284216]\n",
      "[1.88233509]\n",
      "[1.81684343]\n",
      "[1.74765075]\n",
      "[1.84667609]\n",
      "tensor([1.8291, 1.8250, 1.8228, 1.8823, 1.8168, 1.7477, 1.8467],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.817279]\n",
      "[1.85963636]\n",
      "[1.78276221]\n",
      "[1.89615283]\n",
      "[1.97455019]\n",
      "[1.92642182]\n",
      "[1.82089055]\n",
      "tensor([1.8173, 1.8596, 1.7828, 1.8962, 1.9746, 1.9264, 1.8209],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76922179]\n",
      "[1.88100836]\n",
      "[1.8271544]\n",
      "[1.80266275]\n",
      "[1.75415452]\n",
      "[1.74283691]\n",
      "[1.87923155]\n",
      "tensor([1.7692, 1.8810, 1.8272, 1.8027, 1.7542, 1.7428, 1.8792],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85139161]\n",
      "[1.88495703]\n",
      "[1.89417586]\n",
      "[1.8154535]\n",
      "[1.74038706]\n",
      "[1.79103809]\n",
      "[1.82997456]\n",
      "tensor([1.8514, 1.8850, 1.8942, 1.8155, 1.7404, 1.7910, 1.8300],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87516176]\n",
      "[1.83315813]\n",
      "[1.74898791]\n",
      "[1.84725605]\n",
      "[1.81467247]\n",
      "[1.87915764]\n",
      "[1.83757354]\n",
      "tensor([1.8752, 1.8332, 1.7490, 1.8473, 1.8147, 1.8792, 1.8376],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96712321]\n",
      "[1.83846617]\n",
      "[1.7963894]\n",
      "[1.81729516]\n",
      "[1.86955119]\n",
      "[1.8856783]\n",
      "[1.79689514]\n",
      "tensor([1.9671, 1.8385, 1.7964, 1.8173, 1.8696, 1.8857, 1.7969],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75154257]\n",
      "[1.79390098]\n",
      "[1.77331534]\n",
      "[1.7189898]\n",
      "[1.88323618]\n",
      "[1.81914708]\n",
      "[1.81755779]\n",
      "tensor([1.7515, 1.7939, 1.7733, 1.7190, 1.8832, 1.8191, 1.8176],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80599564]\n",
      "[2.06085445]\n",
      "[1.88978789]\n",
      "[1.85356376]\n",
      "[1.79710591]\n",
      "[1.88199714]\n",
      "[1.75484586]\n",
      "tensor([1.8060, 2.0609, 1.8898, 1.8536, 1.7971, 1.8820, 1.7548],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84460179]\n",
      "[1.87367388]\n",
      "[1.83743172]\n",
      "[1.77417762]\n",
      "[1.78910476]\n",
      "[1.83365851]\n",
      "[1.87554676]\n",
      "tensor([1.8446, 1.8737, 1.8374, 1.7742, 1.7891, 1.8337, 1.8755],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82689247]\n",
      "[1.86725441]\n",
      "[1.80134134]\n",
      "[1.81588208]\n",
      "[1.75434057]\n",
      "[1.8371212]\n",
      "[1.85230579]\n",
      "tensor([1.8269, 1.8673, 1.8013, 1.8159, 1.7543, 1.8371, 1.8523],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8761124]\n",
      "[1.91617037]\n",
      "[1.83076024]\n",
      "[1.81590919]\n",
      "[1.82123601]\n",
      "[1.88360187]\n",
      "[1.85264455]\n",
      "tensor([1.8761, 1.9162, 1.8308, 1.8159, 1.8212, 1.8836, 1.8526],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78579944]\n",
      "[1.84338948]\n",
      "[1.80942983]\n",
      "[1.81579137]\n",
      "[1.92087768]\n",
      "[1.85072976]\n",
      "[1.8672094]\n",
      "tensor([1.7858, 1.8434, 1.8094, 1.8158, 1.9209, 1.8507, 1.8672],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84769609]\n",
      "[1.76866413]\n",
      "[1.87813213]\n",
      "[1.75894091]\n",
      "[1.74417967]\n",
      "[1.79221053]\n",
      "[1.75801327]\n",
      "tensor([1.8477, 1.7687, 1.8781, 1.7589, 1.7442, 1.7922, 1.7580],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87754064]\n",
      "[1.82294539]\n",
      "[1.93913379]\n",
      "[1.81494758]\n",
      "[1.9077118]\n",
      "[1.80424585]\n",
      "[1.76548355]\n",
      "tensor([1.8775, 1.8229, 1.9391, 1.8149, 1.9077, 1.8042, 1.7655],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88700573]\n",
      "[1.7805783]\n",
      "[1.73201335]\n",
      "[1.84910108]\n",
      "[1.91363075]\n",
      "[1.86899152]\n",
      "[1.98594717]\n",
      "tensor([1.8870, 1.7806, 1.7320, 1.8491, 1.9136, 1.8690, 1.9859],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82014275]\n",
      "[1.76844507]\n",
      "[1.75280882]\n",
      "[1.82721758]\n",
      "[1.81245149]\n",
      "[1.78619105]\n",
      "[1.82067909]\n",
      "tensor([1.8201, 1.7684, 1.7528, 1.8272, 1.8125, 1.7862, 1.8207],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84791285]\n",
      "[1.78106191]\n",
      "[1.90614281]\n",
      "[1.82673262]\n",
      "[1.85661802]\n",
      "[1.92231261]\n",
      "[1.8492669]\n",
      "tensor([1.8479, 1.7811, 1.9061, 1.8267, 1.8566, 1.9223, 1.8493],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81940927]\n",
      "[1.82670913]\n",
      "[1.81958514]\n",
      "[1.86108804]\n",
      "[1.73091703]\n",
      "[1.87794111]\n",
      "[1.84859568]\n",
      "tensor([1.8194, 1.8267, 1.8196, 1.8611, 1.7309, 1.8779, 1.8486],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78599501]\n",
      "[1.82733802]\n",
      "[1.77832119]\n",
      "[1.77246141]\n",
      "[1.79638476]\n",
      "[1.7908505]\n",
      "[1.89767691]\n",
      "tensor([1.7860, 1.8273, 1.7783, 1.7725, 1.7964, 1.7909, 1.8977],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84391537]\n",
      "[1.83924517]\n",
      "[1.95788163]\n",
      "[1.81262568]\n",
      "[1.92524095]\n",
      "[1.74170703]\n",
      "[1.8181187]\n",
      "tensor([1.8439, 1.8392, 1.9579, 1.8126, 1.9252, 1.7417, 1.8181],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85589226]\n",
      "[1.80397608]\n",
      "[1.82616587]\n",
      "[1.8255477]\n",
      "[1.90445507]\n",
      "[1.84060886]\n",
      "[1.9214117]\n",
      "tensor([1.8559, 1.8040, 1.8262, 1.8255, 1.9045, 1.8406, 1.9214],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88561064]\n",
      "[1.81866252]\n",
      "[1.82651456]\n",
      "[1.81200294]\n",
      "[1.88419912]\n",
      "[1.81123137]\n",
      "[1.74424074]\n",
      "tensor([1.8856, 1.8187, 1.8265, 1.8120, 1.8842, 1.8112, 1.7442],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92337097]\n",
      "[1.8497066]\n",
      "[1.81725054]\n",
      "[1.87141098]\n",
      "[1.82811497]\n",
      "[1.87898198]\n",
      "[1.73873087]\n",
      "tensor([1.9234, 1.8497, 1.8173, 1.8714, 1.8281, 1.8790, 1.7387],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85558608]\n",
      "[1.84730207]\n",
      "[1.83940772]\n",
      "[1.94062632]\n",
      "[1.82969749]\n",
      "[1.80279291]\n",
      "[1.82308839]\n",
      "tensor([1.8556, 1.8473, 1.8394, 1.9406, 1.8297, 1.8028, 1.8231],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75472693]\n",
      "[1.69423276]\n",
      "[1.78163906]\n",
      "[1.88540905]\n",
      "[1.82703543]\n",
      "[1.89674649]\n",
      "[1.89674683]\n",
      "tensor([1.7547, 1.6942, 1.7816, 1.8854, 1.8270, 1.8967, 1.8967],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83414506]\n",
      "[1.78635787]\n",
      "[1.85609451]\n",
      "[1.86589246]\n",
      "[1.776176]\n",
      "[1.74815452]\n",
      "[1.83797292]\n",
      "tensor([1.8341, 1.7864, 1.8561, 1.8659, 1.7762, 1.7482, 1.8380],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82286611]\n",
      "[1.82045062]\n",
      "[1.83033432]\n",
      "[1.84724388]\n",
      "[1.78404141]\n",
      "[1.8692126]\n",
      "[1.75567479]\n",
      "tensor([1.8229, 1.8205, 1.8303, 1.8472, 1.7840, 1.8692, 1.7557],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82727407]\n",
      "[1.79871187]\n",
      "[1.91232226]\n",
      "[1.85532944]\n",
      "[1.82920178]\n",
      "[1.91482339]\n",
      "[1.85014405]\n",
      "tensor([1.8273, 1.7987, 1.9123, 1.8553, 1.8292, 1.9148, 1.8501],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.71524432]\n",
      "[1.82936288]\n",
      "[1.82173659]\n",
      "[1.88100486]\n",
      "[1.8763552]\n",
      "[1.75426615]\n",
      "[1.94504812]\n",
      "tensor([1.7152, 1.8294, 1.8217, 1.8810, 1.8764, 1.7543, 1.9450],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81301392]\n",
      "[1.85319561]\n",
      "[1.88640614]\n",
      "[1.85327168]\n",
      "[1.8704302]\n",
      "[1.8490839]\n",
      "[1.84475856]\n",
      "tensor([1.8130, 1.8532, 1.8864, 1.8533, 1.8704, 1.8491, 1.8448],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73576643]\n",
      "[1.94920501]\n",
      "[1.8513735]\n",
      "[1.80655696]\n",
      "[1.84236422]\n",
      "[1.83282245]\n",
      "[1.79089994]\n",
      "tensor([1.7358, 1.9492, 1.8514, 1.8066, 1.8424, 1.8328, 1.7909],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.94766138]\n",
      "[1.88370364]\n",
      "[1.89610969]\n",
      "[1.84945319]\n",
      "[1.87686182]\n",
      "[1.80339194]\n",
      "[1.81273903]\n",
      "tensor([1.9477, 1.8837, 1.8961, 1.8495, 1.8769, 1.8034, 1.8127],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80710742]\n",
      "[1.9196882]\n",
      "[1.85956222]\n",
      "[1.85432854]\n",
      "[1.80072671]\n",
      "[1.84661525]\n",
      "[1.93891633]\n",
      "tensor([1.8071, 1.9197, 1.8596, 1.8543, 1.8007, 1.8466, 1.9389],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83908089]\n",
      "[1.85936701]\n",
      "[1.91885998]\n",
      "[1.86596001]\n",
      "[1.73250693]\n",
      "[1.91907946]\n",
      "[1.88622538]\n",
      "tensor([1.8391, 1.8594, 1.9189, 1.8660, 1.7325, 1.9191, 1.8862],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.74001497]\n",
      "[1.79008961]\n",
      "[1.80119988]\n",
      "[1.83804722]\n",
      "[1.87084106]\n",
      "[1.78929394]\n",
      "[1.81984012]\n",
      "tensor([1.7400, 1.7901, 1.8012, 1.8380, 1.8708, 1.7893, 1.8198],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05797223]\n",
      "[1.727416]\n",
      "[1.79774736]\n",
      "[1.86816023]\n",
      "[1.88571582]\n",
      "[1.80066989]\n",
      "[1.81938711]\n",
      "tensor([2.0580, 1.7274, 1.7977, 1.8682, 1.8857, 1.8007, 1.8194],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77019858]\n",
      "[1.78923669]\n",
      "[1.80914266]\n",
      "[1.84541417]\n",
      "[1.80878345]\n",
      "[1.93525923]\n",
      "[1.88868158]\n",
      "tensor([1.7702, 1.7892, 1.8091, 1.8454, 1.8088, 1.9353, 1.8887],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83811896]\n",
      "[1.8264874]\n",
      "[1.8756033]\n",
      "[1.90549967]\n",
      "[1.81159356]\n",
      "[1.8480636]\n",
      "[1.80542395]\n",
      "tensor([1.8381, 1.8265, 1.8756, 1.9055, 1.8116, 1.8481, 1.8054],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95515003]\n",
      "[1.69861248]\n",
      "[1.75189533]\n",
      "[1.83129163]\n",
      "[1.82492353]\n",
      "[1.90452037]\n",
      "[1.84331753]\n",
      "tensor([1.9552, 1.6986, 1.7519, 1.8313, 1.8249, 1.9045, 1.8433],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92898586]\n",
      "[1.8277263]\n",
      "[1.88764241]\n",
      "[1.78589026]\n",
      "[1.79908671]\n",
      "[1.84789572]\n",
      "[1.88151194]\n",
      "tensor([1.9290, 1.8277, 1.8876, 1.7859, 1.7991, 1.8479, 1.8815],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85863937]\n",
      "[1.76015676]\n",
      "[1.81932111]\n",
      "[1.9114964]\n",
      "[1.86827682]\n",
      "[1.82911811]\n",
      "[1.88795016]\n",
      "tensor([1.8586, 1.7602, 1.8193, 1.9115, 1.8683, 1.8291, 1.8880],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79665859]\n",
      "[1.82813272]\n",
      "[1.80196072]\n",
      "[1.8342386]\n",
      "[1.88597127]\n",
      "[1.72163032]\n",
      "[1.86616312]\n",
      "tensor([1.7967, 1.8281, 1.8020, 1.8342, 1.8860, 1.7216, 1.8662],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92563998]\n",
      "[1.79879169]\n",
      "[1.81530119]\n",
      "[1.83342664]\n",
      "[1.80670863]\n",
      "[1.78390438]\n",
      "[1.76321227]\n",
      "tensor([1.9256, 1.7988, 1.8153, 1.8334, 1.8067, 1.7839, 1.7632],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85795821]\n",
      "[1.73944751]\n",
      "[1.95072941]\n",
      "[1.92342253]\n",
      "[1.79963038]\n",
      "[1.8390927]\n",
      "[1.75839671]\n",
      "tensor([1.8580, 1.7394, 1.9507, 1.9234, 1.7996, 1.8391, 1.7584],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91589612]\n",
      "[1.73952473]\n",
      "[1.85190281]\n",
      "[1.8919339]\n",
      "[1.87515067]\n",
      "[1.88520797]\n",
      "[1.81708062]\n",
      "tensor([1.9159, 1.7395, 1.8519, 1.8919, 1.8752, 1.8852, 1.8171],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76064312]\n",
      "[1.75199146]\n",
      "[1.81853305]\n",
      "[1.84198689]\n",
      "[1.88550432]\n",
      "[1.89361141]\n",
      "[1.78949106]\n",
      "tensor([1.7606, 1.7520, 1.8185, 1.8420, 1.8855, 1.8936, 1.7895],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77431721]\n",
      "[1.85908895]\n",
      "[1.81448991]\n",
      "[1.82700002]\n",
      "[1.78227177]\n",
      "[1.89579456]\n",
      "[1.85319191]\n",
      "tensor([1.7743, 1.8591, 1.8145, 1.8270, 1.7823, 1.8958, 1.8532],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84159115]\n",
      "[1.74078196]\n",
      "[1.7645166]\n",
      "[1.8076002]\n",
      "[1.86788445]\n",
      "[1.83099839]\n",
      "[1.81671326]\n",
      "tensor([1.8416, 1.7408, 1.7645, 1.8076, 1.8679, 1.8310, 1.8167],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83966926]\n",
      "[1.80664446]\n",
      "[1.79504119]\n",
      "[1.98508307]\n",
      "[1.76930621]\n",
      "[1.85311327]\n",
      "[1.85819669]\n",
      "tensor([1.8397, 1.8066, 1.7950, 1.9851, 1.7693, 1.8531, 1.8582],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8891906]\n",
      "[1.79664026]\n",
      "[1.81135635]\n",
      "[1.90358009]\n",
      "[1.80152245]\n",
      "[1.90676622]\n",
      "[1.79995096]\n",
      "tensor([1.8892, 1.7966, 1.8114, 1.9036, 1.8015, 1.9068, 1.8000],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82914376]\n",
      "[1.8405617]\n",
      "[1.80456697]\n",
      "[1.80047676]\n",
      "[1.84094616]\n",
      "[1.95161469]\n",
      "[1.74385027]\n",
      "tensor([1.8291, 1.8406, 1.8046, 1.8005, 1.8409, 1.9516, 1.7439],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87553014]\n",
      "[1.79598539]\n",
      "[1.77512868]\n",
      "[1.79625602]\n",
      "[1.92322624]\n",
      "[1.92198977]\n",
      "[1.92817115]\n",
      "tensor([1.8755, 1.7960, 1.7751, 1.7963, 1.9232, 1.9220, 1.9282],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81955851]\n",
      "[1.86518881]\n",
      "[1.8987401]\n",
      "[1.83137079]\n",
      "[1.91519806]\n",
      "[1.83782274]\n",
      "[1.80712786]\n",
      "tensor([1.8196, 1.8652, 1.8987, 1.8314, 1.9152, 1.8378, 1.8071],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85081194]\n",
      "[1.80086929]\n",
      "[1.81635578]\n",
      "[1.8224592]\n",
      "[1.8160633]\n",
      "[1.79693392]\n",
      "[1.89517813]\n",
      "tensor([1.8508, 1.8009, 1.8164, 1.8225, 1.8161, 1.7969, 1.8952],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77284618]\n",
      "[1.79244844]\n",
      "[1.80772275]\n",
      "[1.86595408]\n",
      "[1.74348975]\n",
      "[1.88943564]\n",
      "[1.95834039]\n",
      "tensor([1.7728, 1.7924, 1.8077, 1.8660, 1.7435, 1.8894, 1.9583],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7328329]\n",
      "[1.84975775]\n",
      "[1.74052319]\n",
      "[1.84397305]\n",
      "[1.84358639]\n",
      "[1.79799199]\n",
      "[1.74368815]\n",
      "tensor([1.7328, 1.8498, 1.7405, 1.8440, 1.8436, 1.7980, 1.7437],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85972419]\n",
      "[1.85223324]\n",
      "[1.81219793]\n",
      "[1.70411663]\n",
      "[1.91308574]\n",
      "[1.9500409]\n",
      "[1.80196021]\n",
      "tensor([1.8597, 1.8522, 1.8122, 1.7041, 1.9131, 1.9500, 1.8020],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85515702]\n",
      "[1.80689912]\n",
      "[1.91313361]\n",
      "[1.85929185]\n",
      "[1.90643243]\n",
      "[1.82693805]\n",
      "[1.78796964]\n",
      "tensor([1.8552, 1.8069, 1.9131, 1.8593, 1.9064, 1.8269, 1.7880],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81267474]\n",
      "[1.80395917]\n",
      "[1.87754762]\n",
      "[1.88829551]\n",
      "[1.828008]\n",
      "[1.80846031]\n",
      "[1.87353262]\n",
      "tensor([1.8127, 1.8040, 1.8775, 1.8883, 1.8280, 1.8085, 1.8735],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79457855]\n",
      "[1.82695115]\n",
      "[1.81994011]\n",
      "[1.87788806]\n",
      "[1.80374219]\n",
      "[1.82570442]\n",
      "[1.84990613]\n",
      "tensor([1.7946, 1.8270, 1.8199, 1.8779, 1.8037, 1.8257, 1.8499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86532363]\n",
      "[1.8257614]\n",
      "[1.81879519]\n",
      "[1.8613039]\n",
      "[1.84180253]\n",
      "[1.79823716]\n",
      "[1.85149938]\n",
      "tensor([1.8653, 1.8258, 1.8188, 1.8613, 1.8418, 1.7982, 1.8515],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8164255]\n",
      "[1.82954731]\n",
      "[1.93714971]\n",
      "[1.82029207]\n",
      "[1.79242809]\n",
      "[1.77493849]\n",
      "[1.853713]\n",
      "tensor([1.8164, 1.8295, 1.9371, 1.8203, 1.7924, 1.7749, 1.8537],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8307957]\n",
      "[1.84130208]\n",
      "[1.81698785]\n",
      "[1.84966097]\n",
      "[1.84373391]\n",
      "[1.81942593]\n",
      "[1.81780521]\n",
      "tensor([1.8308, 1.8413, 1.8170, 1.8497, 1.8437, 1.8194, 1.8178],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77642136]\n",
      "[1.86648418]\n",
      "[1.91525882]\n",
      "[1.80563642]\n",
      "[1.75725551]\n",
      "[1.82652578]\n",
      "[1.81308727]\n",
      "tensor([1.7764, 1.8665, 1.9153, 1.8056, 1.7573, 1.8265, 1.8131],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80508232]\n",
      "[1.92172783]\n",
      "[1.81506672]\n",
      "[1.86504731]\n",
      "[1.85291966]\n",
      "[1.83038285]\n",
      "[1.82027323]\n",
      "tensor([1.8051, 1.9217, 1.8151, 1.8650, 1.8529, 1.8304, 1.8203],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.95063065]\n",
      "[1.87975038]\n",
      "[1.92208734]\n",
      "[1.92880838]\n",
      "[1.840238]\n",
      "[1.80365238]\n",
      "[1.84103544]\n",
      "tensor([1.9506, 1.8798, 1.9221, 1.9288, 1.8402, 1.8037, 1.8410],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90049927]\n",
      "[1.84282412]\n",
      "[1.88765938]\n",
      "[1.81717147]\n",
      "[1.77511896]\n",
      "[1.82671726]\n",
      "[1.88066972]\n",
      "tensor([1.9005, 1.8428, 1.8877, 1.8172, 1.7751, 1.8267, 1.8807],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81896147]\n",
      "[1.75424243]\n",
      "[1.74354249]\n",
      "[1.95086309]\n",
      "[1.79883336]\n",
      "[1.92283877]\n",
      "[1.86140831]\n",
      "tensor([1.8190, 1.7542, 1.7435, 1.9509, 1.7988, 1.9228, 1.8614],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79765058]\n",
      "[1.87119138]\n",
      "[1.98638886]\n",
      "[1.91841345]\n",
      "[1.82653223]\n",
      "[1.85054308]\n",
      "[1.84292814]\n",
      "tensor([1.7977, 1.8712, 1.9864, 1.9184, 1.8265, 1.8505, 1.8429],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89477389]\n",
      "[1.79977556]\n",
      "[1.72095082]\n",
      "[1.92888412]\n",
      "[1.91044189]\n",
      "[1.81868925]\n",
      "[1.9064818]\n",
      "tensor([1.8948, 1.7998, 1.7210, 1.9289, 1.9104, 1.8187, 1.9065],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85425507]\n",
      "[1.9849482]\n",
      "[1.95063107]\n",
      "[1.86794807]\n",
      "[1.73661388]\n",
      "[1.79327109]\n",
      "[1.84174555]\n",
      "tensor([1.8543, 1.9849, 1.9506, 1.8679, 1.7366, 1.7933, 1.8417],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82079508]\n",
      "[1.82635844]\n",
      "[1.76880998]\n",
      "[1.80599086]\n",
      "[1.82686139]\n",
      "[1.78749095]\n",
      "[1.97703653]\n",
      "tensor([1.8208, 1.8264, 1.7688, 1.8060, 1.8269, 1.7875, 1.9770],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8057671]\n",
      "[1.78681167]\n",
      "[1.8751519]\n",
      "[1.7518429]\n",
      "[1.87781925]\n",
      "[1.90643123]\n",
      "[1.84692916]\n",
      "tensor([1.8058, 1.7868, 1.8752, 1.7518, 1.8778, 1.9064, 1.8469],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76694156]\n",
      "[1.82830256]\n",
      "[1.81011497]\n",
      "[1.88731588]\n",
      "[1.88622828]\n",
      "[1.81737676]\n",
      "[1.81875543]\n",
      "tensor([1.7669, 1.8283, 1.8101, 1.8873, 1.8862, 1.8174, 1.8188],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.808652]\n",
      "[1.79595946]\n",
      "[1.76103671]\n",
      "[1.80570986]\n",
      "[1.82636543]\n",
      "[1.81916863]\n",
      "[1.92633795]\n",
      "tensor([1.8087, 1.7960, 1.7610, 1.8057, 1.8264, 1.8192, 1.9263],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.73700955]\n",
      "[1.87062034]\n",
      "[1.86636454]\n",
      "[1.88403087]\n",
      "[1.92790205]\n",
      "[1.74346607]\n",
      "[1.82840025]\n",
      "tensor([1.7370, 1.8706, 1.8664, 1.8840, 1.9279, 1.7435, 1.8284],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83043729]\n",
      "[1.87908912]\n",
      "[1.78367587]\n",
      "[1.8465597]\n",
      "[1.84082687]\n",
      "[1.84530845]\n",
      "[1.79240839]\n",
      "tensor([1.8304, 1.8791, 1.7837, 1.8466, 1.8408, 1.8453, 1.7924],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86589028]\n",
      "[1.81348011]\n",
      "[1.82958231]\n",
      "[1.84495869]\n",
      "[1.81641036]\n",
      "[1.75635988]\n",
      "[1.7647671]\n",
      "tensor([1.8659, 1.8135, 1.8296, 1.8450, 1.8164, 1.7564, 1.7648],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79735716]\n",
      "[1.84464447]\n",
      "[1.81721138]\n",
      "[1.89535052]\n",
      "[1.80789343]\n",
      "[1.79519433]\n",
      "[1.77256981]\n",
      "tensor([1.7974, 1.8446, 1.8172, 1.8954, 1.8079, 1.7952, 1.7726],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7760648]\n",
      "[1.93756666]\n",
      "[1.75309927]\n",
      "[1.80825205]\n",
      "[1.90681049]\n",
      "[1.85254958]\n",
      "[1.87628939]\n",
      "tensor([1.7761, 1.9376, 1.7531, 1.8083, 1.9068, 1.8525, 1.8763],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80693517]\n",
      "[1.77439325]\n",
      "[1.82936721]\n",
      "[1.75374182]\n",
      "[1.84124098]\n",
      "[1.89833354]\n",
      "[1.7757556]\n",
      "tensor([1.8069, 1.7744, 1.8294, 1.7537, 1.8412, 1.8983, 1.7758],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.89661853]\n",
      "[1.81776033]\n",
      "[1.80283942]\n",
      "[1.83656568]\n",
      "[1.87098131]\n",
      "[1.88767317]\n",
      "[1.72074663]\n",
      "tensor([1.8966, 1.8178, 1.8028, 1.8366, 1.8710, 1.8877, 1.7207],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90028803]\n",
      "[1.89568486]\n",
      "[1.85813204]\n",
      "[1.84132267]\n",
      "[1.77468392]\n",
      "[1.92442681]\n",
      "[1.84924932]\n",
      "tensor([1.9003, 1.8957, 1.8581, 1.8413, 1.7747, 1.9244, 1.8492],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83052146]\n",
      "[1.82830157]\n",
      "[1.8095683]\n",
      "[1.92847296]\n",
      "[1.87818038]\n",
      "[1.80066466]\n",
      "[1.88199465]\n",
      "tensor([1.8305, 1.8283, 1.8096, 1.9285, 1.8782, 1.8007, 1.8820],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88488275]\n",
      "[1.73631281]\n",
      "[1.81605577]\n",
      "[1.83172353]\n",
      "[1.9654812]\n",
      "[1.92835794]\n",
      "[1.8070056]\n",
      "tensor([1.8849, 1.7363, 1.8161, 1.8317, 1.9655, 1.9284, 1.8070],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8449484]\n",
      "[1.82609729]\n",
      "[1.87260541]\n",
      "[1.92575704]\n",
      "[1.79974717]\n",
      "[1.74036015]\n",
      "[1.90505853]\n",
      "tensor([1.8449, 1.8261, 1.8726, 1.9258, 1.7997, 1.7404, 1.9051],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81900584]\n",
      "[1.871064]\n",
      "[1.75138929]\n",
      "[1.830656]\n",
      "[1.7696254]\n",
      "[1.86769893]\n",
      "[1.93721218]\n",
      "tensor([1.8190, 1.8711, 1.7514, 1.8307, 1.7696, 1.8677, 1.9372],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79799805]\n",
      "[1.79739745]\n",
      "[1.89557354]\n",
      "[1.83823174]\n",
      "[1.85349429]\n",
      "[1.92833317]\n",
      "[1.90642884]\n",
      "tensor([1.7980, 1.7974, 1.8956, 1.8382, 1.8535, 1.9283, 1.9064],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.77283581]\n",
      "[1.84640777]\n",
      "[1.85191941]\n",
      "[1.8083095]\n",
      "[1.96658983]\n",
      "[1.79898313]\n",
      "[1.90009761]\n",
      "tensor([1.7728, 1.8464, 1.8519, 1.8083, 1.9666, 1.7990, 1.9001],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82695659]\n",
      "[1.78659852]\n",
      "[1.88191044]\n",
      "[1.87950968]\n",
      "[1.83495067]\n",
      "[1.85342054]\n",
      "[1.87559194]\n",
      "tensor([1.8270, 1.7866, 1.8819, 1.8795, 1.8350, 1.8534, 1.8756],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.91849083]\n",
      "[1.8754725]\n",
      "[1.83792984]\n",
      "[1.95737399]\n",
      "[1.81912463]\n",
      "[1.85258709]\n",
      "[1.82656766]\n",
      "tensor([1.9185, 1.8755, 1.8379, 1.9574, 1.8191, 1.8526, 1.8266],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90466685]\n",
      "[1.9286436]\n",
      "[1.82123225]\n",
      "[1.82862471]\n",
      "[1.75109408]\n",
      "[1.88640259]\n",
      "[1.80805128]\n",
      "tensor([1.9047, 1.9286, 1.8212, 1.8286, 1.7511, 1.8864, 1.8081],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81723959]\n",
      "[1.78340037]\n",
      "[1.91023321]\n",
      "[1.80782481]\n",
      "[1.92458267]\n",
      "[1.92866362]\n",
      "[1.82004723]\n",
      "tensor([1.8172, 1.7834, 1.9102, 1.8078, 1.9246, 1.9287, 1.8200],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7039449]\n",
      "[1.88715256]\n",
      "[1.79800431]\n",
      "[1.71769898]\n",
      "[1.95129498]\n",
      "[1.92549621]\n",
      "[1.92873296]\n",
      "tensor([1.7039, 1.8872, 1.7980, 1.7177, 1.9513, 1.9255, 1.9287],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86263873]\n",
      "[1.88810328]\n",
      "[1.80310789]\n",
      "[1.78729855]\n",
      "[1.83386378]\n",
      "[1.82709596]\n",
      "[1.9187837]\n",
      "tensor([1.8626, 1.8881, 1.8031, 1.7873, 1.8339, 1.8271, 1.9188],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80868317]\n",
      "[1.83057745]\n",
      "[1.81379179]\n",
      "[1.9583663]\n",
      "[1.91028011]\n",
      "[1.90056775]\n",
      "[1.8751708]\n",
      "tensor([1.8087, 1.8306, 1.8138, 1.9584, 1.9103, 1.9006, 1.8752],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80337297]\n",
      "[1.84918549]\n",
      "[1.83069583]\n",
      "[1.77507047]\n",
      "[1.75518938]\n",
      "[1.80938107]\n",
      "[1.88502688]\n",
      "tensor([1.8034, 1.8492, 1.8307, 1.7751, 1.7552, 1.8094, 1.8850],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83148425]\n",
      "[1.8034426]\n",
      "[1.87012289]\n",
      "[1.82035087]\n",
      "[1.75636052]\n",
      "[1.7761683]\n",
      "[1.69496042]\n",
      "tensor([1.8315, 1.8034, 1.8701, 1.8204, 1.7564, 1.7762, 1.6950],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.76853214]\n",
      "[1.86650702]\n",
      "[1.90006853]\n",
      "[1.81618971]\n",
      "[1.88793905]\n",
      "[1.84352744]\n",
      "[1.82706252]\n",
      "tensor([1.7685, 1.8665, 1.9001, 1.8162, 1.8879, 1.8435, 1.8271],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81854106]\n",
      "[1.84692584]\n",
      "[1.90628805]\n",
      "[1.73275019]\n",
      "[1.84658951]\n",
      "[1.81148509]\n",
      "[1.84286957]\n",
      "tensor([1.8185, 1.8469, 1.9063, 1.7328, 1.8466, 1.8115, 1.8429],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90673561]\n",
      "[1.90538557]\n",
      "[1.80122183]\n",
      "[1.73946672]\n",
      "[1.79193448]\n",
      "[1.80000352]\n",
      "[1.80606204]\n",
      "tensor([1.9067, 1.9054, 1.8012, 1.7395, 1.7919, 1.8000, 1.8061],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92545859]\n",
      "[1.86437217]\n",
      "[1.92176118]\n",
      "[1.90002319]\n",
      "[1.83149631]\n",
      "[1.69438031]\n",
      "[1.86094426]\n",
      "tensor([1.9255, 1.8644, 1.9218, 1.9000, 1.8315, 1.6944, 1.8609],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86551259]\n",
      "[1.8287784]\n",
      "[1.81794234]\n",
      "[1.73999202]\n",
      "[1.84895526]\n",
      "[1.88880184]\n",
      "[1.81505976]\n",
      "tensor([1.8655, 1.8288, 1.8179, 1.7400, 1.8490, 1.8888, 1.8151],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79466435]\n",
      "[1.88636745]\n",
      "[1.86737266]\n",
      "[1.80415633]\n",
      "[1.9206358]\n",
      "[1.93917078]\n",
      "[1.79683881]\n",
      "tensor([1.7947, 1.8864, 1.8674, 1.8042, 1.9206, 1.9392, 1.7968],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8128292]\n",
      "[1.8195102]\n",
      "[1.7613308]\n",
      "[1.84353266]\n",
      "[1.83111372]\n",
      "[1.83031988]\n",
      "[1.75466884]\n",
      "tensor([1.8128, 1.8195, 1.7613, 1.8435, 1.8311, 1.8303, 1.7547],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83144377]\n",
      "[1.82785368]\n",
      "[1.76918554]\n",
      "[1.82618275]\n",
      "[1.88557086]\n",
      "[1.80095624]\n",
      "[1.88906777]\n",
      "tensor([1.8314, 1.8279, 1.7692, 1.8262, 1.8856, 1.8010, 1.8891],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.85804586]\n",
      "[1.84871926]\n",
      "[1.82623363]\n",
      "[1.82701728]\n",
      "[1.84204342]\n",
      "[1.80842729]\n",
      "[1.70409064]\n",
      "tensor([1.8580, 1.8487, 1.8262, 1.8270, 1.8420, 1.8084, 1.7041],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83060716]\n",
      "[1.7609702]\n",
      "[1.88333853]\n",
      "[1.84364904]\n",
      "[1.84136353]\n",
      "[1.81994213]\n",
      "[1.8051558]\n",
      "tensor([1.8306, 1.7610, 1.8833, 1.8436, 1.8414, 1.8199, 1.8052],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84943905]\n",
      "[1.79229353]\n",
      "[1.8535185]\n",
      "[1.76685019]\n",
      "[1.93734079]\n",
      "[1.74476184]\n",
      "[1.79297765]\n",
      "tensor([1.8494, 1.7923, 1.8535, 1.7669, 1.9373, 1.7448, 1.7930],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[2.05947852]\n",
      "[1.88739033]\n",
      "[1.79987389]\n",
      "[1.82873638]\n",
      "[1.84725759]\n",
      "[1.81965056]\n",
      "[1.80774013]\n",
      "tensor([2.0595, 1.8874, 1.7999, 1.8287, 1.8473, 1.8197, 1.8077],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.88919372]\n",
      "[1.84757308]\n",
      "[1.8410046]\n",
      "[1.78979328]\n",
      "[1.93674083]\n",
      "[1.7043491]\n",
      "[1.7846691]\n",
      "tensor([1.8892, 1.8476, 1.8410, 1.7898, 1.9367, 1.7043, 1.7847],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9045452]\n",
      "[1.76651359]\n",
      "[1.91534267]\n",
      "[1.93737239]\n",
      "[1.78421797]\n",
      "[1.80367115]\n",
      "[1.92438964]\n",
      "tensor([1.9045, 1.7665, 1.9153, 1.9374, 1.7842, 1.8037, 1.9244],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84679307]\n",
      "[1.81657182]\n",
      "[1.85113108]\n",
      "[1.85792401]\n",
      "[1.79995437]\n",
      "[1.82634571]\n",
      "[1.92240291]\n",
      "tensor([1.8468, 1.8166, 1.8511, 1.8579, 1.8000, 1.8263, 1.9224],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79253969]\n",
      "[1.70419131]\n",
      "[1.84065149]\n",
      "[1.87042969]\n",
      "[1.8466204]\n",
      "[1.79751145]\n",
      "[1.82849975]\n",
      "tensor([1.7925, 1.7042, 1.8407, 1.8704, 1.8466, 1.7975, 1.8285],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84121932]\n",
      "[1.84463289]\n",
      "[1.74497937]\n",
      "[1.78349677]\n",
      "[1.92416412]\n",
      "[1.91054452]\n",
      "[1.84989547]\n",
      "tensor([1.8412, 1.8446, 1.7450, 1.7835, 1.9242, 1.9105, 1.8499],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.9513482]\n",
      "[1.81777278]\n",
      "[1.91015378]\n",
      "[1.75760869]\n",
      "[1.79572294]\n",
      "[1.82847949]\n",
      "[1.79705014]\n",
      "tensor([1.9513, 1.8178, 1.9102, 1.7576, 1.7957, 1.8285, 1.7971],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79786072]\n",
      "[1.92779945]\n",
      "[1.81377399]\n",
      "[1.81918281]\n",
      "[1.83167716]\n",
      "[1.81956468]\n",
      "[1.76647021]\n",
      "tensor([1.7979, 1.9278, 1.8138, 1.8192, 1.8317, 1.8196, 1.7665],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.92824412]\n",
      "[1.83343117]\n",
      "[1.79248322]\n",
      "[1.79678985]\n",
      "[1.95132245]\n",
      "[1.80649293]\n",
      "[1.88777979]\n",
      "tensor([1.9282, 1.8334, 1.7925, 1.7968, 1.9513, 1.8065, 1.8878],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.86637061]\n",
      "[1.79902816]\n",
      "[1.95785293]\n",
      "[1.82027526]\n",
      "[1.8204436]\n",
      "[1.84946477]\n",
      "[1.79761966]\n",
      "tensor([1.8664, 1.7990, 1.9579, 1.8203, 1.8204, 1.8495, 1.7976],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84758469]\n",
      "[1.79284177]\n",
      "[1.93809357]\n",
      "[1.79674395]\n",
      "[1.95826381]\n",
      "[1.86049979]\n",
      "[1.81977475]\n",
      "tensor([1.8476, 1.7928, 1.9381, 1.7967, 1.9583, 1.8605, 1.8198],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8533197]\n",
      "[1.8277131]\n",
      "[1.98593926]\n",
      "[1.74467787]\n",
      "[1.84234126]\n",
      "[1.85999309]\n",
      "[1.82685127]\n",
      "tensor([1.8533, 1.8277, 1.9859, 1.7447, 1.8423, 1.8600, 1.8269],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80328599]\n",
      "[1.84772444]\n",
      "[1.81939437]\n",
      "[1.71660706]\n",
      "[1.76981337]\n",
      "[1.85861726]\n",
      "[1.93638201]\n",
      "tensor([1.8033, 1.8477, 1.8194, 1.7166, 1.7698, 1.8586, 1.9364],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82669712]\n",
      "[1.8647968]\n",
      "[1.82990556]\n",
      "[1.84229842]\n",
      "[1.83767096]\n",
      "[1.87165546]\n",
      "[1.84125418]\n",
      "tensor([1.8267, 1.8648, 1.8299, 1.8423, 1.8377, 1.8717, 1.8413],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.7963532]\n",
      "[1.92553731]\n",
      "[1.87024901]\n",
      "[1.83155175]\n",
      "[1.83686309]\n",
      "[1.90046499]\n",
      "[1.83797481]\n",
      "tensor([1.7964, 1.9255, 1.8702, 1.8316, 1.8369, 1.9005, 1.8380],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78689396]\n",
      "[1.77615381]\n",
      "[1.84159577]\n",
      "[1.74318426]\n",
      "[1.87132772]\n",
      "[1.83745027]\n",
      "[1.84769741]\n",
      "tensor([1.7869, 1.7762, 1.8416, 1.7432, 1.8713, 1.8375, 1.8477],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.82111729]\n",
      "[1.83133101]\n",
      "[1.87541766]\n",
      "[1.85002926]\n",
      "[1.79706827]\n",
      "[1.88936002]\n",
      "[1.87966923]\n",
      "tensor([1.8211, 1.8313, 1.8754, 1.8500, 1.7971, 1.8894, 1.8797],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.90478737]\n",
      "[1.80780895]\n",
      "[1.77446346]\n",
      "[1.92643625]\n",
      "[1.84545599]\n",
      "[1.84748912]\n",
      "[1.81242173]\n",
      "tensor([1.9048, 1.8078, 1.7745, 1.9264, 1.8455, 1.8475, 1.8124],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.8256905]\n",
      "[1.81734514]\n",
      "[1.78677605]\n",
      "[1.84289405]\n",
      "[1.94765743]\n",
      "[1.75338367]\n",
      "[1.9140476]\n",
      "tensor([1.8257, 1.8173, 1.7868, 1.8429, 1.9477, 1.7534, 1.9140],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.72273415]\n",
      "[1.76231825]\n",
      "[1.84919775]\n",
      "[1.82086673]\n",
      "[1.81537815]\n",
      "[1.86611704]\n",
      "[1.8729629]\n",
      "tensor([1.7227, 1.7623, 1.8492, 1.8209, 1.8154, 1.8661, 1.8730],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.80317448]\n",
      "[1.82662916]\n",
      "[1.74705772]\n",
      "[1.73552925]\n",
      "[1.79805624]\n",
      "[1.84306046]\n",
      "[1.7315855]\n",
      "tensor([1.8032, 1.8266, 1.7471, 1.7355, 1.7981, 1.8431, 1.7316],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.78414848]\n",
      "[1.87856122]\n",
      "[2.06000716]\n",
      "[1.78348957]\n",
      "[1.92473106]\n",
      "[1.70350612]\n",
      "[1.69461251]\n",
      "tensor([1.7841, 1.8786, 2.0600, 1.7835, 1.9247, 1.7035, 1.6946],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.79700316]\n",
      "[1.93733642]\n",
      "[1.78688707]\n",
      "[1.81912162]\n",
      "[1.81424699]\n",
      "[1.91830296]\n",
      "[1.88776753]\n",
      "tensor([1.7970, 1.9373, 1.7869, 1.8191, 1.8142, 1.9183, 1.8878],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83344857]\n",
      "[1.79197708]\n",
      "[1.84385666]\n",
      "[1.8026507]\n",
      "[1.82836581]\n",
      "[1.76170343]\n",
      "[1.84054461]\n",
      "tensor([1.8334, 1.7920, 1.8439, 1.8027, 1.8284, 1.7617, 1.8405],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.69509971]\n",
      "[1.78468379]\n",
      "[1.97588456]\n",
      "[1.82032914]\n",
      "[1.84729002]\n",
      "[1.78378865]\n",
      "[1.85900106]\n",
      "tensor([1.6951, 1.7847, 1.9759, 1.8203, 1.8473, 1.7838, 1.8590],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.83177584]\n",
      "[1.79742974]\n",
      "[1.9366787]\n",
      "[1.81804988]\n",
      "[1.84207838]\n",
      "[1.82865398]\n",
      "[1.88748176]\n",
      "tensor([1.8318, 1.7974, 1.9367, 1.8180, 1.8421, 1.8287, 1.8875],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81881625]\n",
      "[1.79886959]\n",
      "[1.76115584]\n",
      "[1.78400026]\n",
      "[1.79900512]\n",
      "[1.81832539]\n",
      "[1.82785321]\n",
      "tensor([1.8188, 1.7989, 1.7612, 1.7840, 1.7990, 1.8183, 1.8279],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.93710669]\n",
      "[1.76640059]\n",
      "[1.85180782]\n",
      "[1.78408878]\n",
      "[1.84978793]\n",
      "[1.90533601]\n",
      "[1.8578007]\n",
      "tensor([1.9371, 1.7664, 1.8518, 1.7841, 1.8498, 1.9053, 1.8578],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.96639656]\n",
      "[1.7931458]\n",
      "[1.80393135]\n",
      "[1.7992731]\n",
      "[1.73987033]\n",
      "[1.75141199]\n",
      "[1.88660921]\n",
      "tensor([1.9664, 1.7931, 1.8039, 1.7993, 1.7399, 1.7514, 1.8866],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.75245689]\n",
      "[1.85409372]\n",
      "[1.71649683]\n",
      "[1.83666345]\n",
      "[1.74129978]\n",
      "[1.83050561]\n",
      "[1.82595043]\n",
      "tensor([1.7525, 1.8541, 1.7165, 1.8367, 1.7413, 1.8305, 1.8260],\n",
      "       dtype=torch.float64)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87260314]\n",
      "[1.86568313]\n",
      "[1.88341358]\n",
      "[1.82608443]\n",
      "[1.88184561]\n",
      "[1.84153075]\n",
      "[1.9513634]\n",
      "tensor([1.8726, 1.8657, 1.8834, 1.8261, 1.8818, 1.8415, 1.9514],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.84151375]\n",
      "[1.8183181]\n",
      "[1.85377625]\n",
      "[1.85204374]\n",
      "[1.82672125]\n",
      "[1.79949582]\n",
      "[1.82061825]\n",
      "tensor([1.8415, 1.8183, 1.8538, 1.8520, 1.8267, 1.7995, 1.8206],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81078323]\n",
      "[1.84247225]\n",
      "[1.74653048]\n",
      "[1.75450096]\n",
      "[1.90006768]\n",
      "[1.74495618]\n",
      "[1.91475003]\n",
      "tensor([1.8108, 1.8425, 1.7465, 1.7545, 1.9001, 1.7450, 1.9148],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.81771178]\n",
      "[1.91046926]\n",
      "[1.9049282]\n",
      "[1.78670793]\n",
      "[1.81996499]\n",
      "[1.76097975]\n",
      "[1.85424455]\n",
      "tensor([1.8177, 1.9105, 1.9049, 1.7867, 1.8200, 1.7610, 1.8542],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "[1.87534021]\n",
      "[1.81440865]\n",
      "[1.85248275]\n",
      "[1.82065644]\n",
      "[1.81109836]\n",
      "[1.81543307]\n",
      "[1.80096928]\n",
      "tensor([1.8753, 1.8144, 1.8525, 1.8207, 1.8111, 1.8154, 1.8010],\n",
      "       dtype=torch.float64)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#b=np.random.choice(range(X_train.shape[0]),18,replace=False)\n",
    "p = int(X0.shape[0]*0.05)\n",
    "n = int(X0.shape[0]/p)\n",
    "m = 18\n",
    "MSE_a = np.zeros((n,m,7))\n",
    "R2_a = np.zeros((n,m,7))\n",
    "reps = 5\n",
    "for i in range(n):\n",
    "    for k in range(m):\n",
    "        for j in range(reps):\n",
    "            b=np.random.choice(range(X_train.shape[0]),(k+1)*p,replace=False)\n",
    "            a=np.random.choice(range(X0.shape[0]),(i+1)*p,replace=False)\n",
    "            \n",
    "            emulator_0 = GPE.ensemble(X0[a,:],Y0[a,:],mean_func=\"linear\",training_iter=500)\n",
    "            m0 = emulator_0.predict(X_train[b,:])\n",
    "            \n",
    "            a_d=np.zeros(y_train.shape[1])\n",
    "            for l in range(y_train.shape[1]):\n",
    "                result = scipy.optimize.minimize(proxy, 1, args=(y_train[b,:],m0,l), method='Nelder-Mead', tol=1e-8)\n",
    "                print(result.x)\n",
    "                a_d[l]=result.x\n",
    "\n",
    "            a_d=torch.tensor(a_d)\n",
    "            print(a_d)\n",
    "            \n",
    "            \n",
    "            y_adjust = torch.tensor(y_train[b] - a_d*m0)\n",
    "            delta_1 = GPE.ensemble(X_train[b,:],y_adjust,mean_func=\"linear\",training_iter=500)\n",
    "            MSE_a[i,k] += np.sqrt(((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0).detach().numpy())/reps\n",
    "            R2_a[i,k] += (1-((a_d*emulator_0.predict(X_test)+delta_1.predict(X_test)-torch.tensor(y_test))**2).mean(axis=0)/torch.tensor(y_test.var(axis=0))).detach().numpy()/reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef47af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8fe46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fde30803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2afa37c90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x\n",
    "\n",
    "y = np.linspace(9,180,20)\n",
    "\n",
    "y\n",
    "\n",
    "xx,yy=np.meshgrid(x,y)\n",
    "\n",
    "xx[1:,1:].shape\n",
    "\n",
    "level = 1\n",
    "\n",
    "plt.contourf(xx[level:,level:],yy[level:,level:],R2_a[level:,level:,0],origin='lower',levels=50)\n",
    "plt.ylabel('n')\n",
    "plt.xlabel('m')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1349dc8",
   "metadata": {},
   "source": [
    "# Emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df903aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a91180",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_all.values[0:200])\n",
    "x_train = torch.tensor(X_all.values[0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670120df",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator = GPE.ensemble(x_train,y_train,mean_func=\"linear\",training_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2561335",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea199b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nDim = X_all.shape[1]\n",
    "boundsMaxMin = []\n",
    "for i in range(nDim):\n",
    "    boundsMaxMin.append([np.min(X_all.iloc[:,i]),np.max(X_all.iloc[:,i])])\n",
    "    print(boundsMaxMin[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "centre = (np.array(boundsMaxMin)[:,1]+np.array(boundsMaxMin)[:,0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "ndim = nDim\n",
    "nwalkers = 18\n",
    "p0 = np.random.multivariate_normal(centre, 0.000000001*np.identity(ndim), size=(nwalkers))\n",
    "y_val = y_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ee18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundsMaxMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(boundsMaxMin)[:,0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9489ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    \n",
    "    #if (np.array(boundsMaxMin)[:,0]<theta).all() and (theta<np.array(boundsMaxMin)[:,1]).all():\n",
    "        \n",
    "    if (np.array(boundsMaxMin)[:,0]*0.5<theta).all() and (theta<np.array(boundsMaxMin)[:,1]*2).all():\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    \n",
    "    #if (np.array(boundsMaxMin)[:,0]<theta).all() and (theta<np.array(boundsMaxMin)[:,1]).all():\n",
    "        \n",
    "    if (np.array(boundsMaxMin)[:,0]<theta).all() and (theta<np.array(boundsMaxMin)[:,1]).all():\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7608e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(p0[0])[None]\n",
    "ll =np.sum(emulator.ensemble_log_likelihood_obs_error(x,y_val[None,:],torch.ones(9)*0.01).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903a146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(x,emulator,y_val):\n",
    "    x=torch.tensor(x)[None]\n",
    "    ll =np.sum((emulator.ensemble_log_likelihood_obs_error(x,y_val[None,:],[0.01,0.01,0.01,0.01,0.01,0.01,0.01,1e-6,0.01])).detach().numpy())\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e19210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_likelihood(p0[1],emulator,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(theta, emulator,y_val):\n",
    "    \n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    \n",
    "    return lp + log_likelihood(theta,emulator, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a07cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[emulator,y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8004877",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e70bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(p0[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed05061",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator.predict(torch.tensor(p0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550560d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(log_prob(p0[i],emulator,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd493fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(x,emulator,y_val):\n",
    "    x=torch.tensor(x)[None]\n",
    "    ll =np.sum((emulator.ensemble_log_likelihood_obs_error(x,y_val[None,:],[0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0001])).detach().numpy())\n",
    "    return -ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bds=np.array(boundsMaxMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scipy.optimize.minimize(neg_log_likelihood, p0[0], args=(emulator,y_val), method='Nelder-Mead', tol=1e-8,bounds=bds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04192b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9032198",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood(p0[1],emulator,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd50fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502a53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run_mcmc(p0, 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf097d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b2dee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=20000, thin=10, flat=True)\n",
    "print(flat_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b372a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, label_kwargs=dict(fontsize=18),color='orange',truths=result.x\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be679a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, label_kwargs=dict(fontsize=18),color='orange',truths=x_train[100]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbcab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41da0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = pd.DataFrame(flat_samples).sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b15ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp.to_csv(\"MCMC_samples_scenario_6_80_2timesUpper.dat\", sep = \" \",index=False,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c69e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1b334",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = torch.tensor(flat_samples.mean(axis=0).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator.predict(x_out[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a51672",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all=torch.tensor(X_all.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa41f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all=torch.tensor(y_all.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ba1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_all[45,:]\n",
    "x_test = x_all[45,:]\n",
    "\n",
    "y_train = y_all[~torch.all(y_all == y_test, dim=1)]\n",
    "x_train = x_all[~torch.all(x_all == x_test, dim=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulator = GPE.ensemble(x_train,y_train,mean_func=\"linear\",training_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b6e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[emulator,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3279d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(log_prob(p0[i],emulator,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cae58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.run_mcmc(p0, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6f7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6cb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_samples = sampler.get_chain(discard=8000, thin=1, flat=True)\n",
    "print(flat_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c6e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b7b23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, label_kwargs=dict(fontsize=18),color='orange',truths=y_test\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb55a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60accee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
